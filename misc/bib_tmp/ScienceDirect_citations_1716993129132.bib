@article{TING201364,
title = {Enhanced adhesion of epoxy-bonded steel surfaces using O2/Ar microwave plasma treatment},
journal = {International Journal of Adhesion and Adhesives},
volume = {40},
pages = {64-69},
year = {2013},
issn = {0143-7496},
doi = {https://doi.org/10.1016/j.ijadhadh.2012.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0143749612001212},
author = {Julie Anne S. Ting and Leo Mendel D. Rosario and Ma.Camille C. Lacdan and Henry V. Lee and Jeffrey C. {De Vero} and Henry J. Ramos and Roy B. Tumlos},
keywords = {Surface treatment by plasma, Metals, Epoxy, Contact angles, Adhesion},
abstract = {Steel surfaces have been modified using low pressure microwave plasma to enhance its adhesion with an epoxy adhesive. Optimization of the wettability of the surface was done using contact angle measurements for varying plasma parameters. Maximum wettability (19.9°) was obtained at 1000W microwave power with 20min of treatment time, −50V sample bias and 1.67% O2/Ar gas flow rate ratio. Enhanced wettability of the steel surface was attributed to increased surface roughness and oxide deposition. Using atomic force microscopy, surface roughness was observed to increase from 64.4nm for the untreated surface to 76.7nm for the O2/Ar plasma treated surface. Deposition of oxides on the steel surface was also confirmed by the energy dispersive x-ray spectroscopy. Moreover, the increase in the total surface energy to 53.2mN/m for the O2 plasma treated steel surface supported the enhancement of its wettability, and hence, the adhesion with epoxy. Based on tensile test results, the adhesion strength of epoxy-bonded O2/Ar plasma treated surfaces at optimum settings was increased to 3816.0N, which is significantly higher compared to 3038.3N for the epoxy-bonded untreated surfaces.}
}
@article{LIU201835,
title = {Relationship between street scale and subjective assessment of audio-visual environment comfort based on 3D virtual reality and dual-channel acoustic tests},
journal = {Building and Environment},
volume = {129},
pages = {35-45},
year = {2018},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2017.11.040},
url = {https://www.sciencedirect.com/science/article/pii/S036013231730553X},
author = {Fangfang Liu and Jian Kang},
keywords = {Visual comfort, Acoustic comfort, Audio-visual comfort, Street scale},
abstract = {We examine the influence of street scales (the street width, building height, and street-width-to-building-height ratio, referred to as ‘width-to-height ratio’ in the paper) on visual, acoustic, and audio-visual comfort evaluation (as evaluated by a set of participants) in urban areas. In addition, we examine the relationships between the sound level and the abovementioned subjective comfort evaluation except the visual one. After measuring the street scales and recording the street visual information with a 3D camcorder, the virtual 3D models of the streets were generated. Meanwhile, dual-channel acoustic signals of the streets were collected. Subsequently, subjective tests were carried out using a 3D virtual reality with corresponding sounds using 164 participants. The analysis shows that subjective attitudes are directly related to the street scales. In particular, there is a strong positive correlation between audio-visual comfort and the street width-to-height ratio. In contrast, the three indicators (visual, acoustic, and audio-visual comfort) are strongly negatively correlated to the height, and this type of negative correlation is also observed between subjective indicators (except the visual one) and the sound level. Overall, the respondents found the audio-visual level most comfortable when the street width-to-height ratio is greater than 1, street width is within 20 m, height of street buildings is less than 26 m, and the sound level is less than 58 dBA. It is expected that these findings can aid designers in predicting the ideal audio-visual environment quality for urban streets.}
}
@article{JYOTI2023105744,
title = {Transversely-isotropic brain in vivo MR elastography with anisotropic damping},
journal = {Journal of the Mechanical Behavior of Biomedical Materials},
volume = {141},
pages = {105744},
year = {2023},
issn = {1751-6161},
doi = {https://doi.org/10.1016/j.jmbbm.2023.105744},
url = {https://www.sciencedirect.com/science/article/pii/S1751616123000978},
author = {Dhrubo Jyoti and Matthew McGarry and Diego A. Caban-Rivera and Elijah {Van Houten} and Curtis L. Johnson and Keith Paulsen},
abstract = {Measuring tissue parameters from increasingly sophisticated mechanical property models may uncover new contrast mechanisms with clinical utility. Building on previous work on in vivo brain MR elastography (MRE) with a transversely-isotropic with isotropic damping (TI-ID) model, we explore a new transversely-isotropic with anisotropic damping (TI-AD) model that involves six independent parameters describing direction-dependent behavior for both stiffness and damping. The direction of mechanical anisotropy is determined by diffusion tensor imaging and we fit three complex-valued moduli distributions across the full brain volume to minimize differences between measured and modeled displacements. We demonstrate spatially accurate property reconstruction in an idealized shell phantom simulation, as well as an ensemble of 20 realistic, randomly-generated simulated brains. We characterize the simulated precisions of all six parameters across major white matter tracts to be high, suggesting that they can be measured independently with acceptable accuracy from MRE data. Finally, we present in vivo anisotropic damping MRE reconstruction data. We perform t-tests on eight repeated MRE brain exams on a single-subject, and find that the three damping parameters are statistically distinct for most tracts, lobes and the whole brain. We also show that population variations in a 17-subject cohort exceed single-subject measurement repeatability for most tracts, lobes and whole brain, for all six parameters. These results suggest that the TI-AD model offers new information that may support differential diagnosis of brain diseases.}
}
@article{NORI201572,
title = {The virtual reality Walking Corsi Test},
journal = {Computers in Human Behavior},
volume = {48},
pages = {72-77},
year = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.01.035},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215000497},
author = {Raffaella Nori and Laura Piccardi and Matteo Migliori and Antonella Guidazzoli and Francesca Frasca and Daniele {De Luca} and Fiorella Giusberti},
keywords = {Corsi Test, Human navigation, Virtual reality, Gender differences, Topographical memory},
abstract = {We compared the performance of men and women on a modified and a virtual version of the Walking Corsi Test (WalCT). The WalCT is a large version of the Corsi Block-Tapping Task that requires learning a path and then recalling it. It has been proved to measure topographical memory. The main aim of the study was to compare the effects of real and virtual reality learning environment on the acquisition of spatial information. A secondary aim was to detect the presence of gender-related differences in the two environments. Specifically, we expected that men would perform better in both environments. Eighty college students (40 men) were assigned to real or virtual environments and had to learn four different paths. Gender differences emerged in both environments: men outperformed women in both the real and the virtual reality environment. Results did not show difference in virtual and real environment supporting the equivalence of the two tests to measure topographical memory. Gender-related differences are interpreted in light of Coluccia and Louse’s model, according to which men outperform women when tasks require a high visuo-spatial working memory load and the different spatial strategy used by men and women.}
}
@article{ZHANG2023107217,
title = {Online view enhancement for exploration inside medical volumetric data using virtual reality},
journal = {Computers in Biology and Medicine},
volume = {163},
pages = {107217},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.107217},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523006820},
author = {Hongkun Zhang and Lifeng Zhu and Qingxiang Zhang and Yunhai Wang and Aiguo Song},
keywords = {Medical volumetric data, Volume rendering, Virtual reality},
abstract = {Background and Objective:
Medical image visualization is an essential tool for conveying anatomical information. Ray-casting-based volume rendering is commonly used for generating visualizations of raw medical images. However, exposing a target area inside the skin often requires manual tuning of transfer functions or segmentation of original images, as preset parameters in volume rendering may not work well for arbitrary scanned data. This process is tedious and unnatural. To address this issue, we propose a volume visualization system that enhances the view inside the skin, enabling flexible exploration of medical volumetric data using virtual reality.
Methods:
In our proposed system, we design a virtual reality interface that allows users to walk inside the data. We introduce a view-dependent occlusion weakening method based on geodesic distance transform to support this interaction. By combining these methods, we develop a virtual reality system with intuitive interactions, facilitating online view enhancement for medical data exploration and annotation inside the volume.
Results:
Our rendering results demonstrate that the proposed occlusion weakening method effectively weakens obstacles while preserving the target area. Furthermore, comparative analysis with other alternative solutions highlights the advantages of our method in virtual reality. We conducted user studies to evaluate our system, including area annotation and line drawing tasks. The results showed that our method with enhanced views achieved 47.73% and 35.29% higher accuracy compared to the group with traditional volume rendering. Additionally, subjective feedback from medical experts further supported the effectiveness of the designed interactions in virtual reality.
Conclusions:
We successfully address the occlusion problems in the exploration of medical volumetric data within a virtual reality environment. Our system allows for flexible integration of scanned medical volumes without requiring extensive manual preprocessing. The results of our user studies demonstrate the feasibility and effectiveness of walk-in interaction for medical data exploration.}
}
@article{PUSCHMANN2016490,
title = {Risk Analysis (Assessment) Using Virtual Reality Technology - Effects of Subjective Experience: An Experimental Study},
journal = {Procedia CIRP},
volume = {50},
pages = {490-495},
year = {2016},
note = {26th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2016.04.115},
url = {https://www.sciencedirect.com/science/article/pii/S2212827116303031},
author = {Patrick Puschmann and Tina Horlitz and Volker Wittstock and Astrid Schütz},
keywords = {VR-Visualization, Product development, Presence, Risk perception},
abstract = {Depending on the specific design phase and relevant goals, engineers have various options to visualize machine tool development. This study examined two types of visualization (e.g. concerning complexity, colors, animations, vividness) using VR technology. Over 25 experts were asked to identify and assess hazards in two 3D-models that differed in complexity. Besides technical aspects, we tested whether psychological aspects such as sense of “being there” and the quality of the risk assessment were affected by the type of the 3D-representation. Furthermore the relations between the user‘s traits (e.g. conscientiousness, risk perception, etc.) and the properties of the 3D-models were explored.}
}
@article{PIERDICCA201667,
title = {Smart maintenance of riverbanks using a standard data layer and Augmented Reality},
journal = {Computers & Geosciences},
volume = {95},
pages = {67-74},
year = {2016},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2016.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S0098300416301662},
author = {Roberto Pierdicca and Emanuele Frontoni and Primo Zingaretti and Adriano Mancini and Eva Savina Malinverni and Anna Nora Tassetti and Ernesto Marcheggiani and Andrea Galli},
keywords = {Buffer strips, Augmented Reality, Environmental monitoring, Mobile visualization, GIS},
abstract = {Linear buffer strips (BS) along watercourses are commonly adopted to reduce run-off, accumulation of bank-top sediments and the leaking of pesticides into fresh-waters, which strongly increase water pollution. However, the monitoring of their conditions is a difficult task because they are scattered over wide rural areas. This work demonstrates the benefits of using a standard data layer and Augmented Reality (AR) in watershed control and outlines the guideline of a novel approach for the health-check of linear BS. We designed a mobile environmental monitoring system for smart maintenance of riverbanks by embedding the AR technology within a Geographical Information System (GIS). From the technological point of view, the system's architecture consists of a cloud-based service for data sharing, using a standard data layer, and of a mobile device provided with a GPS based AR engine for augmented data visualization. The proposed solution aims to ease the overall inspection process by reducing the time required to run a survey. Indeed, ordinary operational survey conditions are usually performed basing the fieldwork on just classical digitized maps. Our application proposes to enrich inspections by superimposing information on the device screen with the same point of view of the camera, providing an intuitive visualization of buffer strip location. This way, the inspection officer can quickly and dynamically access relevant information overlaying geographic features, comments and other contents in real time. The solution has been tested in fieldwork to prove at what extent this cutting-edge technology contributes to an effective monitoring over large territorial settings. The aim is to encourage officers, land managers and practitioners toward more effective monitoring and management practices.}
}
@article{ELBERT2018686,
title = {Transferability of order picking performance and training effects achieved in a virtual reality using head mounted devices},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {11},
pages = {686-691},
year = {2018},
note = {16th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.08.398},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318315234},
author = {Ralf Elbert and Jan-Karl Knigge and Tessa Sarnow},
keywords = {Virtual reality, Head mounted device, Order picking, Logistics, Computer simulation, Learning, Training, Human factors},
abstract = {In recent years, technological advances have led to the development of high-performance head mounted devices (HMDs) for displaying virtual reality (VR) simulations. Due to their relatively low cost and the ability to display highly immersive VR environments, these HMDs show great potential for on-the-job training of order pickers as well as for research in the field of human factors in logistics. In this paper, an experimental setup is presented in order to analyse the transferability of picking times and training effects between the virtual and real order picking environment. The experimental setup has been tested in first studies and the results are used to deduct an advanced and improved experimental setup for ongoing studies.}
}
@article{SUYIN2021103659,
title = {Formative feedback generation in a VR-based dental surgical skill training simulator},
journal = {Journal of Biomedical Informatics},
volume = {114},
pages = {103659},
year = {2021},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2020.103659},
url = {https://www.sciencedirect.com/science/article/pii/S1532046420302872},
author = {Myat {Su Yin} and Peter Haddawy and Siriwan Suebnukarn and Farin Kulapichitr and Phattanapon Rhienmora and Varistha Jatuwat and Nuttanun Uthaipattanacheep},
keywords = {Virtual reality, Dental skill training simulator, Formative feedback, Objective feedback, Video-based feedback},
abstract = {Fine motor skill is indispensable for a dentist. As in many other medical fields of study, the traditional surgical master-apprentice model is widely adopted in dental education. Recently, virtual reality (VR) simulators have been employed as supplementary components to the traditional skill-training curriculum, and numerous dental VR systems have been developed academically and commercially. However, the full promise of such systems has yet to be realized due to the lack of sufficient support for formative feedback. Without such a mechanism, evaluation still demands dedicated time of experts in scarce supply. To fill the gap of formative assessment using VR simulators in skill training in dentistry, we present a framework to objectively assess the surgical skill and generate formative feedback automatically. VR simulators enable collecting detailed data on relevant metrics throughout a procedure. Our approach to formative feedback is to correlate procedure metrics with the procedure outcome to identify the portions of a procedure that need to be improved. Specifically, for the errors in the outcome, the responsible portions of the procedure are identified by using the location of the error. Tutoring formative feedback is provided using the video modality. The effectiveness of the feedback system is evaluated with dental students using randomized controlled trials. The findings show the feedback mechanisms to be effective and to have the potential to be used as valuable supplemental training resources.}
}
@article{HARMOUCHE2012410,
title = {3D registration of MR and X-ray spine images using an articulated model},
journal = {Computerized Medical Imaging and Graphics},
volume = {36},
number = {5},
pages = {410-418},
year = {2012},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2012.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0895611112000493},
author = {Rola Harmouche and Farida Cheriet and Hubert Labelle and Jean Dansereau},
keywords = {Articulated model, Magnetic resonance imaging, X-ray imaging, Multimodal medical image registration, scoliosis},
abstract = {This paper presents a magnetic resonance image (MRI)/X-ray spine registration method that compensates for the change in the curvature of the spine between standing and prone positions for scoliotic patients. MRIs in prone position and X-rays in standing position are acquired for 14 patients with scoliosis. The 3D reconstructions of the spine are then aligned using an articulated model which calculates intervertebral transformations. Results show significant decrease in registration error when the proposed articulated model is compared with rigid registration. The method can be used as a basis for full body MRI/X-ray registration incorporating soft tissues for surgical simulation.}
}
@article{BANERJEE2018167,
title = {Transfer learning on fused multiparametric MR images for classifying histopathological subtypes of rhabdomyosarcoma},
journal = {Computerized Medical Imaging and Graphics},
volume = {65},
pages = {167-175},
year = {2018},
note = {Advances in Biomedical Image Processing},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2017.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0895611117300459},
author = {Imon Banerjee and Alexis Crawley and Mythili Bhethanabotla and Heike E Daldrup-Link and Daniel L. Rubin},
keywords = {Rhabdomyosarcoma, Computer aided diagnosis, Image fusion, Transfer learning, Deep neural networks},
abstract = {This paper presents a deep-learning-based CADx for the differential diagnosis of embryonal (ERMS) and alveolar (ARMS) subtypes of rhabdomysarcoma (RMS) solely by analyzing multiparametric MR images. We formulated an automated pipeline that creates a comprehensive representation of tumor by performing a fusion of diffusion-weighted MR scans (DWI) and gadolinium chelate-enhanced T1−weighted MR scans (MRI). Finally, we adapted transfer learning approach where a pre-trained deep convolutional neural network has been fine-tuned based on the fused images for performing classification of the two RMS subtypes. We achieved 85% cross validation prediction accuracy from the fine-tuned deep CNN model. Our system can be exploited to provide a fast, efficient and reproducible diagnosis of RMS subtypes with less human interaction. The framework offers an efficient integration between advanced image processing methods and cutting-edge deep learning techniques which can be extended to deal with other clinical domains that involve multimodal imaging for disease diagnosis.}
}
@article{DEUSDADO20231112,
title = {Virtual Reality Haptic Device for Mental Illness Treatment},
journal = {Procedia Computer Science},
volume = {219},
pages = {1112-1119},
year = {2023},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN – International Conference on Project MANagement / HCist – International Conference on Health and Social Care Information Systems and Technologies 2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.01.391},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923004003},
author = {Leonel D. Deusdado and Alexandre F.J. Antunes},
keywords = {Schizophrenia, Rehabilitation, Health care, Virtual reality, Haptic device, Serious gamee},
abstract = {Schizophrenia is a mental disorder that alters mental functioning and can cause hallucinations, mental disorientation, and a variety of other symptoms, which results in a separation of schizophrenics from society. Despite the fact that the condition has been known about for a long time, there is still an urgent need for research and testing to develop better therapies. Virtual reality (VR) has had interesting outcomes when used to treat illnesses, and it is gradually emerging as a viable technical choice for the healthcare sector due to its immersion, which offers better and more intense user experiences. Once linked to a serious game, it can introduce the user to a number of situations that, when combined with medical assistance, aid in their rehabilitation and treatment. The use of haptic devices enhances VR immersion by enabling users to comprehend virtual environments with greater nuance, which increases their level of believing in the new environment they are in. When used in conjunction with VR, it can improve the efficacy of the treatment, making its use viable for the treatment of psychic diseases. The goal of this research is to develop haptic vest interactions using a three-dimensional virtual testing scenario to support and improve the use of VR for rehabilitation and therapy for schizophrenia. The established functionalities can be applied to a further serious game with the same focus.}
}
@incollection{DU202057,
title = {Chapter 4 - Self-powered MR seat suspension},
editor = {Haiping Du and Weihua Li and Donghong Ning and Shuaishuai Sun and Quan Min Zhu},
booktitle = {Advanced Seat Suspension Control System Design for Heavy Duty Vehicles},
publisher = {Academic Press},
pages = {57-77},
year = {2020},
series = {Emerging Methodologies and Applications in Modelling},
isbn = {978-0-12-819601-4},
doi = {https://doi.org/10.1016/B978-0-12-819601-4.00004-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128196014000047},
author = {Haiping Du and Weihua Li and Donghong Ning and Shuaishuai Sun and Quan Min Zhu},
keywords = {MR damper, seat suspension, self-power, vibration control},
abstract = {A self-powered magnetorheological (MR) seat suspension which includes a rotary MR damper and an electromagnetic induction (EMI) device was designed, constructed, and tested in this chapter. The inclusion of the self-powering component is able to activate this MR seat suspension without requiring external power supply, which contributes to reducing the cost. An MTS testing was performed to characterize the property of the self-powering MR seat suspension. Then its vibration reduction performance was evaluated under two kinds of vibration excitations. For this test, a robust control was used and the experimental results demonstrate that the ride comfort has achieved a higher level by using this controlled self-powering MR seat suspension.}
}
@article{CHEN20172,
title = {Cross contrast multi-channel image registration using image synthesis for MR brain images},
journal = {Medical Image Analysis},
volume = {36},
pages = {2-14},
year = {2017},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2016.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1361841516301852},
author = {Min Chen and Aaron Carass and Amod Jog and Junghoon Lee and Snehashis Roy and Jerry L. Prince},
keywords = {Multi-modal image registration, Multi-channel image registration, Multi-contrast magnetic resonance imaging, Image synthesis, Image processing, Multi-modal imaging, Brain imaging},
abstract = {Multi-modal deformable registration is important for many medical image analysis tasks such as atlas alignment, image fusion, and distortion correction. Whereas a conventional method would register images with different modalities using modality independent features or information theoretic metrics such as mutual information, this paper presents a new framework that addresses the problem using a two-channel registration algorithm capable of using mono-modal similarity measures such as sum of squared differences or cross-correlation. To make it possible to use these same-modality measures, image synthesis is used to create proxy images for the opposite modality as well as intensity-normalized images from each of the two available images. The new deformable registration framework was evaluated by performing intra-subject deformation recovery, intra-subject boundary alignment, and inter-subject label transfer experiments using multi-contrast magnetic resonance brain imaging data. Three different multi-channel registration algorithms were evaluated, revealing that the framework is robust to the multi-channel deformable registration algorithm that is used. With a single exception, all results demonstrated improvements when compared against single channel registrations using the same algorithm with mutual information.}
}
@article{OSGOOEI2015293,
title = {Experimental and finite element study on the lateral response of modified rectangular fiber-reinforced elastomeric isolators (MR-FREIs)},
journal = {Engineering Structures},
volume = {85},
pages = {293-303},
year = {2015},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2014.11.037},
url = {https://www.sciencedirect.com/science/article/pii/S0141029614007251},
author = {Peyman M. Osgooei and Niel C. {Van Engelen} and Dimitrios Konstantinidis and Michael J. Tait},
keywords = {Fiber-reinforced elastomeric isolator (FREI), Rubber bearing, Base isolation, Geometric modifications, 3D finite element analysis},
abstract = {Fiber-reinforced elastomeric isolators (FREIs) have been shown to be viable and potentially inexpensive devices for seismic mitigation of low-rise buildings. FREIs utilize fiber material for the reinforcing layers resulting in lower weight and manufacturing costs compared to conventional steel-reinforced elastomeric isolators (SREIs). Experimental test results have shown that modifying FREIs, by cutting holes in the center portion of the isolators or removing sections from the sides, can enhance their lateral response characteristics. This study investigates the lateral response of modified rectangular FREIs (MR-FREIs) through experimental tests and 3D finite element analysis. Experimental test results of five FREIs with and without modifications are used to evaluate the 3D finite element models. These models are subsequently used to investigate the effect of modifications on the lateral behavior of the isolators, in addition to the stress and strain demands in the elastomer and fiber reinforcement layers.}
}
@article{DROGEMULLER2020100937,
title = {Examining virtual reality navigation techniques for 3D network visualisations},
journal = {Journal of Computer Languages},
volume = {56},
pages = {100937},
year = {2020},
issn = {2590-1184},
doi = {https://doi.org/10.1016/j.cola.2019.100937},
url = {https://www.sciencedirect.com/science/article/pii/S2590118419300620},
author = {Adam Drogemuller and Andrew Cunningham and James Walsh and Bruce H. Thomas and Maxime Cordeil and William Ross},
keywords = {Virtual reality, Navigation, Graphs, Visualisation},
abstract = {Research into how virtual reality (VR) can be a beneficial technology for new and emerging large, complex data visualisations for data scientists is ongoing. In this paper, we evaluate three-dimensional VR navigation technique for data visualisations and test their effectiveness with a large graph visualisation. We evaluate two prominent navigation techniques employed in VR (Teleportation and One-Handed Flying) against two less common methods (Two-Handed Flying and Worlds-In-Miniature) and evaluate their performance and effectiveness through a series of tasks. We found Steering Patterns (One-Handed Flying and Two-Handed Flying) to be faster and preferred by participants for completing searching tasks in comparison to Teleportation. Worlds-In-Miniature was the least physically demanding of the navigations, and was preferred by participants for tasks that required an overview of the graph such as triangle counting.}
}
@article{LEE200888,
title = {Empirical analysis of consumer reaction to the virtual reality shopping mall},
journal = {Computers in Human Behavior},
volume = {24},
number = {1},
pages = {88-104},
year = {2008},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2007.01.018},
url = {https://www.sciencedirect.com/science/article/pii/S0747563207000155},
author = {Kun Chang Lee and Namho Chung},
keywords = {Shopping mall, User interface, Virtual reality, Convenience, Enjoyment, Quality assurance, Customer satisfaction},
abstract = {The Internet shopping mall has received wide attention from researchers and practitioners due to the fact that it is one of the most killing applications customers can find on the Internet. Though numerous studies have been performed on various issues of the Internet shopping mall, some research issues relating to the user interface of VR (virtual reality) shopping malls still await further empirical investigation. The objective of this study is to investigate whether the user interface of the VR shopping mall positively affects customer satisfaction in comparison with the ordinary shopping mall. For this purpose, we developed a prototype of the VR shopping mall for which the user interface consists of both 3D graphics and an avatar, using it as an experimental medium. 102 valid questionnaires were gathered from active student users of the ordinary shopping mall, and two research hypotheses were then tested to prove whether the three explanatory variables such as convenience, enjoyment, quality assurance improve in the VR shopping mall, and whether customer satisfaction is also significantly enhanced in the VR shopping mall in comparison with the ordinary shopping mall. Additionally, we conducted the PLS (partial least square) analysis to test whether the customer satisfaction is explained significantly by the three explanatory variables or not.}
}
@article{PREMALATHA2023104824,
title = {Robust neutrosophic fusion design for magnetic resonance (MR) brain images},
journal = {Biomedical Signal Processing and Control},
volume = {84},
pages = {104824},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2023.104824},
url = {https://www.sciencedirect.com/science/article/pii/S1746809423002574},
author = {R. Premalatha and P. Dhanalakshmi},
keywords = {Fusion, Neutrosophic set, Spatial frequency, Grey-level co-occurrence matrix},
abstract = {Fusion plays a pivotal role in the field of clinical processing; it could minimize the impacts of human errors, enhance diagnostic performance, and save manpower and time. Thus, the study examines the robust image fusion technique of MR brain images via a neutrosophic set (NS) subject to neutrosophic theory, wherein the effect of uncertainty in the frame of spatial and texture information is considered in the fusion design. Typically, the mechanism comprises four modules: (i) NS domain conversion; (ii) spatial feature extraction; (iii) texture feature extraction; and (iv) fusion. Primarily, we transform the input MR brain image into the field of NS, which consists of three subsets. Following the determined subsets, we apply spatial frequency to grab the spatial information present in the image. In particular, a grey level co-occurrence matrix (GLCM) is employed to describe the texture information of the addressed technique. After that, the fusion rule is applied to integrate both spatial and textural information from the input images, and then an addressed fusion design is derived. Subsequently, evaluation metrics are eventually offered to determine the significance as well as the efficacy of the suggested fusion design.}
}
@article{YANG2002309,
title = {Large-scale MR fluid dampers: modeling and dynamic performance considerations},
journal = {Engineering Structures},
volume = {24},
number = {3},
pages = {309-323},
year = {2002},
issn = {0141-0296},
doi = {https://doi.org/10.1016/S0141-0296(01)00097-9},
url = {https://www.sciencedirect.com/science/article/pii/S0141029601000979},
author = {G. Yang and B.F. Spencer and J.D. Carlson and M.K. Sain},
keywords = {MR fluids, MR dampers, Dampers, Smart damping devices, Smart materials, Hysteresis model, Parameter estimation, System identification, Rheological technology},
abstract = {The magnetorheological (MR) damper is one of the most promising new devices for structural vibration reduction. Because of its mechanical simplicity, high dynamic range, low power requirements, large force capacity and robustness, this device has been shown to mesh well with application demands and constraints to offer an attractive means of protecting civil infrastructure systems against severe earthquake and wind loading. In this paper, an overview of the essential features and advantages of MR materials and devices is given. This is followed by the derivation of a quasi-static axisymmetric model of MR dampers, which is then compared with both a simple parallel-plate model and experimental results. While useful for device design, it is found that these models are not sufficient to describe the dynamic behavior of MR dampers. Dynamic response time is an important characteristic for determining the performance of MR dampers in practical civil engineering applications. This paper also discusses issues affecting the dynamic performance of MR dampers, and a mechanical model based on the Bouc–Wen hysteresis model is developed. Approaches and algorithms to optimize the dynamic response are investigated, and experimental verification is provided.}
}
@article{ZHAO2023102786,
title = {SpineRegNet: Spine Registration Network for volumetric MR and CT image by the joint estimation of an affine-elastic deformation field},
journal = {Medical Image Analysis},
volume = {86},
pages = {102786},
year = {2023},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2023.102786},
url = {https://www.sciencedirect.com/science/article/pii/S1361841523000476},
author = {Lei Zhao and Shumao Pang and Yangfan Chen and Xiongfeng Zhu and Ziyue Jiang and Zhihai Su and Hai Lu and Yujia Zhou and Qianjin Feng},
keywords = {Deep learning, Spine registration, Affine-elastic registration, Local rigidity constrain},
abstract = {Spine registration for volumetric magnetic resonance (MR) and computed tomography (CT) images plays a significant role in surgical planning and surgical navigation system for the radiofrequency ablation of spine intervertebral discs. The affine transformation of each vertebra and elastic deformation of the intervertebral disc exist at the same time. This situation is a major challenge in spine registration. Existing spinal image registration methods failed to solve the optimal affine-elastic deformation field (AEDF) simultaneously, only consider the overall rigid or elastic alignment with the help of a manual spine mask, and encounter difficulty in meeting the accuracy requirements of clinical registration application. In this study, we propose a novel affine-elastic registration framework named SpineRegNet. The SpineRegNet consists of a Multiple Affine Matrices Estimation (MAME) Module for multiple vertebrae alignment, an Affine-Elastic Fusion (AEF) Module for joint estimation of the overall AEDF, and a Local Rigidity Constraint (LRC) Module for preserving the rigidity of each vertebra. Experiments on T2-weighted volumetric MR and CT images show that the proposed approach achieves impressive performance with mean Dice similarity coefficients of 91.36%, 81.60%, and 83.08% for the mask of the vertebrae on Datasets A-C, respectively. The proposed technique does not require a mask or manual participation during the tests and provides a useful tool for clinical spinal disease surgical planning and surgical navigation systems.}
}
@article{BRENNEMANWILSON2023105651,
title = {Integrating MR imaging with full-surface indentation mapping of femoral cartilage in an ex vivo porcine stifle},
journal = {Journal of the Mechanical Behavior of Biomedical Materials},
volume = {139},
pages = {105651},
year = {2023},
issn = {1751-6161},
doi = {https://doi.org/10.1016/j.jmbbm.2023.105651},
url = {https://www.sciencedirect.com/science/article/pii/S1751616123000048},
author = {Elora C. {Brenneman Wilson} and Cheryl E. Quenneville and Monica R. Maly},
keywords = {Cartilage, Articular, Magnetic resonance imaging, Statistics, Elastic modulus.},
abstract = {The potential of MRI to predict cartilage mechanical properties across an entire cartilage surface in an ex vivo model would enable novel perspectives in modeling cartilage tolerance and predicting disease progression. The purpose of this study was to integrate MR imaging with full-surface indentation mapping to determine the relationship between femoral cartilage thickness and T2 relaxation change following loading, and cartilage mechanical properties in an ex vivo porcine stifle model. Matched-pairs of stifle joints from the same pig were randomized into either 1) an imaging protocol where stifles were imaged at baseline and after 35 min of static axial loading; and 2) full surface mapping of the instantaneous modulus (IM) and an electromechanical property named quantitative parameter (QP). The femur and femoral cartilage were segmented from baseline and post-intervention scans, then meshes were generated. Coordinate locations of the indentation mapping points were rigidly registered to the femur. Multiple linear regressions were performed at each voxel testing the relationship between cartilage outcomes (thickness change, T2 change) and mechanical properties (IM, QP) after accounting for covariates. Statistical Parametric Mapping was used to determine significance of clusters. No significant clusters were identified; however, this integrative method shows promise for future work in ex vivo modeling by identifying spatial relationships among variables.}
}
@article{HUANG2023102245,
title = {Semi-supervised hybrid spine network for segmentation of spine MR images},
journal = {Computerized Medical Imaging and Graphics},
volume = {107},
pages = {102245},
year = {2023},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2023.102245},
url = {https://www.sciencedirect.com/science/article/pii/S0895611123000630},
author = {Meiyan Huang and Shuoling Zhou and Xiumei Chen and Haoran Lai and Qianjin Feng},
keywords = {Spine segmentation, MR images, Semi-supervised learning, Cross tri-attention},
abstract = {Automatic segmentation of vertebral bodies (VBs) and intervertebral discs (IVDs) in 3D magnetic resonance (MR) images is vital in diagnosing and treating spinal diseases. However, segmenting the VBs and IVDs simultaneously is not trivial. Moreover, problems exist, including blurry segmentation caused by anisotropy resolution, high computational cost, inter-class similarity and intra-class variability, and data imbalances. We proposed a two-stage algorithm, named semi-supervised hybrid spine network (SSHSNet), to address these problems by achieving accurate simultaneous VB and IVD segmentation. In the first stage, we constructed a 2D semi-supervised DeepLabv3+ by using cross pseudo supervision to obtain intra-slice features and coarse segmentation. In the second stage, a 3D full-resolution patch-based DeepLabv3+ was built. This model can be used to extract inter-slice information and combine the coarse segmentation and intra-slice features provided from the first stage. Moreover, a cross tri-attention module was applied to compensate for the loss of inter-slice and intra-slice information separately generated from 2D and 3D networks, thereby improving feature representation ability and achieving satisfactory segmentation results. The proposed SSHSNet was validated on a publicly available spine MR image dataset, and remarkable segmentation performance was achieved. Moreover, results show that the proposed method has great potential in dealing with the data imbalance problem. Based on previous reports, few studies have incorporated a semi-supervised learning strategy with a cross attention mechanism for spine segmentation. Therefore, the proposed method may provide a useful tool for spine segmentation and aid clinically in spinal disease diagnoses and treatments. Codes are publicly available at: https://github.com/Meiyan88/SSHSNet.}
}
@article{SANGIORGIO2021103567,
title = {Augmented reality based - decision making (AR-DM) to support multi-criteria analysis in constructions},
journal = {Automation in Construction},
volume = {124},
pages = {103567},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103567},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521000182},
author = {Valentino Sangiorgio and Silvia Martiradonna and Fabio Fatiguso and Ignacio Lombillo},
keywords = {Augmented reality, Building construction technologies, Analytic hierarchy process, Multi-criteria decision methods, Simos-Roy-Figueira (SRF) method, Building retrofitting, Precast concrete panels},
abstract = {Multi-Criteria Decision Analysis (MCDA) and in particular the Analytic Hierarchy Process (AHP) is widely used in construction thanks to its versatility and ability to involve qualitative and quantitative data in the analysis. On the other hand, many complex problems are difficult to be solved because of the large amount of information to be considered. In this paper, an Augmented Reality based Decision Making (AR-DM) is proposed to get a novel MCDA following the hierarchical structure of the AHP. For the first time, the AR immersive environment is combined with the Simos-Roy-Figueira method to provide a large amount of visual information during the decision phase. The proposed approach is tested to support the selection of an experimental Precast Concrete Panel for RC buildings retrofitting. Finally, a comparison with the classical approach and two other improved version of the AHP procedure is performed to validate and show the potential of the method.}
}
@article{KELLER20131951,
title = {ITER design, integration and assembly studies assisted by virtual reality},
journal = {Fusion Engineering and Design},
volume = {88},
number = {9},
pages = {1951-1954},
year = {2013},
note = {Proceedings of the 27th Symposium On Fusion Technology (SOFT-27); Liège, Belgium, September 24-28, 2012},
issn = {0920-3796},
doi = {https://doi.org/10.1016/j.fusengdes.2013.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S092037961300118X},
author = {D. Keller and L. Doceul and F. Ferlay and G. Jiolat and J.J. Cordier and I. Kuehn and B. Manfreo and J. Reich},
keywords = {ITER, Virtual reality, Integration, Assembly, Maintenance, Safety},
abstract = {In a project like ITER where schedule, resources and cost is continuously optimized, emphasis has to be put on developing long lead items first while keeping other designs very low in definition. Hence, at a particular stage of the project, several components have to coexist in the integrated system while handling different level of maturity. Therefore, all the difficulty consists in managing the interfaces between all these components and to minimize the risk of design changes on the most advanced components. As a future exploitant, ITER is in charge of managing these interfaces and to ensure that maintenance of especially safety important class components (SIC) is feasible. These operation and maintenance constraints have to be taken into account since the earliest design of the components itselves. In this context, CEA IRFM is taking the benefit of using its virtual reality (VR) platform and simulation tools to assist ITER Organization in improving the efficiency of the inconsistencies identification and the machine sub-system design optimization. Currently, two contracts are on-going: the first one concerns the cryostat and in-vessel components; the second one concerns the overall Tokamak (TKM) and diagnostic buildings. This paper describes how VR tools applied to fusion and especially to ITER can help design and Integration with taking into account assembly and maintenance requirements at early stage in the design of complex systems.}
}
@article{HU2012687,
title = {MR to ultrasound registration for image-guided prostate interventions},
journal = {Medical Image Analysis},
volume = {16},
number = {3},
pages = {687-703},
year = {2012},
note = {Computer Assisted Interventions},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2010.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1361841510001295},
author = {Yipeng Hu and Hashim Uddin Ahmed and Zeike Taylor and Clare Allen and Mark Emberton and David Hawkes and Dean Barratt},
keywords = {Image registration, Biomechanical modelling, Statistical shape modelling, Minimum-invasive interventions, Prostate cancer},
abstract = {A deformable registration method is described that enables automatic alignment of magnetic resonance (MR) and 3D transrectal ultrasound (TRUS) images of the prostate gland. The method employs a novel “model-to-image” registration approach in which a deformable model of the gland surface, derived from an MR image, is registered automatically to a TRUS volume by maximising the likelihood of a particular model shape given a voxel-intensity-based feature that represents an estimate of surface normal vectors at the boundary of the gland. The deformation of the surface model is constrained by a patient-specific statistical model of gland deformation, which is trained using data provided by biomechanical simulations. Each simulation predicts the motion of a volumetric finite element mesh due to the random placement of a TRUS probe in the rectum. The use of biomechanical modelling in this way also allows a dense displacement field to be calculated within the prostate, which is then used to non-rigidly warp the MR image to match the TRUS image. Using data acquired from eight patients, and anatomical landmarks to quantify the registration accuracy, the median final RMS target registration error after performing 100 MR–TRUS registrations for each patient was 2.40mm.}
}
@article{HONG2021107688,
title = {A mixed-reality approach to soundscape assessment of outdoor urban environments augmented with natural sounds},
journal = {Building and Environment},
volume = {194},
pages = {107688},
year = {2021},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2021.107688},
url = {https://www.sciencedirect.com/science/article/pii/S0360132321000998},
author = {Joo Young Hong and Bhan Lam and Zhen-Ting Ong and Kenneth Ooi and Woon-Seng Gan and Jian Kang and Samuel Yeong and Irene Lee and Sze-Tiong Tan},
keywords = {Soundscape, Soundscape intervention, Acoustic environment, Natural sounds, Augmented reality, Mixed reality},
abstract = {To investigate the effect of augmenting natural sounds in noisy environments, an in-situ experiment was conducted using a mixed-reality head-mounted display (MR HMD). Two outdoor locations close to an expressway were selected for the experiment. A natural sound (birdsong or stream) along with a hologram (sparrow/fountain or loudspeaker) was projected through the MR HMD. Participants were asked to adjust the natural sound levels to their preferred level under ambient traffic noise conditions at each location. Participants also assessed the perceived loudness of traffic (PLN) and overall soundscape quality (OSQ) in conditions with and without the augmented natural sounds. The results showed that both natural sounds significantly reduced the PLN and enhanced the OSQ. No significant differences in subjective responses were found between the loudspeaker and visual representations of the natural sound source as holograms. Analysis on the preferred signal-to-noise ratio (SNR), i.e. ratio of natural sound to traffic levels, indicated a strong negative correlation between the preferred SNRs and ambient traffic noise levels. Overall, the preferred SNR of the birdsong was significantly higher than that of the water sound. Among the acoustic parameters tested, the A-weighted traffic noise level was the strongest predictor for the preferred SNR of both the birdsong and water sound. However, the correlation for the water sound was relatively higher than the birdsong. This was due to the larger variance in the subjective evaluation for the birdsong.}
}
@article{ZHANG2020346,
title = {Compressed sensing MR image reconstruction via a deep frequency-division network},
journal = {Neurocomputing},
volume = {384},
pages = {346-355},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219317126},
author = {Jiulou Zhang and Yunbo Gu and Hui Tang and Xiaoqing Wang and Youyong Kong and Yang Chen and Huazhong Shu and Jean-Louis Coatrieux},
keywords = {Magnetic resonance imaging, Compressed sensing, Iterative reconstruction, Deep learning, Convolutional neural network},
abstract = {Compressed sensing MRI (CS-MRI) is considered as a powerful technique for decreasing the scan time of MRI while ensuring the image quality. However, state of the art reconstruction algorithms are still subjected to two challenges including terrible parameters tuning and image details loss resulted from over-smoothing. In this paper, we propose a deep frequency-division network (DFDN) to face these two image reconstruction issues. The proposed DFDN approach applies a deep iterative reconstruction network (DIRN) to replace the regularization terms and the corresponding parameters by a stacked convolution neural network (CNN). And then multiple DIRN blocks are cascaded continuously as one deeper neural network. Data consistency (DC) layer is incorporated after each DIRN block to correct the k-space data of intermediate results. Image content loss is computed after each DC layer and frequency-division loss is gained by weighting the high frequency loss and low frequency loss after each DIRN block. The combination of image content loss and frequency-division loss is considered as the total loss for constraining the network training procedure. Validations of the proposed method have been performed on two brain datasets. Visual results and quantitative evaluations show that the proposed DFDN algorithm has better performance in sparse MRI reconstruction than other comparative methods.}
}
@article{ZHONG2023117844,
title = {Effects of Ar-N2-He shielding gas on microstructure, mechanical properties and corrosion resistance of the Laser-MIG additive manufacturing 316L stainless steel},
journal = {Journal of Materials Processing Technology},
volume = {312},
pages = {117844},
year = {2023},
issn = {0924-0136},
doi = {https://doi.org/10.1016/j.jmatprotec.2022.117844},
url = {https://www.sciencedirect.com/science/article/pii/S0924013622003557},
author = {Yang Zhong and Zhizhen Zheng and Jianjun Li and Cheng Wang and Xuanguo Wang},
keywords = {Laser-MIG additive manufacturing, 316L stainless steel, Nitrogen, Microstructure evolution, Mechanical properties, Corrosion properties},
abstract = {To eliminate excessive δ-ferrite in the 316L stainless steel fabricated by wire arc additive manufacturing (WAAM) under traditional Ar-20%CO2 shielding gas, a novel Ar-N2-He mixed shielding gas with laser intervention was first applied in laser-MIG hybrid additive manufacturing 316L. The results show that the residual δ-ferrite can be completely removed, and the highest fraction of γ-austenite can be obtained under 80%Ar-10%N2-10%He, which is in total contrast with the amounts of skeletal/dendritic δ-ferrite in Laser-MAG 316L shielded by 80%Ar-20%CO2. Meanwhile, the Laser-MIG 316L has significantly higher mechanical properties and corrosion resistance than the Laser-MAG 316L due to the combined effects of the interstitial solid solution strengthening of N, inhibition of Cr-Mo-Ni atomic segregation at the δ-γ interface, and substantially greater enrichment of Cr-Mo-Ni-N passivating species in the passive film. In particular, the higher fractions of Cr2O3, MoO3 and NH4+ were identified to reduce the oxygen vacancy density defects and suppress the film dissolution. Furthermore, the allowable ratio of N2 can be increased to 15% during the Laser-MIG depositing 316L process, which can never be achieved in the traditional MIG 316L process due to the more adequate conversions among the excited N2, N, and N+ species within the higher stabilized Laser-MIG arc plasma. This study confirms the feasibility of applying Ar-N2-He shielding gas in eliminating δ-ferrite and improving the service performance of the 316L stainless steel fabricated by Laser-MIG additive manufacturing without post-heat treatment.}
}
@article{GAO2011105,
title = {3D augmented reality teleoperated robot system based on dual vision},
journal = {The Journal of China Universities of Posts and Telecommunications},
volume = {18},
number = {1},
pages = {105-112},
year = {2011},
issn = {1005-8885},
doi = {https://doi.org/10.1016/S1005-8885(10)60035-0},
url = {https://www.sciencedirect.com/science/article/pii/S1005888510600350},
author = {Xin GAO and Huan HU and Qing-xuan JIA and Han-xu SUN and Jing-zhou SONG},
keywords = {teleoperated robotic system, augmented reality, immersive interface, stereo display, binocular registration},
abstract = {A 3D augmented reality navigation system using stereoscopic images is developed for teleoperated robot systems. The accurate matching between the simulated model and the video image of the actual robot can be realized, which helps the operator to accomplish the remote control task correctly and reliably. The system introduces the disparity map translation transformation method to take parallax images for stereoscopic displays, providing the operator an immersive 3D experience. Meanwhile, a fast and accurate registration method of dynamic stereo video is proposed, and effective integration of a virtual robot and the real stereo scene can be achieved. Preliminary experiments show that operation error of the system is maintained at less than 2.2 mm and the average error is 0.854 7, 0.909 3 and 0.697 2 mm at x, y, z direction respectively. Lots of experiments such as pressing the button, pulling the drawer and so on are also conducted to evaluate the performance of the system. The feasibility studies show that the depth information of structure can be rapidly and recognized in remote environment site. The augmented reality of the image overlay system could increase the operating accuracy and reduce the procedure time as a result of intuitive 3D viewing.}
}
@article{DU201863,
title = {Preliminary study of albendazole liposome treatment of cerebral alveolar echinococcosis by 1H-MR spectroscopy},
journal = {Radiology of Infectious Diseases},
volume = {5},
number = {2},
pages = {63-68},
year = {2018},
issn = {2352-6211},
doi = {https://doi.org/10.1016/j.jrid.2018.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S2352621117300529},
author = {Xiaodan Du and Yongxiao You and Jian Wang and Chunhui Jiang and Yibanu Abudureheman and Juan Ma and Ling Wu},
keywords = {Alveolar echinococcosis, Albendazole liposome, Proton magnetic resonance spectroscopy, Cerebral},
abstract = {Objective
To investigate the 1H-MRS characteristics of cerebral alveolar echinococcosis (CAE) treated by albendazole liposome.
Materials and methods
Nine patients with 20 lesions proven histologically and clinically to be CAE positive were examined via conventional MRI and 2D multivoxel spectroscopy with a 3.0 T double gradient superconductivity magnetic resonance scanner. In patients who took medication regularly for at least one year, the levels of NAA, CR, Cho, MI, Lip, Lac, and other metabolites from the same lesion parenchyma were observed and then used to calculate NAA/Cr, NAA/Cho, NAA/(Cho+Cr), and (Lip+Lac)/Cr. Statistical analysis was performed using the Wilcoxon signed-rank test.
Results
Comparisons between cMRI scans taken before patients began taking medication and cMRI scans taken after patients completed one year of regular medication, the volume of legions increased slightly, and the signals of lesions increased on T2WI. The medians and interquartile ranges of NAA/Cho, NAA/CR, NAA/(Cho+Cr), and (Lip+Lac)/Cr in the same lesions in CAE patients prior to treatment via albendazole liposomes were: 2.285 (1.388–3.655), 3.620 (2.173–5.165), 0.651 (0.552–0938), and 29 (15.219–41.609), respectively. The medians and interquartile ranges of NAA/Cho, NAA/CR, NAA/(Cho+Cr), and (Lip+Lac)/Cr in the same lesions in CAE patients after treatment via albendazole liposomes were: 5.120 (1.853–12.00), 6.120 (3.690–9.733), 0.900 (0.651–1.218), and 26.427 (16.536–49.904), respectively. Proton magnetic resonance spectroscopy images of patients with CAE before and after one year of treatment via albendazole liposomes were characterized by the increase of NAA with ratios of NAA/Cho, NAA/CR, and NAA/(Cho+Cr) increasing by different degrees. Compared with the same lesion before and after treatment twice, the differences were statistically significant (P < 0.01). In regard to the change in (Lip+Lac)/Cr ratios, the differences were not statistically significant (P > 0.05).
Conclusion
In patients with CAE, minimal change in CAE lesions imaged via conventional MRI, 1H-MRS was observed. Slight changes of cerebral alveolar echinococcosis lesions before and after treatment via albendazole liposome were observed, providing valuable imaging information for the treatment of CAE lesions.}
}
@article{BARSASELLA2021105892,
title = {Effects of Virtual Reality Sessions on the Quality of Life, Happiness, and Functional Fitness among the Older People: A Randomized Controlled Trial from Taiwan},
journal = {Computer Methods and Programs in Biomedicine},
volume = {200},
pages = {105892},
year = {2021},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2020.105892},
url = {https://www.sciencedirect.com/science/article/pii/S0169260720317259},
author = {Diana Barsasella and Megan F. Liu and Shwetambara Malwade and Cooper J Galvin and Eshita Dhar and Chia-Chi Chang and Yu-Chuan Jack Li and Shabbir Syed-Abdul},
keywords = {virtual reality, older people, randomized controlled trial, quality of life, happiness, functional fitness},
abstract = {Background and Objective
Ageing is a complex process with physical, psychological, and social changes, which can lead to diseases and disability, and further reduce happiness levels. Virtual reality (VR) is an emerging technology with the potential to improve overall well-being, quality of life (QoL), muscle activity and balance. Our study aimed to determine the influence of VR sessions on the QoL, happiness, and functional fitness components of an elderly cohort.
Methods
A non-blinded randomized controlled trial was conducted. Sixty participants, who visited the active ageing center at the university were randomized into two groups- intervention and control. The intervention group received VR experience sessions for 15 min twice a week for a duration of 6 weeks, while the control group received no sessions. Participants filled out a questionnaire for QoL assessment and happiness assessment. They were also tested for several functional fitness components. Both questionnaires and fitness tests were conducted at the beginning and at the end of study.
Results
QoL improved by some metrics assessed (Pain/Discomfort and Anxiety/Depression). Happiness significantly improved in the intervention group relative to the control group. Among the functional fitness tests, the back scratch test 1st and back scratch test 2nd were measured to be significantly improved in the intervention group in comparison to control group.
Conclusions
VR sessions have potential to influence the well-being and functional fitness of older adults and further support the process of healthy and active ageing. Future considerations could focus on supporting more physical and psychological aspects of the older people through VR content.
Trial registration
NCT04166747.}
}
@article{JUGE2023105638,
title = {Ex vivo bovine liver nonlinear viscoelastic properties: MR elastography and rheological measurements},
journal = {Journal of the Mechanical Behavior of Biomedical Materials},
volume = {138},
pages = {105638},
year = {2023},
issn = {1751-6161},
doi = {https://doi.org/10.1016/j.jmbbm.2022.105638},
url = {https://www.sciencedirect.com/science/article/pii/S1751616122005434},
author = {Lauriane Jugé and Patrick Foley and Alice Hatt and Jade Yeung and Lynne E. Bilston},
keywords = {Magnetic resonance elastography, Rheometry, Nonlinear viscoelastic mechanical properties, Static preloads, Liver},
abstract = {Introduction
Knowledge of the nonlinear viscoelastic properties of the liver is important, but the complex tissue behavior outside the linear viscoelastic regime has impeded their characterization, particularly in vivo. Combining static compression with magnetic resonance (MR) elastography has the potential to be a useful imaging method for assessing large deformation mechanical properties of soft tissues in vivo. However, this remains to be verified. Therefore this study aims first to determine whether MR elastography can measure the nonlinear mechanical properties of ex vivo bovine liver tissue under varying levels of uniform and focal preloads (up to 30%), and second to compare MR elastography-derived complex shear modulus with standard rheological measurements.
Method
Nine fresh bovine livers were collected from a local abattoir, and experiments were conducted within 12hr of death. Two cubic samples (∼10 × 10 × 10 cm3) were dissected from each liver and imaged using MR elastography (60 Hz) under 4 levels of uniform and focal preload (1, 10, 20, and 30% of sample width) to investigate the relationship between MR elastography-derived complex shear modulus (G∗) and the maximum principal Right Cauchy Green Strain (C11). Three tissue samples from each of the same 9 livers underwent oscillatory rheometry under the same 4 preloads (1, 10, 20, and 30% strain). MR elastography-derived complex shear modulus (G∗) from the uniform preload was validated against rheometry by fitting the frequency dependence of G∗ with a power-law and extrapolating rheometry-derived G∗ to 60 Hz.
Results
MR elastography-derived G∗ increased with increasing compressive large deformation strain, and followed a power-law curve (G∗ = 1.73 × C11−0.38, R2 = 0.96). Similarly, rheometry-derived G∗ at 1 Hz, increasing from 0.66 ± 1.03 kPa (1% strain) to 1.84 ± 1.65 kPa (30% strain, RM one-way ANOVA, P < 0.001), and the frequency dependence of G∗ followed a power-law with the exponent decreasing from 0.13 to 0.06 with increasing preload. MR elastography-derived G∗ was 1.4–3.1 times higher than the extrapolated rheometry-derived G∗ at 60 Hz, but the strain dependence was consistent between rheometry and MR elastography measurements.
Conclusions
This study demonstrates that MR elastography can detect changes in ex vivo bovine liver complex shear modulus due to either uniform or focal preload and therefore can be a useful technique to characterize nonlinear viscoelastic properties of soft tissue, provided that strains applied to the tissue can be quantified. Although MR elastography could reliably characterize the strain dependence of the ex vivo bovine liver, MR elastography overestimated the complex shear modulus of the tissue compared to rheological measurements, particularly at lower preload (<10%). That is likely to be important in clinical hepatic MR elastography diagnosis studies if preload is not carefully considered. A limitation is the absence of overlapping frequency between rheometry and MR elastography for formal validation.}
}
@article{LANGEVIN2009273,
title = {Signal reduction at high velocities during one plug MR inflow},
journal = {IRBM},
volume = {30},
number = {5},
pages = {273-280},
year = {2009},
note = {NUMÉRO SPÉCIAL TECHNOLOGIES POUR L'AUTONOMIE},
issn = {1959-0318},
doi = {https://doi.org/10.1016/j.irbm.2009.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1959031809001043},
author = {F. Langevin and A. Darwich and S. Capellino},
keywords = {MRI, Time of flight, Flow velocity, Blood velocity, IRM, Temps de vol, Vitesse du flux, Vitesse sanguine},
abstract = {An inflow MR signal behavior for high fluid velocity is reported here, for which there is no existing literature. It is obtained thanks to a bare and fast gradient echo sequence. Acquisition parameters were defined to follow the signal of a once excited bolus. We observed a considerable and reproducible drop in the signal intensity, inversely proportional to the flow velocity. This relation is hyperbolic, with reliable R2>0.97 for high velocities. Several experiments were performed in order to test the possible reasons for signal reduction. Distance to the reception coil, slice thickness and echo time, fluid viscosity and radiofrequency impact on a moving fluid. The determinist relationship between signal and velocity incited us to check the feasibility of a velocity quantification method based on that process. Its high time resolution is an advantage for hemodynamic vascular properties understanding.
Résumé
Nous rapportons ici l’observation en IRM d’un phénomène d’entrée de coupe à haute vitesse par rapport à l’épaisseur de coupe, qui n’est pas décrit dans la littérature. Il est mis en évidence en utilisant une séquence d’écho de gradient dépouillée et rapide. Les paramètres d’acquisition sont définis de façon à suivre le signal lorsqu’un seul embole de liquide est excité à la fois dans le plan de coupe. Nous avons observé une réduction considérable et reproductible de l’intensité de signal, inversement proportionnelle à la vitesse d’écoulement. Cette relation est hyperbolique, avec un R2 fiable supérieur à 0,97 pour des vitesses élevées. Des essais ont été réalisés afin de tester différentes hypothèses sur l’origine de cette décroissance. Distance à l’antenne de réception, épaisseur de la coupe et temps d’écho, viscosité du liquide et effet des impulsions radiofréquence sur un liquide en mouvement. La relation déterministe entre le signal et la vitesse incite à s’interroger sur la faisabilité d’une méthode de quantification de vitesse basée sur ce processus. Sa résolution temporelle est un atout pour comprendre les propriétés hémodynamiques vasculaires.}
}
@article{WANG2021101250,
title = {The role of user-centered AR instruction in improving novice spatial cognition in a high-precision procedural task},
journal = {Advanced Engineering Informatics},
volume = {47},
pages = {101250},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101250},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621000057},
author = {Zhuo Wang and Xiaoliang Bai and Shusheng Zhang and Mark Billinghurst and Weiping He and Yang Wang and Dong Han and Gong Chen and Jianghong Li},
keywords = {Augmented reality, User-centered design, Spatial cognition, Precision},
abstract = {AR instruction is a kind of virtual information presented on a human–computer interface. It allows users to view the geometric state, spatial relationship, operation method, and other information involved in the physical task, to form the spatial cognition of the current interaction process. At present, AR instructions cannot support high-precision procedural tasks. The reason is that the existing research work is to use visual elements to express the spatial relationship of physical tasks, without considering transforming the long-term accumulated potential experience of advanced users into a series of effective visual features and interaction modes, to promote the new users to quickly conceive the task intention. In this paper, a user-centered AR instruction(UcAI) is defined and tested for the first time in a procedural task. The control experiment and behavior analysis of 30 participants designing two tasks with different operation precision show that UcAI is more beneficial to improve the user's spatial cognitive ability than conventional AR instruction. Especially in the high-precision operation task, UcAI plays an important role. Our research results have a certain guiding significance for advanced AR instruction design, which extends AR technology to physical tasks with high cognitive complexity.}
}
@article{RUEDA2013113,
title = {Single-image super-resolution of brain MR images using overcomplete dictionaries},
journal = {Medical Image Analysis},
volume = {17},
number = {1},
pages = {113-132},
year = {2013},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2012.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1361841512001326},
author = {Andrea Rueda and Norberto Malpica and Eduardo Romero},
keywords = {Image super-resolution, Sparse representation, Principal component analysis, Magnetic resonance imaging},
abstract = {Resolution in Magnetic Resonance (MR) is limited by diverse physical, technological and economical considerations. In conventional medical practice, resolution enhancement is usually performed with bicubic or B-spline interpolations, strongly affecting the accuracy of subsequent processing steps such as segmentation or registration. This paper presents a sparse-based super-resolution method, adapted for easily including prior knowledge, which couples up high and low frequency information so that a high-resolution version of a low-resolution brain MR image is generated. The proposed approach includes a whole-image multi-scale edge analysis and a dimensionality reduction scheme, which results in a remarkable improvement of the computational speed and accuracy, taking nearly 26min to generate a complete 3D high-resolution reconstruction. The method was validated by comparing interpolated and reconstructed versions of 29 MR brain volumes with the original images, acquired in a 3T scanner, obtaining a reduction of 70% in the root mean squared error, an increment of 10.3dB in the peak signal-to-noise ratio, and an agreement of 85% in the binary gray matter segmentations. The proposed method is shown to outperform a recent state-of-the-art algorithm, suggesting a substantial impact in voxel-based morphometry studies.}
}
@article{ZHOU2023112529,
title = {An experimental and kinetic modeling study on the low and intermediate temperatures oxidation of NH3/O2/Ar, NH3/H2/O2/Ar, NH3/CO/O2/Ar, and NH3/CH4/O2/Ar mixtures in a jet-stirred reactor},
journal = {Combustion and Flame},
volume = {248},
pages = {112529},
year = {2023},
issn = {0010-2180},
doi = {https://doi.org/10.1016/j.combustflame.2022.112529},
url = {https://www.sciencedirect.com/science/article/pii/S0010218022005387},
author = {Shangkun Zhou and Wenjun Yang and Shijie Zheng and Shilin Yu and Houzhang Tan and Baochong Cui and Jinhua Wang and Shuanghui Deng and Xuebin Wang},
keywords = {Ammonia, Low temperatures oxidation, Intermediate temperatures oxidation, Jet-stirred reactor, Kinetic modeling, C-N interaction},
abstract = {The oxidation of neat NH3 and co-oxidation of NH3 with H2/CO/CH4 are investigated both experimentally and numerically. Experiments were carried out in a fused silica jet-stirred reactor with a fixed residence time of 1.5 s. Oxidation products of NH3/O2/Ar, NH3/H2/O2/Ar, NH3/CO/O2/Ar, and NH3/CH4/O2/Ar mixtures were measured at various temperatures from 950 K to 1400 K, and equivalence ratios of 0.5∼2.0. A detailed kinetic model was developed and validated by the present experimental data and literature data. The experimental results indicate that NH3 reactivity is promoted by H2 addition below 950 K and by CO/CH4 addition below 1175 K. Kinetic analysis shows that HO2 radical is an important intermediate to trigger the oxidation of NH3. HO2 radicals can be converted into OH radicals through the catalytic cycle reactions of NO+HO2NO2+OH and NO2+HNO+OH, realizing the consumption of NH3. Then NH2 is oxidized by HO2 radicals and NO2 through the pathway of NH2→H2NO→HNO→NO→NO2 for producing more active radicals. H2 can provide a large amount of HO2 and H radicals, and CO relies on the interaction of NH2 and CO (NH2+COHNCO+H) to provide H radicals for achieving the catalytic cycle, while CH4 faces the competition between CH3 and H radicals for NO2 (CH3+NO2CH3O+NO and NO2+HNO+OH), resulting in the ability of H2 to lower the NH3 reactivity onset much stronger than that of CO and CH4. With the increase in temperature, the HO2 radicals tend to inhibit the oxidation of NH3 by the chain-termination reaction of NH2+HO2NH3+O2. The oxidation of NH3 is gradually dominated by the independent interaction of fuels and H/OH/O radicals. H/OH/O radicals promote the conversion of NHi (i = 0, 1, 2) to NO. As a result of the stronger ability to carry H atoms, the most active NO chemistry is found in the co-oxidation of NH3/CH4, while the least active NO chemistry is discovered in the oxidation of neat NH3 for the strong reduction effect of NHi. In stoichiometric conditions, the formation of NO mainly depends on NH radicals, and the formation and reduction of NO by N and NH2 radicals are almost equivalent. In lean conditions, as the importance of NH radicals decrease, the production of NO is mainly dependent on the conversion of NH2 to NO through HNO intermediate.}
}
@article{ANDRIA201357,
title = {A statistical approach for MR and CT images comparison},
journal = {Measurement},
volume = {46},
number = {1},
pages = {57-65},
year = {2013},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2012.05.016},
url = {https://www.sciencedirect.com/science/article/pii/S0263224112002254},
author = {Gregorio Andria and Filippo Attivissimo and Anna Maria Lucia Lanzolla},
keywords = {Biomedical magnetic resonance imaging, Rayleigh scattering, Computer tomography},
abstract = {Recently, many complex medical exams require correlating the information from magnetic resonance (MR) and computed tomography (CT) images in order to obtain a more accurate diagnostics. This is rather complex when the images under test have very different noise level. In this paper, a technique to compare the quality of the CT and MR images is introduced. The proposed technique is useful to assess the effect of different noise distribution on medical images and to equalize the examinations produced by different imagining technologies in terms of clearness of images and sharpness of contours. The authors, after examining the statistical properties of the noise affecting CT and MR images, analyze its effect on final image quality. Then, a methodology to compare the mean square errors relevant to CT and MR images is proposed. The study was carried out using 148 images obtained from patients under neuropsychological test. The experimental tests have been performed by corrupting the original data with different noise levels.}
}
@article{MOURTZIS20211668,
title = {A Methodology for the Assessment of Operator 4.0 Skills based on Sentiment Analysis and Augmented Reality},
journal = {Procedia CIRP},
volume = {104},
pages = {1668-1673},
year = {2021},
note = {54th CIRP CMS 2021 - Towards Digitalized Manufacturing 4.0},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.11.281},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121011793},
author = {Dimitris Mourtzis and John Angelopoulos and Vasilis Siatras and Nikos Panopoulos},
keywords = {Skills, Competencies, Operator 4.0, Augmented Reality, Natural Language Processing},
abstract = {Human-Cyber-Physical Systems are the key to the successful operation of manufacturing systems. Consequently, the need for adequate assessment of human operators and tracking of their skills and competencies evolution emerges. Additionally, the advances in digital technologies encourage the development of supportive and adaptive frameworks for the operation of flexible manufacturing systems. This paper presents an Augmented Reality based methodology for the detailed evaluation of human skills and competencies based on the processing of raw textual data with a Natural Language Processing algorithm, aiming at the provision of technician guidance. The developed framework is tested and validated in an industrial environment.}
}
@article{HU2015332,
title = {Population-based prediction of subject-specific prostate deformation for MR-to-ultrasound image registration},
journal = {Medical Image Analysis},
volume = {26},
number = {1},
pages = {332-344},
year = {2015},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2015.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S1361841515001486},
author = {Yipeng Hu and Eli Gibson and Hashim Uddin Ahmed and Caroline M. Moore and Mark Emberton and Dean C. Barratt},
keywords = {Statistical shape modelling, Organ motion, Tissue deformation, Kernel regression, Image registration},
abstract = {Statistical shape models of soft-tissue organ motion provide a useful means of imposing physical constraints on the displacements allowed during non-rigid image registration, and can be especially useful when registering sparse and/or noisy image data. In this paper, we describe a method for generating a subject-specific statistical shape model that captures prostate deformation for a new subject given independent population data on organ shape and deformation obtained from magnetic resonance (MR) images and biomechanical modelling of tissue deformation due to transrectal ultrasound (TRUS) probe pressure. The characteristics of the models generated using this method are compared with corresponding models based on training data generated directly from subject-specific biomechanical simulations using a leave-one-out cross validation. The accuracy of registering MR and TRUS images of the prostate using the new prostate models was then estimated and compared with published results obtained in our earlier research. No statistically significant difference was found between the specificity and generalisation ability of prostate shape models generated using the two approaches. Furthermore, no statistically significant difference was found between the landmark-based target registration errors (TREs) following registration using different models, with a median (95th percentile) TRE of 2.40 (6.19) mm versus 2.42 (7.15) mm using models generated with the new method versus a model built directly from patient-specific biomechanical simulation data, respectively (N = 800; 8 patient datasets; 100 registrations per patient). We conclude that the proposed method provides a computationally efficient and clinically practical alternative to existing complex methods for modelling and predicting subject-specific prostate deformation, such as biomechanical simulations, for new subjects. The method may also prove useful for generating shape models for other organs, for example, where only limited shape training data from dynamic imaging is available.}
}
@article{KATAHIRA20151595,
title = {Development and Evaluation of a System for AR Enabling Realistic Display of Gripping Motions Using Leap Motion Controller},
journal = {Procedia Computer Science},
volume = {60},
pages = {1595-1603},
year = {2015},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.08.269},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915023960},
author = {Reiji Katahira and Masato Soga},
keywords = {Augmented Reality, depth, Leap Motion Controller, finger, hand, 3Dmodel},
abstract = {Augmented Reality (AR) in the traditional systems have a problem that the drawn objects are always displayed in the foreground because 3D models by AR are superimposed later than the picture of the actual world. This paper proposed a system to produce a realistic picture of AR in accordance with every depth. We developed a prototype system to verify the effect of the method. The prototype system was developed by focusing on a human hand. This paper utilized a Leap Motion Controller as a motion capture device to acquire the depth data of the hand and fingers.}
}
@article{RUMINDO202016,
title = {In vivo estimation of normal left ventricular stiffness and contractility based on routine cine MR acquisition},
journal = {Medical Engineering & Physics},
volume = {85},
pages = {16-26},
year = {2020},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2020.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1350453320301363},
author = {Gerardo Kenny Rumindo and Jacques Ohayon and Pierre Croisille and Patrick Clarysse},
keywords = {Left ventricle model, Finite element analysis, Cine MRI, Myocardial stiffness, Myocardial contractility, Ischemic heart disease},
abstract = {Post-myocardial infarction remodeling process is known to alter the mechanical properties of the heart. Biomechanical parameters, such as tissue stiffness and contractility, would be useful for clinicians to better assess the severity of the diseased heart. However, these parameters are difficult to obtain in the current clinical practice. In this paper, we estimated subject-specific in vivo myocardial stiffness and contractility from 21 healthy volunteers, based on left ventricle models constructed from data acquired from routine cardiac MR acquisition only. The subject-specific biomechanical parameters were quantified using an inverse finite-element modelling approach. The personalized models were evaluated against relevant clinical metrics extracted from the MR data, such as circumferential strain, wall thickness and fractional thickening. We obtained the ranges of healthy biomechanical indices of 1.60 ± 0.22 kPa for left ventricular stiffness and 95.13 ± 14.56 kPa for left ventricular contractility. These reference normal values can be used for future model-based investigation on the stiffness and contractility of ischemic myocardium.}
}
@article{KIM2005121,
title = {Material characterization of MR fluid at high frequencies},
journal = {Journal of Sound and Vibration},
volume = {283},
number = {1},
pages = {121-133},
year = {2005},
issn = {0022-460X},
doi = {https://doi.org/10.1016/j.jsv.2004.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0022460X04003001},
author = {Jaehwan Kim and Kyoung-Mi Park},
abstract = {Magnetorheological (MR) fluid is made of fine iron powders dispersed in silicon oil, which is utilized in many smart structures and devices because of its significant rheological property changes by the applied magnetic field. The evaluation of high frequency characteristics of MR fluids is necessary in many smart structure applications, for example, noise reduction and shock wave attenuation. The characterization of MR fluid is experimentally performed in the frequency range of 50–100kHz. An experimental setup based on wave transmission test is made and the storage and loss moduli of MR fluid are found from the measured speed of sound and attenuation data. To investigate the magnetic field effect, the magnetic fields are applied in parallel and orthogonal directions to the wave propagation direction. The storage modulus of MR fluid trends to be linearly increased with the frequency. The direction effect of magnetic field and the loss factor for MR fluid are discussed.}
}
@article{SRINIVASAN2006283,
title = {A quantitative analysis of the effectiveness of laparascopy and endoscopy virtual reality simulators},
journal = {Computers & Electrical Engineering},
volume = {32},
number = {4},
pages = {283-298},
year = {2006},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2005.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0045790605000996},
author = {Shankar Srinivasan and Dinesh P. Mital and Syed Haque},
keywords = {Virtual reality, Surgical simulators, Training performance, Meta-analysis},
abstract = {The increasing use of virtual reality (VR) simulators in surgical training makes it imperative that definitive studies be performed to assess their training effectiveness. Indeed in this paper we report the meta-analysis of the efficacy of virtual reality simulators in (1) the transference of skills from the simulator training environment to the operating room and (2) their ability to discriminate between the experience levels of its users. The task completion time and the error score were the two study outcomes collated and analyzed in this meta-analysis. Sixteen studies were identified from a computer-based literature search (1996–2004). The meta-analysis of the random-effects model (because of the heterogeneity of the data) revealed that training on virtual reality simulators did lessen the time taken to complete a given surgical task as also clearly differentiate between the experienced and the novice trainees. Meta-analytic studies such as the one reported here would be very helpful in the planning and setting up of surgical training programs and for the establishment of reference ‘learning curves’ for a specific simulator and surgical task. If any such programs already exist they can then indicate the improvements to be made in the simulator used such as providing for more variety in their case scenarios based on the state and/or rate of learning of the trainee.}
}
@article{INATOME20182050,
title = {Development of an AR Drawing System with Point Cloud Data suitable for Real-time Gripping Movement by using Kinect},
journal = {Procedia Computer Science},
volume = {126},
pages = {2050-2057},
year = {2018},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 22nd International Conference, KES-2018, Belgrade, Serbia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.07.247},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918312237},
author = {Hiroki Inatome and Masato Soga},
keywords = {Augmented Reality, Point Cloud Data, Sketch Learning, Human Body Figure},
abstract = {Virtual human figures have been used in the conventional human figure sketch learning support system. A learner selects one of the virtual figures for a motif. However, the learner could not intuitively manipulate the virtual human figure in real time to change the orientation of the figure for learner’s favorite viewpoint. Therefore, in this research, we developed a system to change the orientation of the virtual model of human figure intuitively by using the drawing doll as a tangible interface. Specifically, it uses PCL which can acquire point cloud data by RGB-D camera of KINECT, then it acquires and tracks the three-dimensional coordinates of the real object and superimposes and displays the virtual human figure on the real drawing doll. In the verification experiment tracking accuracy was verified and the improvement of the system was discussed.}
}
@article{CHEN2019416,
title = {ImmerTai: Immersive Motion Learning in VR Environments},
journal = {Journal of Visual Communication and Image Representation},
volume = {58},
pages = {416-427},
year = {2019},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2018.11.039},
url = {https://www.sciencedirect.com/science/article/pii/S1047320318303183},
author = {Xiaoming Chen and Zhibo Chen and Ye Li and Tianyu He and Junhui Hou and Sen Liu and Ying He},
keywords = {Immersive education, Motion training, VR education},
abstract = {Immersive learning in Virtual Reality (VR) environments is the developing trend for future education systems including remote physical training. This paper presents “ImmerTai”, a system that is designed for effective remote motion training, particularly for Chinese Taichi, in an immersive way. With ImmerTai, the Taichi expert’s motion is captured and delivered to remote students in CAVE, HMD and PC environments for learning. The students’ motions are also captured for motion quality assessment and a group of students can form a virtual collaborative learning scenario. We built up a Taichi motion dataset with ground truth of motion quality, and based on this, we developed and evaluated several motion quality assessment methods. Then, user tests were designed and carried out to measure and compare the learning outcomes (learning time, quality and overall efficiency) of students in Cave Automatic Virtual Environment (CAVE), Head Mounted Display (HMD) and Personal Computer (PC) environments. Meanwhile, the connections between students’ learning outcomes and their VR experience were investigated and discussed too. Our results show that ImmerTai can accelerate the learning process of students noticeably (up to 17%) compared to non-immersive learning with the conventional PC setup. However, we observed a substantial difference in the quality of the learnt motion between CAVE (26% gain) and HMD (23% drop) compared to PC (baseline). While strong VR presence can enhance the learning experience of students, their learning outcomes are not fully consistent to their experience. Overall, ImmerTai with CAVE demonstrated a significantly higher learning efficiency than other tested environments.}
}
@article{ISIK2024483,
title = {Integrating extended reality in industrial maintenance: a game-based framework for compressed air system training},
journal = {Procedia Computer Science},
volume = {232},
pages = {483-492},
year = {2024},
note = {5th International Conference on Industry 4.0 and Smart Manufacturing (ISM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.01.048},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924000486},
author = {Birkan Isik and Gulbahar Emir Isik and Miroslav Zilka},
keywords = {Extended reality, Serious game, Maintenance training, Compressed Air System},
abstract = {In industrial environments, maintenance technologies developed under Industry 5.0 are important to ensure trouble-free production and reduce downtime. Compressed Air Systems (CASs) are an integral part of industrial production processes and require competent and correct maintenance. Maintenance personnel should be equipped with continuous and up-to-date training and their knowledge should be tested. There is a significant gap in the field of interactive educational games to improve the technical skills of the care staff, especially in the field of CAS. This research proposes a theoretical framework for a game based on Extended Reality (XR) technologies adapted for CAS maintenance training. The game leverages the trio of Augmented Reality (AR), Virtual Reality (VR), and Mixed Reality (MR) to provide immersive and interactive learning encounters aimed at improving technical proficiency, problem-solving skills, and safety awareness among maintenance workers. The aim is to take advantage of the rewards of game-oriented learning, such as enhanced user engagement and knowledge absorption, to increase the effectiveness of training. In this context, the CAS game framework was created with three frameworks: education, game, and CAS. The study concludes by highlighting the potential benefits, research areas, and technologies that underpin the proposed structure.}
}
@article{WAN2023104940,
title = {Trace analysis using Wi-Fi probe positioning and virtual reality for commercial building complex design},
journal = {Automation in Construction},
volume = {153},
pages = {104940},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.104940},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523002005},
author = {Hongyu Wan and Siyu Wang and Jiachun Du and Li Li and Jing Zhang},
keywords = {Human flow, Trace analysis, Wi-Fi probe, Virtual reality, Design verification, Downtown shopping mall design},
abstract = {The effective management of human flow is critical to the success of complex projects in urban centers, such as shopping malls. However, conventional methods of flow organization, which rely on observation and empirical knowledge, face challenges in fully comprehending the intricate environment. This study proposes an analytical approach to manage human flow in shopping malls in urban centers. A Wi-Fi probe positioning system recorded real-time human flow to assess current movement patterns, while virtual reality (VR) identified issues and optimized the space layout. The Maoye shopping mall in Nanjing experienced a decline in human flow, prompting the need for a new design. The study demonstrates that the Wi-Fi probe positioning system supports the setting of entrances and main corridors during the design phase, while VR tracing evaluates space layout and aids optimization. The study contributes to data-informed design by integrating analytical approaches into the conventional design process.}
}
@article{SAPINSKI2020102324,
title = {Electrical harmonic oscillator with MR damper and energy harvester operating as TMD: Experimental study},
journal = {Mechatronics},
volume = {66},
pages = {102324},
year = {2020},
issn = {0957-4158},
doi = {https://doi.org/10.1016/j.mechatronics.2020.102324},
url = {https://www.sciencedirect.com/science/article/pii/S0957415820300040},
author = {Bogdan Sapiński and Łukasz Jastrzębski and Janusz Gołdasz},
keywords = {TMD, MR damper, Harvester, RLC circuit, Vibration, Resonance},
abstract = {In the study we propose and examine a novel concept, eMR-TMD as we call it, replacing a standard tuned mass damper (TMD) by an electrical harmonic oscillator (RLC circuit). The concept employs an electromagnetic energy harvester (EEH) to extract energy from vibrations, an RLC circuit in which serial resonance phenomenon occurs and a magnetorheological (MR) damper. The approach does not require modifications to the structural part of the system, i.e. no additional mass and spring are needed. The essence of the concept relies on the introduction of a tuned RLC circuit between the EEH coil and the control coil of the MR damper. The RLC circuit parameters we select in such a way so that the electrical resonance frequency is close to or equal mechanical resonance frequency in which the eMR-TMD concept is applicable. Moreover, it is required that the RLC circuit's quality factor is greater than 1 and then the voltage activated the MR damper is higher than the EEH induced voltage at the resonance frequency. Fulfilling the criteria allows tuning the current in the MR damper's control coil so that it is maximized at resonance frequency and minimized at high excitation frequencies. To prove the concept's potential we test the engineered eMR-TMD system experimentally under sinusoidal excitations. We compare the obtained test results with those acquired with the MR damper powered directly from the EEH (dMR-EEH concept) and when the MR damper's control coil is not powered (without TMD concept).}
}
@article{ZHAO201793,
title = {Augmented reality for enhancing tele-robotic system with force feedback},
journal = {Robotics and Autonomous Systems},
volume = {96},
pages = {93-101},
year = {2017},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2017.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S0921889016306066},
author = {Zhou Zhao and Panfeng Huang and Zhenyu Lu and Zhengxiong Liu},
keywords = {Augmented reality, Teleoperation, Robot, Force feedback, Haptic},
abstract = {In the teleoperation, the force feedback is indispensable, which can enhance the sense of presence of the operator and help the operator accomplish tasks comfortably. The time delay is one of the main challenges that influence the stability of the teleoperation systems, which leads to the discontinuous operation. Thus building a local virtual model in the master side is an effective way to solve this problem. In this paper, a new method is presented to reconstruct the virtual model of the remote object. The virtual model can estimate the real-time force feedback to the operator and eliminate the effects of the time delay. Then the tele-robotic system based on augmented reality technology is set up in our laboratory. In the tele-robotic system, the dynamic parameters including damping and stiffness of the virtual model are constantly updated by utilizing the positions and forces information from sensors of the remote robot site. Finally, the effectiveness of the proposed method and the correctness of the visual model parameters are verified by two experiments.}
}
@article{LUO2020105099,
title = {Augmented reality navigation for liver resection with a stereoscopic laparoscope},
journal = {Computer Methods and Programs in Biomedicine},
volume = {187},
pages = {105099},
year = {2020},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2019.105099},
url = {https://www.sciencedirect.com/science/article/pii/S0169260719300422},
author = {Huoling Luo and Dalong Yin and Shugeng Zhang and Deqiang Xiao and Baochun He and Fanzheng Meng and Yanfang Zhang and Wei Cai and Shenghao He and Wenyu Zhang and Qingmao Hu and Hongrui Guo and Shuhang Liang and Shuo Zhou and Shuxun Liu and Linmao Sun and Xiao Guo and Chihua Fang and Lianxin Liu and Fucang Jia},
keywords = {Augmented reality, Laparoscopic surgery, Liver resection, Surgical navigation},
abstract = {Objective
Understanding the three-dimensional (3D) spatial position and orientation of vessels and tumor(s) is vital in laparoscopic liver resection procedures. Augmented reality (AR) techniques can help surgeons see the patient's internal anatomy in conjunction with laparoscopic video images.
Method
In this paper, we present an AR-assisted navigation system for liver resection based on a rigid stereoscopic laparoscope. The stereo image pairs from the laparoscope are used by an unsupervised convolutional network (CNN) framework to estimate depth and generate an intraoperative 3D liver surface. Meanwhile, 3D models of the patient's surgical field are segmented from preoperative CT images using V-Net architecture for volumetric image data in an end-to-end predictive style. A globally optimal iterative closest point (Go-ICP) algorithm is adopted to register the pre- and intraoperative models into a unified coordinate space; then, the preoperative 3D models are superimposed on the live laparoscopic images to provide the surgeon with detailed information about the subsurface of the patient's anatomy, including tumors, their resection margins and vessels.
Results
The proposed navigation system is tested on four laboratory ex vivo porcine livers and five operating theatre in vivo porcine experiments to validate its accuracy. The ex vivo and in vivo reprojection errors (RPE) are 6.04 ± 1.85 mm and 8.73 ± 2.43 mm, respectively.
Conclusion and Significance
Both the qualitative and quantitative results indicate that our AR-assisted navigation system shows promise and has the potential to be highly useful in clinical practice.}
}
@article{LIN2023112471,
title = {A new type of increasingly higher order finite difference and finite volume MR-WENO schemes with adaptive linear weights for hyperbolic conservation laws},
journal = {Journal of Computational Physics},
volume = {493},
pages = {112471},
year = {2023},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2023.112471},
url = {https://www.sciencedirect.com/science/article/pii/S0021999123005661},
author = {Yicheng Lin and Zhenming Wang and Jun Zhu},
keywords = {Multi-resolution WENO scheme, Adaptive linear weights, Hyperbolic conservation laws, Finite difference scheme, Finite volume scheme},
abstract = {In this paper, the new fifth-order, seventh-order, and ninth-order finite difference and finite volume multi-resolution weighted essentially non-oscillatory (MR-WENO) schemes with adaptive linear weights are presented for hyperbolic conservation laws on structured meshes. They are termed as high-order finite difference and finite volume ALW-WENO schemes. These ALW-WENO schemes only apply one small stencil and one large stencil in reconstruction processes, which could achieve the desired accuracy in the region of smoothness and non-oscillatory properties in the region of containing strong shocks. The linear weights that sum to one can be automatically adjusted to any positive numbers. This is the first time that arbitrary high-order finite difference and finite volume WENO schemes are designed by using only two unequal-sized central spatial stencils. The structure of these novel WENO schemes is simple, so it is easier for obtaining high-order accuracy and solving multi-dimensional problems in large scale engineering applications. Compared to traditional MR-WENO schemes with same order, the computational efficiency can be further improved. Some benchmark tests indicate that these new ALW-WENO schemes have good robustness and performance.}
}
@article{VANENGELEN201452,
title = {Experimental and finite element study on the compression properties of Modified Rectangular Fiber-Reinforced Elastomeric Isolators (MR-FREIs)},
journal = {Engineering Structures},
volume = {74},
pages = {52-64},
year = {2014},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2014.04.046},
url = {https://www.sciencedirect.com/science/article/pii/S0141029614002685},
author = {Niel C. {Van Engelen} and Peyman M. Osgooei and Michael J. Tait and Dimitrios Konstantinidis},
keywords = {Fiber-reinforced, Rubber bearing, Base isolation, Modified geometry, 3D finite element analysis, Compression modulus},
abstract = {This study investigates the compressive behavior of Modified Rectangular Fiber-Reinforced Elastomeric Isolators (MR-FREIs). The geometric modifications are introduced to reduce the horizontal stiffness and increase the energy dissipation of the isolation system, allowing long rectangular isolators that provide uniform support along walls to be utilized. It is of critical importance that MR-FREIs maintain adequate vertical stiffness to satisfy the requirements for an isolation system. Experimental data from vertical tests of four rectangular FREIs with and without geometric modifications is used to evaluate a three-dimensional (3D) finite element (FE) model. The 3D FE model is then used to conduct a parametric study on two MR-FREI configurations with varying geometry. The parametric study investigates the effect of the geometric modifications on the vertical stiffness and compression modulus in addition to stress and strain distributions in the elastomer and fiber reinforcement. The study identifies that, similar to annular isolators, introducing a minor geometric modification to the interior of the isolator results in a significant decrease in vertical stiffness and compression modulus. This influence is considerably less for geometric modifications positioned on the exterior of the isolator.}
}
@article{BAUER2017140,
title = {Anatomical augmented reality with 3D commodity tracking and image-space alignment},
journal = {Computers & Graphics},
volume = {69},
pages = {140-153},
year = {2017},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2017.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0097849317301747},
author = {Armelle Bauer and Debanga Raj Neog and Ali-Hamadi Dicko and Dinesh K. Pai and François Faure and Olivier Palombi and Jocelyne Troccaz},
keywords = {User-specific anatomy, Augmented human, Real-time, Motion capture, Augmented reality, Markerless device, Image warping, Handled occlusion and self-occlusion},
abstract = {This paper presents a mirror-like augmented reality (AR) system to display the internal anatomy of the current user. Using a single Microsoft V2.0 Kinect (later on referenced as the Kinect), we animate in real-time a user-specific model of internal anatomy according to the user’s motion and we superimpose it onto the user’s color map. Users can visualize their anatomy moving as if they where looking inside their own bodies in real-time. A new calibration procedure to set up and attach a user-specific anatomy to the Kinect body tracking skeleton is introduced. At calibration time, the bone lengths are estimated using a set of poses. By using Kinect data as input, the practical limitation of skin correspondence in prior work is overcome. The generic 3D anatomical model is attached to the internal anatomy registration skeleton, and warped on the depth image using a novel elastic deformer subject to a closest-point registration force and anatomical constraints. The noise in Kinect outputs precludes direct display of realistic human anatomy. Therefore, to enforce anatomical plausibility, a novel filter to reconstruct plausible motions based on fixed bones lengths as well as realistic angular degrees of freedom (DOFs) and limits are introduced. Anatomical constraints, applied to the Kinect body tracking skeleton joints, are used to maximize the physical plausibility of the anatomy motion while minimizing the distance to the raw data. At run-time, a simulation loop is used to attract the bones toward the raw data. Skinning shaders efficiently drag the resulting anatomy to the user’s tracked motion. Our user-specific internal anatomy model is validated by comparing the skeleton with segmented MRI images. A user study is established to evaluate the believability of the animated anatomy. As an extension of [1], we also propose an image-based algorithm that corrects accumulated inaccuracy of the system steps: motion capture, anatomy transfer, image generation and animation. These inaccuracies show up as occlusion and self-occlusion misalignments of the anatomy regions when superimposed between them and on top of the color map. We also show that the proposed work can efficiently reduce these inaccuracies.}
}
@article{ABDELTAWAB2020101717,
title = {A deep learning-based approach for automatic segmentation and quantification of the left ventricle from cardiac cine MR images},
journal = {Computerized Medical Imaging and Graphics},
volume = {81},
pages = {101717},
year = {2020},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2020.101717},
url = {https://www.sciencedirect.com/science/article/pii/S0895611120300203},
author = {Hisham Abdeltawab and Fahmi Khalifa and Fatma Taher and Norah Saleh Alghamdi and Mohammed Ghazal and Garth Beache and Tamer Mohamed and Robert Keynton and Ayman El-Baz},
keywords = {Cardiac MR, Cardiac parameters, Deep learning, Left ventricle, Segmentation},
abstract = {Cardiac MRI has been widely used for noninvasive assessment of cardiac anatomy and function as well as heart diagnosis. The estimation of physiological heart parameters for heart diagnosis essentially require accurate segmentation of the Left ventricle (LV) from cardiac MRI. Therefore, we propose a novel deep learning approach for the automated segmentation and quantification of the LV from cardiac cine MR images. We aim to achieve lower errors for the estimated heart parameters compared to the previous studies by proposing a novel deep learning segmentation method. Our framework starts by an accurate localization of the LV blood pool center-point using a fully convolutional neural network (FCN) architecture called FCN1. Then, a region of interest (ROI) that contains the LV is extracted from all heart sections. The extracted ROIs are used for the segmentation of LV cavity and myocardium via a novel FCN architecture called FCN2. The FCN2 network has several bottleneck layers and uses less memory footprint than conventional architectures such as U-net. Furthermore, a new loss function called radial loss that minimizes the distance between the predicted and true contours of the LV is introduced into our model. Following myocardial segmentation, functional and mass parameters of the LV are estimated. Automated Cardiac Diagnosis Challenge (ACDC-2017) dataset was used to validate our framework, which gave better segmentation, accurate estimation of cardiac parameters, and produced less error compared to other methods applied on the same dataset. Furthermore, we showed that our segmentation approach generalizes well across different datasets by testing its performance on a locally acquired dataset. To sum up, we propose a deep learning approach that can be translated into a clinical tool for heart diagnosis.}
}
@article{BERNARDINI2023106778,
title = {Can active and passive wayfinding systems support fire evacuation in buildings? Insights from a virtual reality-based experiment},
journal = {Journal of Building Engineering},
volume = {74},
pages = {106778},
year = {2023},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2023.106778},
url = {https://www.sciencedirect.com/science/article/pii/S2352710223009579},
author = {Gabriele Bernardini and Ruggiero Lovreglio and Enrico Quagliarini and Marco D'Orazio},
keywords = {Fire safety, Evacuation, Virtual reality, Wayfinding, Active emergency wayfinding systems, Theory of affordances},
abstract = {Occupant safety in case of building fires depends on the selection of proper evacuation routes. Today, several passive and active Emergency Wayfinding Systems (EWSs) have been proposed to support occupant route choices. Nevertheless, their effectiveness should be accurately assessed before being manufactured and used. In this sense, Virtual Reality (VR) could support the design and preliminary evaluation phases, using the Theory of Affordances to quantitatively verify if the EWSs are correctly visible, understood, and able to support users in fulfilling the evacuation goal. This work hence aims at comparing the efficiency of different EWSs in terms of the Theory of Affordances through a VR experiment involving more than 70 volunteers of different ages. The experimental setup focuses on three types of EWSs (punctual and photoluminescent; passive, continuous and photoluminescent; continuous and active) and lights-on, lights-off and smoke conditions in an educational building. Results mainly indicate that the passive EWSs receive a higher rating while supporting the direction selection, while the active EWS is more effective along mono-directional paths. The work also confirms the capabilities of the proposed combined affordances-based and VR-based approach, boosting future works and suggesting additional comparisons between real-world and VR experiments on emergency wayfinding tasks and systems.}
}
@article{LEE2022106709,
title = {Development of three-dimensional visualisation technology of aerodynamic environment in fattening pig house using CFD and VR technology},
journal = {Computers and Electronics in Agriculture},
volume = {194},
pages = {106709},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2022.106709},
url = {https://www.sciencedirect.com/science/article/pii/S0168169922000266},
author = {Sang-Yeon Lee and Jun-Gyu Kim and Rack-Woo Kim and Uk-Hyeon Yeo and In-Bok Lee},
keywords = {Computational fluid dynamics, Fattening pig house, Visualisation technology, Virtual reality, Virtual reality simulator},
abstract = {In this study, a virtual reality (VR) simulator to visualise the aerodynamic environment of a fattening pig house was developed as educational materials for farmers and consultants. The aerodynamic environments inside a fattening pig house were firstly analysed according to various environmental conditions using computational fluid dynamics (CFD). Using the validated CFD model (Kim et al., 2019), the aerodynamic environment inside the fattening pig house was analysed with 54 cases of environmental conditions in winter and 60 cases of environmental conditions in summer. And then, the VR simulator was developed by visualising the CFD-computed data of aerodynamic environments in virtual space. The three-dimensional fattening pig house models were designed following the CFD-computed cases, and the three-dimensional pig model was developed with real shape and texture. The virtual space was organized by arranging the three-dimensional image models of the fattening pig house and fattening pig. A C language-based code was also used to extract the CFD-computed results for developing visualisation of the aerodynamic environment inside the fattening pig house. Visualisation was realized using contour plot, two-dimensional vector flow, and smoke effect in the virtual space. In the case of the contour plot, a scalar of air temperature, relative humidity, and gas concentration were expressed using color on the active plane. A two-dimensional vector flow represented two-dimensional flows on the active plane. From streamline data, the smoke effect was developed to describe the airflow from the air inlet. In this study, a tablet-shaped user interface (UI) was created so that the user can directly select the desired cases. Through a performance test, the optimal number of frames was determined. Finally, the VR simulator was developed to effectively describe the aerodynamic environments inside the fattening pig house.}
}
@article{OLALDE2013136,
title = {The Importance of Geometry Combined with New Techniques for Augmented Reality},
journal = {Procedia Computer Science},
volume = {25},
pages = {136-143},
year = {2013},
note = {2013 International Conference on Virtual and Augmented Reality in Education},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913012222},
author = {Karle Olalde and Beñat García and Andres Seco},
keywords = {Augmented reality, geometry, geomatics},
abstract = {From the field of the “Geomatics Engineering”[1], better known as “Topographic Engineering” and other fields as “surveyors”, has always driven the knowledge of our environment in order to capture it on a support then allow other users to work, taking decisions on where you’ve never been, and are known early nautical charts, the world map, the cartographic maps of cities and countries, orthophotos and more recently around the digital medium, satellite images, google earth, etc... Augmented reality allows us to make visible developing products that take years but it was very difficult to bring them to the general public (requiring knowledge of cartographic techniques, knowledge of graphic expression, heritage documentation methods, ....) in this article want to show the techniques that allow us to make measurements of complete geometric precision to ensure that the final product is not only attractive but strictly accurate to the real model. We explain how we use robotic total stations with reflectorless measurement, centimeter GPS, 3D scanner, close range photogrammetry[2], all so that our model is strictly accurate. There are models that have intrinsic value in their own actions, no escape ancient Egyptian pyramid is not enough just to model it in an attractive way, but measurements have to be geometrically accurate if you want to test any hypothesis about their mathematical knowledge, astronomical, etc. For all this we believe that both techniques can support each other in achieving the best possible models, augmented reality will showcase showing geometrically exact elements obtained with geomatics techniques that can be displayed to the general public or even to researchers who know they are working real and exact values (an archaeological dig, a pyramid, a sculpture, caves, ...).}
}
@article{MEMIS201983,
title = {A new scheme for automatic 2D detection of spheric and aspheric femoral heads: A case study on coronal MR images of bilateral hip joints of patients with Legg-Calve-Perthes disease},
journal = {Computer Methods and Programs in Biomedicine},
volume = {175},
pages = {83-93},
year = {2019},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2019.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169260718311581},
author = {Abbas Memiş and Songül Albayrak and Fuat Bilgili},
keywords = {Femoral head detection, MR image segmentation, Medical image analysis, Legg-Calve-Perthes disease, Circular hough transform, Integro-differential operator},
abstract = {Background and objective
In orthopaedics, hip joint and circular structure of the femoral head can be distorted by a wide variety of hip joint disorders. Hence, automatic detection and segmentation of the femoral head is an important issue in the studies of computerized hip joint segmentation, quantification and assessment. In the proposed study, we need to detect the center coordinates and radius of spheric and aspheric femoral heads automatically in bilateral hip magnetic resonance (MR) images using a new scheme.
Methods
This paper presents a new two-level scheme based on the Circular Hough Transform (CHT) and Integro-differential Operator (IDO) to detect the spheric and aspheric femoral heads in MR images in 2D. Initially, MR slices are divided vertically into two equal halves to automatically separate the hip joints and Canny’s edge detection method is performed on each of the halves to obtain edge images. Then, healthy and pathological femoral heads are detected by performing the CHT over edge images in the first stage of proposed scheme. In the second stage, femoral head circle detected with CHT is fine tuned by performing Daugman’s IDO.
Results
Performance evaluations of the proposed femoral head detection scheme were carried out on healthy and pathological hip joints in 24 coronal MR image sections belong to 13 patients with Legg-Calve-Perthes Disease (LCPD). In performance evaluations on 24 healthy and 24 pathological hip joints, Root Mean Square Error (RMSE) and Dice Similarity Coefficient (DSC) values were measured for automatically detected femoral heads. We observed 1.96 mm. (std. 1.21 mm.) mean RMSE for center coordinates, 1.45 mm. (std. 1.39 mm) mean RMSE for radii, 0.8978 (std. 0.0733) mean DSC on healthy femoral heads and 3.56 mm. (std. 3.19 mm.) mean RMSE for center coordinates, 1.56 mm. (std. 1.33 mm.) mean RMSE for radii, 0.8529 (std. 0.0927) mean DSC on pathological femoral heads.
Conclusions
Proposed femoral head detection scheme has promising results for the detection and the segmentation of the spheric and aspheric femoral heads and also has a potential to be used in detection of the other anatomical structures having a circular shape.}
}
@article{SUNDARESAN2021102184,
title = {Triplanar ensemble U-Net model for white matter hyperintensities segmentation on MR images},
journal = {Medical Image Analysis},
volume = {73},
pages = {102184},
year = {2021},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2021.102184},
url = {https://www.sciencedirect.com/science/article/pii/S1361841521002309},
author = {Vaanathi Sundaresan and Giovanna Zamboni and Peter M. Rothwell and Mark Jenkinson and Ludovica Griffanti},
keywords = {Deep learning, White matter hyperintensities, U-Nets, Segmentation, MRI},
abstract = {White matter hyperintensities (WMHs) have been associated with various cerebrovascular and neurodegenerative diseases. Reliable quantification of WMHs is essential for understanding their clinical impact in normal and pathological populations. Automated segmentation of WMHs is highly challenging due to heterogeneity in WMH characteristics between deep and periventricular white matter, presence of artefacts and differences in the pathology and demographics of populations. In this work, we propose an ensemble triplanar network that combines the predictions from three different planes of brain MR images to provide an accurate WMH segmentation. In the loss functions the network uses anatomical information regarding WMH spatial distribution in loss functions, to improve the efficiency of segmentation and to overcome the contrast variations between deep and periventricular WMHs. We evaluated our method on 5 datasets, of which 3 are part of a publicly available dataset (training data for MICCAI WMH Segmentation Challenge 2017 - MWSC 2017) consisting of subjects from three different cohorts, and we also submitted our method to MWSC 2017 to be evaluated on the unseen test datasets. On evaluating our method separately in deep and periventricular regions, we observed robust and comparable performance in both regions. Our method performed better than most of the existing methods, including FSL BIANCA, and on par with the top ranking deep learning methods of MWSC 2017.}
}
@article{XUE2022102346,
title = {2D probabilistic undersampling pattern optimization for MR image reconstruction},
journal = {Medical Image Analysis},
volume = {77},
pages = {102346},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2021.102346},
url = {https://www.sciencedirect.com/science/article/pii/S1361841521003911},
author = {Shengke Xue and Zhaowei Cheng and Guangxu Han and Chaoliang Sun and Ke Fang and Yingchao Liu and Jian Cheng and Xinyu Jin and Ruiliang Bai},
keywords = {Magnetic resonance imaging, Undersampling, Probability distribution, Deep learning},
abstract = {With 3D magnetic resonance imaging (MRI), a tradeoff exists between higher image quality and shorter scan time. One way to solve this problem is to reconstruct high-quality MRI images from undersampled k-space. There have been many recent studies exploring effective k-space undersampling patterns and designing MRI reconstruction methods from undersampled k-space, which are two necessary steps. Most studies separately considered these two steps, although in theory, their performance is dependent on each other. In this study, we propose a joint optimization model, trained end-to-end, to simultaneously optimize the undersampling pattern in the Fourier domain and the reconstruction model in the image domain. A 2D probabilistic undersampling layer was designed to optimize the undersampling pattern and probability distribution in a differentiable manner. A 2D inverse Fourier transform layer was implemented to connect the Fourier domain and the image domain during the forward and back propagation. Finally, we discovered an optimized relationship between the probability distribution of the undersampling pattern and its corresponding sampling rate. Further testing was performed using 3D T1-weighted MR images of the brain from the MICCAI 2013 Grand Challenge on Multi-Atlas Labeling dataset and locally acquired brain 3D T1-weighted MR images of healthy volunteers and contrast-enhanced 3D T1-weighted MR images of high-grade glioma patients. The results showed that the recovered MR images using our 2D probabilistic undersampling pattern (with or without the reconstruction network) significantly outperformed those using the existing start-of-the-art undersampling strategies for both qualitative and quantitative comparison, suggesting the advantages and some extent of the generalization of our proposed method.}
}
@article{CHERVYAKOV20191080,
title = {AR-RRNS: Configurable reliable distributed data storage systems for Internet of Things to ensure security},
journal = {Future Generation Computer Systems},
volume = {92},
pages = {1080-1092},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.09.061},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17306015},
author = {Nikolay Chervyakov and Mikhail Babenko and Andrei Tchernykh and Nikolay Kucherov and Vanessa Miranda-López and Jorge M. Cortés-Mendoza},
keywords = {Big data storage, Multi-cloud, Internet of Things, Resource management, Security, Safety, Reliability, Residue number system},
abstract = {Benefits of Internet of Things and cloud–fog-edge computing are associated with the risks of confidentiality, integrity, and availability related with the loss of information, denial of access for a long time, information leakage, conspiracy and technical failures. In this article, we propose a configurable, reliable, and confidential distributed data storage scheme with the ability to process encrypted data and control results of computations. Our system utilizes Redundant Residue Number System (RRNS) with new method of error correction codes and secret sharing schemes. We introduce the concept of an approximate value of a rank of a number (AR), which allows us to reduce the computational complexity of the decoding from RNS to binary representation, and size of the coefficients. Based on the properties of the approximate value and arithmetic properties of RNS, we introduce AR-RRNS method for error detection, correction, and controlling computational results. We provide a theoretical basis to configure probability of information loss, data redundancy, speed of encoding and decoding to cope with different objective preferences, workloads, and storage properties. Theoretical analysis shows that by appropriate selection of RRNS parameters, the proposed scheme allows not only increasing safety, reliability, and reducing an overhead of data storage, but also processing of encrypted data.}
}
@article{MANARIKKAL2021108314,
title = {Diagnostics and prognostics of planetary gearbox using CWT, auto regression (AR) and K-means algorithm},
journal = {Applied Acoustics},
volume = {184},
pages = {108314},
year = {2021},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2021.108314},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X21004084},
author = {Imthiyas Manarikkal and Faris Elasha and David Mba},
keywords = {Condition monitoring, Auto regression modelling, Continuous wavelet transforms, Fault classification, Prognostics, Diagnostics},
abstract = {Condition monitoring of machine is recognized as effective strategy for undertaking the maintenance in wide variety of industries. Planetary gearbox is a critical component in helicopters, wind turbines, hybrid vehicles and so forth. Planetary gearbox are complex in nature due to its size and meshing components. Condition monitoring and fault diagnosis of planetary gearbox is challenging due to complexity in dependable fault extraction from raw vibration signal. The mechanism of planetary gearbox is complex as there are several gears meshing at the same time. To find out the nature of fault and defective component in planetary gearbox is difficult. In this paper, the fault detection and fault type identification diagnostic approach using auto regression model (AR) and continuous wavelet transforms (CWT) by considering different frequency range is established. The experimental research conducted with different type of fault vibration signals in the gearbox have been diagnosed and identified the fault type using AR Modelling, Impulse and Shape Factor for validation purposes. The unique behaviors and fault characteristics of planetary gearboxes are identified and analyzed. The fault frequency identification and extraction of features from the non-stationary signals in different fault severity level of vibration data demonstrates the reliability of proposed method. The developed algorithm adds efficacy in detecting the nature of fault and defective component without performing a visual inspection.}
}
@article{GUI20121565,
title = {Morphology-driven automatic segmentation of MR images of the neonatal brain},
journal = {Medical Image Analysis},
volume = {16},
number = {8},
pages = {1565-1579},
year = {2012},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2012.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1361841512000989},
author = {Laura Gui and Radoslaw Lisowski and Tamara Faundez and Petra S. Hüppi and François Lazeyras and Michel Kocher},
keywords = {Automatic segmentation, Magnetic resonance imaging, Neonatal brain, Watershed segmentation, Mathematical morphology},
abstract = {The segmentation of MR images of the neonatal brain is an essential step in the study and evaluation of infant brain development. State-of-the-art methods for adult brain MRI segmentation are not applicable to the neonatal brain, due to large differences in structure and tissue properties between newborn and adult brains. Existing newborn brain MRI segmentation methods either rely on manual interaction or require the use of atlases or templates, which unavoidably introduces a bias of the results towards the population that was used to derive the atlases. We propose a different approach for the segmentation of neonatal brain MRI, based on the infusion of high-level brain morphology knowledge, regarding relative tissue location, connectivity and structure. Our method does not require manual interaction, or the use of an atlas, and the generality of its priors makes it applicable to different neonatal populations, while avoiding atlas-related bias. The proposed algorithm segments the brain both globally (intracranial cavity, cerebellum, brainstem and the two hemispheres) and at tissue level (cortical and subcortical gray matter, myelinated and unmyelinated white matter, and cerebrospinal fluid). We validate our algorithm through visual inspection by medical experts, as well as by quantitative comparisons that demonstrate good agreement with expert manual segmentations. The algorithm’s robustness is verified by testing on variable quality images acquired on different machines, and on subjects with variable anatomy (enlarged ventricles, preterm- vs. term-born).}
}
@article{BORSCI201517,
title = {Empirical evidence, evaluation criteria and challenges for the effectiveness of virtual and mixed reality tools for training operators of car service maintenance},
journal = {Computers in Industry},
volume = {67},
pages = {17-26},
year = {2015},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2014.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0166361514002073},
author = {Simone Borsci and Glyn Lawson and Simon Broome},
keywords = {Augmented and virtual reality, Automotive, Service maintenance, Training effectiveness, Training evaluation},
abstract = {The debate on effectiveness of virtual and mixed reality (VR/MR) tools for training professionals and operators is long-running with prominent contributions arguing that there are several shortfalls of experimental approaches and assessment criteria reported within the literature. In the automotive context, although car-makers were pioneers in the use of VR/MR tools for supporting designers, researchers started only recently to explore the effectiveness of VR/MR systems as mean for driving external operators of service centres to acquire the procedural skills necessary for car maintenance processes. In fact, from 463 journal articles on VR/MR tools for training published in the last thirty years, we identified only eight articles in which researchers experimentally tested the effectiveness of VR/MR tools for training service operators’ skills. To survey the current findings and the deficiencies of these eight studies, we use two main drivers: (i) a well-known framework of organizational training programmes, and (ii) a list of eleven evaluation criteria widely applied by researchers of different fields for assessing the effectiveness of training carried out with VR/MR systems. The analysis that we present allows us to: (i) identify a trend among automotive researchers of focusing their analysis only on car service operators’ performance in terms of time and errors, by leaving unexplored important pre- and post-training aspects that could affect the effectiveness of VR/MR tools to deliver training contents – e.g., people skills, previous experience, cibersickness, presence and engagement, usability and satisfaction and (ii) outline the future challenges for designing and assessing VR/MR tools for training car service operators.}
}
@article{CHEN2017437,
title = {Assessing the use of immersive virtual reality, mouse and touchscreen in pointing and dragging-and-dropping tasks among young, middle-aged and older adults},
journal = {Applied Ergonomics},
volume = {65},
pages = {437-448},
year = {2017},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2017.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0003687017300728},
author = {Jiayin Chen and Calvin Or},
keywords = {Virtual reality, Human-computer interaction, Older adults},
abstract = {This study assessed the use of an immersive virtual reality (VR), a mouse and a touchscreen for one-directional pointing, multi-directional pointing, and dragging-and-dropping tasks involving targets of smaller and larger widths by young (n = 18; 18–30 years), middle-aged (n = 18; 40–55 years) and older adults (n = 18; 65–75 years). A three-way, mixed-factorial design was used for data collection. The dependent variables were the movement time required and the error rate. Our main findings were that the participants took more time and made more errors in using the VR input interface than in using the mouse or the touchscreen. This pattern applied in all three age groups in all tasks, except for multi-directional pointing with a larger target width among the older group. Overall, older adults took longer to complete the tasks and made more errors than young or middle-aged adults. Larger target widths yielded shorter movement times and lower error rates in pointing tasks, but larger targets yielded higher rates of error in dragging-and-dropping tasks. Our study indicated that any other virtual environments that are similar to those we tested may be more suitable for displaying scenes than for manipulating objects that are small and require fine control. Although interacting with VR is relatively difficult, especially for older adults, there is still potential for older adults to adapt to that interface. Furthermore, adjusting the width of objects according to the type of manipulation required might be an effective way to promote performance.}
}
@article{ABDI2015242,
title = {In-Vehicle Augmented Reality Traffic Information System: A New Type of Communication Between Driver and Vehicle},
journal = {Procedia Computer Science},
volume = {73},
pages = {242-249},
year = {2015},
note = {International Conference on Advanced Wireless Information and Communication Technologies (AWICT 2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.12.024},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915034857},
author = {Lotfi Abdi and Faten Ben Abdallah and Aref Meddeb},
keywords = {Augmented Reality, Region Of Interest, Driving-Safety, Head-up Display, Camera Calibration, Traffic Information, OpenCV.},
abstract = {In order to improve driving safety and minimize driving workload, the information provided should be represented in such a way that it is more easily understood and imposing less cognitive load onto the driver. Augmented Reality Head-up Display (AR- HUD) can facilitate a new form of dialogue between the vehicle and the driver; and enhance intelligent transportation systems by superimposing surrounding traffic information on the users view and keep drivers view on roads. In this paper, we investigated the potential costs and benefits of using AR cues to improve driving safety as new form of dialog between the vehicle and the driver. We present a new approach for marker-less AR Traffics Signs Recognition system that superimposes augmented virtual objects onto a real scene under all types of driving situations, including unfavorable weather conditions. Our method uses two steps: hypothesis generation and hypothesis verification. In the first step, Region Of Interest (ROI) is extracted using a scanning window with Haar cascade detector and AdaBoost classifier to reduce the computational region in the hypothesis generation step. The second step verifies whether a given candidate and classified into vehicle and non-vehicle classes using edge information and symmetry measurement to verify them. We employ this approach to improve the accuracy of AR traffic information system to assist the driver in various driving situations, increase the driving comfort and reduce traffic accidents.}
}
@article{LIANG2023296,
title = {A Visual Reasoning-based AR-HUD Service Design Approach for Better Driving Experience},
journal = {Procedia CIRP},
volume = {119},
pages = {296-301},
year = {2023},
note = {The 33rd CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2023.02.136},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123004675},
author = {Yongshi Liang and Pai Zheng and Liqiao Xia},
keywords = {Smart product-service system, augmented reality head-up display, visual reasoning, value co-creation, smart driving},
abstract = {Smart traffic or transportation, as a critical part of realizing the smart city, utilizes various smart product-service systems to support it. Among them, the augmented reality head-up display (AR-HUD) system is a typical smart driving solution, which projects vital information about driving situations with pre-defined AR graphics onto the windshield of vehicles. The AR-HUD service design attracts increasing concerns owing to its enhancement of drivers’ situational awareness without glancing down at the instrument cluster. Nevertheless, current in-car AR-HUDs only stack some simple driving information from sensors, such as the driving speed. It's difficult to meet the demand of drivers since they ignore a higher level of drivers’ situation awareness, i.e., driving situation prediction and recommendation of driving advice. To overcome the challenge, this paper proposes a visual reasoning-based service design approach for advancing AR-HUDs’ digital servitization and better user experience. Additionally, drivers are involved in the service design development in a value co-creation manner through human-computer interaction design. With the combination of experiential driving knowledge and cognitive intelligence computing on the driving scene, the proposed novel service design approach enables AR-HUD to percept driving scenarios and infer good strategies accordingly. Finally, an illustrative example is carried out to validate the feasibility of the proposed AR-HUD service design approach.}
}
@article{PEPERKORN2015542,
title = {Temporal dynamics in the relation between presence and fear in virtual reality},
journal = {Computers in Human Behavior},
volume = {48},
pages = {542-547},
year = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.02.028},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215001260},
author = {Henrik M. Peperkorn and Julia Diemer and Andreas Mühlberger},
keywords = {Virtual reality, Presence, Exposure therapy, Behavioral avoidance test, Anxiety disorders, Specific phobia},
abstract = {Virtual reality (VR) is increasingly investigated as a new medium for exposure therapy, but process variables are not well understood. In particular, presence and fear during VR exposure correlate strongly, but the causal relationship between them remains unclear. We assigned 22 female spider-fearful participants randomly to either a stereoscopic (high presence) or a monoscopic (low presence) condition and exposed them repeatedly to a large virtual spider presented on a Powerwall. Presence and fear were assessed on subjective, physiological, and behavioral levels. Fear reactions were stronger and presence ratings were higher in the stereoscopic than the monoscopic condition. Presence in the first exposure trial correlated significantly with fear in the second exposure trial, while fear in the first exposure trial did not correlate significantly with presence in the second exposure trial. For the following exposure trials, correlations between presence and fear were significant in both directions. Limitations of our study include the small sample and the fact that we did not check diagnostic criteria of specific phobia. This is the first study to show temporal dynamics of the relationship between presence and fear. Initially, presence in VR seems to directly influence fear, while over time, presence and fear appear mutually dependent.}
}
@article{JENA2021104293,
title = {Maximum 3D Tsallis entropy based multilevel thresholding of brain MR image using attacking Manta Ray foraging optimization},
journal = {Engineering Applications of Artificial Intelligence},
volume = {103},
pages = {104293},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104293},
url = {https://www.sciencedirect.com/science/article/pii/S0952197621001408},
author = {Bibekananda Jena and Manoj Kumar Naik and Rutuparna Panda and Ajith Abraham},
keywords = {Machine intelligence, Soft computing, Multilevel thresholding, Brain MRI},
abstract = {Nevertheless, the accuracy of a multilevel image thresholding technique using 1D or 2D Tsallis entropy is limited. To overcome this, we propose a maximum 3D Tsallis entropy-based multilevel thresholding method. The idea of 3D Tsallis entropy is introduced. Opposed to the 1D/2D Tsallis entropy, the 3D Tsallis entropy-based approach is more robust, it performs well even in the case of the low signal-to-noise-ratio and contrast. Manta Ray Foraging Optimization (MRFO) algorithm is a newly introduced algorithm to solve the optimization problem by imitating the foraging technique of Manta Ray fish in the ocean using a mathematical model. Due to insufficient energy levels of search agents in MRFO, they fail to avoid local minima and fall on it. To make the algorithm more effective for the segmentation application, we introduce a new algorithm coined as attacking Manta Ray foraging optimization (AMRFO). A set of classical benchmark functions together with composite functions (CEC 2014) is used to validate the proposed AMRFO algorithm. Statistical analysis is implicitly carried out using Wilcoxon’s signed-rank test and Friedman’s mean rank test. Interestingly, the results show that the proposed AMRFO is superior to the state-of-the-art optimization algorithms. Moreover, the proposed method is also compared with 1D/2D Tsallis entropy-based approaches. To experiment, 100 test images from the AANLIB MR Image dataset are considered. Our method outperforms 1D/2D Tsallis entropy-based approaches. The proposed scheme would be useful for the segmentation of multi-spectral color images.}
}
@article{PALMARINI2018350,
title = {Designing an AR interface to improve trust in Human-Robots collaboration},
journal = {Procedia CIRP},
volume = {70},
pages = {350-355},
year = {2018},
note = {28th CIRP Design Conference 2018, 23-25 May 2018, Nantes, France},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2018.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S2212827118300155},
author = {Riccardo Palmarini and Iñigo Fernandez {del Amo} and Guglielmo Bertolino and Gino Dini and John Ahmet Erkoyuncu and Rajkumar Roy and Michael Farnsworth},
keywords = {Augmented Reality, robot, digital engineering},
abstract = {In a global, e-commerce marketplace, product customisation is driven towards manufacturing flexibility. Conventional caged robots are designed for high volume and low mix production cannot always comply with the increasing low volume and high customisation requirements. In this scenario, the interest in collaborative robots is growing. A critical aspect of Human-Robot Collaboration (HRC) is human trust in robots. This research focuses on increasing the human confidence and trust in robots by designing an Augmented Reality (AR) interface for HRC. The variable affecting the trust involved in HRC have been estimated. These have been utilised for designing the AR-HRC. The proposed design aims to provide situational awareness and spatial dialog. The AR-HRC developed has been tested on 15 participants which have performed a “pick-and-place” task. The results show that the utilisation of AR in the proposed scenario positively affects the human trust in robot. The human-robot collaboration enhanced by AR are more natural and effective. The trust has been measured through an empirical psychometric method also presented in this paper.}
}
@article{SAKTHIVEL201874,
title = {Influence of Cd on optical and photoluminescence behavior of Zn0.98-xCdxMn0.02S quantum dots under Ar atmosphere},
journal = {Optik},
volume = {154},
pages = {74-82},
year = {2018},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2017.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S0030402617312093},
author = {P. Sakthivel and T. Jayasri and J. Madhumitha and S. Mahalakshmi and N. Subhashini},
keywords = {Cd, Mn doped ZnS, Co-precipitation method, Energy gap, Photoluminescence},
abstract = {In the present study, Zn0.98-xMn0.02CdxS (x=0, 0.02 and 0.04) quantum dots have been successfully synthesized using co-precipitation method. X-ray diffraction (XRD) study confirmed substitution of Cd, Mn well in ZnS host with existing cubic structure. The average size of the particles was measured from XRD pattern and it was ∼2nm. The SEM study was taken to reveal the surface morphology of the samples. EDX spectra evidenced the existence of Cd, Mn, Zn and S in the samples as per the targeted stoichiometry. FTIR spectra confirmed the presence of peaks which corresponding to molecules present in the samples. UV–visible absorption and transmission spectra were studied and high intensity of absorption was received for the higher composition of Cd. A huge suppression was noticed in transmission peaks during Cd addition. When 2% of Cd added with Mn: ZnS, A small blue shift was identified and got redshift for higher concentration of Cd. Band gap values were tuned from 3.79eV to 3.98eV and discussed based on the quantum confinement effect. From this tailoring of band gap and optical property, these materials shall be selected for optoelectronic device applications. A room temperature photoluminescence study was carried out and sharp as well as strong UV band emissions were observed. Blue and green emission bands were also exhibited by Cd doping. The variations in luminescence intensities were discussed in terms of the crystallite size and defect state formation.}
}
@article{HUANG200814755,
title = {Senseless Maneuver Optimal Washout Filter Design with Human Vestibular Based (HVB) for VR-based Motion Simulator},
journal = {IFAC Proceedings Volumes},
volume = {41},
number = {2},
pages = {14755-14760},
year = {2008},
note = {17th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20080706-5-KR-1001.02498},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016413637},
author = {Chin-I Huang and Li-Chen Fu},
abstract = {In this paper, we propose a new approach “HVB senseless maneuver optimal washout filter” which is based on human vestibular system, senseless maneuver and motion platform limitation for designing washout filter such that a cost function constraining the pilot sensation error (between simulator and vehicle) is minimized. This approach can curtail over strong feelings of pilot reception and increase efficiency of platform workspace for task running. Finally, the experimental results confirm the effectiveness of our algorithm hereby proposed. Moreover, the results show that a better performance can be attained.}
}
@article{LI2021107886,
title = {Research on environmental comfort and cognitive performance based on EEG+VR+LEC evaluation method in underground space},
journal = {Building and Environment},
volume = {198},
pages = {107886},
year = {2021},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2021.107886},
url = {https://www.sciencedirect.com/science/article/pii/S0360132321002924},
author = {Junjie Li and Wei Wu and Yichun Jin and Ruyue Zhao and Wenyan Bian},
keywords = {EEG, VR, LEC, Human perception feedback, Building environment},
abstract = {Significant research on space has been conducted to stimulate the potential of the environment to positively impact the human body and accurately optimize the quality of the living environment. In underground spaces, there is a reduced ability to connect with the outdoor natural environment; thus, it is very important to study methods of optimizing the quality of underground space by exploring people's feelings as they relate to the built environment. This study adopted an electroencephalogram (EEG) + virtual reality (VR) + laboratory environmental control (LEC) method to simulate the underground building environment, explore the mechanisms operating between building space information and human perception feedback, and reveal the laws of interaction between the two. The space prototype was a typical independent underground office space. Three experimental scenes were created using VR. An EEG test, blood oxygen rhythm evaluation, and subjective questionnaire were employed to identify the influence of the space on environmental comfort and cognitive performance. Through an analysis of the EEG energy distribution, CP6 was found to be the most significant active degree. Regarding regional distribution, the active areas of the scene elements were located in the posterior and central zones. Additionally, by analyzing the EEG rhythm, a correlational relationship between β H/β L and cognitive performance was identified. The results strongly indicate that in different scenes, subjects' cognitive performance was affected by changes in the environment. Therefore, this study provides accurate reference information for designers of architectural spaces, based on user satisfaction and physical and mental health.}
}
@article{LI202373,
title = {X-Space: Interaction design of extending mixed reality space from Web2D visualization},
journal = {Visual Informatics},
volume = {7},
number = {4},
pages = {73-83},
year = {2023},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2023.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X23000463},
author = {Tiemeng Li and Songqian Wu and Yanning Jin and Haopai Shi and Shiran Liu},
keywords = {Mobile and ubiquitous visualization, Visualization system and toolkit design, Immersive analytic, Information data visualization, Human–computer interaction},
abstract = {Mixed reality offers a larger visualization space and more intuitive means of interaction for data exploration, and many works have been dedicated to combining 2D visualizations on screen with mixe reality. However, for each combination, we need to customize the implementation of the corresponding mixed reality 3D visualization. It is a challenge to simplify this development process and enable agile building of mixed reality 3D visualizations for 2D visualizations. In addition, many existing 2D visualizations do not provide interfaces oriented to immersive analytics, so how to extend the mixed reality 3D space from existing 2D visualizations is another challenge. This work presents an agile and flexible approach to interactively transfer visualizations from 2D screens to mixed reality 3D spaces. We designed an interactive process for spatial generation of mixed-reality 3D visualizations, defined a unified data transfer framework, integrated data deconstruction techniques for 2D visualizations, implemented interfaces to immersive visualization building tool-kits, and encapsulated these techniques into a tool named X-Space. We validated that the approach is feasible and effective through 2D visualization cases including scatter plots, stacked bar charts, and adjacency matrix. Finally, we conducted expert interviews to discuss the usability and value of the method.}
}
@article{GE201960,
title = {Multi-stream multi-scale deep convolutional networks for Alzheimer’s disease detection using MR images},
journal = {Neurocomputing},
volume = {350},
pages = {60-69},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.04.023},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219305478},
author = {Chenjie Ge and Qixun Qu and Irene Yu-Hua Gu and Asgeir Store Jakola},
keywords = {Alzheimer’s disease detection, MR images, Deep learning, Deep convolutional networks, Multi-scale feature learning, Feature fusion, Tissue region, Feature boosting and dimension reduction},
abstract = {This paper addresses the issue of Alzheimer’s disease (AD) detection from Magnetic Resonance Images (MRIs). Existing AD detection methods rely on global feature learning from the whole brain scans, while depending on the tissue types, AD related features in different tissue regions, e.g. grey matter (GM), white matter (WM), and cerebrospinal fluid (CSF), show different characteristics. In this paper, we propose a deep learning method for multi-scale feature learning based on segmented tissue areas. A novel deep 3D multi-scale convolutional network scheme is proposed to generate multi-resolution features for AD detection. The proposed scheme employs several parallel 3D multi-scale convolutional networks, each applying to individual tissue regions (GM, WM and CSF) followed by feature fusions. The proposed fusion is applied in two separate levels: the first level fusion is applied on different scales within the same tissue region, and the second level is on different tissue regions. To further reduce the dimensions of features and mitigate overfitting, a feature boosting and dimension reduction method, XGBoost, is utilized before the classification. The proposed deep learning scheme has been tested on a moderate open dataset of ADNI (1198 scans from 337 subjects), with excellent test performance on randomly partitioned datasets (best 99.67%, average 98.29%), and good test performance on subject-separated partitioned datasets (best 94.74%, average 89.51%). Comparisons with state-of-the-art methods are also included.}
}
@article{LANGLOTZ2011831,
title = {Robust detection and tracking of annotations for outdoor augmented reality browsing},
journal = {Computers & Graphics},
volume = {35},
number = {4},
pages = {831-840},
year = {2011},
note = {Semantic 3D Media and Content},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2011.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0097849311001075},
author = {Tobias Langlotz and Claus Degendorfer and Alessandro Mulloni and Gerhard Schall and Gerhard Reitmayr and Dieter Schmalstieg},
keywords = {Augmented reality, Annotation, Tracking, Mobile phone},
abstract = {A common goal of outdoor augmented reality (AR) is the presentation of annotations that are registered to anchor points in the real world. We present an enhanced approach for registering and tracking such anchor points, which is suitable for current generation mobile phones and can also successfully deal with the wide variety of viewing conditions encountered in real life outdoor use. The approach is based on on-the-fly generation of panoramic images by sweeping the camera over the scene. The panoramas are then used for stable orientation tracking, while the user is performing only rotational movements. This basic approach is improved by several new techniques for the re-detection and tracking of anchor points. For the re-detection, specifically after temporal variations, we first compute a panoramic image with extended dynamic range, which can better represent varying illumination conditions. The panorama is then searched for known anchor points, while orientation tracking continues uninterrupted. We then use information from an internal orientation sensor to prime an active search scheme for the anchor points, which improves matching results. Finally, global consistency is enhanced by statistical estimation of a global rotation that minimizes the overall position error of anchor points when transforming them from the source panorama in which they were created, to the current view represented by a new panorama. Once the anchor points are redetected, we track the user's movement using a novel 3-degree-of-freedom orientation tracking approach that combines vision tracking with the absolute orientation from inertial and magnetic sensors. We tested our system using an AR campus guide as an example application and provide detailed results for our approach using an off-the-shelf smartphone. Results show that the re-detection rate is improved by a factor of 2 compared to previous work and reaches almost 90% for a wide variety of test cases while still keeping the ability to run at interactive frame rates.}
}
@article{SZALKOWSKI2021104917,
title = {Synthetic digital reconstructed radiographs for MR-only robotic stereotactic radiation therapy: A proof of concept},
journal = {Computers in Biology and Medicine},
volume = {138},
pages = {104917},
year = {2021},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.104917},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521007113},
author = {Gregory Szalkowski and Dong Nie and Tong Zhu and Pew-Thian Yap and Jun Lian},
keywords = {Synthetic CT, Robotic radiotherapy, Deep learning},
abstract = {Purpose
To create synthetic CTs and digital reconstructed radiographs (DRRs) from MR images that allow for fiducial visualization and accurate dose calculation for MR-only radiosurgery.
Methods
We developed a machine learning model to create synthetic CTs from pelvic MRs for prostate treatments. This model has been previously proven to generate synthetic CTs with accuracy on par or better than alternate methods, such as atlas-based registration. Our dataset consisted of 11 paired CT and conventional MR (T2) images used for previous CyberKnife (Accuray, Inc) radiotherapy treatments. The MR images were pre-processed to mimic the appearance of fiducial-enhancing images. Two models were trained for each parameter case, using a sub-set of the available image pairs, with the remaining images set aside for testing and validation of the model to identify the optimal patch size and number of image pairs used for training. Four models were then trained using the identified parameters and used to generate synthetic CTs, which in turn were used to generate DRRs at angles 45° and 315°, as would be used for a CyberKnife treatment. The synthetic CTs and DRRs were compared visually and using the mean squared error and peak signal-to-noise ratio against the ground-truth images to evaluate their similarity.
Results
The synthetic CTs, as well as the DRRs generated from them, gave similar visualization of the fiducial markers in the prostate as the true counterparts. There was no significant difference found for the fiducial localization for the CTs and DRRs. Across the 8 DRRs analyzed, the mean MSE between the normalized true and synthetic DRRs was 0.66 ± 0.42% and the mean PSNR for this region was 22.9 ± 3.7 dB. For the full CTs, the mean MAE was 72.9 ± 88.1 HU and the mean PSNR was 31.2 ± 2.2 dB.
Conclusions
Our machine learning-based method provides a proof of concept of a way to generate synthetic CTs and DRRs for accurate dose calculation and fiducial localization for use in radiation treatment of the prostate.}
}
@article{CHAN2023105042,
title = {A comparative analysis of digital health usage intentions towards the adoption of virtual reality in telerehabilitation},
journal = {International Journal of Medical Informatics},
volume = {174},
pages = {105042},
year = {2023},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2023.105042},
url = {https://www.sciencedirect.com/science/article/pii/S1386505623000606},
author = {Yee Kiu Chan and Yuk Ming Tang and Long Teng},
keywords = {Telerehabilitation, Virtual reality, Behavioral intention, E-rehabilitation, Digital health},
abstract = {Background
With the rapid development of the metaverse and the problem of non-attendance in traditional rehabilitation, virtual reality in telerehabilitation has become increasingly vital in modern medicine. However, research on determining predictors that influence the public's behavioral intention to adopt VR-based telerehabilitation has not been extensively studied.
Objective
This study aims to propose a new research model with a comparative analysis on understanding factors affecting the public's behavioral intention to adopt VR in telerehabilitation for different user groups.
Methods
A total of 215 respondents from the general public completed an online questionnaire to validate the proposed research model. The collected data was analyzed using SPSS and AMOS. The proposed model was additionally validated using CFA and multiple linear regression.
Results
This study found that effort expectancy, threat appraisals, and trust had a positive significant influence on the public’s behavioral intention to adopt VR in telerehabilitation. However, performance expectancy and facilitating conditions had no significant relationship with behavioral intention. Notably, the average of the primary factors for older adults was generally higher than for younger adults.
Conclusions
The present study confirms the applicability of the proposed research model. Our findings contribute up-to-date insights for related stakeholders to minimize implementation failures and develop successful adoption strategies for the future expansion of telerehabilitation.}
}
@article{DATTEO2017317,
title = {Statistical pattern recognition approach for long-time monitoring of the G.Meazza stadium by means of AR models and PCA},
journal = {Engineering Structures},
volume = {153},
pages = {317-333},
year = {2017},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2017.10.022},
url = {https://www.sciencedirect.com/science/article/pii/S014102961730384X},
author = {Alessio Datteo and Francescantonio Lucà and Giorgio Busca},
keywords = {Statistical pattern recognition, Autoregressive models, Principal component analysis, Structural health monitoring, Environmental conditions, Operational conditions},
abstract = {In recent years, the interest for the automatic evaluation of the state of civil structures is increased. The development of Structural Health Monitoring is allowed by the low costs of the hardware and the improving of the computational capacity of computers that can analyze considerable amount of data in short time. A Structural Health Monitoring (SHM) system should continuously monitor structures, extracting and processing relevant information, to efficiently allocate the resources for maintenance and ensure the security of the structure. Considering the latest developments in this field, great attention has been paid to data-based approaches, especially to autoregressive models; these econometric models, born in the field of finance, are usually used to analyze the vibration time series provided by the sensors applied on the monitored structures. Indexes based on these autoregressive models can be used as features by which the structural integrity can be assessed. This work proposes the application of a multivariable analysis, Principal Component Analysis (PCA), to the set of the autoregressive model parameters estimated on the vibration responses of a real structure under operational conditions. This approach reduces a complex set of data to a lower dimension, by representing the behavior of the structure through the few variables. This work uses the principal components of the autoregressive model parameters as indicators that can effectively describe different operational levels and some important environmental effects. The strategy is applied for the first time on the data collected by the long-time monitoring system installed on the stands of the G. Meazza stadium in Milan. The results will show that this procedure is effective in representing the status of the structure and can be used in a structural health monitoring prospective.}
}
@article{HIGUERATRUJILLO2017398,
title = {Psychological and physiological human responses to simulated and real environments: A comparison between Photographs, 360° Panoramas, and Virtual Reality},
journal = {Applied Ergonomics},
volume = {65},
pages = {398-409},
year = {2017},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2017.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0003687017301175},
author = {Juan Luis Higuera-Trujillo and Juan {López-Tarruella Maldonado} and Carmen {Llinares Millán}},
keywords = {Virtual reality, 360° Panorama, Validity, Psychological human responses, Physiological human responses},
abstract = {Psychological research into human factors frequently uses simulations to study the relationship between human behaviour and the environment. Their validity depends on their similarity with the physical environments. This paper aims to validate three environmental-simulation display formats: photographs, 360° panoramas, and virtual reality. To do this we compared the psychological and physiological responses evoked by simulated environments set-ups to those from a physical environment setup; we also assessed the users' sense of presence. Analysis show that 360° panoramas offer the closest to reality results according to the participants' psychological responses, and virtual reality according to the physiological responses. Correlations between the feeling of presence and physiological and other psychological responses were also observed. These results may be of interest to researchers using environmental-simulation technologies currently available in order to replicate the experience of physical environments.}
}
@article{MASTMEYER2016161,
title = {Efficient patient modeling for visuo-haptic VR simulation using a generic patient atlas},
journal = {Computer Methods and Programs in Biomedicine},
volume = {132},
pages = {161-175},
year = {2016},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2016.04.017},
url = {https://www.sciencedirect.com/science/article/pii/S0169260715300729},
author = {Andre Mastmeyer and Dirk Fortmeier and Heinz Handels},
keywords = {Virtual reality simulation, Efficient CT image segmentation, Atlas-based segmentation, Full body segmentation, Cloud computing},
abstract = {Background and Objective
This work presents a new time-saving virtual patient modeling system by way of example for an existing visuo-haptic training and planning virtual reality (VR) system for percutaneous transhepatic cholangio-drainage (PTCD).
Methods
Our modeling process is based on a generic patient atlas to start with. It is defined by organ-specific optimized models, method modules and parameters, i.e. mainly individual segmentation masks, transfer functions to fill the gaps between the masks and intensity image data. In this contribution, we show how generic patient atlases can be generalized to new patient data. The methodology consists of patient-specific, locally-adaptive transfer functions and dedicated modeling methods such as multi-atlas segmentation, vessel filtering and spline-modeling.
Results
Our full image volume segmentation algorithm yields median DICE coefficients of 0.98, 0.93, 0.82, 0.74, 0.51 and 0.48 regarding soft-tissue, liver, bone, skin, blood and bile vessels for ten test patients and three selected reference patients. Compared to standard slice-wise manual contouring time saving is remarkable.
Conclusions
Our segmentation process shows out efficiency and robustness for upper abdominal puncture simulation systems. This marks a significant step toward establishing patient-specific training and hands-on planning systems in a clinical environment.}
}
@article{TAN201763,
title = {Towards large-scale MR thigh image analysis via an integrated quantification framework},
journal = {Neurocomputing},
volume = {229},
pages = {63-76},
year = {2017},
note = {Advances in computing techniques for big medical image data},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2016.05.108},
url = {https://www.sciencedirect.com/science/article/pii/S0925231216313698},
author = {Chaowei Tan and Kang Li and Zhennan Yan and Jingru Yi and Pengxiang Wu and Hui Jing Yu and Klaus Engelke and Dimitris N. Metaxas},
keywords = {Radiographic knee osteoarthritis, Inter- and intra-muscular adipose tissue, Fascia lata, Individual skeletal muscles, Femur extraction, Data-driven and sparsity-constrained deformable segmentation, Joint label fusion based multi-atlas labeling, Temporal related changes of thigh tissue},
abstract = {In this paper, we focus on large scale magnetic resonance (MR) thigh image analysis via accurately quantifying major tissue composition in the thigh by a novel integrated framework. Specifically, the framework is able to distinguish muscular tissue and different types of adipose tissues, i.e. subcutaneous adipose tissue(SAT), inter- and intra-muscular adipose tissue (IMAT and IAMAT), efficiently. Deformable models and learning based techniques are integrated in the novel framework to enable robust quantification. Importantly, extensive evaluations are conducted on a large set of 3D MR thigh volumes from longitudinal studies of hundreds of subjects to investigate radiographic osteoarthritis (OA) related changes of muscular and adipose tissue volumes. The analysis is constructed by two subcohorts (G1 and G2). G2 has 61 patients which keep healthy at baseline (BL) and 48 months (M48), while G1's 85 patients are healthy at BL but have knee OA at M48. Paired t-tests are used to investigate the changes of these tissue size over time passing with/without pathological progression. The experimental results show that, in G1, patients' IMAT and IAMAT are statistically significant respectively, yet G2 has no such variation in the same tissue type. Thus we conclude from the statistical analysis that age may not directly affect thigh tissues, but IMAT and IAMAT may have obvious changes in patients with knee OA.}
}
@article{BIAN2007171,
title = {A STUDY ON TRACKING ERROR ESTIMATION FOR AUGMENTED REALITY},
journal = {IFAC Proceedings Volumes},
volume = {40},
number = {16},
pages = {171-176},
year = {2007},
note = {10th IFAC,IFIP,IFORS,IEA Symposium on Analysis, Design, and Evaluation of Human-Machine Systems},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20070904-3-KR-2922.00030},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015327798},
author = {Zhiqiang Bian and Hirotake Ishii and Hiroshi Shimoda},
keywords = {Augmented reality, tracking accuracy, tracking error estimation method, Marker Arrangement, design system, evaluation method, industrial plant, maintenance support, linecode marker},
abstract = {Improvement of tracking accuracy is an important issue when applying augmented reality to nuclear power plant fieldwork. Tracking accuracy depends highly on the marker arrangement when employing a tracking method using a camera and markers. For those reasons, this study develops a wheel tracking error computation method to compute the tracking error from the marker arrangement and errors in the screen coordinate. An evaluation experiment was conducted using a kind of linecode markers developed before. Experimental results show that the tracking error computation is reliable and the speed of the tracking error computation is affordable to be applied in real time error estimation in NPP field work support.}
}
@article{NWOBODO20234344,
title = {A review on tracking head movement in augmented reality systems},
journal = {Procedia Computer Science},
volume = {225},
pages = {4344-4353},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.431},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923015892},
author = {Onyeka J. Nwobodo and Kamil Wereszczyński and Krzysztof Cyran},
keywords = {Head tracking, augmented reality, deep learning, DOF, immersive experience, pose estimation},
abstract = {This paper reviews the recent development of augmented reality (AR) head-tracking techniques. AR is an emerging technology that provides users with digital augmentation layered on the real-life environment. AR systems use tracking to maintain the point of reference and enable the device to follow the user's movements and position within the physical world. Head-tracking is a crucial component of AR that inputs and interprets the movement of the device and the user's physical location in real-time. The main challenge in head-tracking is the appearance change that results from head rotation, which necessitates high accuracy and long-range tracking in a noisy environment. Latency and errors in head-tracking can reduce the system's overall effectiveness and cause jarring or unsettling effects for the user. This paper's contribution is to shed light on the best methods for tracking and registering in augmented reality, which will guide future advancements in the field. The review covers recent work proposed to improve head-tracking performance and reduce latency, highlighting the challenges and future directions of head-tracking techniques in AR.}
}
@article{WEI2021106117,
title = {A deep learning approach for 2D ultrasound and 3D CT/MR image registration in liver tumor ablation},
journal = {Computer Methods and Programs in Biomedicine},
volume = {206},
pages = {106117},
year = {2021},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2021.106117},
url = {https://www.sciencedirect.com/science/article/pii/S0169260721001929},
author = {Wei WEI and Xu Haishan and Julian Alpers and Marko Rak and Christian Hansen},
keywords = {Slice-to-volume, Ultrasound, Image registration, Image classification, Image segmentation},
abstract = {Background and Objective
Liver tumor ablation is often guided by ultrasound (US). Due to poor image quality, intraoperative US is fused with preoperative computed tomography or magnetic tomography (CT/MR) images to provide visual guidance. As of today, the underlying 2D US to 3D CT/MR registration problem remains a very challenging task.
Methods
We propose a novel pipeline to address this registration problem. Contrary to previous work, we do not formulate the problem as a regression task, which - for the given registration problem - achieves a low performance regarding accuracy and robustness due to the limited US soft-tissue contrast and the inter-patient variability on liver vessels. Instead, we first estimate the US probe angle roughly by using a classification network. Given this coarse initialization, we then improve the registration by formulation of the problem as a segmentation task, estimating the US plane in the 3D CT/MR through segmentation.
Results
We benchmark our approach on 1035 clinical images from 52 patients, yielding average registration errors of 11.6° and 4.7 mm, which outperforms the state of the art SVR method[1].
Conclusion
Our results show the efficiency of the proposed registration pipeline, which has potential to improve the robustness and accuracy of intraoperative patient registration.}
}
@article{PENUMUDI2020103010,
title = {The effects of target location on musculoskeletal load, task performance, and subjective discomfort during virtual reality interactions},
journal = {Applied Ergonomics},
volume = {84},
pages = {103010},
year = {2020},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2019.103010},
url = {https://www.sciencedirect.com/science/article/pii/S0003687019302194},
author = {Sai Akhil Penumudi and Veera Aneesh Kuppam and Jeong Ho Kim and Jaejin Hwang},
keywords = {Virtual environment, Hand gestures, Head-mounted display, Task performance},
abstract = {The objective of this study was to evaluate the effect of different target locations on musculoskeletal loading and task performance during virtual reality (VR) interactions. A repeated-measures laboratory study with 20 participants (24.2 ± 1.5 years; 10 males) was conducted to compare biomechanical exposures (joint angle, moment, and muscle activity in the neck and shoulder), subjective discomfort, and task performance (speed and accuracy) during two VR tasks (omni-directional pointing and painting tasks) among different vertical target locations (ranged from 15° above to 30° below eye height). The results showed that neck flexion/extension angle and moment, shoulder flexion angle and moment, shoulder abduction angle, muscle activities of neck and shoulder muscles, and subjective discomfort in the neck and shoulder significantly varied by target locations (p's < 0.001). The target locations at 15° above and 30° below eye height demonstrated greater shoulder flexion (up to 52°), neck flexion moment (up to 2.7Nm), anterior deltoid muscle activity, and subjective discomfort in the neck and shoulder as compared to the other locations. This result indicates that excessive vertical target locations should be avoided to reduce musculoskeletal discomfort and injury risks during VR interactions. Based on relatively lower biomechanical exposures and trade-off between neck and shoulder postures, vertical target location between eye height and 15° below eye height could be recommended for VR use.}
}
@article{WANG2006314,
title = {Compatibility issues in Augmented Reality systems for AEC: An experimental prototype study},
journal = {Automation in Construction},
volume = {15},
number = {3},
pages = {314-326},
year = {2006},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2005.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0926580505000671},
author = {Xiangyu Wang and Phillip S. Dunston},
keywords = {Augmented Reality, Compatibility, Human factors, Mixed Reality},
abstract = {While human factors have been well researched in virtual environments, it has not received commensurate consideration in Mixed Reality (MR) research. This paper (1) analyzes the feasibility of augmenting human abilities via MR applications in construction tasks from the perspective of cognitive engineering, (2) acknowledges the ergonomics features and research issues in MR systems, and (3) generates partial guidelines to solve ergonomics issues. Also, perceptual incompatibility was validated through an experiment comparing a head mounted display versus a desktop monitor in performing an orientation task. The perceptual incompatibility by using the monitor was significant regarding performance time, accuracy and workload.}
}
@article{MALCZEWSKI2020100302,
title = {Super-Resolution with compressively sensed MR/PET signals at its input},
journal = {Informatics in Medicine Unlocked},
volume = {18},
pages = {100302},
year = {2020},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2020.100302},
url = {https://www.sciencedirect.com/science/article/pii/S2352914819304186},
author = {Krzysztof Malczewski},
keywords = {MRI, PET, Super-resolution, Compressed sensing},
abstract = {The aim of this paper is to present a highly effective Magnetic Resonance Imaging- Positron Emission Tomography (MR/PET) image reconstruction strategy allowing for simultaneous resolution enhancing and scanning time minimisation. The presented algorithm employs the combined sparsity, compressed sensing (CS) theory and super resolution to achieve high-resolution output maintaining data collecting steps at the lowest possible levels. This paper presents a very promising application of super-resolution of highly sensitively compressed MR/PET raw data. The presented algorithm nests image priors, deblurring, and a discrete dense displacement sampling for the deformable registration of high-resolution images at its core. Data from preliminary trials can also be valuable in providing background information useful in reducing examinations times. In accordance with expectations, the presented algorithm can enhance image resolution without any hardware modifications. However, the motion estimation algorithm can drastically eliminate diagnostic image artifacts that increase the chances of a correct diagnosis. The robustness of the suggested algorithm was subjected to state-of-the art image resolution enhancement algorithms: 3D kernel regression, Enhanced Deep Residual Networks for Single Image Super-Resolution, Image Super-Resolution Using Very Deep Residual Channel Attention Networks, Residual Dense Network for Image Super-Resolution. It is worth underlining that combining Compressed Sensing with its conjugate symmetry, as well as Partial Fourier methodology leads to data acquisition acceleration when compared to the different and unmodified k-space sampling patterns. It can be clearly seen that the obtained improvements have led to much better sharpness, edge interpretations, and contrast. Moreover, the accomplishments have been validated by PSNR. In accordance with expectations, the presented algorithm is able to enhance image resolution without any hardware adjustments. Besides the resolution tradeoffs, this method is able to minimise motion artifacts what is especially important for effective physician-to-physician communication and unbiased diagnosis.}
}
@article{IMOTTESJO2018120,
title = {The Urban CoBuilder – A mobile augmented reality tool for crowd-sourced simulation of emergent urban development patterns: Requirements, prototyping and assessment},
journal = {Computers, Environment and Urban Systems},
volume = {71},
pages = {120-130},
year = {2018},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2018.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0198971517305008},
author = {Hyekyung Imottesjo and Jaan-Henrik Kain},
keywords = {Urban design and planning, Emergent planning, Multi-stakeholder inclusion, Outdoor mobile augmented reality, Urban simulative game},
abstract = {Policy and research argue for multi-stakeholder inclusion in design and planning to increase urban qualities and resilience. Communicative planning and agent-based modelling are two approaches facilitating such inclusion, but both have shortcomings. In this paper, a third complementary approach is explored: rule-based emergent planning supported through mobile augmented reality (MAR) and gamification. Such an approach would serve to crowdsource data on how people collectively build their city under different types of planning rules, mimicking emergent development patterns but, currently, there is a lack of functioning participative outdoor MAR tools. The objectives of this paper are to a) identify a set of specifications detailing the necessary performance of a MAR tool; b) describe the development of a prototype MAR tool; and c) assess this prototype MAR tool through pilot application. A literature review was carried out to identify tool requirements. An iterative research by design approach was applied to turn these specifications into a functioning MAR tool: the Urban CoBuilder. The tool was then piloted in a series of tests. The findings suggest that the MAR tool makes it possible for multiple stakeholders to design urban environments on site and that crowdsourced data on collective results of individual design and planning decisions can be gathered. Although the immersive qualities of the Urban CoBuilder were highly appreciated, further development is needed. The realism of planning rules, building types and functions has to be strengthened, the techniques for positioning the MAR model in relation to real space need improvement, and the gaming mechanisms should be enhanced to make gameplay attractive for a large number of stakeholders.}
}
@article{CAI201937,
title = {The influences of Ar-He shielding gas mixture on welding characteristics of fiber laser-MIG hybrid welding of aluminum alloy},
journal = {Optics & Laser Technology},
volume = {113},
pages = {37-45},
year = {2019},
issn = {0030-3992},
doi = {https://doi.org/10.1016/j.optlastec.2018.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0030399218313185},
author = {Chuang Cai and Shuang He and Hui Chen and Weihua Zhang},
keywords = {Laser-MIG hybrid welding of aluminum alloy, Ar-He shielding gas mixture, Plasma spectra, Weld penetration depth, Porosity defect},
abstract = {During laser or laser-arc hybrid welding process of aluminum alloy, laser power waste and keyhole fluctuation are drastic due to the shielding effect of dense plasma. Consequently, small weld penetration depth and numerous weld porosity defects are produced. In the present work, Ar-He shielding gas mixture was used to improve the weld quality of fiber laser-metal inert gas (MIG) hybrid welded aluminum alloy. The influences of Ar-He shielding gas mixtures with various He volume ratios on plasma temperature, electron density, weld penetration depth and porosity defect were investigated, respectively. The He volume ratio enough for improving the weld penetration depth and suppressing the porosity defect was 50%. The effective laser power density increased with the increasing He volume ratio, which contributed to the increase of weld penetration depth. The weld porosity defects were suppressed efficiently, since the stability of the keyhole was improved while using Ar-He shielding gas mixture.}
}
@article{BORGERS2010377,
title = {A virtual reality tool to measure shoppers’ tenant mix preferences},
journal = {Computers, Environment and Urban Systems},
volume = {34},
number = {5},
pages = {377-388},
year = {2010},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2010.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0198971510000359},
author = {Aloys Borgers and Menno Brouwer and Tristan Kunen and Joran Jessurun and Ingrid Janssen},
keywords = {Virtual reality, Shopping centres, Tenant mix, Measuring preferences},
abstract = {Tenant mix is an important key to the success of a shopping centre. Rules dictating the ideal tenant mix are still based on assumptions about consumer preferences and consumer behaviour. However, research into consumers’ tenant mix preferences seems to become more prominent in this context. As standard questionnaires are inadequate to measure preferences regarding the locational components of tenant mix, the purpose of this project is to develop and test an enhanced virtual reality tool to elicit shoppers’ preferences regarding tenant mix. The tool can be used in the case of designing or developing new shopping centres as well as in the case of refurbishing or restructuring existing shopping centres. A prototype version of the VR-tool has been tested in a real world context. A Dutch neighbourhood centre, planned to be refurbished in the near future, was selected as a test case. The findings show that the VR-tool can be used to measure shoppers’ preferences regarding tenant selection and tenant placement. Taking into consideration these preferences may increase the attractiveness of a shopping centre, and therewith the competitive position of the centre in the region.}
}
@article{WILLIAMS2024106522,
title = {Viscoelastic polyacrylamide MR elastography phantoms with tunable damping ratio independent of shear stiffness},
journal = {Journal of the Mechanical Behavior of Biomedical Materials},
volume = {154},
pages = {106522},
year = {2024},
issn = {1751-6161},
doi = {https://doi.org/10.1016/j.jmbbm.2024.106522},
url = {https://www.sciencedirect.com/science/article/pii/S1751616124001541},
author = {L. Tyler Williams and Zheng Cao and Ali H. Lateef and Matthew D.J. McGarry and Elise A. Corbin and Curtis L. Johnson},
keywords = {Elastography, Phantoms, Viscosity, Rheometry, Hydrogel},
abstract = {Physiologically modeled test samples with known properties and characteristics, or phantoms, are essential for developing sensitive, repeatable, and accurate quantitative MRI techniques. Magnetic resonance elastography (MRE) is one such technique used to estimate tissue mechanical properties, and it is advantageous to use phantoms with independently tunable mechanical properties to benchmark the accuracy of MRE methods. Phantoms with tunable shear stiffness are commonly used for MRE, but tuning the viscosity or damping ratio has proven to be difficult. A promising candidate for MRE phantoms with tunable damping ratio is polyacrylamide (PAA). While pure PAA has very low attenuation, viscoelastic hydrogels have been made by entrapping linear polyacrylamide strands (LPAA) within the PAA network. In this study, we evaluate the use of LPAA/PAA gels as physiologically accurate phantoms with tunable damping ratio, independent of shear stiffness, via MRE. Phantoms were made with 15.3 wt% PAA while the LPAA concentration ranged from 4.5 wt% to 8.0 wt%. MRE was performed at 9.4 T with 400 Hz vibration on all phantoms revealing a strong, positive correlation between damping ratio and LPAA content (p < 0.001). There was no significant correlation between shear stiffness and LPAA content, confirming a constant PAA concentration yielded constant shear stiffness. Rheometry at 10 Hz was performed to verify the damping ratio of the phantoms. Nearly identical slopes for damping ratio versus LPAA content were found from both MRE and rheometry (0.0073 and 0.0075 respectively). Ultimately, this study validates the adaptation of polyacrylamide gels into physiologically-relevant MRE phantoms to enable testing of MRE estimates of damping ratio.}
}
@article{LEE2004719,
title = {Development of a virtual reality environment for somatosensory and perceptual stimulation in the balance assessment of children},
journal = {Computers in Biology and Medicine},
volume = {34},
number = {8},
pages = {719-733},
year = {2004},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2003.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0010482503001021},
author = {Hsiao-Yu Lee and Rong-Ju Cherng and Chi-Hsuan Lin},
keywords = {Virtual reality, Balance, Sensory organization test, Singular value decomposition},
abstract = {In this study, we developed a balance assessment system in which the visual stimulus was generated by a virtual reality (VR) technique and somatosensation was obtained from a movable platform. By standing on the movable platform, the center of pressure (COP) was measured to express the subject's postural control in response to varied visual stimuli. From the COP data, a singular value decomposition technique was used to derive the sway area and direction, represented in a polar form. Our system demonstrated the feasibility of using a VR environment in postural control trials and provided more realistic somatosensory and visual inputs.}
}
@article{ALFAIFI2022101836,
title = {Petrology and kinematic vorticity constraints of the Al Amar region, Northern Ar-Rayn terrane, Eastern Arabian shield, Saudi Arabia},
journal = {Journal of King Saud University - Science},
volume = {34},
number = {3},
pages = {101836},
year = {2022},
issn = {1018-3647},
doi = {https://doi.org/10.1016/j.jksus.2022.101836},
url = {https://www.sciencedirect.com/science/article/pii/S1018364722000179},
author = {Hussain J. {Al Faifi} and Lami Mohammed and Abdel Aziz Mohamed {Al Bassam} and Osama M.K. Kassem},
keywords = {Petrology, Kinematic analysis, Al Amar region, Ar-Rayn terrane, Arabian Shield},
abstract = {The Neoproterozoic basement rocks in Ar Rayn terrane set as parts in the Eastern Arabian Shield. It focus the petrological and kinematic vorticity for high deformed volcanic and granitoids rocks in the Al-Amar locality. The volcanic rocks divide into two main series, the eastern sequence cycle represents dacite, rhyodacite, rhyolite and ignimbrites, and the western sequence cycle characterizes andesite and pyroclastics. Furthermore, the granitoids rocks content monzodiorite, tonalite, granodiorite and alkali-feldspar granite. For assessing the proportions of pure and simple shear contributions in penetrative deformed rocks, the kinematic vorticity number (Wm) to the mean appreciation by applying porphyroclast, rotating in a flowing matrix is crucial. In the Ar Rayn terrane of Arabian shield, kinematic vorticity numbers for high deformed metavolcanics and granitoids gneisses vary from 0.4 to 0.6. The deformation in the studied area varied from simple shear, according to vorticity and strain studies. Nappe stacking getting ready during the thrusting activity only through the Al Amar –Idsas fault, according to the results, most likely due to brittle imbrication. A penetrative sub-horizontal foliation formed sub-parallel to the nappe contacts with the beneath laying nappes, showing that the ductile strain was superimposed on the construction of the nappe under high pressure. The Ar Rayn terranewas created sub-horizontal foliation by the buildup of ductile strain during under plating, which was induced by a vertical shortening component. This foliation was formed in the majority of cases during the thrusting nappes upon each other, implying that nappe stacking was related to vertical shortening due to a massive scale by the active Al Amar –Ideas fault.}
}
@article{HUANG2021104565,
title = {Modeling and simulating nonstationary thunderstorm winds based on multivariate AR-GARCH},
journal = {Journal of Wind Engineering and Industrial Aerodynamics},
volume = {211},
pages = {104565},
year = {2021},
issn = {0167-6105},
doi = {https://doi.org/10.1016/j.jweia.2021.104565},
url = {https://www.sciencedirect.com/science/article/pii/S0167610521000519},
author = {Guoqing Huang and Ruili Liu and Min Liu and Haitao Zheng},
keywords = {Simulation, Multivariate nonstationary thunderstorm winds, Autoregressive-generalized autoregressive conditional heteroskedasticity model},
abstract = {Extreme winds such as thunderstorm winds typically exhibit nonstationary characteristics. When these winds act on the structure, the time domain analysis method is used considering the structural and/or aerodynamic nonlinearity in the wind-induced structural response analysis. Because the time domain analysis method needs a sufficient number of wind speed samples, the efficient simulation of nonstationary winds becomes a crucial task. The time series method is more suitable in generating the nonstationary process due to the high efficiency. As a typical time series model, the autoregressive-generalized autoregressive conditional heteroskedasticity (AR-GARCH) model could be a good candidate to characterize these samples. In this paper, the method based on the multivariate AR-GARCH model is proposed to model and simulate the multivariate nonstationary wind speed process. Specifically, Baba-Engle-Kraft-Kroner (BEKK) model is adopted since it can maintain the positive definiteness of conditional covariance matrix. The numerical simulations based on samples with different time-varying variances obtained by spectral representation method (SRM) are given to demonstrate the applicability of the proposed method. The measured thunderstorm wind speed is adopted to illustrate and validate the accuracy of the proposed method. The results show that the time-varying variance and cross correlation can be satisfactorily maintained.}
}
@article{CHEN2021105952,
title = {Augmented reality navigation for minimally invasive knee surgery using enhanced arthroscopy},
journal = {Computer Methods and Programs in Biomedicine},
volume = {201},
pages = {105952},
year = {2021},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2021.105952},
url = {https://www.sciencedirect.com/science/article/pii/S0169260721000274},
author = {Fang Chen and Xiwen Cui and Boxuan Han and Jia Liu and Xinran Zhang and Hongen Liao},
keywords = {Knee surgery, Augmented reality, Arthroscopic image, Enhanced information},
abstract = {Purpose
During the minimally invasive knee surgery, surgeons insert surgical instruments and arthroscopy through small incisions, and implement treatment assisted by 2D arthroscopic images. However, this 2D arthroscopic navigation faces several problems. Firstly, the guidance information is displayed on a screen away from the surgical area, which makes hand/eye coordination difficult. Secondly, the small incision limits the surgeons to view the internal knee structures only from an arthroscopic camera. In addition, arthroscopic images commonly appear obscure visions.
Methods
To solve these problems, we proposed a novel in-situ augmented reality navigation system with the enhanced arthroscopic information. Firstly, intraoperative anatomical locations were obtained by using arthroscopic images and arthroscopy calibration. Secondly, tissue properties-based model deformation method was proposed to update the 3D preoperative knee model with anatomical location information. Then, the updated model was further rendered with glasses-free real 3D display for achieving the global in-situ augmented reality view. In addition, virtual arthroscopic images were generated from the updated preoperative model to provide the anatomical information of the operation area.
Results
Experimental results demonstrated that virtual arthroscopic images could reflect the correct structure information with a mean error of 0.32 mm. Compared with 2D arthroscopic navigation, the proposed augmented reality navigation reduced the targeting errors by 2.10 mm and 2.70 mm for the experiments of knee phantom and in-vitro swine knee, respectively.
Conclusion
Our navigation method is helpful for minimally invasive knee surgery since it can provide the global in-situ information and detail anatomical information.}
}
@article{RATTS20001667,
title = {Thermal modeling of controlled atmosphere brazing process using virtual reality technology},
journal = {Applied Thermal Engineering},
volume = {20},
number = {17},
pages = {1667-1678},
year = {2000},
issn = {1359-4311},
doi = {https://doi.org/10.1016/S1359-4311(99)00086-1},
url = {https://www.sciencedirect.com/science/article/pii/S1359431199000861},
author = {Eric B. Ratts and Yi Lu Murphey and Youning Zhou},
keywords = {Brazing, Virtual reality, Heat transfer, Heat exchanger},
abstract = {In the automotive industry, heat exchangers are manufactured in large quantities. The controlled atmosphere brazing (CAB) process is one of the fastest growing processes for aluminum radiator production behind vacuum brazing and machine assembly process. In this paper, we describe a thermal model (HETCAB) to predict the transient temperature distribution in an aluminum heat exchanger while it is being brazed in a CAB furnace. This thermal model is simulated using a virtual CAB (VR CAB) furnace created using virtual reality technology. Within this VR CAB furnace, engineers can “walk” through the furnace, observe the dynamic heat exchange, manipulate the products inside the furnace, and test various parameters critical to the process. The VR CAB together with the thermal model provides a realistically simulated environment that enables engineers to control and improve the heat exchange processes, experiment with design parameters, and study the effects of various process parameters including the parameters that control product yield.}
}
@article{YEH201830,
title = {A multiplayer online car racing virtual-reality game based on internet of brains},
journal = {Journal of Systems Architecture},
volume = {89},
pages = {30-40},
year = {2018},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2018.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S1383762118301619},
author = {Shih-Ching Yeh and Chung-Lin Hou and Wei-Hao Peng and Zhen-Zhan Wei and Shiuan Huang and Edward Yu-Chen Kung and Longsong Lin and Yi-Hung Liu},
keywords = {Brain-computer interface, Virtual reality, EEG, Mental arithmetic, Concentration, Car racing game},
abstract = {Development of brain-computer interface (BCI)-controlled virtual reality (VR) games has received increasing attention. Yet, the up-to-date BCI-VR systems were still based on one single BCI and a virtual environment (VE). In this paper, we propose and implement a novel BCI-controlled VR (BCI-VR) game based on a structure of internet of brains (IoB) allowing multiple players from different sites to play a car racing game online. Electroencephalographic (EEG) and electromyographic (EMG) signals from different sites’ BCIs are uploaded to a high-performance cloud server where the car-controlled algorithms are performed. During the online car racing period, the players mentally control the speeds of their chosen cars by means of concentration, and the concentration level can be adjusted by performing a mental arithmetic (MA) task with different levels of difficulty. Two linear and two nonlinear EEG features, including theta band power (BP), beta BP, Higuchi's fractal dimension (HFD), and Katz's FD (KFD), are used to transform the concentration level to speeds of four different cars. The players can also sensitively trigger the car in the VE to jump by performing a slight teeth-gritting task to generate easy-to-detect EMG signals. Six subjects participated in this study to test the performance of the proposed hybrid (EEG plus EMG) BCI-VR car racing game. The results indicate that theta BP and HFD are more sensitive to the MA-induced concentration in comparison with beta BP and KFD. Through the test of online car racing game, the results also demonstrated the feasibility that different players play the game in the same VE through multiple BCI control at different sites. More importantly, our BCI-VR implementation has a high usability (only two electrodes are required; calibration needs only 64 s) and high feasibility (high average scores of the control, sensory, and distraction factors in a 30-item post-experimental presence questionnaire).}
}
@article{JIANG2023109789,
title = {Short-term virtual reality simulation of the effects of space station colour and microgravity and lunar gravity on cognitive task performance and emotion},
journal = {Building and Environment},
volume = {227},
pages = {109789},
year = {2023},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2022.109789},
url = {https://www.sciencedirect.com/science/article/pii/S0360132322010198},
author = {Ao Jiang and Yang Gong and Xiang Yao and Bernard Foing and Richard Allen and Stephen Westland and Caroline Hemingray and Yingen Zhu},
keywords = {Colour environment, Virtual space station, Cognitive task, Emotion},
abstract = {This study implemented a short-term virtual reality examination of the impacts of environmental colour and posture changes (to simulate microgravity and lunar gravity) on cognitive task performance and emotions. In a standard posture change laboratory study, sixty participants performed a simple cognitive task battery (finding A's test and number comparison test) and an emotional state questionnaire within nine different colour scenes while using three postures (normal sitting (SP), −12° head-down bed (HD) and 9.6° head-up tilt bed (HU)). The results showed that in all colour scenes, the HD posture significantly reduced the participants' task performance and level of positive emotions. There was also some variability in task performance and emotional reaction by scene colour. Overall, the study adds to our understanding of how environmental and postural factors impact on cognition and emotion.}
}
@article{ALSABBAG2022101709,
title = {Enabling human–machine collaboration in infrastructure inspections through mixed reality},
journal = {Advanced Engineering Informatics},
volume = {53},
pages = {101709},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101709},
url = {https://www.sciencedirect.com/science/article/pii/S1474034622001677},
author = {Zaid Abbas Al-Sabbag and Chul Min Yeum and Sriram Narasimhan},
keywords = {Visual inspection, Mixed reality, Human–machine collaboration, Damage detection},
abstract = {In this study, we propose a novel end-to-end system called Human–Machine Collaborative Inspection (HMCI) to enable collaboration between inspectors with Mixed Reality (MR) headsets and a robotic data collection platform (robot) for structural inspections. We utilize the MR headset’s holographic display and precise head tracking to allow inspectors to visualize and localize information (e.g., structural defect) on the real scenes, which are gathered by the robot and processed by an offsite computational server. The primary use case of HMCI is to enable the inspector to visualize, supervise, and improve results produced by automated defect detection algorithms in near real-time. The workflow in HMCI starts with collecting images and depth data to generate 3D maps of the site from the robot. A technique called single-shot localization is developed to create visual anchors for real-time spatial alignment between the robot and the MR headset. The 3D map and images are then sent to the computational server for analysis to detect defects and their locations. Then, the information is received by the MR headset and overlaid on the actual scenes to visualize it with spatial context. An experimental study is conducted in a lab environment to demonstrate HMCI using Microsoft HoloLens 2 (HL2) as the MR headset and Turtlebot2 as the robot. We start with the reconstruction of a 3D environment using a 3D depth sensor (Azure Kinect) on Turtlebot2 and visually detect fiducial markers as regions-of-interest (replicating structural damage) along a predefined inspection path. Then, regions-of-interest are successfully anchored to the real scene and visualized through HL2. To our knowledge, HMCI is one of the first human–machine collaborative systems that can integrate robots and inspectors with the MR headset, which has been developed, tested, and presented for structural inspection.}
}