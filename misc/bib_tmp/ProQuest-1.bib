@article{
author={Warchoł,Jan and Tetych,Anna and Tomaszewski,Robert and Kowalczyk,Bartłomiej and Olchowik,Grażyna},
year={2024},
month={2024},
title={Virtual Reality-Induced Modification of Vestibulo–Ocular Reflex Gain in Posturography Tests},
journal={Journal of Clinical Medicine},
volume={13},
number={10},
pages={2742},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-05-24},
abstract={Background: The aim of the study was to demonstrate the influence of virtual reality (VR) exposure on postural stability and determine the mechanism of this influence. Methods: Twenty-six male participants aged 21–23 years were included, who underwent postural stability assessment twice before and after a few minute of single VR exposure. The VR projection was a computer-generated simulation of the surrounding scenery. Postural stability was assessed using the Sensory Organization Test (SOT), using Computerized Dynamic Posturography (CDP). Results: The findings indicated that VR exposure affects the visual and vestibular systems. Significant differences (p < 0.05) in results before and after VR exposure were observed in tests on an unstable surface. It was confirmed that VR exposure has a positive influence on postural stability, attributed to an increase in the sensory weight of the vestibular system. Partial evidence suggested that the reduction in vestibulo-ocular reflex (VOR) reinforcement may result in an adaptive shift to the optokinetic reflex (OKR). Conclusions: By modifying the process of environmental perception through artificial sensory simulation, the influence of VR on postural stability has been demonstrated. The validity of this type of research is determined by the effectiveness of VR techniques in the field of vestibular rehabilitation.},
keywords={Medical Sciences; virtual reality; posturography; vestibulo–ocular reflex; optokinetic reflex; Sensory Organization Test; Motor ability; Eye movements; Nervous system; Retina; Questionnaires; Statistical analysis},
language={English},
url={https://www.proquest.com/scholarly-journals/virtual-reality-induced-modification-vestibulo/docview/3059450723/se-2},
}

@article{
author={Lu,Min and Arikawa,Masatoshi and Oba,Kohei and Ishikawa,Keiichi and Jin,Yuhan and Utsumi,Tomihiro and Sato,Ryo},
year={2024},
month={2024},
title={Indoor AR Navigation Framework Based on Geofencing and Image-Tracking with Accumulated Error Correction},
journal={Applied Sciences},
volume={14},
number={10},
pages={4262},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-05-24},
abstract={Featured ApplicationIndoor AR guide for smartphones suitable for museums, libraries, university buildings, shopping malls, etc.AbstractThis study presents a novel framework for improving indoor augmented reality (AR) navigation with modern smartphone technology, which is achieved by addressing two major challenges: managing large absolute coordinate spaces and reducing error accumulation in camera-based spatial tracking. Our contribution is significant in two ways. First, we integrate geofencing with indoor navigation by considering spatial tracking errors, timing for audio guidance, and dynamic 3D arrow visualization for effective local-to-global spatial coordinate transformation. This method achieves precise local positioning and seamlessly integrates with larger spatial contexts, overcoming the limitations of current AR systems. Second, we introduce a periodic image-based calibration approach to minimize the inherent error accumulation in camera-based tracking, enhancing accuracy over longer distances. Unlike prior studies focusing on individual technologies, our work explores the software architecture of indoor AR navigation by providing a comprehensive framework for its design and practical use. The practicality of our approach is validated through the implementation of a smartphone application at the Mineral Industry Museum of Akita University, highlighting the limitations of component technologies and demonstrating our framework’s effectiveness.},
keywords={Sciences: Comprehensive Works; indoor navigation; augmented reality; spatial tracking; geofencing; accumulated positioning error calibration; Cellular telephones; Cameras; Accuracy; Smartphones; Location based services; Infrastructure; Calibration; Sensors; Semantic web; Codes; Navigation systems; Technology; Museums; Semantics},
language={English},
url={https://www.proquest.com/scholarly-journals/indoor-ar-navigation-framework-based-on/docview/3059272593/se-2},
}

@article{
author={Papagiannis,Georgios and Triantafyllou,Αthanasios and Yiannopoulou,Konstantina G. and Georgoudis,George and Kyriakidou,Maria and Gkrilias,Panagiotis and Skouras,Apostolos Z. and Bega,Xhoi and Stasinopoulos,Dimitrios and Matsopoulos,George and Syringas,Pantelis and Tselikas,Nikolaos and Zestas,Orestis and Potsika,Vassiliki and Pardalis,Athanasios and Papaioannou,Christoforos and Protopappas,Vasilios and Malizos,Nikolas and Tachos,Nikolaos and Fotiadis,Dimitrios I.},
year={2024},
month={2024},
title={Ηand dexterities assessment in stroke patients based on augmented reality and machine learning through a box and block test},
journal={Scientific Reports (Nature Publisher Group)},
volume={14},
number={1},
pages={10598},
note={Copyright - © The Author(s) 2024. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-05-09},
abstract={A popular and widely suggested measure for assessing unilateral hand motor skills in stroke patients is the box and block test (BBT). Our study aimed to create an augmented reality enhanced version of the BBT (AR-BBT) and evaluate its correlation to the original BBT for stroke patients. Following G-power analysis, clinical examination, and inclusion–exclusion criteria, 31 stroke patients were included in this study. AR-BBT was developed using the Open Source Computer Vision Library (OpenCV). The MediaPipe's hand tracking library uses a palm and a hand landmark machine learning model to detect and track hands. A computer and a depth camera were employed in the clinical evaluation of AR-BBT following the principles of traditional BBT. A strong correlation was achieved between the number of blocks moved in the BBT and the AR-BBT on the hemiplegic side (Pearson correlation = 0.918) and a positive statistically significant correlation (p = 0.000008). The conventional BBT is currently the preferred assessment method. However, our approach offers an advantage, as it suggests that an AR-BBT solution could remotely monitor the assessment of a home-based rehabilitation program and provide additional hand kinematic information for hand dexterities in AR environment conditions. Furthermore, it employs minimal hardware equipment.},
keywords={Sciences: Comprehensive Works; Augmented reality; Machine learning; Motor skill; Correlation; Stroke; Diagnostic techniques; Statistical analysis; Learning algorithms},
language={English},
url={https://www.proquest.com/scholarly-journals/ηand-dexterities-assessment-stroke-patients-based/docview/3052296214/se-2},
}

@article{
author={Williams,Lisa A. and Tzelios,Kallie and Masser,Barbara and Thijsen,Amanda and van Dongen,Anne and Davison,Tanya E.},
year={2024},
month={2024},
title={A virtual reality paradigm simulating blood donation serves as a platform to test interventions to promote donation},
journal={Scientific Reports (Nature Publisher Group)},
volume={14},
number={1},
pages={10334},
note={Copyright - © The Author(s) 2024. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-05-07},
abstract={Effective interventions that support blood donor retention are needed. Yet, integrating an intervention into the time-pressed and operationally sensitive context of a blood donation center requires justification for disruptions to an optimized process. This research provides evidence that virtual reality (VR) paradigms can serve as a research environment in which interventions can be tested prior to being delivered in blood donation centers. Study 1 (N = 48) demonstrated that 360°-video VR blood donation environments elicit a similar profile of emotional experience to a live donor center. Presence and immersion were high, and cybersickness symptoms low. Study 2 (N = 134) was an experiment deploying the 360°-video VR environments to test the impact of an intervention on emotional experience and intentions to donate. Participants in the intervention condition who engaged in a suite of tasks drawn from the process model of emotion regulation (including attentional deployment, positive reappraisal, and response modulation) reported more positive emotion than participants in a control condition, which in turn increased intentions to donate blood. By showing the promise for benefitting donor experience via a relatively low-cost and low-resource methodology, this research supports the use of VR paradigms to trial interventions prior to deployment in operationally-context field settings.},
keywords={Sciences: Comprehensive Works; Emotions; Blood; Blood donors; Computer applications; Blood & organ donations; Deployment; Virtual reality; Intervention},
language={English},
url={https://www.proquest.com/scholarly-journals/virtual-reality-paradigm-simulating-blood/docview/3051220237/se-2},
}

@article{
author={Wimmer,Michael and Weidinger,Nicole and Veas,Eduardo and Müller-Putz,Gernot R.},
year={2024},
month={2024},
title={Multimodal decoding of error processing in a virtual reality flight simulation},
journal={Scientific Reports (Nature Publisher Group)},
volume={14},
number={1},
pages={9221},
note={Copyright - © The Author(s) 2024. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-04-23},
abstract={Technological advances in head-mounted displays (HMDs) facilitate the acquisition of physiological data of the user, such as gaze, pupil size, or heart rate. Still, interactions with such systems can be prone to errors, including unintended behavior or unexpected changes in the presented virtual environments. In this study, we investigated if multimodal physiological data can be used to decode error processing, which has been studied, to date, with brain signals only. We examined the feasibility of decoding errors solely with pupil size data and proposed a hybrid decoding approach combining electroencephalographic (EEG) and pupillometric signals. Moreover, we analyzed if hybrid approaches can improve existing EEG-based classification approaches and focused on setups that offer increased usability for practical applications, such as the presented game-like virtual reality flight simulation. Our results indicate that classifiers trained with pupil size data can decode errors above chance. Moreover, hybrid approaches yielded improved performance compared to EEG-based decoders in setups with a reduced number of channels, which is crucial for many out-of-the-lab scenarios. These findings contribute to the development of hybrid brain-computer interfaces, particularly in combination with wearable devices, which allow for easy acquisition of additional physiological data.},
keywords={Sciences: Comprehensive Works; Physiology; Interfaces; Flight; Computer applications; Brain; EEG; Heart rate; Virtual reality; Flight simulation},
language={English},
url={https://www.proquest.com/scholarly-journals/multimodal-decoding-error-processing-virtual/docview/3043548670/se-2},
}

@article{
author={Everard,Gauthier and Burton,Quentin and Van de Sype,Vincent and Thérèse,Ntabuhashe B. and Auvinet,Edouard and Edwards,Martin G. and Batcho,Charles S. and Lejeune,Thierry},
year={2024},
month={2024},
title={Extended reality to assess post-stroke manual dexterity: contrasts between the classic box and block test, immersive virtual reality with controllers, with hand-tracking, and mixed-reality tests},
journal={Journal of Neuroengineering and Rehabilitation},
volume={21},
pages={1-15},
note={Name - Leap Motion; Copyright - © 2024. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-04-13; SubjectsTermNotLitGenreText - Belgium},
abstract={BackgroundRecent technological advancements present promising opportunities to enhance the frequency and objectivity of functional assessments, aligning with recent stroke rehabilitation guidelines. Within this framework, we designed and adapted different manual dexterity tests in extended reality (XR), using immersive virtual reality (VR) with controllers (BBT-VR-C), immersive VR with hand-tracking (BBT-VR-HT), and mixed-reality (MD-MR).ObjectiveThis study primarily aimed to assess and compare the validity of the BBT-VR-C, BBT-VR-HT and MD-MR to assess post-stroke manual dexterity. Secondary objectives were to evaluate reliability, usability and to define arm kinematics measures.MethodsA sample of 21 healthy control participants (HCP) and 21 stroke individuals with hemiparesis (IHP) completed three trials of the traditional BBT, the BBT-VR-C, BBT-VR-HT and MD-MR. Content validity of the different tests were evaluated by asking five healthcare professionals to rate the difficulty of performing each test in comparison to the traditional BBT. Convergent validity was evaluated through correlations between the scores of the traditional BBT and the XR tests. Test-retest reliability was assessed through correlations between the second and third trial and usability was assessed using the System Usability Scale (SUS). Lastly, upper limb movement smoothness (SPARC) was compared between IHP and HCP for both BBT-VR test versions.ResultsFor content validity, healthcare professionals rated the BBT-VR-HT (00–1]) and BBT-MR (00–1]) as equally difficult to the traditional BBT, whereas they rated BBT-VR-C as more difficult than the traditional BBT (10–2]). For IHP convergent validity, the Pearson tests demonstrated larger correlations between the scores of BBT and BBT-VR-HT (r = 0.94;p < 0.001), and BBT and MD-MR (r = 0.95;p < 0.001) than BBT and BBT-VR-C (r = 0.65;p = 0.001). BBT-VR-HT and MD-MR usability were both rated as excellent, with median SUS scores of 8357.5–91.3] and 8353.8–92.5] respectively. Excellent reliability was found for the BBT-VR-C (ICC = 0.96;p < 0.001), BBT-VR-HT (ICC = 0.96;p < 0.001) and BBT-MR (ICC = 0.99;p < 0.001). The usability of the BBT-VR-C was rated as good with a median SUS of 7043.8–83.8]. Upper limb movements of HCP were significantly smoother than for IHP when completing either the BBT-VR-C (t = 2.05;p = 0.043) and the BBT-VR-HT (t = 5.21;p < 0.001).ConclusionThe different XR manual tests are valid, short-term reliable and usable tools to assess post-stroke manual dexterity.Trial registrationhttps://clinicaltrials.gov/ct2/show/NCT04694833; Unique identifier: NCT04694833, Date of registration: 11/24/2020.},
keywords={Medical Sciences--Psychiatry And Neurology; Stroke; Virtual reality; Augmented reality; Upper Extremity; Patient Outcome Assessment; Reliability analysis; Kinematics; Hand (anatomy); Immersive virtual reality; Health care; Osteonectin; Reliability; Motor ability; Rehabilitation; Computer applications; Manual dexterity; Feedback; Evaluation; Correlation; Haptics; Validity; Smoothness; Convergence; Tracking control; Controllers; Mixed reality; Paresis; Belgium},
language={English},
url={https://www.proquest.com/scholarly-journals/extended-reality-assess-post-stroke-manual/docview/3037874141/se-2},
}

@article{
author={Müller,Fabian and Koch,Michael and Hasse,Alexander},
year={2024},
month={2024},
title={User Study to Validate the Performance of an Offline Robot Programming Method That Enables Robot-Independent Kinesthetic Instruction through the Use of Augmented Reality and Motion Capturing},
journal={Robotics},
volume={13},
number={3},
pages={35},
note={Name - National Aeronautics & Space Administration--NASA; Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-28},
abstract={The paper presents a novel offline programming (OLP) method based on programming by demonstration (PbD), which has been validated through user study. PbD is a programming method that involves physical interaction with robots, and kinesthetic teaching (KT) is a commonly used online programming method in industry. However, online programming methods consume significant robot resources, limiting the speed advantages of PbD and emphasizing the need for an offline approach. The method presented here, based on KT, uses a virtual representation instead of a physical robot, allowing independent programming regardless of the working environment. It employs haptic input devices to teach a simulated robot in augmented reality and uses automatic path planning. A benchmarking test was conducted to standardize equipment, procedures, and evaluation techniques to compare different PbD approaches. The results indicate a 47% decrease in programming time when compared to traditional KT methods in established industrial systems. Although the accuracy is not yet at the level of industrial systems, users have shown rapid improvement, confirming the learnability of the system. User feedback on the perceived workload and the ease of use was positive. In conclusion, this method has potential for industrial use due to its learnability, reduction in robot downtime, and applicability across different robot sizes and types.},
keywords={Computers--Robotics; robot programming; programming by demonstration; motion capture; augmented reality; performance evaluation; user study; Teaching; Accuracy; Working conditions; Collaboration; On-line programming; Input devices; Questionnaires; Robots; Programming; Industrial applications; Methods},
language={English},
url={https://www.proquest.com/scholarly-journals/user-study-validate-performance-offline-robot/docview/3003377613/se-2},
}

@article{
author={Gazit,Noa and Ben-Gal,Gilad and Eliashar,Ron},
year={2024},
month={2024},
title={Development and validation of an objective virtual reality tool for assessing technical aptitude among potential candidates for surgical training},
journal={BMC Medical Education},
volume={24},
pages={1-17},
note={Copyright - © 2024. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-04-17; SubjectsTermNotLitGenreText - Computer Simulation; Basic Skills; Validity; Spatial Ability; Depth Perception; Work Sample Tests; Teaching Methods; Academic Achievement; Surgery; Environmental Influences; Evidence; Simulation; Feedback (Response); Aptitude Tests; Psychometrics; Educational Assessment; Test Content; Computer Assisted Instruction; Skill Analysis},
abstract={BackgroundGood technical skills are crucial for surgeons. Yet although surgical training programs strive to assess technical aptitude when selecting surgical residents, valid assessments of such aptitude are still lacking. Surgical simulators have been proposed as a potentially effective tool for this purpose. The current study aims to develop a technical aptitude test using a virtual reality surgical simulator, and to validate its use for the selection of surgical residents.MethodsThe study had three phases. In Phase 1, we developed an initial version of the technical aptitude test using the Lap-X-VR laparoscopic simulator. In Phases 2 and 3 we refined the test and collected empirical data to evaluate four main sources of validity evidence (content, response process, internal structure, and relationships with other variables), and to evaluate the feasibility and acceptability of the test. Specifically, Phase 2 comprised a review of the test by 30 senior surgeons, and in Phase 3 a revised version of the test was administered to 152 interns to determine its psychometric properties.ResultsBoth the surgeons and interns rated the test as highly relevant for selecting surgical residents. Analyses of the data obtained from the trial administration of the test supported the appropriateness of the score calculation process and showed good psychometric properties, including reliability (α = 0.83) and task discrimination (mean discrimination = 0.5, SD = 0.1). The correlations between test scores and background variables revealed significant correlations with gender, surgical simulator experience, and video game experience (ps < 0.001). These variables, however, explained together only 10% of the variance in test scores.ConclusionsWe describe the systematic development of an innovative virtual reality test for assessing technical aptitude in candidates for surgical training, and present evidence for its validity, feasibility and acceptability. Further validation is required to support the application of the test for selection, as well as to discern the impact of gender, surgical simulator experience, and video game experience on the fairness of test results. However, the test appears to be a promising tool that may help training programs assess the suitability of candidates for surgical training.},
keywords={Medical Sciences; Selection; Assessment; Surgical training; Technical skills; Aptitude; Validation; Surgeons; Training; Laparoscopy; Motor ability; Surgical outcomes; Feedback; Virtual reality; Skills; Validity; Surgery; Medical education; Basic Skills; Psychometrics; Computer Assisted Instruction; Work Sample Tests; Environmental Influences; Spatial Ability; Test Content; Skill Analysis; Simulation; Educational Assessment; Aptitude Tests; Computer Simulation; Depth Perception; Academic Achievement; Evidence; Teaching Methods; Feedback (Response)},
language={English},
url={https://www.proquest.com/scholarly-journals/development-validation-objective-virtual-reality/docview/2956853915/se-2},
}

@article{
author={Shen,Jiabin and Clinton,Alex J. and Penka,Jeffrey and Gregory,Megan E. and Sova,Lindsey and Pfeil,Sheryl and Patterson,Jeremy and Maa,Tensing},
year={2024},
month={2024},
title={Smartphone-Based Virtual and Augmented Reality Implicit Association Training (VARIAT) for Reducing Implicit Biases Toward Patients Among Health Care Providers: App Development and Pilot Testing},
journal={JMIR Serious Games},
volume={12},
note={Copyright - © 2024. This work is licensed under https://creativecommons.org/licenses/by/4.0/" target="_blank">https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-14},
abstract={Background:Implicit bias is as prevalent among health care professionals as among the wider population and is significantly associated with lower health care quality.Objective:The study goal was to develop and evaluate the preliminary efficacy of an innovative mobile app, VARIAT (Virtual and Augmented Reality Implicit Association Training), to reduce implicit biases among Medicaid providers.Methods:An interdisciplinary team developed 2 interactive case-based training modules for Medicaid providers focused on implicit bias related to race and socioeconomic status (SES) and sexual orientation and gender identity (SOGI), respectively. The simulations combine experiential learning, facilitated debriefing, and game-based educational strategies. Medicaid providers (n=18) participated in this pilot study. Outcomes were measured on 3 domains: training reactions, affective knowledge, and skill-based knowledge related to implicit biases in race/SES or SOGI.Results:Participants reported high relevance of training to their job for both the race/SES module (mean score 4.75, SD 0.45) and SOGI module (mean score 4.67, SD 0.50). Significant improvement in skill-based knowledge for minimizing health disparities for lesbian, gay, bisexual, transgender, and queer patients was found after training (Cohen d=0.72; 95% CI −1.38 to −0.04).Conclusions:This study developed an innovative smartphone-based implicit bias training program for Medicaid providers and conducted a pilot evaluation on the user experience and preliminary efficacy. Preliminary evidence showed positive satisfaction and preliminary efficacy of the intervention.},
keywords={Medical Sciences; implicit bias; health care; Medicaid; virtual reality; augmented reality; smartphone; mHealth; mobile app; innovative; implicit bias training program; sexual orientation; sexual orientations; gender identity; gender identities; gender preferences; gender preference; efficacy; health care providers; health care provider; socioeconomic; mobile application; training; XR; extended reality; Patients; Socioeconomic factors; Smartphones; Educational objectives; Minority & ethnic groups; Medical personnel; Design; Immersive learning; Bias},
language={English},
url={https://www.proquest.com/scholarly-journals/smartphone-based-virtual-augmented-reality/docview/2956705267/se-2},
}

@article{
author={Jui-Che Tu and Xi-Hui,Jia},
year={2024},
month={2024},
title={A Study on Immersion and Intention to Pay in AR Broadcasting: Validating and Expanding the Hedonic Motivation System Adoption Mode},
journal={Sustainability},
volume={16},
number={5},
pages={2040},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-13},
abstract={With the rapid growth of online entertainment live streaming, how to continuously innovate and achieve long-term sustainability has become a major challenge for the industry. Augmented reality (AR) technology offers users immersive interactive experiences and potentially addresses this challenge. The aim of this study is to explore how AR technology influences key components of user online experience—immersion and intention to pay—using survey data. Building upon the Hedonic Motivation System Adoption Model (HMSAM), this research incorporates aesthetic variables to theoretically expand the model in order to gain a deeper understanding of the mechanisms influencing user behavior. A questionnaire survey was conducted to collect 450 valid samples. Detailed analysis was conducted using structural equation modeling. The findings confirm that aesthetic design significantly impacts users’ judgments of content value and perceived ease of use, generating positive effects at the perceptual level. Additionally, AR applications enhance the quality of user experience, thereby stimulating intrinsic motivations such as curiosity and joy. Further analysis indicates that users’ curiosity and perceived behavioral control directly influence the level of immersion and intention to pay. Overall, the research results offer important insights into industry applications. This study successfully expands the HMSAM theoretically by incorporating aesthetic variables to enhance the explanatory power of user judgment mechanisms. The analytical framework proposed aids in understanding the potential mechanisms of new technologies on customer experience and commercial value creation. The research findings provide guidelines for technological design and marketing strategies of streaming platforms.},
keywords={Environmental Studies; online entertainment; live broadcasting; immersion; intention to pay; augmented reality; Consumer behavior; Motivation; Consumers; User experience; Perceptions; Webcasting; Content creation; Shopping; Willingness to pay; Electronic commerce; Streaming media; Virtual reality; Aesthetics; Museums},
language={English},
url={https://www.proquest.com/scholarly-journals/study-on-immersion-intention-pay-ar-broadcasting/docview/2955913488/se-2},
}

@article{
author={Margull,Nicholas and Parsley,Doug and Somiari,Ibubeleye and Zhao,Linghao and Cao,Mingyuan and Koumoulis,Dimitrios and Liu,Paul K. T. and Manousiouthakis,Vasilios I. and Tsotsis,Theodore T.},
year={2024},
month={2024},
title={Field-Scale Testing of a High-Efficiency Membrane Reactor (MR)—Adsorptive Reactor (AR) Process for H2 Generation and Pre-Combustion CO2 Capture},
journal={Membranes},
volume={14},
number={2},
pages={51},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-24; SubjectsTermNotLitGenreText - United States--US},
abstract={The study objective was to field-validate the technical feasibility of a membrane- and adsorption-enhanced water gas shift reaction process employing a carbon molecular sieve membrane (CMSM)-based membrane reactor (MR) followed by an adsorptive reactor (AR) for pre-combustion CO2 capture. The project was carried out in two different phases. In Phase I, the field-scale experimental MR-AR system was designed and constructed, the membranes, and adsorbents were prepared, and the unit was tested with simulated syngas to validate functionality. In Phase II, the unit was installed at the test site, field-tested using real syngas, and a technoeconomic analysis (TEA) of the technology was completed. All project milestones were met. Specifically, (i) high-performance CMSMs were prepared meeting the target H2 permeance (>1 m3/(m2.hbar) and H2/CO selectivity of >80 at temperatures of up to 300 °C and pressures of up to 25 bar with a 2.5 wt.% and an attrition rate of <0.2; (iii) TEA showed that the MR-AR technology met the CO2 capture goals of 95% CO2 purity at a cost of electricity (COE) 30% less than baseline approaches.},
keywords={Engineering; membrane reactor (MR); adsorptive reactor (AR); H2 generation; CO2 capture; carbon molecular sieve membrane; Combustion; Adsorbents; Reactors; Membranes; Water gas; Adsorptivity; Membrane reactors; Carbon dioxide; Work capacity; Synthesis gas; Shift reaction; Carbon sequestration; Molecular sieves; Capital costs; Technology assessment; Temperature; Cost control; Enhanced oil recovery; Coal; United States--US},
language={English},
url={https://www.proquest.com/scholarly-journals/field-scale-testing-high-efficiency-membrane/docview/2930983363/se-2},
}

@article{
author={Johnson,Diego and Mamani,Brayan and Salas,Cesar},
year={2024},
month={2024},
title={CollabVR: VR Testing for Increasing Social Interaction between College Students},
journal={Computers},
volume={13},
number={2},
pages={40},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-23},
abstract={The impact of the COVID-19 pandemic on education has accelerated the shift in learning paradigms toward synchronous and asynchronous online approaches, significantly reducing students’ social interactions. This study introduces CollabVR, as a social virtual reality (SVR) platform designed to improve social interaction among remote university students through extracurricular activities (ECAs). Leveraging technologies such as Unity3D for the development of the SVR environment, Photon Unity Networking for real-time participant connection, Oculus Quest 2 for immersive virtual reality experience, and AWS for efficient and scalable system performance, it aims to mitigate this social interaction deficit. The platform was tested using the sociability scale of Kreijns et al., comparing it with traditional online platforms. Results from a focus group in Lima, Peru, with students participating in online ECAs, demonstrated that CollabVR significantly improved participants perceived social interaction, with a mean of 4.65 ± 0.49 compared to traditional platforms with a mean of 2.35 ± 0.75, fostering a sense of community and improving communication. The study highlights the potential of CollabVR as a powerful tool to overcome socialization challenges in virtual learning environments, suggesting a more immersive and engaging approach to distance education.},
keywords={Computers; social virtual reality; virtual learning environments; social interaction; college students; remote education; extracurricular activities; higher education; Students; Collaboration; Computer assisted instruction--CAI; Socialization; Communication; Education; Social factors; Immersive virtual reality; Pandemics; Virtual reality; Distance learning; Colleges & universities; Virtual environments; Skills},
language={English},
url={https://www.proquest.com/scholarly-journals/collabvr-vr-testing-increasing-social-interaction/docview/2930561252/se-2},
}

@article{
author={Montuori,Rosario and Nastri,Elide and Piluso,Vincenzo and Pisapia,Alessandro and Todisco,Paolo},
year={2024},
month={2024},
title={Application and Validation of a Simplified Approach to Evaluate the Seismic Performances of Steel MR-Frames},
journal={Applied Sciences},
volume={14},
number={3},
pages={1037},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-09},
abstract={The main aim of this work is to validate the application of a simplified performance-based method for assessing the seismic performance of steel buildings, focusing particularly on Moment Resisting Frames (MRFs) through nonlinear analyses. This simplified method defines the capacity curve of a structure through elastic and rigid-plastic analyses, calibrated by regression analyses conducted on 420 structures. To assess its accuracy, the method was compared with other analytical approaches, including incremental dynamic analyses (IDA) provided by existing codes. These analyses were performed on both real structures and simulated designs, considering recent and older codes. The comparison of capacity results derived from code-based approaches and IDA, aligned with the limit states outlined in current codes, showcased the high reliability of the proposed simplified assessment approach.},
keywords={Sciences: Comprehensive Works; moment resisting frames; structural capacity; performance-based assessment; simplified methods; IDA analysis; Design; Methods; Seismic engineering; Equilibrium; Ductility},
language={English},
url={https://www.proquest.com/scholarly-journals/application-validation-simplified-approach/docview/2923930802/se-2},
}

@article{
author={Alhumaid,Majed M. and Said,Mohamed A. and Adnan,Yuhanis and Khoo,Selina},
year={2024},
month={2024},
title={Cross-Cultural Adaptation and Validation of the Arabic Version of the Physical Activity Scale for Individuals with Physical Disabilities in Saudi Arabia (PASIPD-AR)},
journal={Healthcare},
volume={12},
number={2},
pages={179},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-27; SubjectsTermNotLitGenreText - Saudi Arabia},
abstract={This study aimed to cross-culturally adapt and validate the Arabic version of the Physical Activity Scale for Individuals with Physical Disabilities (PASIPD) with Saudi Arabian participants. The study encompassed four distinct stages: (i) translation and subsequent back-translation; (ii) a preliminary assessment aimed at evaluating the quality of the translated scale; (iii) an assessment of the reliability of the measures employed; and (iv) a comprehensive examination of the validity of the measures. A sample of Saudi Arabian participants with physical disabilities (N = 206) took part, ranging in age from 18 to 70 years old, with an average age of 39.56 years and a standard deviation of 12.16. The findings obtained from the reliability tests indicated a notable level of internal consistency and stability. Experts and confirmatory factor analysis were employed to establish the face, content, and construct validity. The findings of the assessment of the Arabic version of PASIPD demonstrated a satisfactory degree of reliability and validity, rendering it suitable for implementation within the Saudi Arabian setting.},
keywords={Medical Sciences; physical activity; health; physical disability; reliability; translation; validation; scale; Exercise; Physical fitness; Life expectancy; Wheelchairs; Performance evaluation; People with disabilities; Disability; Systematic review; Americans with Disabilities Act 1990-US; Mobility; Spinal cord injuries; Questionnaires; Saudi Arabia},
language={English},
url={https://www.proquest.com/scholarly-journals/cross-cultural-adaptation-validation-arabic/docview/2918740823/se-2},
}

@article{
author={Martinez,Kim and Checa,David and Bustillo,Andres},
year={2024},
month={2024},
title={Development of the Engagement Playability and User eXperience (EPUX) Metric for 2D-Screen and VR Serious Games: A Case-Study Validation of Hellblade: Senua’s Sacrifice},
journal={Electronics},
volume={13},
number={2},
pages={281},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-23},
abstract={Research into the design of serious games still lacks metrics to evaluate engagement with the experience so that users can achieve the learning aims. This study presents the new EPUX metric, based on playability and User eXperience (UX) elements, to measure the capability of any serious game to maintain the attention of players. The metric includes (1) playability aspects: game items that affect the emotions of users and that constitute the different layers of the game, i.e., mechanics, dynamics and aesthetics; and (2) UX features: motivation, meaningful choices, usability, aesthetics and balance both in the short and in the long term. The metric is also adapted to evaluate virtual reality serious games (VR-SGs), so that changes may be considered to features linked to playability and UX. The case study for the assessment of the EPUX metric is Hellblade, developed in two versions: one for 2D-screens and the other for VR devices. The comparison of the EPUX metric scores for both versions showed that (1) some VR dynamics augmented the impact of gameplay and, in consequence, engagement capacity; and (2) some game design flaws were linked to much lower scores. Among those flaws were low numbers of levels, missions, and items; no tutorial to enhance usability; and lack of strategies and rewards to increase motivation in the long term.},
keywords={Electronics; serious games; game design; game evaluation; game engagement; virtual reality; Research; Collaboration; User experience; Games; Aesthetics; Design; Mechanics; Motivation; Evaluation; Computer & video games; Educational software},
language={English},
url={https://www.proquest.com/scholarly-journals/development-engagement-playability-user/docview/2918725269/se-2},
}

@article{
author={Muurling,Marijn and de Boer,Casper and Vairavan,Srinivasan and Harms,Robbert L. and Chadha,Antonella S. and Tarnanas,Ioannis and Luis,Estefania V. and Religa,Dorota and Gjestsen,Martha T. and Galluzzi,Samantha and Ibarria Sala,Marta and Koychev,Ivan and Hausner,Lucrezia and Gkioka,Mara and Aarsland,Dag and Visser,Pieter J. and Brem,Anna-Katharine},
year={2023/12//},
month={Dec 2023},
title={Augmented reality versus standard tests to assess cognition and function in early Alzheimer’s disease},
journal={NPJ Digital Medicine},
volume={6},
number={1},
pages={234},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-04},
abstract={Augmented reality (AR) apps, in which the virtual and real world are combined, can recreate instrumental activities of daily living (IADL) and are therefore promising to measure cognition needed for IADL in early Alzheimer’s disease (AD) both in the clinic and in the home settings. The primary aim of this study was to distinguish and classify healthy controls (HC) from participants with AD pathology in an early AD stage using an AR app. The secondary aims were to test the association of the app with clinical cognitive and functional tests and investigate the feasibility of at-home testing using AR. We furthermore investigated the test-retest reliability and potential learning effects of the task. The digital score from the AR app could significantly distinguish HC from preclinical AD (preAD) and prodromal AD (proAD), and preAD from proAD, both with in-clinic and at-home tests. For the classification of the proAD group, the digital score (AUCclinic_visit = 0.84 0.75–0.93], AUCat_home = 0.77 0.61–0.93]) was as good as the cognitive score (AUC = 0.85 0.78–0.93]), while for classifying the preAD group, the digital score (AUCclinic_visit = 0.66 0.53–0.78], AUCat_home = 0.76 0.61–0.91]) was superior to the cognitive score (AUC = 0.55 0.42–0.68]). In-clinic and at-home tests moderately correlated (rho = 0.57, p < 0.001). The digital score was associated with the clinical cognitive score (rho = 0.56, p < 0.001). No learning effects were found. Here we report the AR app distinguishes HC from otherwise healthy Aβ-positive individuals, both in the outpatient setting and at home, which is currently not possible with standard cognitive tests.},
keywords={Medical Sciences--Computer Applications; Augmented reality; Cognition & reasoning; Activities of daily living; Alzheimer's disease; Medical tests},
language={English},
url={https://www.proquest.com/scholarly-journals/augmented-reality-versus-standard-tests-assess/docview/2903154371/se-2},
}

@article{
author={Stevão Alves,de A. and Nunes,Fatima L. S. and Delamaro,Má},
year={2023/12//},
month={Dec 2023},
title={Exploiting deep reinforcement learning and metamorphic testing to automatically test virtual reality applications},
journal={Software Testing, Verification & Reliability},
volume={33},
number={8},
note={Copyright - © 2023 John Wiley & Sons, Ltd; Last updated - 2023-11-17},
abstract={Despite the rapid growth and popularization of virtual reality (VR) applications, which have enabled new concepts for handling and solving existing problems through VR in various domains, practices related to software engineering have not kept up with this growth. Recent studies indicate that one of the topics that is still little explored in this area is software testing, as VR applications can be built for practically any type of purpose, making it difficult to generalize knowledge to be applied. In this paper, we present an approach that combines metamorphic testing, agent‐based testing and machine learning to test VR applications, focusing on finding collision and camera‐related faults. Our approach proposes the use of metamorphic relations to detect faults in collision and camera components in VR applications, as well as the use of intelligent agents for the automatic generation of test data. To evaluate the proposed approach, we conducted an experimental study on four VR applications, and the results showed an accuracy of the solution ranging from 93% to 69%, depending on the complexity of the application tested. We also discussed the feasibility of extending the approach to identify other types of faults in VR applications. In conclusion, we discussed important trends and opportunities that can benefit both academics and practitioners.},
keywords={Computers--Software; metamorphic testing; software testing; virtual reality; Software; Intelligent agents; Faults; Software engineering; Deep learning; Applications programs; Machine learning; Fault detection; Cameras},
isbn={09600833},
language={English},
url={https://www.proquest.com/scholarly-journals/exploiting-deep-reinforcement-learning/docview/2890671255/se-2},
}

@article{
author={Traon,Yves L. and Xie,Tao},
year={2023/12//},
month={Dec 2023},
title={Model‐based testing, test case prioritization and testing of virtual reality applications},
journal={Software Testing, Verification & Reliability},
volume={33},
number={8},
note={Copyright - © 2023 John Wiley & Sons, Ltd; Last updated - 2023-11-17},
keywords={Computers--Software; Virtual reality},
isbn={09600833},
language={English},
url={https://www.proquest.com/scholarly-journals/model-based-testing-test-case-prioritization/docview/2890671098/se-2},
}

@article{
author={Jae,Woo O. and Kim,Ji E.},
year={2023/12//},
month={Dec 2023},
title={Effectiveness of a virtual reality application-based education programme on patient safety management for nursing students: A pre-test–post-test study},
journal={Nursing Open},
volume={10},
number={12},
pages={7622-7630},
note={Name - World Health Organization; Copyright - © 2023. This work is published under http://creativecommons.org/licenses/by-nc-nd/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-14; SubjectsTermNotLitGenreText - South Korea},
abstract={AimsWe aimed to develop a virtual reality-based smartphone application that improves patient safety competency among nursing students in terms of knowledge, attitudes and confidence in patient safety management. We also sought to evaluate the effects and utility of the application in improving patient safety competency.DesignA parallel, randomized controlled pre- and post-test trial was conducted to test the effects of knowledge, attitudes and performance confidence in patient safety management.MethodsParticipants were randomly allocated to the experimental (n = 22), in which nursing students received a two-week mobile web-based training programme covering key topics in patient safety management or the control group (n = 22), in which nursing students received a training booklet. Participants completed a pre-test and two post-test questionnaires to assess the program's impact. The evaluation tools were patient safety management knowledge, attitude and patient safety management performance confidence scale. Data analysis was performed using descriptive statistics, homogeneity test for pre-test, unpaired t-test and repeated measures ANOVA.ResultsPatient safety competency in the experimental group improved significantly in terms of knowledge (from 11.68 to 18.55, p < 0.000), attitude (from 3.38 to 4.01; p < 0.005) and performance confidence (from 3.93 to 4.52; p < 0.000) compared with the control group. Our findings suggest that mobile app-based education using virtual reality may be effective in enhancing patient safety management in nursing education.},
keywords={Medical Sciences--Nurses And Nursing; competency; education programme; nursing students; patient safety; Students; Nursing education; Smartphones; Safety management; Clinical medicine; Knowledge; Likert scale; Safety training; Attitudes; Virtual reality; Nurses; Health services; South Korea},
language={English},
url={https://www.proquest.com/scholarly-journals/effectiveness-virtual-reality-application-based/docview/2889483139/se-2},
}

@article{
author={Kim,Ko W. and Choi,Jong D. and Chin,Juhee and Lee,Byung H. and Choi,Jee H. and Na,Duk L.},
year={2023/11/23/},
month={2023 Nov 23},
title={Development and preliminary validation of a virtual reality memory test for assessing visuospatial memory},
journal={Frontiers in Aging Neuroscience},
note={Copyright - © 2023. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-24},
abstract={Background: Visuospatial memory impairment is a common symptom of Alzheimer's disease; however, conventional visuospatial memory tests are insufficient to fully reflect visuospatial memory impairment in daily life.To address patients' difficulties in locating and recalling misplaced objects, we introduced a novel visuospatial memory test, the Hidden Objects Test (HOT), conducted in a virtual environment. We categorized HOT scores into prospective memory, item free-recall, place free-recall, item recognition, and place-item matching scores. To validate the VR memory test, we compared HOT scores among individuals with Alzheimer's disease (AD), amnestic mild cognitive impairment (aMCI), and normal controls (NC), and also compared these scores with those of conventional neuropsychological tests. We tracked the participants' movement paths in the virtual environment and assessed basic features, such as total distance, duration, and speed. Additionally, we performed walking trajectory pattern mining such as outlier and stay-point detection.We designed and implemented the HOT to simulate a house's living room and assess participants' ability to locate hidden objects. Our preliminary results showed that the total HOT score differed among 17 patients with AD, 14 with aMCI, and 15 NC (p <0.001). The total HOT score correlated positively with conventional memory test scores (p <0.001). Walking trajectories showed that patients with AD and aMCI wandered rather than going straight to the hidden objects. In terms of basic features, the total duration was significantly greater in AD than in NC (p = 0.008). In terms of trajectory pattern mining, the number of outliers, which were over 95% of the estimated trajectory, was significantly higher in AD than in NC (p = 0.002). The number of stay points, an index in which participants stayed in the same position for more than 2 s, was significantly higher in patients with AD and aMCI compared with NC (AD vs. NC: p = 0.003, aMCI vs. NC: p = 0.019).The HOT simulating real life showed potential as an ecologically valid test for assessing visuospatial memory function in daily life. Walking trajectory analysis suggested that patients with AD and aMCI wandered rather than going straight toward the hidden objects.},
keywords={Medical Sciences--Psychiatry And Neurology; Alzheimer's disease; virtual reality; spatial memory; spatial navigation; head mounted display; Memory; Computer applications; Furniture; Cognitive ability; Neurodegenerative diseases},
isbn={16634365},
language={English},
url={https://www.proquest.com/scholarly-journals/development-preliminary-validation-virtual/docview/2892775639/se-2},
}

@article{
year={2023},
month={2023},
title={ERRATUM TO RAPOSO ET AL. "INCREASING AWARENESS AND EMPATHY AMONG UNIVERSITY STUDENTS THROUGH IMMERSIVE EXERCISES – TESTING OF THE VIRTUAL REALITY APPLICATION: A PILOT STUDY" (MED PR. 2023;74(3):187–97)},
journal={Medycyna pracy},
volume={74},
number={6},
pages={549},
note={Copyright - © 2023. This work is published under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-26},
keywords={Occupational Health And Safety},
isbn={04655893},
language={English},
url={https://www.proquest.com/scholarly-journals/erratum-raposo-et-al-increasing-awareness-empathy/docview/2916458699/se-2},
}

@article{
author={Prabhakaran,Abhinesh and Abdul-Majeed Mahamadu and Mahdjoubi,Lamine and Booth,Colin and Aigbavboa,Clinton},
year={2023},
month={2023},
title={Virtual reality utility and usefulness in the furniture, fixture and equipment sector: a validation of interactive and distributed immersion},
journal={Smart and Sustainable Built Environment},
volume={12},
number={4},
pages={787-819},
note={Name - Autodesk Inc; Copyright - © Emerald Publishing Limited; Last updated - 2023-06-06; SubjectsTermNotLitGenreText - United Kingdom--UK},
abstract={PurposeThe Furniture, Fixture and Equipment (FFE) sector is well placed to leverage virtual reality (VR) technology for competitive and operational advantages; however, the diffusion of VR applications in this sector has followed a steep curve. This study reports on the implementation of two novel VR applications in the FFE sector and also investigates the challenges and benefits associated with their use and adaptability.Design/methodology/approachA sequential exploratory mixed research methodology consisting of three phases was adopted for this study. This included identification of factors that affect/facilitate the implementation of VR (Challenges and Benefits) using experiments during in-house prototyping of VR applications, a rigorous literature review and questionnaire survey to solicit FFE Stakeholder's (n = 117) opinion on the utility and usefulness of the proposed applications and to the understand factors that facilitate and inhibit their implementation in FFE's context, particularly as a design communication and coordination tool.FindingsThe findings of this study revealed that distributed and single-user VR has become essential to digitalising the FFE sector's design communication with improved design communication being regarded as the most important benefit of its use. Conversely, the most critical challenge that inhibits the implementation of these two VR applications in the FFE sector is the perceived cost.Originality/valueThis study provides valuable insight to FFE's stakeholders to devise action plans to mitigate myriad complex and interrelated factors that affect the adoption of virtual reality technology in the FFE sector that are otherwise very hard to understand, and the consequential implementation of any mitigation plans cannot be devised.},
keywords={Environmental Studies; Virtual reality; Challenges; Benefits; Adoption; Construction; Furniture; Fixture; Equipment; Software; Design improvements; Literature reviews; Communication; Mitigation; Technology; Prototyping; Adaptability; Architecture; Computer applications; Stakeholders; Design; Digitization; Building information modeling; United Kingdom--UK},
isbn={20466099},
language={English},
url={https://www.proquest.com/scholarly-journals/virtual-reality-utility-usefulness-furniture/docview/2822646041/se-2},
}

@article{
author={Bishop,Ronald and Best,Talitha},
year={2023},
month={2023},
title={Mental Workload and Task Performance: A Test of the Relative Efficiency of Virtual Reality Training Scenarios},
journal={The e - Journal of Business Education & Scholarship of Teaching},
volume={17},
number={2},
pages={8-16},
note={Name - National Aeronautics & Space Administration--NASA; Copyright - Copyright Australian Business Education Research Association 2023; Last updated - 2024-04-10; SubjectsTermNotLitGenreText - Thinking Skills; Aviation Education; Flight Training; Learning Processes; Student Experience; Educational Environment},
abstract={The purpose of this paper is to evaluation the efficiency of the aviation flight instruction of two different flight training simulations undertaken in virtual reality conditions. The method involves the use of a model developed by Pass and Van Merriënboer (1993) that combines the measures of mental workload with that of task performance through standardisation involving conversion to z scores, and these in turn derive what is referred to as the relative condition efficiency. There were eight participants who undertook aviation flight training in two different modes, a General Aviation Aircraft (GA) and the other a Recreational Aircraft (RA). The results of the study were that the GA simulation was of Low-instructional efficiency, because there was High Mental Workload (0.80) which was accompanied by Low-task performance (-0.08). The RA simulation was found to be of High-instructional efficiency, because there was High-task Performance (0.44) which was combined with High Mental Workload (0.25).},
keywords={Education; Aircraft; Physiology; Simulation; Memory; Aviation; Cognitive load; Cognitive ability; Workloads; Virtual reality; Learning; Cognition & reasoning; Efficiency; Flight training; Student Experience; Thinking Skills; Educational Environment; Aviation Education; Learning Processes; 61151:Technical and Trade Schools; 92711:Space Research and Technology},
language={English},
url={https://www.proquest.com/scholarly-journals/mental-workload-task-performance-test-relative/docview/2878446395/se-2},
}

@article{
author={Chuan,A. and Qian,J. and Bogdanovych,A. and Kumar,A. and McKendrick,M. and McLeod,G.},
year={2023/06//},
month={Jun 2023},
title={Design and validation of a virtual reality trainer for ultrasound‐guided regional anaesthesia},
journal={Anaesthesia},
volume={78},
number={6},
pages={739-746},
note={Copyright - © 2023. This article is published under http://creativecommons.org/licenses/by-nc-nd/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-10-09},
abstract={Virtual reality is a form of high‐fidelity simulation that may be used to enhance the quality of medical education. We created a bespoke virtual reality trainer software using high resolution motion capture and ultrasound imagery to teach cognitive‐motor needling skills necessary for the performance of ultrasound‐guided regional anaesthesia. The primary objective of this study was to determine the construct validity between novice and experienced regional anaesthetists. Secondary objectives were: to create learning curves for needling performance; compare the virtual environment immersion with other high‐fidelity virtual reality software; and compare cognitive task loads imposed by the virtual trainer compared with real‐life medical procedures. We recruited 21 novice and 15 experienced participants, each of whom performed 40 needling attempts on four different virtual nerve targets. Performance scores for each attempt were calculated based on measured metrics (needle angulation, withdrawals, time taken) and compared between the groups. The degree of virtual reality immersion was measured using the Presence Questionnaire, and cognitive burden was measured using the NASA‐Task Load Index. Scores by experienced participants were significantly higher than novices (p = 0.002) and for each nerve target (84% vs. 77%, p = 0.002; 86% vs. 79%, p = 0.003; 87% vs. 81%, p = 0.002; 87% vs. 80%, p = 0.003). Log–log transformed learning curves demonstrated individual variability in performance over time. The virtual reality trainer was rated as being comparably immersive to other high‐fidelity virtual reality software in the realism, possibility to act and quality of interface subscales (all p > 0.06) but not in the possibility to examine and self‐performance subscales (all p < 0.009). The virtual reality trainer created workloads similar to those reported in real‐life procedural medicine (p = 0.53). This study achieved initial validation of our new virtual reality trainer and allows progression to a planned definitive trial that will compare the effectiveness of virtual reality training on real‐life regional anaesthesia performance.},
keywords={Medical Sciences--Anaesthesiology; medical education; regional anaesthesia; ultrasound; virtual reality; Regional anesthesia; Accuracy; Immersion; Motor skill; Software; Immersive virtual reality; Mental task performance; Anesthesia; Learning curves; Computer applications; Cognitive ability; Performance evaluation; Cognitive tasks; Taskload; Nerves; Ultrasonic imaging; Motion capture; Virtual environments},
isbn={00032409},
language={English},
url={https://www.proquest.com/scholarly-journals/design-validation-virtual-reality-trainer/docview/2808905426/se-2},
}

@article{
author={Raposo,Rui and Vairinhos,Má and Laska-LeŚNiewicz,Anna and Sztobryn-Giercuszkiewicz,Joanna},
year={2023},
month={2023},
title={INCREASING AWARENESS AND EMPATHY AMONG UNIVERSITY STUDENTS THROUGH IMMERSIVE EXERCISES – TESTING OF THE VIRTUAL REALITY APPLICATION: A PILOT STUDY},
journal={Medycyna pracy},
volume={74},
number={3},
pages={187-197},
note={Copyright - © 2023. This work is published under https://creativecommons.org/licenses/by-nc/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-09-20},
abstract={For educational purposes, VR products should provide learning value 2]. ...]additional tests are added to check the achievements and progress of students in particular subjects and topics. The VR simulates the experience of a designed challenging situation in a non-real environment, in first-person point of view. ...]it provides a safe training environment and a possibility for learning while experiencing something unusual for a user in the real world. In this article, the authors focus on the impact of the VR exercises on the level of empathy among participants of the pilot study and changing their approach to people with disabilities and various physical limitations. ...]the carried testing sessions allowed to gather valuable user feedback to improve the final version of the VR application and elaborate tasks in the created virtual environment. According to Adams 14], autonomously from purely perceptive immersion, in narrative immersion the user creates emotional and affective connections with the characters, and for that reason feels involved in a story.},
keywords={Occupational Health And Safety; Universal design; Higher education; Research methodology; Empathy; University students; Usability testing; Pilot projects; Emotions; Personality; Virtual reality; Engineers},
isbn={04655893},
language={English},
url={https://www.proquest.com/scholarly-journals/increasing-awareness-empathy-among-university/docview/2866477372/se-2},
}

@article{
author={Finnegan,Sarah L. and Freeman,Daniel and Sergeant,Martin and Taylor,Stephen and Pattinson,Kyle T. S.},
year={2023/04//},
month={Apr 2023},
title={Breathlessness in a virtual world: An experimental paradigm testing how discrepancy between VR visual gradients and pedal resistance during stationary cycling affects breathlessness perception},
journal={PLoS One},
volume={18},
number={4},
note={Name - Oxford University; Copyright - © 2023 Finnegan et al. This is an open access article distributed under the terms of the Creative Commons Attribution License: http://creativecommons.org/licenses/by/4.0/ (the “License”), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-01; SubjectsTermNotLitGenreText - United Kingdom--UK},
abstract={Introduction The sensation of breathlessness is often attributed to perturbations in cardio-pulmonary physiology, leading to changes in afferent signals. New evidence suggests that these signals are interpreted in the light of prior "expectations". A misalignment between afferent signals and expectations may underly unexplained breathlessness. Using a novel immersive virtual reality (VR) exercise paradigm, we investigated whether manipulating an individual’s expectation of effort (determined by a virtual hill gradient) may alter their perception of breathlessness, independent from actual effort (the physical effort of cycling). Methods Nineteen healthy volunteers completed a single experimental session where they exercised on a cycle ergometer while wearing a VR headset. We created an immersive virtual cycle ride where participants climbed up 100 m hills with virtual gradients of 4%, 6%, 8%, 10% and 12%. Each virtual hill gradient was completed twice: once with a 4% cycling ergometer resistance and once with a 6% resistance, allowing us to dissociate expected effort (virtual hill gradient) from actual effort (power). At the end of each hill, participants reported their perceived breathlessness. Linear mixed effects models were used to examine the independent contribution of actual effort and expected effort to ratings of breathlessness (0–10 scale). Results Expectation of effort (effect estimate ± std. error, 0.63 ± 0.11, P < 0.001) and actual effort (0.81 ± 0.21, P < 0.001) independently explained subjective ratings of breathlessness, with comparable contributions of 19% and 18%, respectively. Additionally, we found that effort expectation accounted for 6% of participants’ power and was a significant, independent predictor (0.09 ± 0.03; P = 0.001). Conclusions An individuals’ expectation of effort is equally important for forming perceptions of breathlessness as the actual effort required to cycle. A new VR paradigm enables this to be experimentally studied and could be used to re-align breathlessness and enhance training programmes.},
keywords={Sciences: Comprehensive Works; Exercise; Shortness of breath; Expectation; Power; Effort; Virtual reality; Sensory perception; Anxiety; Emotions; Questionnaires; Sensory cues; Sports and exercise medicine; Misalignment; Ratings; Perceptions; Brain research; Immersive virtual reality; Perturbation; Cycles; Medical research; Sensory neurons; Perception; Likert scale; Computer applications; Sensation; Bicycling; United Kingdom--UK},
language={English},
url={https://www.proquest.com/scholarly-journals/breathlessness-virtual-world-experimental/docview/2804274128/se-2},
}

@article{
author={Bos,Paula and Martens,Roland M. and de Graaf,Pim and Jasperse,Bas and van Griethuysen, Joost J. M. and Boellaard,Ronald and Leemans,C. R. and Beets-Tan,Regina and van de Wiel, Mark A. and van den Brekel, Michiel W. M. and Castelijns,Jonas A.},
year={2023/04//},
month={Apr 2023},
title={External validation of an MR-based radiomic model predictive of locoregional control in oropharyngeal cancer},
journal={European radiology},
volume={33},
number={4},
pages={2850-2860},
note={Copyright - © The Author(s), under exclusive licence to European Society of Radiology 2022. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law; Last updated - 2023-11-24},
abstract={ObjectivesTo externally validate a pre-treatment MR-based radiomics model predictive of locoregional control in oropharyngeal squamous cell carcinoma (OPSCC) and to assess the impact of differences between datasets on the predictive performance.MethodsRadiomic features, as defined in our previously published radiomics model, were extracted from the primary tumor volumes of 157 OPSCC patients in a different institute. The developed radiomics model was validated using this cohort. Additionally, parameters influencing performance, such as patient subgroups, MRI acquisition, and post-processing steps on prediction performance will be investigated. For this analysis, matched subgroups (based on human papillomavirus (HPV) status of the tumor, T-stage, and tumor subsite) and a subgroup with only patients with 4-mm slice thickness were studied. Also the influence of harmonization techniques (ComBat harmonization, quantile normalization) and the impact of feature stability across observers and centers were studied. Model performances were assessed by area under the curve (AUC), sensitivity, and specificity.ResultsPerformance of the published model (AUC/sensitivity/specificity: 0.74/0.75/0.60) drops when applied on the validation cohort (AUC/sensitivity/specificity: 0.64/0.68/0.60). The performance of the full validation cohort improves slightly when the model is validated using a patient group with comparable HPV status of the tumor (AUC/sensitivity/specificity: 0.68/0.74/0.60), using patients acquired with a slice thickness of 4 mm (AUC/sensitivity/specificity: 0.67/0.73/0.57), or when quantile harmonization was performed (AUC/sensitivity/specificity: 0.66/0.69/0.60).ConclusionThe previously published model shows its generalizability and can be applied on data acquired from different vendors and protocols. Harmonization techniques and subgroup definition influence performance of predictive radiomics models.Key Points• Radiomics, a noninvasive quantitative image analysis technique, can support the radiologist by enhancing diagnostic accuracy and/or treatment decision-making.• A previously published model shows its generalizability and could be applied on data acquired from different vendors and protocols.},
keywords={Medical Sciences--Radiology And Nuclear Medicine; Oropharyngeal neoplasms; Magnetic resonance imaging; Oropharyngeal cancer; Human papillomavirus infection; Quantile normalization; Radiomics; Prognosis; Machine learning; Treatment outcome; Feature extraction; Patients; Human papillomavirus; Tumors; Image analysis; Data acquisition; Performance prediction; Image enhancement; Subgroups; Cancer; Squamous cell carcinoma; Predictive control; Image processing; Stability analysis; Decision making; Thickness; Medical prognosis; Throat cancer},
isbn={09387994},
language={English},
url={https://www.proquest.com/scholarly-journals/external-validation-mr-based-radiomic-model/docview/2787045716/se-2},
}

@article{
author={Zhao,Qianfeng and Liu,Bo and Sun,Qiushi and Jin,Yiqiang},
year={2023/03//},
month={Mar 2023},
title={Development and validation of a cost-effective virtual reality educational tool to reduce anxiety and improve set-up accuracy in radiotherapy patients},
journal={Cancer Medicine},
volume={12},
number={5},
pages={6161-6169},
note={Copyright - © 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-22},
abstract={PurposeThis study proposes a cost-effective method for educating radiotherapy patients through an immersive virtual reality (VR) system.MethodsThe VR educational tool comprises VR glasses, a handheld controller, the scientific knowledge of radiotherapy, radiotherapy demonstration, and an audio introduction. To verify its efficacy, 120 radiotherapy patients with tumors were prospectively enrolled and divided into the control group or VR intervention group. After the first treatment, set-up errors, including three translation errors and three rotation errors, were recorded in six directions. In addition, participants were required to complete a questionnaire before radiotherapy to assess anxiety and understanding degrees. The questionnaire was scored using a five-point Likert Scale. Finally, Spearman's rank correlation test was used to evaluate set-up errors and questionnaire scores.ResultsThe set-up errors are significantly reduced in AP, SI, total translation, Roll and total rotation in the intervention group compared with the control group (p < 0.05). The scores are higher in the intervention group than in the control group in question 1 (2.1 ± 0.58 vs. 3.3 ± 0.55), question 2 (1.3 ± 0.44 vs. 2.5 ± 0.65), question 4 (2.2 ± 0.65 vs. 3.2 ± 0.82), question 5 (1.8 ± 0.59 vs. 3.1 ± 0.79), and all subscales (5.5 ± 1.2 vs. 8.9 ± 1.3 and 6.4 ± 1.3 vs. 9.2 ± 1.5). The scores of high, moderate, and low correlation are 47 (74%), 15 (23%), and 2 (3%) for the control group and 44 (69%), 17 (26%), and 3 (5%) for the intervention group, respectively.ConclusionThe VR educational tool can significantly improve comprehension and reduce anxiety. There is a strong correlation between set-up errors and questionnaire scores. The VR educational tool may help reduce set-up errors for radiotherapy patients.},
keywords={Medical Sciences--Oncology; patient education; Understanding; Anxiety; Questionnaire; Radiotherapy; Virtual reality; set-up accuracy; VR education; Radiation therapy; Audio equipment; Computer applications; Translation; Cancer therapies; Knowledge; Questionnaires},
language={English},
url={https://www.proquest.com/scholarly-journals/development-validation-cost-effective-virtual/docview/2788587988/se-2},
}

@article{
author={Wei,Qiurong and Chen,Zeli and Tang,Yehuan and Chen,Weicui and Zhong,Liming and Mao,Liting and Hu,Shaowei and Wu,Yuankui and Deng,Kan and Yang,Wei and Liu,Xian},
year={2023/03//},
month={Mar 2023},
title={External validation and comparison of MR-based radiomics models for predicting pathological complete response in locally advanced rectal cancer: a two-centre, multi-vendor study},
journal={European radiology},
volume={33},
number={3},
pages={1906-1917},
note={Copyright - © The Author(s), under exclusive licence to European Society of Radiology 2022. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law; Last updated - 2023-11-23},
abstract={ObjectivesThe aim of this study was two-fold: (1) to develop and externally validate a multiparameter MR-based machine learning model to predict the pathological complete response (pCR) in locally advanced rectal cancer (LARC) patients after neoadjuvant chemoradiotherapy (nCRT), and (2) to compare different classifiers’ discriminative performance for pCR prediction.MethodsThis retrospective study includes 151 LARC patients divided into internal (centre A, n = 100) and external validation set (centre B, n = 51). The clinical and MR radiomics features were derived to construct clinical, radiomics, and clinical-radiomics model. Random forest (RF), support vector machine (SVM), logistic regression (LR), K-nearest neighbor (KNN), naive Bayes (NB), and extreme gradient boosting (XGBoost) were used as classifiers. The predictive performance was assessed using the receiver operating characteristic (ROC) curve.ResultsEleven radiomics and four clinical features were chosen as pCR-related signatures. In the radiomics model, the RF algorithm achieved 74.0% accuracy (an AUC of 0.863) and 84.4% (an AUC of 0.829) in the internal and external validation sets. In the clinical-radiomics model, RF algorithm exhibited high and stable predictive performance in the internal and external validation datasets with an AUC of 0.906 (87.3% sensitivity, 73.7% specificity, 76.0% accuracy) and 0.872 (77.3% sensitivity, 88.2% specificity, 86.3% accuracy), respectively. RF showed a better predictive performance than the other classifiers in the external validation datasets of three models.ConclusionsThe multiparametric clinical-radiomics model combined with RF algorithm is optimal for predicting pCR in the internal and external sets, and might help improve clinical stratifying management of LARC patients.Key Points• A two-centre study showed that radiomics analysis of pre- and post-nCRT multiparameter MR images could predict pCR in patients with LARC.• The combined model was superior to the clinical and radiomics model in predicting pCR in locally advanced rectal cancer.• The RF classifier performed best in the current study.},
keywords={Medical Sciences--Radiology And Nuclear Medicine; Rectal neoplasm; Machine learning; Colorectal cancer; Radiomics; XGBoost; Magnetic resonance imaging; Neoadjuvant therapy; Accuracy; Datasets; Performance prediction; Sensitivity; Algorithms; Support vector machines; Cancer; Classifiers; Rectum; Chemoradiotherapy},
isbn={09387994},
language={English},
url={https://www.proquest.com/scholarly-journals/external-validation-comparison-mr-based-radiomics/docview/2777162513/se-2},
}

@article{
author={Ettinger,Sarah and Sonnow,Lena and Plaass,Christian and Rahn,Alexandra and Stukenborg-Colsman,Christina and von Falck,Christian and Poehler,Gesa and Becher,Christoph},
year={2023/02//},
month={Feb 2023},
title={Arthroscopic defect size measurement in osteochondral lesions of the talus underestimates the exact defect size and size measurement with arthro-MRI (MR-A) and high-resolution flat-panel CT-arthro imaging (FPCT-A)},
journal={Knee Surgery, Sports Traumatology, Arthroscopy},
volume={31},
number={2},
pages={716-723},
note={Copyright - © The Author(s) under exclusive licence to European Society of Sports Traumatology, Knee Surgery, Arthroscopy (ESSKA) 2022. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law; Last updated - 2023-11-29},
abstract={PurposeThe size of osteochondral lesions of the talus (OLTs) is highly relevant for their treatment. In addition to intraoperative measurement of defect size, preoperative planning by means of magnetic resonance imaging (MRI) or computed tomography (CT) is crucial.MethodsFour defects of different sizes and depths were created on the talar joint surface in 14 cadaver feet. All defects were evaluated, both arthroscopically and via arthrotomy with a probe. Arthro-MRI (MR-A) and high-resolution flat-panel CT arthro scans (FPCT-A) were acquired. Length, width, and depth were measured for every defect and the defect volume was calculated. To determine the exact defect size, each talar defect was filled with plastic pellets to form a cast and the casts were scanned using FPCT to create a 3D multiplanar reconstruction data set. Finally, the surgically measured values were compared with the radiological values and the exact defect size.ResultsOverall, the surgically measured values (both arthroscopic and open) underestimated the exact defect size (p < 0.05). Arthroscopically determined defect length and width showed the largest deviation (p < 0.05) and underestimated the size in comparison with MR-A and FPCT-A. The FPCT-A measurements demonstrated higher correlation with both the arthroscopic and open surgical measurements than did the MR-A measurements (p < 0.05).ConclusionThe exact defect size is underestimated on intraoperative measurement, in both arthroscopic and open approaches. Arthroscopic defect size measurement underestimates defect size in comparison with MR-A and FPCT-A. FPCT-A was shown to be a reliable imaging technique that allows free image reconstruction in every plane and could be considered as the new reference standard for preoperative evaluation of defect size in OLT.},
keywords={Medical Sciences--Surgery; Talus; Magnetic resonance imaging; Arthroscopy; OLT; Defect size; Measurement; CT; MRI; Imaging techniques; Image resolution; Image reconstruction; Lesions; Computed tomography; Medical imaging; High resolution; Image processing; Reconstructive surgery; Defects; Evaluation},
isbn={0942-2056},
language={English},
url={https://www.proquest.com/scholarly-journals/arthroscopic-defect-size-measurement/docview/2772188803/se-2},
}

@article{
author={Sullivan,Lindsay and McKenzie,Lara B. and Roberts,Kristin and Recker,Robyn and Schwebel,David C. and Pommering,Thomas and Yang,Jingzhen},
year={2023},
month={2023},
title={A Virtual Reality App Intervention to Improve Concussion Recognition and Reporting in Athletes Aged 9 to 12 Years: Development and Pilot Testing},
journal={JMIR Formative Research},
volume={7},
note={Copyright - © 2023. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-26; SubjectsTermNotLitGenreText - United States--US},
abstract={Background:Existing concussion education programs for preteen athletes typically do not result in sustained improvements in concussion symptom recognition or reporting behaviors. Virtual reality (VR) technology offers an innovative tool that may improve concussion symptom recognition and reporting behaviors among preteen athletes.Objective:We aimed to describe the design and development of a VR concussion education app, Make Play Safe (MPS), and present findings on the usability and preliminary efficacy of MPS in improving concussion recognition and reporting intentions among soccer athletes aged 9-12 years.Methods:A collaborative user-centered design process was implemented to develop and evaluate MPS, a semi-immersive VR concussion education app designed to address two behavioral outcomes in preteen athletes aged 9-12 years: (1) recognizing concussion and (2) reporting concussion. The development of MPS occurred in three phases: (1) design and development, (2) usability testing, and (3) preliminary efficacy testing. During phase 1, consultations were completed with 6 experts. Additionally, 5 interviews with children who had a history of concussion were conducted to collect feedback about the proof of concept of MPS. During phase 2, a participatory workshop with 11 preteen athletes and a small group discussion with 6 parents and 2 coaches were conducted to explore the usefulness and acceptability of MPS from the perspective of end users. Finally, phase 3 included preliminary efficacy testing with 33 soccer athletes aged 9-12 years to examine changes in concussion-related knowledge, attitudes, and reporting intentions from pre- to postintervention. The data generated from each phase of this study informed the development of the final version of the proof of concept of the VR concussion education app, MPS.Results:Experts positively rated the features of MPS and noted that the design and content were innovative and age-appropriate. Preteens with a history of concussion indicated the scenarios and symptoms portrayed in the app represented well what they experienced while concussed. Further, they stated that the app would be an engaging way for children to learn about concussions. The 11 healthy children in the workshop perceived the app positively, noting that the scenarios were informative and engaging. Results from preliminary efficacy testing revealed increases in many athletes’ knowledge and reporting intentions from pre- to postintervention. Others demonstrated no significant changes or a decrease in knowledge, attitudes, or reporting intentions from pre- to postintervention. Group-level changes in concussion knowledge and intention to report concussions were statistically significant (P<.05), while changes in attitudes toward reporting concussions were not (P=.08).Conclusions:Results suggest VR technology may be an effective and efficient tool to equip preteen athletes with the requisite knowledge and skills to recognize and report future concussions. Further research is recommended to examine the use of VR as an effective strategy to improve concussion-reporting behaviors in preteen athletes.},
keywords={Medical Sciences; concussion; education; sports; athlete; athletic; virtual reality; youth; child; pediatric; head injury; symptom reporting; symptom recognition; patient education; brain injury; user experience; user centered design; Usability; Experiential learning; Participation; Design; Feedback; Soccer; Pediatrics; Interviews; Teenagers; Traumatic brain injury; United States--US},
language={English},
url={https://www.proquest.com/scholarly-journals/virtual-reality-app-intervention-improve/docview/2918539371/se-2},
}

@article{
author={Se,Young K. and Park,Jinseok and Choi,Hojin and Loeser,Martin and Ryu,Hokyoung and Seo,Kyoungwon},
year={2023},
month={2023},
title={Digital Marker for Early Screening of Mild Cognitive Impairment Through Hand and Eye Movement Analysis in Virtual Reality Using Machine Learning: First Validation Study},
journal={Journal of Medical Internet Research},
volume={25},
number={1},
note={Name - Hanyang University; Copyright - © 2023. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-05-28},
abstract={Background:With the global rise in Alzheimer disease (AD), early screening for mild cognitive impairment (MCI), which is a preclinical stage of AD, is of paramount importance. Although biomarkers such as cerebrospinal fluid amyloid level and magnetic resonance imaging have been studied, they have limitations, such as high cost and invasiveness. Digital markers to assess cognitive impairment by analyzing behavioral data collected from digital devices in daily life can be a new alternative. In this context, we developed a “virtual kiosk test” for early screening of MCI by analyzing behavioral data collected when using a kiosk in a virtual environment.Objective:We aimed to investigate key behavioral features collected from a virtual kiosk test that could distinguish patients with MCI from healthy controls with high statistical significance. Also, we focused on developing a machine learning model capable of early screening of MCI based on these behavioral features.Methods:A total of 51 participants comprising 20 healthy controls and 31 patients with MCI were recruited by 2 neurologists from a university hospital. The participants performed a virtual kiosk test—developed by our group—where we recorded various behavioral data such as hand and eye movements. Based on these time series data, we computed the following 4 behavioral features: hand movement speed, proportion of fixation duration, time to completion, and the number of errors. To compare these behavioral features between healthy controls and patients with MCI, independent-samples 2-tailed t tests were used. Additionally, we used these behavioral features to train and validate a machine learning model for early screening of patients with MCI from healthy controls.Results:In the virtual kiosk test, all 4 behavioral features showed statistically significant differences between patients with MCI and healthy controls. Compared with healthy controls, patients with MCI had slower hand movement speed (t49=3.45; P=.004), lower proportion of fixation duration (t49=2.69; P=.04), longer time to completion (t49=–3.44; P=.004), and a greater number of errors (t49=–3.77; P=.001). All 4 features were then used to train a support vector machine to distinguish between healthy controls and patients with MCI. Our machine learning model achieved 93.3% accuracy, 100% sensitivity, 83.3% specificity, 90% precision, and 94.7% F1-score.Conclusions:Our research preliminarily suggests that analyzing hand and eye movements in the virtual kiosk test holds potential as a digital marker for early screening of MCI. In contrast to conventional biomarkers, this digital marker in virtual reality is advantageous as it can collect ecologically valid data at an affordable cost and in a short period (5-15 minutes), making it a suitable means for early screening of MCI. We call for further studies to confirm the reliability and validity of this approach.},
keywords={Medical Sciences--Computer Applications; Alzheimer disease; biomarkers; dementia; digital markers; eye movement; hand movement; machine learning; mild cognitive impairment; screening; virtual reality; Alzheimer's disease; Eye movements; Time series; Activities of daily living; Magnetic resonance imaging; Neuropsychology; Cognitive ability; Statistical significance; Cerebrospinal fluid; Cognitive impairment; Neurologists; Validation studies; Biological markers; Fixation; Medical screening; Cognitive-behavioral factors; Reliability; Behavior; Tests; Executive function},
language={English},
url={https://www.proquest.com/scholarly-journals/digital-marker-early-screening-mild-cognitive/docview/2917629629/se-2},
}

@article{
author={Huey-Pin Tsai and Che-Wei,Lin and Ying-Jun,Lin and Chun-Sheng Yeh and Yan-Shen,Shan},
year={2023},
month={2023},
title={Novel Software for High-level Virological Testing: Self-Designed Immersive Virtual Reality Training Approach},
journal={Journal of Medical Internet Research},
volume={25},
number={1},
note={Copyright - © 2023. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-05-28},
abstract={Background:To ensure the timely diagnosis of emerging infectious diseases, high-tech molecular biotechnology is often used to detect pathogens and has gradually become the gold standard for virological testing. However, beginners and students are often unable to practice their skills due to the higher costs associated with high-level virological testing, the increasing complexity of the equipment, and the limited number of specimens from patients. Therefore, a new training program is necessary to increase training and reduce the risk of test failure.Objective:The aim of the study is to (1) develop and implement a virtual reality (VR) software for simulated and interactive high-level virological testing that can be applied in clinical practice and skills building or training settings and (2) evaluate the VR simulation’s effectiveness on reaction, learning, and behavior of the students (trainees).Methods:Viral nucleic acid tests on a BD MAX instrument were selected for our VR project because it is a high-tech automatic detection system. There was cooperation between teachers of medical technology and biomedical engineering. Medical technology teachers were responsible for designing the lesson plan, and the biomedical engineering personnel developed the VR software. We designed a novel VR teaching software to simulate cognitive learning via various procedure scenarios and interactive models. The VR software contains 2D VR “cognitive test and learning” lessons and 3D VR “practical skills training” lessons. We evaluated students’ learning effectiveness pre- and posttraining and then recorded their behavior patterns when answering questions, performing repeated exercises, and engaging in clinical practice.Results:The results showed that the use of the VR software met participants’ needs and enhanced their interest in learning. The average posttraining scores of participants exposed to 2D and 3D VR training were significantly higher than participants who were exposed solely to traditional demonstration teaching (P<.001). Behavioral assessments of students pre- and posttraining showed that students exposed to VR-based training to acquire relevant knowledge of advanced virological testing exhibited significantly improved knowledge of specific items posttraining (P<.01). A higher participant score led to fewer attempts when responding to each item in a matching task. Thus, VR can enhance students’ understanding of difficult topics.Conclusions:The VR program designed for this study can reduce the costs associated with virological testing training, thus, increasing their accessibility for students and beginners. It can also reduce the risk of viral infections particularly during disease outbreaks (eg, the COVID-19 pandemic) and also enhance students’ learning motivation to strengthen their practical skills.},
keywords={Medical Sciences--Computer Applications; design; immersive; virtual reality; VR; high-level clinical virology; skill training; testing; virological; medical education; clinical practice; simulation; biotechnology; molecular; detection; pathogen; development; software; teaching; Risk reduction; Teaching methods; Medical diagnosis; Trainees; Clinical skills; Equipment; Laboratories; Medical technology; Cooperation; Access; Clinical medicine; Motivation; COVID-19; Teachers; Engineering; Skill development; Pandemics; Behavior; Tests; Infectious diseases; Students; Learning; Cytomegalovirus},
language={English},
url={https://www.proquest.com/scholarly-journals/novel-software-high-level-virological-testing/docview/2917628839/se-2},
}

@article{
author={Delgado-Rodríguez,Santiago and Domínguez,Silvia C. and Garcia-Fandino,Rebeca},
year={2023},
month={2023},
title={Design, Development and Validation of an Educational Methodology Using Immersive Augmented Reality for STEAM Education},
journal={Journal of New Approaches in Educational Research},
volume={12},
number={1},
pages={19-39},
note={Copyright - © 2023. This work is published under https://creativecommons.org/licenses/by-nc/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-04-16; SubjectsTermNotLitGenreText - Secondary Education; Educational Practices; Educational Resources; Learning Processes; Teaching Methods; Academic Achievement; Educational Technology; Educational Environment; Educational Needs},
abstract={The main objective of this study is the design and validation of an educational methodological model based on the use of immersive technological resources (Augmented Reality - AR) to improve learning processes in secondary education science subjects (Biology and Geology). The process was developed based on three main quantitative studies: an exploratory study, a study of performance divided into three cases studies, and an attitudinal study. The information obtained was completed with a fourth qualitative study of the training of teachers who participate in educational technology. This research provides empirical evidence that allows validation of the methodological model developed to explain key concepts and to improve the level of motivation and acceptance of AR technology by students. The proposed model can induce improvements in educational processes in the field of STEAM when used with an immersive AR technological resource and an adapted digital evaluation system. It also demonstrates that teachers require specific training in connection with the creation and the adequate use of AR educational resources, and of digital evaluation systems as well. The results of this study have important implications for the field of education, demonstrating the potential of AR technology to improve learning outcomes and the need for teacher training in its use.},
keywords={Education; Teaching; Augmented reality; Secondary education; Students; Academic achievement; Virtual reality; Technology; Learning; Teacher education; Educational Practices; Educational Environment; Educational Resources; Educational Technology; Educational Needs; Learning Processes; Teaching Methods},
language={English},
url={https://www.proquest.com/scholarly-journals/design-development-validation-educational/docview/2909794444/se-2},
}

@article{
author={Noetscher,Gregory M. and Serano Peter,J. and Horner,Marc and Prokop,Alexander and Hanson,Jonathan and Kyoko,Fujimoto and Brown,James and Ara,Nazarian and Ackerman,Jerome and Makaroff,Sergey N.},
year={2023},
month={2023},
title={An in silico testbed for fast and accurate MR labeling of orthopedic implants},
journal={eLife},
volume={12},
note={Name - Food & Drug Administration--FDA; Department of Health & Human Services; Copyright - © 2023, Noetscher, Serano et al. This work is published under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-01; SubjectsTermNotLitGenreText - United States--US},
abstract={One limitation on the ability to monitor health in older adults using magnetic resonance (MR) imaging is the presence of implants, where the prevalence of implantable devices (orthopedic, cardiac, neuromodulation) increases in the population, as does the pervasiveness of conditions requiring MRI studies for diagnosis (musculoskeletal diseases, infections, or cancer). The present study describes a novel multiphysics implant modeling testbed using the following approaches with two examples: (1) an in silico human model based on the widely available Visible Human Project (VHP) cryo-section dataset; (2) a finite element method (FEM) modeling software workbench from Ansys (Electronics Desktop/Mechanical) to model MR radio frequency (RF) coils and the temperature rise modeling in heterogeneous media. The in silico VHP-Female model (250 parts with an additional 40 components specifically characterizing embedded implants and resultant surrounding tissues) corresponds to a 60-year-old female with a body mass index of 36. The testbed includes the FEM-compatible in silico human model, an implant embedding procedure, a generic parameterizable MRI RF birdcage two-port coil model, a workflow for computing heat sources on the implant surface and in adjacent tissues, and a thermal FEM solver directly linked to the MR coil simulator to determine implant heating based on an MR imaging study protocol. The primary target is MR labeling of large orthopedic implants. The testbed has very recently been approved by the US Food and Drug Administration (FDA) as a medical device development tool for 1.5 T orthopedic implant examinations.},
keywords={Biology; orthopedic impants; MR imaging studies; temperature rise; MR safety/labeling; multiphysics modeling; Infections; Patients; Software; Magnetic resonance imaging; Transplants & implants; Orthopedics; Finite element method; Labeling; Medical equipment; Neuromodulation; Females; Musculoskeletal diseases; Body mass index; Embedding; United States--US},
language={English},
url={https://www.proquest.com/scholarly-journals/silico-testbed-fast-accurate-mr-labeling/docview/2908076992/se-2},
}

@article{
author={Forsberg,Karin and Jirlén,Johan and Jacobson,Inger and Röijezon,Ulrik},
year={2023},
month={2023},
title={Concurrent Validity of Cervical Movement Tests Using VR Technology—Taking the Lab to the Clinic},
journal={Sensors},
volume={23},
number={24},
pages={9864},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-23; SubjectsTermNotLitGenreText - Sweden},
abstract={Reduced cervical range of motion (ROM) and movement velocity are often seen in people with neck pain. Objective assessment of movement characteristics is important to identify dysfunction, to inform tailored interventions, and for the evaluation of the treatment effect. The purpose of this study was to investigate the concurrent validity of a newly developed VR technology for the assessment of cervical ROM and movement velocity. VR technology was compared against a gold-standard three-dimensional optical motion capture system. Consequently, 20 people, 13 without and 7 with neck pain, participated in this quantitative cross-sectional study. ROM was assessed according to right/left rotation, flexion, extension, right/left lateral flexion, and four diagonal directions. Velocity was assessed according to fast cervical rotation to the right and left. The correlations between VR and the optical system for cervical ROM and velocity were excellent, with intraclass correlation coefficient (ICC) values > 0.95. The mean biases between VR and the optical system were ≤ 2.1° for the ROM variables, <12°/s for maximum velocity, and ≤3.0°/s for mean velocity. In conclusion, VR is a useful assessment device for ROM and velocity measurements with clinically acceptable biases. It is a feasible tool for the objective measurement of cervical kinematics in the clinic.},
keywords={Chemistry--Analytical Chemistry; neck pain; cervical; virtual reality; VR; 3D motion capture; validity; agreement; correlation; range of motion; velocity; Software; Motion capture; Data collection; Accuracy; Laboratory equipment; Laboratories; Sweden},
language={English},
url={https://www.proquest.com/scholarly-journals/concurrent-validity-cervical-movement-tests-using/docview/2904929845/se-2},
}

@article{
author={Gardini,Valentina and Ruini,Chiara and Tossani,Eliana and Grandi,Silvana and Tomba,Elena},
year={2023},
month={2023},
title={Protocol for a Randomized Controlled Trial Testing the Efficacy of a Transdiagnostic Virtual Reality-Based Intervention for the Reduction of Unhealthy Lifestyles and Behaviors in the General Population},
journal={Journal of Clinical Medicine},
volume={12},
number={23},
pages={7470},
note={Name - University of Bologna; Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-02},
abstract={Virtual reality (VR) is a valuable tool for the treatment and prevention of psychiatric disorders and dysfunctional behaviors. Although VR software is mainly developed following a disorder-specific approach, this randomized controlled trial (RCT) will test the efficacy of a new transdiagnostic VR application (H.O.M.E. VR-based psychological intervention) in improving dysfunctional behaviors, three transdiagnostic factors concurrently (emotion regulation, experiential avoidance, and psychological flexibility), and stress. Three groups screened as at-risk for nicotine dependence, alcohol abuse, and eating disorders will be assigned to the H.O.M.E. VR intervention and compared to a waiting-list (WL) condition. Participants will be assessed before and after the H.O.M.E. intervention/WL and at the 3- and 6-month follow-ups in the levels of the displayed dysfunctional behavior, the three transdiagnostic factors, and stress. Changes in dysfunctional behaviors, transdiagnostic factors, and stress in each population VR group and differences in such improvements between each population of the VR and WL groups will be evaluated using mixed-model repeated measure analyses of variance. It is expected that, after the H.O.M.E. intervention and at follow-ups, participants will display improvements in physical and psychological health compared to controls. The H.O.M.E. protocol is expected to result in a cost-effective option to tackle cognitive–behavioral factors shared among several psychopathologies and dysfunctional behaviors.},
keywords={Medical Sciences; virtual reality; transdiagnostic factors; eating disorders; substance use disorder; alcohol use disorder; Software; Emotions; Mental disorders; Clinical medicine},
language={English},
url={https://www.proquest.com/scholarly-journals/protocol-randomized-controlled-trial-testing/docview/2899453852/se-2},
}

@article{
author={Xie,Sujun and Grimstrup,Sø and Leizl,Joy N. and Wang,Zheng and Wan,Xing and Konge,Lars},
year={2023},
month={2023},
title={Using a novel virtual-reality simulator to assess performance in lumbar puncture: a validation study},
journal={BMC Medical Education},
volume={23},
pages={1-8},
note={Name - Guangzhou University; Copyright - © 2023. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-04-16; SubjectsTermNotLitGenreText - China; Standardized Tests; Educational Strategies; Computer Simulation; Physicians; Patients; Competence; Validity; Video Technology; Skill Centers; Educational Methods; Reliability; Mastery Learning; Test Results; Outcome Measures; Medical Students; Evidence; Simulation; Feedback (Response); Novices; Anesthesiology; Trainees; Statistical Analysis; Item Analysis; Internal Medicine},
abstract={BackgroundA lumbar puncture procedure’s success depends on a competent physician minimizing the risk of failing to get a sample and avoiding complications such as post-dural headache. A new virtual-reality simulator might be helpful in deciding when a physician is competent to perform lumbar puncture. We aimed to investigate validity evidence for a simulator-based test in lumbar puncture and establish a pass/fail standard to allow a mastery learning training program.MethodsValidity evidence was investigated using Messick’s framework by including participants who were novices, intermediates, or experienced in lumbar puncture. Each participant performed two lumbar puncture procedures on the simulator, and fifty-nine predefined simulator metrics were automatically recorded. Cronbach’s alpha was used to explore internal consistency reliability. Intergroup comparisons were made using independent sample t-tests with Tukey’s correction for multiple comparisons. The learning effect was explored using paired sample t-test analysis, and a pass/fail standard was established using the contrasting groups’ method.Results73 novices, 18 intermediates, and 19 physicians performed the test resulting in a total of 220 procedures. 25 metrics (42.4%) had good discriminatory ability, and the reliability of these metrics was good, Cronbach’s α = 0.81. The experienced physicians were significantly better than the novices (18.3 vs. 13.3, p < 0.001), and the pass/fail standard was established at 16 points. This standard resulted in 22 (30.1%) novices passing (i.e., false positives) and 5 (26.3%) physicians failing (i.e., false negatives).ConclusionThis study provides validity evidence for a simulator-based test of lumbar puncture competence. The test can help ensure basic competence at the end of a simulation-based training program for trainees, i.e., a mastery learning training program.},
keywords={Medical Sciences; Lumbar puncture; Virtual reality; Assessment; Validity; Mastery learning; Simulation; Medicine; Medical students; Clinical medicine; Curricula; Feedback; Diagnostic tests; Independent sample; Validation studies; Educational Methods; Trainees; Competence; Physicians; Skill Centers; China; Computer Simulation; Evidence; Statistical Analysis; Feedback (Response); Educational Strategies; Test Results; Outcome Measures; Internal Medicine; Patients; Video Technology; Standardized Tests; Item Analysis; Anesthesiology; Reliability; Novices},
language={English},
url={https://www.proquest.com/scholarly-journals/using-novel-virtual-reality-simulator-assess/docview/2890060331/se-2},
}

@article{
author={Gomindes,Austin R. and Adeeko,Elizabeth S. and Chetan,Khatri and Ahmed,Imran and Simran,Sehdev and Carlos,William J. and Ward,Thomas and Leverington,James and Luke,Debenham and Metcalfe,Andrew and Ward,Jayne},
year={2023},
month={2023},
title={Use of Virtual Reality in the Education of Orthopaedic Procedures: A Randomised Control Study in Early Validation of a Novel Virtual Reality Simulator},
journal={Cureus},
volume={15},
number={9},
note={Copyright - Copyright © 2023, Gomindes et al. This work is published under https://creativecommons.org/licenses/by/3.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-06},
abstract={BackgroundVirtual reality (VR) simulation is a potential solution to the barriers surgical trainees are facing. There needs to be validation for its implementation within current training. We aimed to compare VR simulation to traditional methods in acquiring surgical skills for a TFN-ADVANCED™ Proximal Femoral Nailing System (TFNA; DePuy Synthes, Auckland, New Zealand) femoral nailing system.MethodsThirty-one surgical trainees were randomised to two groups: traditional-training group (control group) and a VR-training group (intervention group) for insertion of a short cephalomedullary TFNA nail. Both groups then inserted the same TFNA system into saw-bone femurs. Surveys evaluated validity of the relevant activities, perception of simulation, confidence, stress and anxiety. The primary outcomes were tip-apex distance (TAD) and user anxiety/confidence levels. Secondary outcomes included number of screw- and nail-guidewire insertion attempts, the time taken to complete and user validity of the VR system.ResultsThere was no statistical difference in TAD between the intervention and control groups (9mm vs 15mm, p=0.0734). The only TAD at risk of cut-out was in the control group (25mm). There was no statistical difference in time taken (2547.5ss vs 2395ss, p=0.668), nail guide-wire attempts (two for both groups, p=0.355) and screw guide-wire attempts (one for both groups, p=0.702).The control group versus intervention had higher anxiety levels (50% vs 33%) and had lower confidence (61% vs 84%).InterpretationThere was no objective difference in performance on a saw-bone model between groups. However, this VR simulator resulted in more confidence and lower anxiety levels whilst performing a simulated TFNA. Whilst further studies with larger sample sizes and exploration of transfer validity to the operating theatre are required, this study does indicate potential benefits of VR within surgical training.},
keywords={Medical Sciences; training effect; haptics; orthopaedics & traumatology; virtual reality in medical education; virtual reality simulation; virtual augmented reality; tfn-advanced proximal femoral nailing system (tfna); skills and simulation training; Simulation; Software; Surgeons; Anxiety; Validity; Orthopedics; Training; Virtual reality; Questionnaires},
language={English},
url={https://www.proquest.com/scholarly-journals/use-virtual-reality-education-orthopaedic/docview/2884555859/se-2},
}

@article{
author={Pai,Hyunjoo},
year={2023},
month={2023},
title={Presidential address: improving item validity and adopting computer-based testing, clinical skills assessments, artificial intelligence, and virtual reality in health professions licensing examinations in Korea},
journal={Journal of Educational Evaluation for Health Professions},
volume={20},
pages={1-3},
note={Copyright - Copyright Korea Health Personnel Licensing Examination Institute 2023; Last updated - 2023-12-01},
keywords={Medical Sciences; Artificial intelligence},
language={English},
url={https://www.proquest.com/scholarly-journals/presidential-address-improving-item-validity/docview/2884356400/se-2},
}

@article{
author={Fekih-Romdhane,Feten and Azzi,Vanessa and Hallit,Rabih and Malaeb,Diana and Dabbous,Mariam and Sakr,Fouad and Obeid,Sahar and Hallit,Souheil},
year={2023},
month={2023},
title={Validation of the Arabic version of the brief irritability test (Ar-BITe) in non-clinical adolescents},
journal={BMC Psychiatry},
volume={23},
pages={1-8},
note={Copyright - © 2023. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-26; SubjectsTermNotLitGenreText - Arab countries; Lebanon},
abstract={BackgroundDespite the substantial clinical relevance of irritability in the development and maintenance of several mental disorders and its negative effects on functioning, no valid and reliable measures are available yet to identify the presence and consequences of irritability as a distinct construct among the Arabic-speaking populations. To bridge this gap, and help advance this field in the under-researched Arab region, we aimed to validate an Arabic-language version of the Brief Irritability Test (BITe).MethodsEligible participants were native Arabic-speaking non-clinical adolescents from Lebanon; 527 participants aged 15.73 ± 1.81 years (56% females) completed the survey.ResultsUtilizing the Confirmatory Factor Analysis approach, we found that the five items of the Arabic BITe loaded into a single factor structure. The scale showed excellent reliability, as both Cronbach’s alpha and McDonald’s omega coefficient values were of 0.88. Multi-group analyses showed invariance across sex groups in our sample at the configural, metric, and scalar levels. Female adolescents exhibited higher BITe scores than their male counterparts (14.01 vs. 13.25), but this difference did not reach the statistical significance. Good concurrent validity was supported based on positive correlations between irritability scores and measures of aggression, anger and hostility (r Pearson’s coefficients ranging from 0.35 to 0.42), as well as positive correlations with insomnia symptoms scores.ConclusionThe present findings allow us to conclude that the Arabic version of the BITe is a unidimensional, reliable, valid, brief, and economic self-report measure of the irritability construct for both male and female Arabic-speakers. Providing an Arabic validated version of the BITe will hopefully foster the research efforts of the Arab scientific community in this area, and promote the implementation of timely, evidence-informed and culturally-sensitive mental health interventions that appropriately address irritability-related problems and consequences among Arab young populations.},
keywords={Medical Sciences--Psychiatry And Neurology; Irritability; BITe; Arabic; Psychometric properties; Adolescents; Qualitative research; Self report; Factor analysis; Quantitative research; Surveys & questionnaires; Research; Physiology; Insomnia; Validity; Sleep disorders; Quantitative psychology; Chronic pain; Mental disorders; Questionnaires; Psychopathology; Anger; University students; Hostility; Mental health; Teenagers; Psychiatry; Lebanon; Arab countries},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-arabic-version-brief-irritability-test/docview/2877493299/se-2},
}

@article{
author={Xu,Tianming and Wei,Yuesong},
year={2023},
month={2023},
title={Ratio Test for Mean Changes in Time Series with Heavy-Tailed AR(p) Noise Based on Multiple Sampling Methods},
journal={Mathematics},
volume={11},
number={18},
pages={3988},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-10-12},
abstract={This paper discusses the problem of the mean changes in time series with heavy-tailed AR(p) noise. Firstly, it proposes a modified ratio-type test statistic, and the results show that under the null hypothesis of no mean change, the asymptotic distribution of the modified statistic is a functional of Lévy processes and the consistency under the alternative hypothesis is obtained. However, a heavy-tailed index exists in the asymptotic distribution and is difficult to estimate. This paper uses bootstrap sampling, jackknife sampling, and subsampling to approximate the distribution under the null hypothesis, and obtain more accurate critical values and empirical power. In addition, some results from a small simulation study and a practical example give an idea of the finite sample behavior of the proposed statistic.},
keywords={Mathematics; ratio test; heavy tailed; limit distribution; bootstrap; jackknife; subsampling; Statistics; Null hypothesis; Asymptotic properties; Hypothesis testing; Random variables; Time series; Hypotheses; Sampling methods; Normal distribution; Food science},
language={English},
url={https://www.proquest.com/scholarly-journals/ratio-test-mean-changes-time-series-with-heavy/docview/2869422274/se-2},
}

@article{
author={Hallit,Souheil and Rogoza,Radosław and Carl,Abi S. and Azzi,Vanessa and Sawma,Toni and Obeid,Sahar},
year={2023},
month={2023},
title={Validation of the Arabic version of the cyberchondria severity scale 12 items (CSS-12-Ar) among a sample of Lebanese adults},
journal={BMC Psychiatry},
volume={23},
pages={1-8},
note={Copyright - © 2023. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-26; SubjectsTermNotLitGenreText - Beirut Lebanon; Lebanon},
abstract={BackgroundTo the best of our knowledge, the Cyberchondria Severity Scale-12 (CSS-12) has not been translated into Arabic; therefore, our objective was to assess the psychometric properties of the Arabic version of the CSS (CSS-12-Ar) among a sample of Lebanese adults.MethodsParticipants were enrolled in January 2021. A confirmatory factor analysis (CFA) was carried out using the MPlus software v.7.2, reporting several goodness-of-fit indicators: Relative Chi-square (χ2/df), Root Mean Square Error of Approximation (RMSEA), Comparative Fit Index (CFI) and Tucker Lewis Index (TLI). To evaluate measurement invariance across gender, we conducted higher-order multiple group confirmatory analysis using lavaan software.Results449 participants enrolled in this study (mean age: 24.34 ± 8.22 years, 70.6% females). Since the correlations between the four-factor model were very high (r > 0.8), we ran the higher-order CFA in which all first-order latent variables were loading a general factor. The analyzed model was well-fitted to the data χ2(50) = 173.34; p < 0.001; CFI = 0.926; RMSEA = 0.074 0.062, 0.086]. The Cronbach’s alpha values were good for the total score (0.92), as well as for excessiveness (0.80), distress (0.77), reassurance (0.81) and compulsion (0.76). The results provided evidence of full scalar invariance across gender. The comparison of latent mean scores revealed no significant differences across gender, in either the cyberchondria total score or its facets. The CSS-12 score was positively associated with anxiety (r = 0.10; p = 0.003) (convergent validity), OCD (r = 0.11; p = 0.016) and stress (r = 0.35; p < 0.001) (concurrent validity).ConclusionThe CSS-12-Ar was deemed a suitable scale to measure the severity of cyberchondria among Lebanese university students. We hope that researchers and clinicians can benefit now from this scale.},
keywords={Medical Sciences--Psychiatry And Neurology; Cyberchondria severity; CSS-12; Arabic; Psychometric properties; Validation; Lebanon; Factor analysis; Quantitative research; Anxiety; Validity; Internet; Gender; Stress; Quantitative psychology; Pandemics; Sociodemographics; Questionnaires; Mental depression; False information; Professionals; Mental health; Psychologists; COVID-19; Chi-square test; Psychiatry; Beirut Lebanon},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-arabic-version-cyberchondria-severity/docview/2865397499/se-2},
}

@article{
author={Palombi,Tommaso and Galli,Federica and Giancamilli,Francesco and D’Amico,Monica and Alivernini,Fabio and Gallo,Luigi and Neroni,Pietro and Predazzi,Marco and De Pietro,Giuseppe and Lucidi,Fabio and Giordano,Antonio and Chirico,Andrea},
year={2023},
month={2023},
title={The role of sense of presence in expressing cognitive abilities in a virtual reality task: an initial validation study},
journal={Scientific Reports (Nature Publisher Group)},
volume={13},
number={1},
pages={13396},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-05},
abstract={There is a raised interest in literature to use Virtual Reality (VR) technology as an assessment tool for cognitive domains. One of the essential advantages of transforming tests in an immersive virtual environment is the possibility of automatically calculating the test’s score, a time-consuming process under natural conditions. Although the characteristics of VR can deliver different degrees of immersion in a virtual environment, the sense of presence could jeopardize the evolution of these practices. The sense of presence results from a complex interaction between human, contextual factors, and the VR environment. The present study has two aims: firstly, it contributes to the validation of a virtual version of the naturalistic action test (i.e., virtual reality action test); second, it aims to evaluate the role of sense of presence as a critical booster of the expression of cognitive abilities during virtual reality tasks. The study relies on healthy adults tested in virtual and real conditions in a cross-over research design. The study’s results support the validity of the virtual reality action test. Furthermore, two structural equation models are tested to comprehend the role of sense of presence as a moderator in the relationship between cognitive abilities and virtual task performance.},
keywords={Sciences: Comprehensive Works; Computer applications; Cognitive ability; Virtual reality},
language={English},
url={https://www.proquest.com/scholarly-journals/role-sense-presence-expressing-cognitive/docview/2852217820/se-2},
}

@article{
author={Wei,Shu and Freeman,Daniel and Rovira,Aitor},
year={2023},
month={2023},
title={A randomised controlled test of emotional attributes of a virtual coach within a virtual reality (VR) mental health treatment},
journal={Scientific Reports (Nature Publisher Group)},
volume={13},
number={1},
pages={11517},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-07-18},
abstract={We set out to test whether positive non-verbal behaviours of a virtual coach can enhance people's engagement in automated virtual reality therapy. 120 individuals scoring highly for fear of heights participated. In a two-by-two factor, between-groups, randomised design, participants met a virtual coach that varied in warmth of facial expression (with/without) and affirmative nods (with/without). The virtual coach provided a consultation about treating fear of heights. Participants rated the therapeutic alliance, treatment credibility, and treatment expectancy. Both warm facial expressions (group difference = 7.44 3.25, 11.62], p = 0.001, etap2=0.10) and affirmative nods (group difference = 4.36 0.21, 8.58], p = 0.040, etap2 = 0.04) by the virtual coach independently increased therapeutic alliance. Affirmative nods increased the treatment credibility (group difference = 1.76 0.34, 3.11], p = 0.015, etap2 = 0.05) and expectancy (group difference = 2.28 0.45, 4.12], p = 0.015, etap2 = 0.05) but warm facial expressions did not increase treatment credibility (group difference = 0.64 − 0.75, 2.02], p = 0.363, etap2 = 0.01) or expectancy (group difference = 0.36 − 1.48, 2.20], p = 0.700, etap2 = 0.001). There were no significant interactions between head nods and facial expressions in the occurrence of therapeutic alliance (p = 0.403, etap2 = 0.01), credibility (p = 0.072, etap2 = 0.03), or expectancy (p = 0.275, etap2 = 0.01). Our results demonstrate that in the development of automated VR therapies there is likely to be therapeutic value in detailed consideration of the animations of virtual coaches.},
keywords={Sciences: Comprehensive Works; Fear; Expectancy; Computer applications; Automation; Credibility; Virtual reality},
language={English},
url={https://www.proquest.com/scholarly-journals/randomised-controlled-test-emotional-attributes/docview/2838513554/se-2},
}

@article{
author={Hutter,Daniel E. and Wingsted,Line and Cejvanovic,Sanja and Jacobsen,Mads F. and Ochoa,Luis and González Daher,Karla P. and la Cour,Morten and Konge,Lars and Thomsen,Ann S. S.},
year={2023},
month={2023},
title={A validated test has been developed for assessment of manual small incision cataract surgery skills using virtual reality simulation},
journal={Scientific Reports (Nature Publisher Group)},
volume={13},
number={1},
pages={10655},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-09-15},
abstract={This study investigates the validity evidence of metrics used for the assessment of surgical skills for Manual Small Incision Cataract Surgery (MSICS) in a virtual reality simulator. MSICS surgery is a low-cost, low-technology cataract surgery technique, which is widely used in low- and middle-income countries. However, there is a lack of cataract surgeons globally, and efficient and evidence-based training of new surgeons is needed. In order to investigate the validity of simulator metrics, we included three groups of participants: (1) MSICS novices who were ophthalmologists with no cataract surgery experience, (2) MSICS novices who were experienced phacoemulsification cataract surgeons, but with no MSICS experience, and (3) experienced phacoemulsification and MSICS surgeons. The evaluation included 11 steps of the MSICS procedure, and all simulator metrics for those steps were reviewed. Of the 55 initial metrics, 30 showed high positive discriminative ability. A test passing score of 20 out of 30 was established, and one of 15 novices with no MSICS experience (mean score 15.5) and 7 out of 10 experienced MSICS surgeons (mean score 22.7) passed the test. We have developed and established validity evidence for a test for MSICS skills in a virtual reality simulator for future use in proficiency-based training and evidence-based testing of training interventions.},
keywords={Sciences: Comprehensive Works; Training; Surgeons; Validity; Computer applications; Eye surgery; Virtual reality; Surgery; Cataracts},
language={English},
url={https://www.proquest.com/scholarly-journals/validated-test-has-been-developed-assessment/docview/2831683460/se-2},
}

@article{
author={Maloca,Peter M. and Zarranz-Ventura,Javier and Valmaggia,Philippe and Faludi,Balázs and Zelechowski,Marek and Tufail,Adnan and Zentai,Norbert Z. and Scholl,Hendrik P. N. and Cattin,Philippe C.},
year={2023},
month={2023},
title={Validation of collaborative cyberspace virtual reality oculometry enhanced with near real-time spatial audio},
journal={Scientific Reports (Nature Publisher Group)},
volume={13},
number={1},
pages={10076},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-06-22},
abstract={Currently, most medical image data, such as optical coherence tomography (OCT) images, are displayed in two dimensions on a computer screen. Advances in computer information technology have contributed to the growing storage of these data in electronic form. However, the data are usually processed only locally on site. To overcome such hurdles, a cyberspace virtual reality (csVR) application was validated, in which interactive OCT data were presented simultaneously to geographically distant sites (Lucerne, London, and Barcelona) where three graders independently measured the ocular csVR OCT diameters. A total of 109 objects were measured, each three times, resulting in a total of 327 csVR measurements. A minor mean absolute difference of 5.3 µm was found among the 3 measurements of an object (standard deviation 4.2 µm, coefficient of variation 0.3% with respect to the mean object size). Despite the 5 h of online work, csVR was well tolerated and safe. Digital high-resolution OCT data can be remotely and collaboratively processed in csVR. With csVR, measurements and actions enhanced with spatial audio communication can be made consistently in near real time, even if the users are situated geographically far apart. The proposed visuo-auditory framework has the potential to further boost the convenience of digital medicine toward csVR precision and collaborative medicine.},
keywords={Sciences: Comprehensive Works; Computer applications; Collaboration; Virtual reality},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-collaborative-cyberspace-virtual/docview/2828067503/se-2},
}

@article{
author={Muhammad Danish,Affan A. and Ismail,Ismahafezi and Nur Saadah,Mohd S. and Wan Mohd Amir Fazamin,Wan Hamzah and Maizan,Mat A. and Karim,Fazida},
year={2023},
month={2023},
title={Validate the Users’ Comfortable Level in the Virtual Reality Walkthrough Environment for Minimizing Motion Sickness},
journal={International Journal of Advanced Computer Science and Applications},
volume={14},
number={4},
note={Copyright - © 2023. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-27},
abstract={Motion sickness is a common scenario for users when they are exposed to a virtual reality (VR) environment. It is due to the conflict that occurs in the brain that tells the user that they are moving in the environment, but the fact is that the user’s body is sitting still causing them to get symptoms of motion sickness like nausea and dizziness. Therefore, motion sickness has become one of the main reasons why users still do not prefer to use VR to enhance their productivity. Motion sickness can be overcome by increasing the user's comfort level of walkthrough in the VR environment. Meanwhile, a popular VR simulation which is widely used in many industries is a walkthrough in a VR environment at a certain speed. This paper is focused on presenting the result of walkthroughs in a VR environment using movement speed and based on frame rates performance and adopting the unified theory of acceptance and use of technology (UTAUT) model construct variables namely performance expectancy (PE) and effort expectancy (EE) to measure the user’s comfort level. A mobile VR, ‘VR Terrain’ application software was developed based on the proposed framework. The application software was tested by 30 users by moving around in a VR environment with 4 different movement speeds that were implemented into four colored gates using a head-mounted display (HMD). A descriptive and coefficient analysis was used to analyze all the data. The blue gate revealed the most comfortable, outperforming all other three gates. Overall, the most suitable speed to use for VR walkthrough is 4.0 km/h. The experiment result may be used to create a parameter for the VR developers to reduce the VR motion sickness effect in the future.},
keywords={Sciences: Comprehensive Works; Virtual reality; motion sickness; head-mounted display; head lean movement; mobile VR; walkthrough technique; UTAUT; frame rate; Software; Helmet mounted displays; Movement},
isbn={2158107X},
language={English},
url={https://www.proquest.com/scholarly-journals/validate-users-comfortable-level-virtual-reality/docview/2819915820/se-2},
}

@article{
author={Maksoud,Aref and Hussien,Aseel and Mushtaha,Emad and Abdul-Rahman Alawneh,Sarah I.},
year={2023},
month={2023},
title={Computational Design and Virtual Reality Tools as an Effective Approach for Designing Optimization, Enhancement, and Validation of Islamic Parametric Elevation},
journal={Buildings},
volume={13},
number={5},
pages={1204},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-08-24},
abstract={Virtual reality was investigated with various computational design approaches to improve users’ ability to communicate, share, and grasp the design’s requirements to better conceptualize ideas during various design and review stages. The study aims to show how computational design and virtual reality are utilized to forecast challenges, address design problems/limitations in a specific study space, and validate results. A case study of the main Architectural Engineering department building at the University of Sharjah (UoS) campus in Sharjah, United Arab Emirates, was considered. The study focused on indoor daylight intake, ventilation, functionality, user comfortability, structural integrity, coherency and consistency, and performance optimization as factors to further evaluate and aid in the selection process of the optimal design. Consequently, innovative computational design tools were used in the study’s methodology to assess offered alternatives, such as altering and fabricating the building’s skin to deal with the challenges described above and improving the selected room’s visual and environmental conditions, such as optimal daylighting and ensuring users’ comfortability. The users’ immersive experience resulted in more accurate visualization and navigation around the to-be-built environment, allowing for more significant analysis and comprehension that further validated the results obtained. The chosen case study thus demonstrated the potential for computational design, mixed reality techniques, and strategies to enable an efficient process that ultimately verifies approaches taken toward a much more optimal solution through better visualization and contextualizing.},
keywords={Building And Construction; computational design; energy performance; visual comfort; virtual reality; lighting design optimization; grasshopper; Construction; Case studies; Collaboration; Optimization; Structural integrity; Sustainability; Environmental conditions; Design; Architecture; Computer applications; Visualization; Urban environments; Mixed reality; Software; Daylight},
language={English},
url={https://www.proquest.com/scholarly-journals/computational-design-virtual-reality-tools-as/docview/2819413204/se-2},
}

@article{
author={Campo-Prieto,Pablo and José Mª Cancela-Carral and Rodríguez-Fuentes,Gustavo},
year={2023},
month={2023},
title={Immersive Virtual Reality Reaction Time Test and Relationship with the Risk of Falling in Parkinson’s Disease},
journal={Sensors},
volume={23},
number={9},
pages={4529},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-04},
abstract={Immersive virtual reality (IVR) uses customized and advanced software and hardware to create a digital 3D reality in which all of the user’s senses are stimulated with computer-generated sensations and feedback. This technology is a promising tool that has already proven useful in Parkinson’s disease (PD). The risk of falls is very high in people with PD, and reaction times and processing speed may be markers of postural instability and functionality, cognitive impairment and disease progression. An exploratory study was conducted to explore the feasibility of reaction time tests performed in IVR as predictors of falls. A total of 26 volunteers (79.2% male; 69.73 ± 6.32 years) diagnosed with PD (1.54 ± 0.90 H&Y stage; 26.92 ± 2.64 MMSE) took part in the study. IVR intervention was feasible, with no adverse effects (no Simulator Sickness Questionnaire symptoms). IVR reaction times were related (Spearman’s rho) to functionality (timed up and go test (TUG) (rho = 0.537, p = 0.005); TUG-Cognitive (rho = 0.576, p = 0.020); cognitive impairment mini mental state exam (MMSE) (rho = −0.576, p = 0.002)) and the years of the patients (rho = 0.399, p = 0.043) but not with the first PD symptom or disease stage. IVR test is a complementary assessment tool that may contribute to preventing falls in the proposed sample. Additionally, based on the relationship between TUG and reaction times, a cut-off time is suggested that would be effective at predicting the risk of suffering a fall in PD patients using a simple and quick IVR test.},
keywords={Chemistry--Analytical Chemistry; virtual reality exposure therapy; Parkinson's disease; Timed Up and Go test; Mental chronometry; Autumn; Immersion; Virtual reality; digital health; Parkinson’s disease; reaction time; falls; videogames; physical activity; measurement of movement; rehabilitation; games for health; Software; Older people; Risk; Signs and symptoms; Immersive virtual reality; Feasibility studies; Impairment; Exercise},
language={English},
url={https://www.proquest.com/scholarly-journals/immersive-virtual-reality-reaction-time-test/docview/2812737457/se-2},
}

@article{
author={Faity,Germain and Sidahmed,Yasmine and Laffont,Isabelle and Froger,Jé},
year={2023},
month={2023},
title={Quantification and Rehabilitation of Unilateral Spatial Neglect in Immersive Virtual Reality: A Validation Study in Healthy Subjects},
journal={Sensors},
volume={23},
number={7},
pages={3481},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-23},
abstract={Unilateral spatial neglect is a common sensorimotor disorder following the occurrence of a stroke, for which prismatic adaptation is a promising rehabilitation method. However, the use of prisms for rehabilitation often requires the use of specific equipment that may not be available in clinics. To address this limitation, we developed a new software package that allows for the quantification and rehabilitation of unilateral spatial neglect using immersive virtual reality. In this study, we compared the effects of virtual and real prisms in healthy subjects and evaluated the performance of our virtual reality tool (HTC Vive) against a validated motion capture tool. Ten healthy subjects were randomly exposed to virtual and real prisms, and measurements were taken before and after exposure. Our findings indicate that virtual prisms are at least as effective as real prisms in inducing aftereffects (4.39° ± 2.91° with the virtual prisms compared to 4.30° ± 3.49° with the real prisms), but that these effects were not sustained beyond 2 h regardless of exposure modality. The virtual measurements obtained with our software showed excellent metrological qualities (ICC = 0.95, error = 0.52° ± 1.18°), demonstrating its validity and reliability for quantifying deviation during pointing movements. Overall, our results suggest that our virtual reality software (Virtualis, Montpellier, France) could provide an easy and reliable means of quantifying and rehabilitating spatial neglect. Further validation of these results is required in individuals with unilateral spatial neglect.},
keywords={Chemistry--Analytical Chemistry; stroke rehabilitation; Stroke; Hemispatial neglect; Rehabilitation; Immersion; Virtual reality; unilateral spatial neglect; prism adaptation; subjective straight ahead; visual open-loop; pointing; serious game; HTC Vive; mocap; Prisms; Software packages; Immersive virtual reality; Exposure; Motion capture; Computer & video games; Educational software},
language={English},
url={https://www.proquest.com/scholarly-journals/quantification-rehabilitation-unilateral-spatial/docview/2799788723/se-2},
}

@article{
author={Tang,Yingying and Chen,Yuling and Luo,Yun and Sen,Dong and Li,Tao},
year={2023},
month={2023},
title={VR-PEKS: A Verifiable and Resistant to Keyword Guess Attack Public Key Encryption with Keyword Search Scheme},
journal={Applied Sciences},
volume={13},
number={7},
pages={4166},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-19},
abstract={Public key encryption with keyword search (PEKS) allows users to perform keyword searches of ciphertext on untrusted cloud storage servers, protecting data privacy while sharing data. However, it faces several security problems in practical applications. First, an attacker can launch a keyword guessing attack to obtain keywords of interest to users, causing the leakage of their sensitive information. Second, untrusted cloud servers may return incorrect or incomplete results. In addition, with the continuous development of quantum computers, existing PEKS schemes face the problem of quantum attacks. Since cloud servers are mostly untrusted, verifiable search has become a hot research topic among scholars. However, most of the current schemes are based on bilinear pairing constructions, which are vulnerable to quantum attacks. To solve these problems, we propose a new ciphertext retrieval scheme based on fully homomorphic encryption (FHE), called VR-PEKS. This scheme implements verifiable search and is able to solve the problems of keyword guessing attacks and quantum attacks. We propose to improve the security of the scheme by using the oblivious pseudorandom function to randomize keywords and then encrypt them using FHE. An encrypted verified index structure is constructed and exposed by the data owner, enabling the data recipient to achieve verification of the correctness and integrity of the retrieved results without relying on a trusted third party. We demonstrate the security of the proposed scheme in a stochastic prediction model, and prove that our scheme satisfies keyword ciphertext indistinguishability and keyword trapdoor indistinguishability under adaptive keyword selection attacks. The comparison shows that our scheme is secure and feasible.},
keywords={Sciences: Comprehensive Works; cloud storage; public key encryption with keyword search; fully homomorphic encryption; keyword guess attack; verifiable; Encryption; Homomorphic encryption; Public-key cryptography; Hospitals; Medical records; Information sharing; Privacy; Keywords; Servers},
language={English},
url={https://www.proquest.com/scholarly-journals/vr-peks-verifiable-resistant-keyword-guess-attack/docview/2799592277/se-2},
}

@article{
author={Guzsvinecz,Tibor and Perge,Erika and Szűcs,Judit},
year={2023},
month={2023},
title={Examining the Results of Virtual Reality-Based Egocentric Distance Estimation Tests Based on Immersion Level},
journal={Sensors},
volume={23},
number={6},
pages={3138},
note={Name - Samsung Electronics Co Ltd; Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-04},
abstract={Depth perception as well as egocentric distance estimation can be trained in virtual spaces, although incorrect estimates can occur in these environments. To understand this phenomenon, a virtual environment with 11 changeable factors was created. Egocentric distance estimation skills of 239 participants were assessed with it in the range 25 cm, 160 cm]. One hundred fifty-seven people used a desktop display and seventy-two the Gear VR. According to the results, these investigated factors can have various effects combined with the two display devices on distance estimation and its time. Overall, desktop display users are more likely to accurately estimate or overestimate distances, and significant overestimations occur at 130 and 160 cm. With the Gear VR, distances in the range 40 cm, 130 cm] are significantly underestimated, while at 25 cm, they are significantly overestimated. Estimation times are significantly decreased with the Gear VR. When developing future virtual environments that require depth perception skills, developers should take these results into account.},
keywords={Chemistry--Analytical Chemistry; desktop display; Virtual environment; Gear; Virtual reality; Depth perception; egocentric distance estimation; Gear VR; head-mounted display; human–computer interaction; immersion; Investigations; Display devices; Space perception; Estimates; Keyboards; Skills; Virtual environments},
language={English},
url={https://www.proquest.com/scholarly-journals/examining-results-virtual-reality-based/docview/2791721803/se-2},
}

@article{
author={Loetscher,Tobias and Nadia,Siena J. and Michalski,Stefan C. and Billinghurst,Mark and Lee,Gun},
year={2023},
month={2023},
title={Online Platforms for Remote Immersive Virtual Reality Testing: An Emerging Tool for Experimental Behavioral Research},
journal={Multimodal Technologies and Interaction},
volume={7},
number={3},
pages={32},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-30},
abstract={Virtual Reality (VR) technology is gaining in popularity as a research tool for studying human behavior. However, the use of VR technology for remote testing is still an emerging field. This study aimed to evaluate the feasibility of conducting remote VR behavioral experiments that require millisecond timing. Participants were recruited via an online crowdsourcing platform and accessed a task on the classic cognitive phenomenon “Inhibition of Return” through a web browser using their own VR headset or desktop computer (68 participants in each group). The results confirm previous research that remote participants using desktop computers can be used effectively for conducting time-critical cognitive experiments. However, inhibition of return was only partially replicated for the VR headset group. Exploratory analyses revealed that technical factors, such as headset type, were likely to significantly impact variability and must be mitigated to obtain accurate results. This study demonstrates the potential for remote VR testing to broaden the research scope and reach a larger participant population. Crowdsourcing services appear to be an efficient and effective way to recruit participants for remote behavioral testing using high-end VR headsets.},
keywords={Computers--Cybernetics; crowdsourcing; Inhibition of return; Reality testing; Immersion; Virtual reality; online testing; reaction time; Prolific; Research; Behavior; Data collection; Headsets; Personal computers; Experiments; Immersive virtual reality; Consent; Inhibition (psychology)},
language={English},
url={https://www.proquest.com/scholarly-journals/online-platforms-remote-immersive-virtual-reality/docview/2791673654/se-2},
}

@article{
author={Gorash,Yevgen and Comlekci,Tugrul and Styger,Gary and Kelly,James and Brownlie,Frazer and Milne,Lewis},
year={2023},
month={2023},
title={Ultrasonic Fatigue Testing of Structural Steel S275JR+AR with Insights into Corrosion, Mean Stress and Frequency Effects},
journal={Materials},
volume={16},
number={5},
pages={1799},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-03-10},
abstract={There are limited experimental data on VHCF for structural steels for >107 cycles. Unalloyed low-carbon steel S275JR+AR is a common structural material for the heavy machinery in minerals, sand and aggregate applications. The purpose of this research is to investigate the fatigue behaviour in the gigacycle domain (>109 cycles) for S275JR+AR grade steel. This is achieved using accelerated ultrasonic fatigue testing in as-manufactured, pre-corroded and non-zero mean stress conditions. As internal heat generation is a massive challenge for ultrasonic fatigue testing of structural steels which exhibit a pronounced frequency effect, effective temperature control is crucial for implementation of testing. The frequency effect is assessed by comparing the test data at 20 kHz and 15–20 Hz. Its contribution is significant, as there is no overlap between the stress ranges of interest. The obtained data are intended to be applied to the fatigue assessments of the equipment operating at the frequency for up to 1010 cycles over years of continuous service.},
keywords={Engineering--Civil Engineering; structural steel; very high cycle fatigue; ultrasonic fatigue; corrosion; frequency effect; mean stress correction; Corrosion effects; Ultrasonic testing; Metal fatigue; Low carbon steels; Heat generation; Yield stress; Structural steels; Temperature control; Crack initiation; Accelerated tests; Design; Fatigue tests; Corrosion fatigue; Steel; Crack propagation},
language={English},
url={https://www.proquest.com/scholarly-journals/ultrasonic-fatigue-testing-structural-steel/docview/2785231150/se-2},
}

@article{
author={Veiga-Canuto,Diana and Cerdà-Alberich,Leonor and Jiménez-Pastor,Ana and José Miguel,Carot S. and Gomis-Maya,Armando and Sangüesa-Nebot,Cinta and Fernández-Patón,Matías and Blanca Martínez de,las H. and Taschner-Mandl,Sabine and Düster,Vanessa and Pötschger,Ulrike and Simon,Thorsten and Neri,Emanuele and Alberich-Bayarri,Ángel and Cañete,Adela and Hero,Barbara and Ladenstein,Ruth and Martí-Bonmatí,Luis},
year={2023},
month={2023},
title={Independent Validation of a Deep Learning nnU-Net Tool for Neuroblastoma Detection and Segmentation in MR Images},
journal={Cancers},
volume={15},
number={5},
pages={1622},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-22; SubjectsTermNotLitGenreText - Spain},
abstract={Simple SummaryTumor segmentation is a key step in oncologic imaging processing. We have recently developed a model to detect and segment neuroblastic tumors on MR images based on deep learning architecture nnU-Net. In this work, we performed an independent validation of the automatic segmentation tool with a large heterogeneous dataset. We reviewed the automatic segmentations and manually edited them when necessary. We were able to show that the automatic network was able to locate and segment the primary tumor on the T2 weighted images in the majority of cases, with an extremely high agreement between the automatic tool and the manually edited masks. The time needed for manual adjustment was very low.AbstractObjectives. To externally validate and assess the accuracy of a previously trained fully automatic nnU-Net CNN algorithm to identify and segment primary neuroblastoma tumors in MR images in a large children cohort. Methods. An international multicenter, multivendor imaging repository of patients with neuroblastic tumors was used to validate the performance of a trained Machine Learning (ML) tool to identify and delineate primary neuroblastoma tumors. The dataset was heterogeneous and completely independent from the one used to train and tune the model, consisting of 300 children with neuroblastic tumors having 535 MR T2-weighted sequences (486 sequences at diagnosis and 49 after finalization of the first phase of chemotherapy). The automatic segmentation algorithm was based on a nnU-Net architecture developed within the PRIMAGE project. For comparison, the segmentation masks were manually edited by an expert radiologist, and the time for the manual editing was recorded. Different overlaps and spatial metrics were calculated to compare both masks. Results. The median Dice Similarity Coefficient (DSC) was high 0.997; 0.944–1.000 (median; Q1–Q3). In 18 MR sequences (6%), the net was not able neither to identify nor segment the tumor. No differences were found regarding the MR magnetic field, type of T2 sequence, or tumor location. No significant differences in the performance of the net were found in patients with an MR performed after chemotherapy. The time for visual inspection of the generated masks was 7.9 ± 7.5 (mean ± Standard Deviation (SD)) seconds. Those cases where manual editing was needed (136 masks) required 124 ± 120 s. Conclusions. The automatic CNN was able to locate and segment the primary tumor on the T2-weighted images in 94% of cases. There was an extremely high agreement between the automatic tool and the manually edited masks. This is the first study to validate an automatic segmentation model for neuroblastic tumor identification and segmentation with body MR images. The semi-automatic approach with minor manual editing of the deep learning segmentation increases the radiologist’s confidence in the solution with a minor workload for the radiologist.},
keywords={Medical Sciences--Oncology; tumor segmentation; Machine learning; Neuroblastoma; Deep learning; Neurodegenerative disease; independent validation; external validation; neuroblastic tumors; automatic segmentation; Cancer; Datasets; Artificial intelligence; Algorithms; Segmentation; Neural networks; Medical research; Biomarkers; Tumors; Image processing; Chemotherapy; Performance evaluation; Feasibility studies; Pediatrics; Reproducibility; Spain},
language={English},
url={https://www.proquest.com/scholarly-journals/independent-validation-deep-learning-nnu-net-tool/docview/2785176591/se-2},
}

@article{
author={Malhotra,Shivali and Halabi,Osama and Sarada,Prasad D. and Padhan,Jhasketan and Santu,Paul and Palliyali,Waseem},
year={2023},
month={2023},
title={Augmented Reality in Surgical Navigation: A Review of Evaluation and Validation Metrics},
journal={Applied Sciences},
volume={13},
number={3},
pages={1629},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-19},
abstract={Pre-operative imaging has been used earlier to guide traditional surgical navigation systems. There has been a lot of effort in the last decade to integrate augmented reality into the operating room to help surgeons intra-operatively. An augmented reality (AR) based navigation system provides a clear three-dimensional picture of the interested areas over the patient to aid surgical navigation and operations, which is a promising approach. The goal of this study is to review the application of AR technology in various fields of surgery and how the technology is used for its performance in each field. Assessment of the available AR assisted navigation systems being used for surgery is reviewed in this paper. Furthermore, a discussion about the required evaluation and validation metric for these systems is also presented. The paper comprehensively reviews the literature since the year 2008 for providing relevant information on applying the AR technology for training, planning and surgical navigation. It also describes the limitations which need to be addressed before one can completely rely on this technology for surgery. Thus, additional research is desirable in this emerging field, particularly to evaluate and validate the use of AR technology for surgical navigation.},
keywords={Sciences: Comprehensive Works; augmented reality; surgery; visualization; evaluation; validation; Navigation; Computer-assisted surgery; Navigation systems; Usability; Trauma; Bone surgery; Technology; Planning; Magnetic resonance imaging; Neurosurgery; Surgical techniques; Three dimensional imaging; Registration; Orthopedics; Medical imaging; Back surgery; Virtual reality; Cognition & reasoning; Clinical outcomes; Interfaces},
language={English},
url={https://www.proquest.com/scholarly-journals/augmented-reality-surgical-navigation-review/docview/2779899590/se-2},
}

@article{
author={Fratini,Elena and Welsh,Ruth and Thomas,Pete},
year={2023},
month={2023},
title={Ranking Crossing Scenario Complexity for eHMIs Testing: A Virtual Reality Study},
journal={Multimodal Technologies and Interaction},
volume={7},
number={2},
pages={16},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-30},
abstract={External human–machine interfaces (eHMIs) have the potential to benefit AV–pedestrian interactions. The majority of studies investigating eHMIs have used relatively simple traffic environments, i.e., a single pedestrian crossing in front of a single eHMI on a one-lane straight road. While this approach has proved to be efficient in providing an initial understanding of how pedestrians respond to eHMIs, it over-simplifies interactions which will be substantially more complex in real-life circumstances. A process is illustrated in a small-scale study (N = 10) to rank different crossing scenarios by level of complexity. Traffic scenarios were first developed for varying traffic density, visual complexity of the road scene, road geometry, weather and visibility conditions, and presence of distractions. These factors have been previously shown to increase difficulty and riskiness of the crossing task. The scenarios were then tested in a motion-based, virtual reality environment. Pedestrians’ perceived workload and objective crossing behaviour were measured as indirect indicators of the level of complexity of the crossing scenario. Sense of presence and simulator sickness were also recorded as a measure of the ecological validity of the virtual environment. The results indicated that some crossing scenarios were more taxing for pedestrians than others, such as those with road geometries where traffic approached from multiple directions. Further, the presence scores showed that the virtual environments experienced were found to be realistic. This paper concludes by proposing a “complex” environment to test eHMIs under more challenging crossing circumstances.},
keywords={Computers--Cybernetics; external human-machine interface; Simulator sickness; Virtual reality; User interface; eHMI; autonomous vehicles; head-mounted display; pedestrian behaviour; road safety; pedestrian–vehicle interaction; traffic interaction; workload (SIM-TLX); Fatalities; Traffic volume; Pedestrian crossings; Complexity; Pedestrians; Ecological effects; Decision making; Virtual environments},
language={English},
url={https://www.proquest.com/scholarly-journals/ranking-crossing-scenario-complexity-ehmis/docview/2779630214/se-2},
}

@article{
author={Eagleson,Roy and Joskowicz,Leo},
year={2023},
month={2023},
title={Verification, Evaluation, and Validation: Which, How & Why, in Medical Augmented Reality System Design},
journal={Journal of Imaging},
volume={9},
number={2},
pages={20},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-27},
abstract={This paper presents a discussion about the fundamental principles of Analysis of Augmented and Virtual Reality (AR/VR) Systems for Medical Imaging and Computer-Assisted Interventions. The three key concepts of Analysis (Verification, Evaluation, and Validation) are introduced, illustrated with examples of systems using AR/VR, and defined. The concepts of system specifications, measurement accuracy, uncertainty, and observer variability are defined and related to the analysis principles. The concepts are illustrated with examples of AR/VR working systems.},
keywords={Photography; system analysis; Verification; Medical imaging; Reality; Computer-assisted interventions; Evaluation; Validation; Virtual reality; Augmented reality; medical augmented reality; uncertainty; observer variability; measurements accuracy; Accuracy; Validity; Systems design; Design engineering; Design; Cognitive ability; Back surgery; Reproducibility; Cognition & reasoning; Principles},
language={English},
url={https://www.proquest.com/scholarly-journals/verification-evaluation-validation-which-how-amp/docview/2779555958/se-2},
}

@article{
author={Fekih-Romdhane,Feten and Merhy,Georges and Moubarak,Verginia and He,Jinbo and Rogoza,Radoslaw and Hallit,Rabih and Obeid,Sahar and Hallit,Souheil},
year={2023},
month={2023},
title={Validation of the Arabic version of the Muscle Dysmorphic Disorder Inventory (Ar-MDDI) among Lebanese male university students},
journal={Journal of Eating Disorders},
volume={11},
pages={1-10},
note={Copyright - © 2023. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-26; SubjectsTermNotLitGenreText - Lebanon},
abstract={BackgroundTo date, the vast majority of research on disordered eating symptomatology and body image disturbances from the Arab world have been performed exclusively among women; and mainly used thinness-oriented measures that are not sensitive to detect muscularity-oriented symptoms, which are more evident in males. Therefore, the objective of our study was to validate the Arabic version of the Muscle Dysmorphic Disorder Inventory (Ar-MDDI), in order to make it accessible for Arabic-speaking populations.MethodsUsing a snowball sampling technique, men university students (n = 396) from multiple universities in Lebanon filled the survey in this cross-sectional designed study (January–May 2022). A soft copy of the questionnaire was created using google forms software, and sent to participants through the different social media platforms such as Facebook, Instagram, and WhatsApp. We used the Muscle Dysmorphic Disorder Inventory to assess Muscle Dysmorphia, along with the Big Three Perfectionism Scale to assess perfectionism and Eating Attitude Test (EAT) to evaluate the inappropriate eating attitudes. To explore the factor structure of Ar-MDDI, we computed a principal-axis Exploratory Factor Analysis (EFA) with the first split-half subsample using the FACTOR software. We used data from the second split-half to conduct a Confirmatory Factor Analysis (CFA) using the SPSS AMOS v.29 software. Pearson correlation test was used to test the convergent and divergent validity of the Ar-MDDI scale with the other scores included in the study.ResultsThe results of the EFA revealed three factors, which explained 57.68% of the common variance: Factor 1 = Appearance intolerance, Factor 2 = Drive for size, and Factor 3 = Functional impairment. The CFA fit indices of the three-factor model of the Ar-MDDI scale showed good results. Moreover, 254 (64.1%) of the participants had inappropriate eating attitudes (EAT scores ≥ 20). Indices suggested that configural, metric, and scalar invariance was supported according to eating attitudes. No significant difference between participants with appropriate versus inappropriate eating attitudes in terms of functional impairment, drive for size and appearance intolerance. Perfectionism scores correlated positively with the Ar-MDDI, which suggests divergent validity.ConclusionOur findings revealed that the validation of the Arabic scale yielded excellent properties, preliminarily supporting its use for the assessment of muscle dysmorphia among Arabic-speaking university men. This would hopefully allow for its timely detection and management in Arab clinical settings and encourage cross-cultural research on this topic.},
keywords={Psychology; Muscle dysmorphia; Skeletal muscle; Dysmorphic; Eating Attitudes Test; Fatigue; Arabic; Disordered eating; Confirmatory factor analysis; Validity; Validation; Factor analysis; Quantitative research; Surveys & questionnaires; Qualitative research; Cross-cultural research; Research; Arabic language; Self image; Data collection; University students; Eating behavior; Eating disorders; Social networks; Body image; Questionnaires; Lebanon},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-arabic-version-muscle-dysmorphic/docview/2777784984/se-2},
}

@article{
author={Charlery-Adèle,Ambre and Guigou,Caroline and Ryard,Julien and Chartier,Mathis and Toupet,Michel and Guillet,Christophe and Mérienne,Férédric and Bozorg Grayeli,Alexis},
year={2023},
month={2023},
title={Effects of saccade delay, side of deficit, and training on detection of catch-up saccades during head-impulse test in virtual-reality-enhanced mannequin},
journal={Scientific Reports (Nature Publisher Group)},
volume={13},
number={1},
pages={2718},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-04},
abstract={In this study, a training simulator for the examination of dizzy patients based on a virtual-reality-enhanced mannequin (VREM) was developed to evaluate the detection of catch-up saccades during head impulse test (HIT) and the effect of training in VREM. For novices (n = 35), 2 trials were conducted before and after a training session. Experts (n = 7) were submitted to an evaluation session. In each trial, a left or a right horizontal canal deficit with an overt catch-up saccade (delay between 110 and 320 ms) was randomly presented. Participants scored the difficulty in performing the maneuver, in recognizing the saccades, and the self-confidence in the diagnosis using a visual analogue scale (VAS). Saccade delay significantly influenced the performance. Training significantly improved the sensitivity in the residents (69.1% before to 97.9% after the training, p < 0.001, Fisher's exact test, n = 560 tests), surpassing experts’ performances (p < 0.001, versus 87% in experts, Fisher's exact test). The specificity also increased to the expert level (78% before to 95% after the training, and 95% in experts, p < 0.001, Fisher’s exact test). The VAS showed a decrease difficulty to execute the HIT, with an increase in the confidence after training. VREM improved the HIT execution performance and the confidence in novice practitioners.},
keywords={Sciences: Comprehensive Works; Saccade; Virtual reality; Dizziness; Training; Clinical trials; Confidence; Saccadic eye movements},
language={English},
url={https://www.proquest.com/scholarly-journals/effects-saccade-delay-side-deficit-training-on/docview/2776897684/se-2},
}

@article{
author={Afrashtehfar,Kelvin I. and Jing-Wen,Yang and Al-Sammarraie,A. and Chen,Hui and Saeed,Musab H.},
year={2023},
month={2023},
title={Pre-clinical undergraduate students’ perspectives on the adoption of virtual and augmented reality to their dental learning experience: A one-group pre- and post-test design protocol},
journal={F1000Research},
volume={10},
note={Copyright - Copyright: © 2023 Afrashtehfar KI et al. This work is published under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-24},
abstract={Background: We live in a time where traditional education has rapidly incorporated online modalities due to the recent SARS-CoV-2 (COVID-19) safety measures such as social distancing. Regardless of these challenges, health education constantly strives to implement the best technologies available for an effective student deep learning outcome. Virtual (VR) and augmented reality (AR) in the dental pre-clinical stage may help stimulate students to better understand the foundation material prescribed in the curriculum. Most visual material available for students is still mainly based on 2D graphics. Thus, this study will attempt to evaluate the students' perceptions about implementing VR/AR technologies in the learning setting. Methods: A single-group pretest-posttest design will be implemented where students will be exposed to VR/AR and fill out two questionnaires, one before and one after the exposure. Conclusions: This project is intended to start once the institutional ethical approval is obtained. It is expected that the analysis from the current project will provide recommendations to improve the students' academic curriculum pre-clinical experience. The recommendations will be provided in the form of at least three scientific publications, with one publication for each subject area intended to be evaluated (i.e., head and neck anatomy, dental anatomy, and removable prosthodontics).},
keywords={Medical Sciences; Augmented Reality; Dentistry; Undergraduate education; Virtual reality; Curriculum; Dental Students; Health Education; Immersion; Learning; Perception; Prosthodontics; Research; Software; Perceptions; Neck; Anatomy; School environment; Questionnaires; College students; Severe acute respiratory syndrome coronavirus 2; Data collection; Data analysis; COVID-19; Core curriculum; Deep learning; Dental prosthetics; Consent},
language={English},
url={https://www.proquest.com/scholarly-journals/pre-clinical-undergraduate-students-perspectives/docview/2771303786/se-2},
}

@article{
author={Alnahdi,Ghaleb H. and Alwadei,Arwa},
year={2023},
month={2023},
title={Validation of the Arabic Version of the Transition Planning Inventory (TPI-AR)},
journal={International Journal of Environmental Research and Public Health},
volume={20},
number={2},
pages={1135},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-25; SubjectsTermNotLitGenreText - Saudi Arabia},
abstract={The Transition Planning Inventory (TPI) is an important tool for planning the transition to life after school for students with disabilities. While interest in transition services has increased in the last decade in the Arab region, no transition assessment tools validated for the Arab population are currently available. This study is the first to validate an Arabic version (TPI-AR) for all three rating forms (student, home, and school) and examine its psychometric properties. The sample comprised 203 students with disabilities, a member of their family, and one of their teachers. The 11 subscales of TPI-AR for all three forms were found reliable and valid to be used with students with disabilities in Saudi Arabia, particularly in middle and high schools.},
keywords={Sciences: Comprehensive Works; transition planning inventory; Planning; Transition; Validation; arabic TPI; psychometric properties; students with disabilities; transition planning; confirmatory factor analysis; Arabic language; Students; Validity; Quantitative psychology; Families & family life; Special education; Translations; Schools; Bilingualism; Learning; People with disabilities; Saudi Arabia},
isbn={1661-7827},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-arabic-version-transition-planning/docview/2767225381/se-2},
}

@article{
author={Navab,Nassir and Martin-Gomez,Alejandro and Seibold,Matthias and Sommersperger,Michael and Song,Tianyu and Winkler,Alexander and Yu,Kevin and Eck,Ulrich},
year={2023},
month={2023},
title={Medical Augmented Reality: Definition, Principle Components, Domain Modeling, and Design-Development-Validation Process},
journal={Journal of Imaging},
volume={9},
number={1},
pages={4},
note={Copyright - © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-27},
abstract={Three decades after the first set of work on Medical Augmented Reality (MAR) was presented to the international community, and ten years after the deployment of the first MAR solutions into operating rooms, its exact definition, basic components, systematic design, and validation still lack a detailed discussion. This paper defines the basic components of any Augmented Reality (AR) solution and extends them to exemplary Medical Augmented Reality Systems (MARS). We use some of the original MARS applications developed at the Chair for Computer Aided Medical Procedures and deployed into medical schools for teaching anatomy and into operating rooms for telemedicine and surgical guidance throughout the last decades to identify the corresponding basic components. In this regard, the paper is not discussing all past or existing solutions but only aims at defining the principle components and discussing the particular domain modeling for MAR and its design-development-validation process, and providing exemplary cases through the past in-house developments of such solutions.},
keywords={Photography; Augmented Reality; Reality; Augment; Medical education; Medical Augmented Reality; surgical data science; Artificial Intelligence; multi-modal sensing; computer vision; acoustic sensing; perceptual visualization; sonification; validation; Design; Ethics; Modelling; Domains; Ultrasonic imaging; Principles; Data science},
language={English},
url={https://www.proquest.com/scholarly-journals/medical-augmented-reality-definition-principle/docview/2767223766/se-2},
}

@article{
author={Pezzetta,R. and Ozkan,D. G. and Era,V. and Tieri,G. and Zabberoni,S. and Taglieri,S. and Costa,A. and Peppe,A. and Caltagirone,C. and Aglioti,S. M.},
year={2023},
month={2023},
title={Combined EEG and immersive virtual reality unveil dopaminergic modulation of error monitoring in Parkinson’s Disease},
journal={NPJ Parkinson's Disease},
volume={9},
number={1},
pages={3},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-30},
abstract={Detecting errors in your own and others’ actions is associated with discrepancies between intended and expected outcomes. The processing of salient events is associated with dopamine release, the balance of which is altered in Parkinson’s disease (PD). Errors in observed actions trigger various electrocortical indices (e.g. mid-frontal theta, error-related delta, and error positivity oPe]). However, the impact of dopamine depletion to observed errors in the same individual remains unclear. Healthy controls (HCs) and PD patients observed ecological reach-to-grasp-a-glass actions performed by a virtual arm from a first-person perspective. PD patients were tested under their dopaminergic medication (on-condition) and after dopaminergic withdrawal (off-condition). Analyses of oPe, delta, and theta-power increases indicate that while the formers were elicited after incorrect vs. correct actions in all groups, the latter were observed in on-condition but altered in off-condition PD. Therefore, different EEG error signatures may index the activity of distinct mechanisms, and error-related theta power is selectively modulated by dopamine depletion. Our findings may facilitate discovering dopamine-related biomarkers for error-monitoring dysfunctions that may have crucial theoretical and clinical implications.},
keywords={Medical Sciences--Psychiatry And Neurology; Parkinson's disease; Electroencephalography; Dopamine; Virtual reality; Influence; Executive function},
language={English},
url={https://www.proquest.com/scholarly-journals/combined-eeg-immersive-virtual-reality-unveil/docview/2765232120/se-2},
}

@article{
author={Mayer,Gwendolyn and Gronewold,Nadine and Polte,Kirsten and Hummel,Svenja and Barniske,Joshua and Korbel,Jakob J. and Zarnekow,Rü and Schultz,Jobst-Hendrik},
year={2022/12//},
month={Dec 2022},
title={Experiences of Patients and Therapists Testing a Virtual Reality Exposure App for Symptoms of Claustrophobia: Mixed Methods Study},
journal={JMIR Mental Health},
volume={9},
number={12},
note={Copyright - © 2022. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-20},
abstract={Background: The effectiveness of virtual reality exposure (VRE) in the treatment of anxiety disorders is well established. Several psychological mechanisms of VRE have been identified, whereby both emotional processing and the sense of presence play a key role. However, there are only few studies that contribute to our knowledge of examples of implementation in the case of VRE for claustrophobia based on patients' experiences and the perspective of therapists. Objective: This study asks for key elements of a VRE app that are necessary for effective exposure for people with claustrophobic symptoms. Methods: A mixed methods design was applied in which patients (n=15) and therapeutic experts (n=15) tested a VRE intervention of an elevator ride at 5 intensity levels. Intensity was varied by elevator size, duration of the elevator ride, and presence of virtual humans. Quantitative measures examined self-reported presence with the Igroup Presence Questionnaire (IPQ) ranging from 0 to 6 and 15 Likert-scaled evaluation items that had been developed for the purpose of this study, ranging from 1 to 5. In both measures, higher scores indicate higher levels of presence or agreement. Think-aloud protocols of the patients and semistructured interviews posttreatment of all participants were conducted to gain in-depth perspectives on emotional processes. Results: The intervention induced a feeling of presence in patients and experts, posttreatment scores showed a high IPQ presence score (mean 3.84, SD 0.88), with its subscores IPQ spatial presence (mean 4.53, SD 1.06), IPQ involvement (mean 3.83, SD 1.22), and IPQ experienced realism (mean 2.75, SD 1.02). Patients preferred a setting in the presence of a therapist (mean 4.13, SD 0.83) more than the experts did (mean 3.33, SD 1.54). Think-aloud protocols of the patients revealed that presence and anxiety both were achieved. Qualitative interviews of patients and experts uncovered 8 topics: feelings and emotions, personal story, telepresence, potential therapeutic effects, barriers, conditions and requirements, future prospects, and realization. The intensity levels were felt to appropriately increase in challenge, with ambivalent results regarding the final level. Virtual humans contributed to feelings of fear. Conclusions: Key elements of a VRE app for claustrophobic symptoms should include variation of intensity by adding challenging cues in order to evoke presence and anxiety. Virtual humans are a suitable possibility to make the intervention realistic and to provide a sense of closeness; however, some of the fears might then be related to symptoms of social phobia or agoraphobia. Patients may need the physical presence of a therapist, though not all of them share this view. A higher degree of sophistication in the intensity levels is needed to deliver targeted help for specific symptoms of anxiety.},
keywords={Medical Sciences--Psychiatry And Neurology; virtual reality; Claustrophobia; Anxiety; Presence; Anxiety disorder; Multimethodology; Therapy; Intervention; exposure therapy; anxiety disorders; think-aloud; mixed methods; virtual reality exposure therapy; VR; mental health; user experience; perspective; Quantitative research; Surveys & questionnaires; Qualitative research; Self report; Interviews; Mixed-methods; Comorbidity; Fear & phobias; Therapists; Success factors; Mental disorders; Social anxiety; Mixed methods research},
language={English},
url={https://www.proquest.com/scholarly-journals/experiences-patients-therapists-testing-virtual/docview/2759738752/se-2},
}

@article{
author={Kovshov,Evgeny E. and Kuvshinnikov,Vladimir S.},
year={2022/12//},
month={Dec 2022},
title={Non-destructive testing operations simulation in virtual reality environment},
journal={Journal of Physics: Conference Series},
volume={2373},
number={6},
pages={062024},
note={Copyright - Published under licence by IOP Publishing Ltd. This work is published under http://creativecommons.org/licenses/by/3.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-28},
abstract={This article considers the prerequisites for creating virtual educational simulators for non-destructive testing teaching. Currently, virtual reality technologies are most widely used in the training process of engineers and workers directly engaged in production during complex and responsible operations, including the control of products and materials. Approaches to the creation and application of virtual reality in the development and use of a digital radiography simulator for non-destructive testing of materials and products are announced. It is noted that the developed software and algorithmic solutions allow to judge their effective applicability in industry as the results of R&D and various computational experiments. Constructing and processing images technology of digital twins’ samples, which allows to obtain image close to the results of metal samples’ X-ray film is considered. Basic physical principles underlying the developing of a digital model are formalized. The results of obtaining digital X-ray images are presented. Prospects for expanding the applicability range of virtual reality software and hardware solutions in non-destructive testing educational process are touched upon.},
keywords={Physics; Simulation; Nondestructive testing; Digital twin; Virtual; Digital radiography; Virtual reality; Digital imaging; Simulators; Education; Software; Digital twins},
isbn={17426588},
language={English},
url={https://www.proquest.com/scholarly-journals/non-destructive-testing-operations-simulation/docview/2755151671/se-2},
}

@article{
author={Gottlieb,Amihai and Doniger,Glen M. and Kimel-Naor,Shani and Ben-Gal,Oran and Cohen,Maya and Iny,Hila and Beeri,Michal S. and Plotnik,Meir},
year={2022/09/14/},
month={2022 Sep 14},
title={Development and validation of virtual reality-based Rey Auditory Verbal Learning Test},
journal={Frontiers in Aging Neuroscience},
note={Copyright - © 2022. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-24},
abstract={Objective: Translations and adaptations of traditional neuropsychological tests to Virtual Reality (VR) technology bear the potential to increase their ecological validity since the technology enables simulating everyday life conditions in a controlled manner. The current paper describes our attempt in translating a commonly used neuropsychological test to VR, the Rey Auditory Verbal Learning Test (RAVLT). For this aim, we developed a VR adaptation of the RAVLT (VR-RAVLT) Which is based on a conversation with a secretary in a virtual office using a fully immersive VR system. To validate the VR-RAVLT, we tested its construct validity, its age-related discriminant validity, and its test-retest validity in reference to the original gold standard RAVLT (GS-RAVLT). Method: 78 participants from different age groups performed GS-RAVLT and the VR-RAVLT test in a counterbalanced order in addition to other neuropsychological tests. Construct validity was validated using Pearson's correlations coefficients and serial position effects; discriminant validity was validated using receiver operating characteristic area under the curve values and test-retest reliability was validated using intraclass correlation coefficients. Results: Comparing both RAVLTs' format results indicates that the VR-RAVLT has comparable construct, discriminant, and test-retest validities. Conclusions: the novel VR-RAVLT and the GS-RAVLT share similar psychometric properties suggesting that the two tests measure the same cognitive construct. This is an indication of the feasibility of adapting the RAVLT to the VR environment. Future developments will employ this approach for clinical diagnosis and treatment.},
keywords={Medical Sciences--Psychiatry And Neurology; Memory and learning tests; Neuropsychological test; Virtual reality; Validation; Adaptation; Neuropsychological Tests; reliability and validity; Rey Auditory Verbal Learning Test; Validation study; Validity; Memory; Position effects; Dementia; Age; Retention; Computer applications; Neuropsychology; Cognitive ability; Auditory discrimination learning; Verbal learning; Virtual offices; Validation studies},
isbn={16634365},
language={English},
url={https://www.proquest.com/scholarly-journals/development-validation-virtual-reality-based-rey/docview/2714184431/se-2},
}

@article{
author={Sauer,Yannick and Sipatchin,Alexandra and Wahl,Siegfried and García García,Miguel},
year={2022/09//},
month={Sep 2022},
title={Assessment of consumer VR-headsets’ objective and subjective field of view (FoV) and its feasibility for visual field testing},
journal={Virtual Reality},
volume={26},
number={3},
pages={1089-1101},
note={Copyright - © The Author(s) 2022. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-06},
abstract={Virtual reality as a research environment has seen a boost in its popularity during the last decades. Not only the usage fields for this technology have broadened, but also a research niche has appeared as the hardware improved and became more affordable. Experiments in vision research are constructed upon the basis of accurately displaying stimuli with a specific position and size. For classical screen setups, viewing distance and pixel position on the screen define the perceived position for subjects in a relatively precise fashion. However, projection fidelity in HMDs strongly depends on eye and face physiological parameters. This study introduces an inexpensive method to measure the perceived field of view and its dependence upon the eye position and the interpupillary distance, using a super wide angle camera. Measurements of multiple consumer VR headsets show that manufacturers’ claims regarding field of view of their HMDs are mostly unrealistic. Additionally, we performed a “Goldmann” perimetry test in VR to obtain subjective results as a validation of the objective camera measurements. Based on this novel data, the applicability of these devices to test humans’ field of view was evaluated.},
keywords={Computers--Computer Graphics; Virtual reality; Visual field; Virtual reality headset; Visual system; Field of View; HMD; Perimetry; Eye relief; Eye; Position measurement; Visual fields; Headsets; Eye (anatomy); Cameras},
isbn={13594338},
language={English},
url={https://www.proquest.com/scholarly-journals/assessment-consumer-vr-headsets-objective/docview/2708604340/se-2},
}

@article{
author={McLaren,Ruth and Chaudhary,Shikha and Rashid,Usman and Ravindran,Shobika and Taylor,Denise},
year={2022/08/12/},
month={2022 Aug 12},
title={Reliability of the triangle completion test in the real-world and in virtual reality},
journal={Frontiers in Human Neuroscience},
note={Name - Auckland University of Technology; Copyright - © 2022. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-24},
abstract={BACKGROUND: The triangle completion test has been used to assess egocentric wayfinding for decades, yet there is little information on its reliability. We developed a virtual reality (VR) based test and investigated whether either test of spatial navigation was reliable. OBJECTIVE: To examine test-retest reliability of the real-world and VR triangle completion tests. A secondary objective was to examine the usability of the VR based test. METHODS: 30 healthy adults aged 18-45yrs were recruited to this block randomised study. Participants completed two sessions of triangle completion tests in the real-world and VR on the same day with a break between sessions. RESULTS: In both test versions distance from the endpoint and angle of deviation showed poor test-retest reliability (r<0.5). Distance traveled had moderate reliability in both the real-world and VR tests (r=0.55 95% CI 0.23, 0.76]; r=0.66 95% CI 0.4, 0.83 respectively]). The VR triangle test showed poor correlation with the real-world test. CONCLUSIONS: The triangle completion test has poor test-retest reliability and demonstrates poor concurrent validity between the real-world and VR. Nevertheless, it was feasible to translate a real-world test of spatial navigation into VR. VR provides opportunities for development of clinically relevant spatial navigation tests in the future.},
keywords={Medical Sciences--Psychiatry And Neurology; spatial navigation; Reliability; Wayfinding; Test; Virtual reality; triangle completion test; navigation; spatial cognition; vestibular; Motion sickness; Usability; Validity; Computer applications; Animal memory; Navigation behavior; Cognition & reasoning; Questionnaires},
language={English},
url={https://www.proquest.com/scholarly-journals/reliability-triangle-completion-test-real-world/docview/2701315477/se-2},
}

@article{
author={Gammeri,Roberto and Léonard,Jacques and Toupet,Michel and Hautefort,Charlotte and van Nechel,Christian and Besnard,Stéphane and Machado,Marie-Laure and Nakul,Estelle and Montava,Marion and Lavieille,Jean-Pierre and Lopez,Christophe},
year={2022/08//},
month={Aug 2022},
title={Navigation strategies in patients with vestibular loss tested in a virtual reality T-maze},
journal={Journal of neurology},
volume={269},
number={8},
pages={4333-4348},
note={Copyright - © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany 2022; Last updated - 2024-01-22},
abstract={During navigation, humans mainly rely on egocentric and allocentric spatial strategies, two different frames of reference working together to build a coherent representation of the environment. Spatial memory deficits during navigation have been repeatedly reported in patients with vestibular disorders. However, little is known about how vestibular disorders can change the use of spatial navigation strategies. Here, we used a new reverse T-maze paradigm in virtual reality to explore whether vestibular loss specifically modifies the use of egocentric or allocentric spatial strategies in patients with unilateral (n = 23) and bilateral (n = 23) vestibular loss compared to healthy volunteers (n = 23) matched for age, sex and education level. Results showed that the odds of selecting and using a specific strategy in the T-maze were significantly reduced in both unilateral and bilateral vestibular loss. An exploratory analysis suggests that only right vestibular loss decreased the odds of adopting a spatial strategy, indicating an asymmetry of vestibular functions. When considering patients who used strategies to navigate, we observed that a bilateral vestibular loss reduced the odds to use an allocentric strategy, whereas a unilateral vestibular loss decreased the odds to use an egocentric strategy. Age was significantly associated with an overall lower chance to adopt a navigation strategy and, more specifically, with a decrease in the odds of using an allocentric strategy. We did not observe any sex difference in the ability to select and use a specific navigation strategy. Findings are discussed in light of previous studies on visuo-spatial abilities and studies of vestibulo-hippocampal interactions in peripheral vestibular disorders. We discuss the potential impact of the history of the disease (chronic stage in patients with a bilateral vestibulopathy vs. subacute stage in patients with a unilateral vestibular loss), of hearing impairment and non-specific attentional deficits in patients with vestibular disorders.},
keywords={Medical Sciences--Psychiatry And Neurology; Vestibular system; Allocentrism; Egocentrism; Hearing loss; T-maze; Spatial navigation; Balance disorder; Virtual reality; Labyrinth; Spatial strategies; Egocentric; Allocentric; Reference frame; Hippocampus; Sex differences; Computer applications; Animal memory; Navigation behavior; Spatial memory; Neurology},
isbn={03405354},
language={English},
url={https://www.proquest.com/scholarly-journals/navigation-strategies-patients-with-vestibular/docview/2691245149/se-2},
}

@article{
author={Misa,Anamaria and Melenciuc,Mihaela and Pădurariu,Ioana and Văduva,Cecilia},
year={2022},
month={2022},
title={Augmented Reality Body and Face Filters for Digitally Manipulated Visual Narratives: Physical Appearance Ideals, Perceived Social Validation, and Aesthetic and Affective Technologies},
journal={Journal of Research in Gender Studies},
volume={12},
number={2},
pages={160-175},
note={Copyright - Copyright Addleton Academic Publishers 2022; Last updated - 2024-05-09},
abstract={This paper provides a systematic literature review of studies investigating flawless fashionable ideals, digitally-enhanced augmented reality-based perception of beauty, and individual expressions and representations of visual identity. Throughout June 2022, we performed a quantitative literature review of the Web of Science, Scopus, and ProQuest databases, with search terms including "augmented reality body and face filters for digitally manipulated visual narratives" + "physical appearance ideals," "perceived social validation," and "aesthetic and affective technologies." As we inspected research published between 2013 and 2022, only 169 articles satisfied the eligibility criteria. By eliminating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, we decided upon 32, generally empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AMSTAR, Distiller SR, MMAT, and ROBIS.},
keywords={Social Sciences: Comprehensive Works; Augmented reality; Y; GenderWatch; Narratives; Visualization; Databases; Literature reviews; Objectification; Social networks; Aesthetics; Body image; Mapping; Visual perception; Social structure; Augmentation; Quality assessment; Layout; Beauty; Social interaction; Self image; Self expression; Algorithms; Consciousness; Physical appearance; Personal appearance; Bibliometrics},
isbn={21640262},
language={English},
url={https://www.proquest.com/scholarly-journals/augmented-reality-body-face-filters-digitally/docview/2809782660/se-2},
}

@article{
author={Won,JuHye and Kim,Yoon S.},
year={2022/07//},
month={Jul 2022},
title={A New Approach for Reducing Virtual Reality Sickness in Real Time: Design and Validation Study},
journal={JMIR Serious Games},
volume={10},
number={3},
note={Copyright - © 2022. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-23},
abstract={Background: Recently, technology that provides virtual reality (VR) content based on streaming services has been rapidly developed. However, there have been few studies to reduce VR sickness that occurs while the user watches VR content while wearing a head-mounted display (HMD) in real time. Objective: Based on this background, we propose a new approach to measure and reduce VR sickness that occurs while the user watches VR content while wearing an HMD in real time. Methods: The proposed approach is to apply VR sickness reduction methods in accordance with the user’s real-time VR sickness level. Three methods that are known to be effective in reducing VR sickness and a single type of VR content were used to examine the effectiveness of the proposed approach, which was confirmed by the experimental results. Results: Our results show that VR sickness significantly decreased when a new approach was applied to VR content (in all cases, P<.05). Conclusions: From our results, it was confirmed that VR sickness could be measured without wearing additional equipment, and its reduction method could be applied in real time in accordance with the user’s condition by the proposed approach in this paper.},
keywords={Medical Sciences; virtual reality; Head-mounted display; Virtual; Reality; VR; VR sickness; VR sickness reduction method; simulator sickness questionnaire; SSQ, visual guide; field of view; serious game; VR sickness reduction; VR content; technology; digital health; Methods; Experiments; Real time; Questionnaires; Computer & video games; Educational software},
language={English},
url={https://www.proquest.com/scholarly-journals/new-approach-reducing-virtual-reality-sickness/docview/2719579909/se-2},
}

@article{
author={Kalron,Alon and Frid,Lior and Fonkatz,Iliya and Menascu,Shay and Dolev,Mark and Magalashvili,David and Achiron,Anat},
year={2022/07//},
month={Jul 2022},
title={The Design, Development, and Testing of a Virtual Reality Device for Upper Limb Training in People With Multiple Sclerosis: Single-Center Feasibility Study},
journal={JMIR Serious Games},
volume={10},
number={3},
note={Copyright - © 2022. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-26; SubjectsTermNotLitGenreText - Israel},
abstract={Background: Multiple sclerosis (MS) is a common nontraumatic, neurological, disabling disease that often presents with upper limb dysfunction. Exercise training has resulted in improvement for patients; however, there can be a lack of compliance due to access because of location and lack of MS experts. Virtual reality (VR) is a promising technology that can offer exercise therapy/rehabilitation at a distance. This type of remote training can be motivational and effective for patients with MS and can improve range of motion and muscle strength for those with upper limb dysfunction. Objective: The aim of this study is to evaluate the safety and feasibility of the XRHealth software and the Oculus Rift Station for patients with MS with upper limb motor dysfunction. Methods: A single-center, prospective, feasibility study was conducted with patients with MS who had upper limb motor dysfunction. Patients participated in a single 45-minute digital environment session with VR and completed a questionnaire about the quality of the training and fatigability. The clinician also completed a questionnaire to evaluate the suitability and safety of the training. Results: Overall, 30 patients were enrolled between the ages of 20 and 81 years. Patients reported that the training sessions within the digital environment were helpful, challenging, fun, and simple to understand, and that they would be willing to repeat the sessions again. The physical therapist that oversaw the patients reported that the training was suitable for 87% (n=26) of the patients. Anticipated adverse events were fatigue, temporary dizziness, and temporary nausea. The operator complications included that the cable of the head-mounted display interrupted the training (n=2, 7%) and fatigue that caused cessation of the VR training session (n=2, 7%). No serious adverse events were reported. Conclusions: These preliminary results demonstrated that the use of the XRHealth software and Oculus Rift Station platform is feasible, safe, and engaging for patients, and has the potential to improve the functionality of the upper limbs in patients with MS. This study provides support for future studies of implementing a series of training sessions with virtual reality in a home-based environment.},
keywords={Medical Sciences; virtual reality; Feasibility study; Multiple sclerosis; Virtual environment; Training; Physical therapy; Upper limb; rehabilitation; feasibility; Patients; Exercise; Software; Physical fitness; Physical therapists; Therapy; Multimedia; FDA approval; Questionnaires; Medical research; Feasibility studies; Fitness training programs; Israel},
language={English},
url={https://www.proquest.com/scholarly-journals/design-development-testing-virtual-reality-device/docview/2719579907/se-2},
}

@article{
author={Sureshkumar,Haarisudhan and Xu,Ruidi and Erukulla,Nikith and Wadhwa,Aditi and Zhao,Linping},
year={2022/06//},
month={Jun 2022},
title={“Snap on” or Not? A Validation on the Measurement Tool in a Virtual Reality Application},
journal={Journal of Digital Imaging},
volume={35},
number={3},
pages={692-703},
note={Copyright - © The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine 2022; Last updated - 2023-11-27},
abstract={This multi-rater comparison study aims to validate the measurement tool with a “snap” feature option (SNAP ON vs. SNAP OFF), in a virtual reality (VR) application, ImmersiveView v. 2.1, against a conventional software Mimics Innovation Suite v.22 (MIS). It is hypothesized that these measurement tools are equivalent between SNAP ON, and SNAP OFF, and when compared to MIS, in terms of basic linear and angular measurements. Six (6) raters conducted a set of 40 linear and 15 angular measurements using CT scan data of three objects (L-block, hand model, and dry skull) with fiducial markers. Inter-rater repeatability and intra-rater reproducibility were assessed via inter-class coefficient (ICC). Equivalency between each pair of modules (SNAP ON, SNAP OFF, and MIS) was analyzed via Bland–Altman plots and two one-sided t-tests (TOST) procedure. The ICC for intra-rater repeatability yielded 0.999 to 1.000, and inter-rater reproducibility yielded 0.998 to 1.000, which suggests high degree of intra- and inter-rater reliability. The Bland–Altman plots demonstrated that measurements acquired from SNAP ON, SNAP OFF, and MIS were equivalent. The TOST procedure yielded that the measurements through all three modules are equivalent within ± 0.2 mm interval for distance, and ± 0.3° interval for angular measurements. The measurement tool with the “snap” feature in a newly developed VR application (ImmersiveView v.2.1) has been validated through a multi-rater comparison study. In terms of linear and angular measurements, this VR application, whether the “snap” feature was on or off, was equivalent to each other and to the control software (MIS) under the condition of this study. A strong reliability, both intra-rater repeatability and inter-rater reproducibility, has been found.},
keywords={Medical Sciences--Radiology And Nuclear Medicine; Validation; Virtual; Measuring instrument; Virtual reality; Measurements; Reliability; Reproducibility; Equivalency; Reliability aspects; Software; Computer applications; Modules; Computed tomography; Equivalence},
isbn={08971889},
language={English},
url={https://www.proquest.com/scholarly-journals/snap-on-not-validation-measurement-tool-virtual/docview/2671808915/se-2},
}

@article{
author={Tibor,Guzsvinecz and Orbán-Mihálykó Éva and Sik-Lányi Cecília and Erika,Perge},
year={2022/06//},
month={Jun 2022},
title={Investigation of spatial ability test completion times in virtual reality using a desktop display and the Gear VR},
journal={Virtual Reality},
volume={26},
number={2},
pages={601-614},
note={Copyright - © The Author(s) 2021. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-05},
abstract={The interaction time of students who did spatial ability tests in a virtual reality environment is analyzed. The spatial ability test completion times of 240 and 61 students were measured. A desktop display as well as the Gear VR were used by the former group and by the latter one, respectively. Logistic regression analysis was used to investigate the relationship between the probability of correct answers and completion times, while linear regression was used to evaluate effects and interactions of following factors on test completion times: the users’ gender and primary hand, test type and device used. The findings were that while the completion times are not significantly affected by the users’ primary hand, other factors have significant effects on them: they are decreased by the male gender in itself, while they are increased by solving Mental Rotation Tests or by using the Gear VR. The largest significant increment in interaction time in virtual reality during spatial ability tests is when Mental Rotation Tests are accomplished by males with the Gear VR, while the largest significant decrease in interaction time is when Mental Cutting Tests are completed with a desktop display.},
keywords={Computers--Computer Graphics; Cognitive skills; Gender; Virtual reality; Display; Desktop display; Gear VR; Human-computer interaction; Interaction time; Mental rotation; Spatial ability; Ability tests; Regression analysis; Statistical analysis; Rotation; Students},
isbn={13594338},
language={English},
url={https://www.proquest.com/scholarly-journals/investigation-spatial-ability-test-completion/docview/2666079302/se-2},
}

@article{
author={Karina,Miranda B. and Khayra Magalhães,de L. and Carolina Bahia,Galante F. and Sabino,George S.},
year={2022/05//},
month={May 2022},
title={Validity and reliability of using an augmented reality smartphone application during Modified Star Excursion Balance Test},
journal={Physical Therapy in Sport},
volume={55},
note={Copyright - Copyright Elsevier Limited May 2022; Last updated - 2024-01-18},
keywords={Medical Sciences--Sports Medicine; Validity; Sports medicine},
isbn={1466853X},
language={English},
url={https://www.proquest.com/scholarly-journals/validity-reliability-using-augmented-reality/docview/2676546521/se-2},
}

@article{
author={Morizio,Charles and Compagnat,Maxence and Boujut,Arnaud and Labbani-Igbida,Ouiddad and Billot,Maxime and Perrochon,Anaick},
year={2022},
month={2022},
title={Immersive Virtual Reality during Robot-Assisted Gait Training: Validation of a New Device in Stroke Rehabilitation},
journal={Medicina},
volume={58},
number={12},
pages={1805},
note={Copyright - © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-29; SubjectsTermNotLitGenreText - United States--US},
abstract={Background and objective: Duration of rehabilitation and active participation are crucial for gait rehabilitation in the early stage after stroke onset. Virtual reality (VR) is an innovative tool providing engaging and playful environments that could promote intrinsic motivation and higher active participation for non-ambulatory stroke patients when combined with robot-assisted gait training (RAGT). We have developed a new, fully immersive VR application for RAGT, which can be used with a head-mounted display and wearable sensors providing real-time gait motion in the virtual environment. The aim of this study was to validate the use of this new device and assess the onset of cybersickness in healthy participants before testing the device in stroke patients. Materials and Methods: Thirty-seven healthy participants were included and performed two sessions of RAGT using a fully immersive VR device. They physically walked with the Gait Trainer for 20 min in a virtual forest environment. The occurrence of cybersickness, sense of presence, and usability of the device were assessed with three questionnaires: the Simulator Sickness Questionnaire (SSQ), the Presence Questionnaire (PQ), and the System Usability Scale (SUS). Results: All of the participants completed both sessions. Most of the participants (78.4%) had no significant adverse effects (SSQ < 5). The sense of presence in the virtual environment was particularly high (106.42 ± 9.46). Participants reported good usability of the device (86.08 ± 7.54). Conclusions: This study demonstrated the usability of our fully immersive VR device for gait rehabilitation and did not lead to cybersickness. Future studies should evaluate the same parameters and the effectiveness of this device with non-ambulatory stroke patients.},
keywords={Medical Sciences; virtual reality; Gait trainer; Stroke recovery; Usability; Gait training; head-mounted display; robot-assisted gait training; gait rehabilitation; cybersickness; Robots; Motion sickness; Gait; Patients; Software; Velocity; Rehabilitation; Stroke; Fitness equipment; Training; Sensors; United States--US},
isbn={1010660X},
language={English},
url={https://www.proquest.com/scholarly-journals/immersive-virtual-reality-during-robot-assisted/docview/2756752607/se-2},
}

@article{
author={Burton,Quentin and Lejeune,Thierry and Dehem,Stéphanie and Lebrun,Noémie and Ajana,Khawla and Edwards,Martin G. and Everard,Gauthier},
year={2022},
month={2022},
title={Performing a shortened version of the Action Research Arm Test in immersive virtual reality to assess post-stroke upper limb activity},
journal={Journal of Neuroengineering and Rehabilitation},
volume={19},
pages={1-12},
note={Copyright - © 2022. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-28},
abstract={Background To plan treatment and measure post-stroke recovery, frequent and time-bounded functional assessments are recommended. With increasing needs for neurorehabilitation advances, new technology based methods, such as virtual reality (VR) have emerged. Here, we developed an immersive VR version of the Action Research Arm Test (ARAT-VR) to complement neurorehabilitation. Objective This study aimed to assess the validity, usability and test–retest reliability of the ARAT-VR among individuals with stroke, healthcare professionals and healthy control subjects (HCS). Methods Among the 19 items of the ARAT, 13 items were selected and developed in immersive VR. 11 healthcare professionals, 30 individuals with stroke, and 25 HCS were recruited. Content validity was assessed by asking healthcare professionals to rate the difficulty of performing each item of the ARAT-VR in comparison to the classical Action Research Arm Test (ARAT-19). Concurrent validity was first measured using correlation (Spearman tests) between the ARAT-VR and ARAT-19 scores for the individuals with stroke, and second through correlation and comparison between the scores of the ARAT-VR and the reduced version of the ARAT (ARAT-13) for both individuals with stroke and HCS (Wilcoxon signed rank tests and Bland–Altman plots). Usability was measured using the System Usability Scale. A part of individuals with stroke and HCS were re-tested following a convenient delay to measure test–retest reliability (Intra-class correlation and Wilcoxon tests). Results Regarding the content validity, median difficulty of the 13 ARAT-VR items (00 to − 1] to 00–1]) evaluated by healthcare professionals was rated as equivalent to the classical ARAT for all tasks except those involving the marbles. For these, the difficulty was rated as superior to the real tasks (10–1] when pinching with the thumb-index and thumb-middle fingers, and 10–2] when pinching with thumb-ring finger). Regarding the concurrent validity, for paretic hand scores, there were strong correlations between the ARAT-VR and ARAT-13 (r = 0.84), and between the ARAT-VR and ARAT-19 (r = 0.83). Usability (SUS = 82.575–90]) and test–retest reliability (ICC = 0.99; p < 0.001) were excellent. Conclusion The ARAT-VR is a valid, usable and reliable tool that can be used to assess upper limb activity among individuals with stroke, providing potential to increase assessment frequency, remote evaluation, and improve neurorehabilitation. Trial registrationhttps://clinicaltrials.gov/ct2/show/NCT04694833; Unique identifier: NCT04694833, Date of registration: 11/24/2020.},
keywords={Medical Sciences--Psychiatry And Neurology; Stroke; Reliability; Upper limb; Usability; Rehabilitation; Virtual reality; Upper extremity; Remote sensing technology; Patient outcome assessment; Reliability analysis; Software; Neurology; Action research; Recovery of function; Health care; Rank tests; Immersive virtual reality; Motor ability; Fingers; Computer applications; Arm; Orthopedics; Evaluation; New technology},
language={English},
url={https://www.proquest.com/scholarly-journals/performing-shortened-version-action-research-arm/docview/2755653192/se-2},
}

@article{
author={Carbonari,Alessandro and Franco,Carlos and Naticchia,Berardo and Spegni,Francesco and Vaccarini,Massimo},
year={2022},
month={2022},
title={A Mixed Reality Application for the On-Site Assessment of Building Renovation: Development and Testing},
journal={Sustainability},
volume={14},
number={20},
pages={13239},
note={Copyright - © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-08},
abstract={This paper contributes to a sustainable construction design management approach to increase the successful renovation rate of existing residential building stock. Indeed, coupling BIM with mixed reality can speed up and improve the quality of the renovation design processes, because it can display virtual models of alternative design scenarios superimposed over the existing physical facility. To this purpose, a sample of technicians was enrolled to test the reliability of this technology. A prototype was developed that enables cooperation among stakeholders and the implementation of an efficient workflow. The volunteers carried out real-life tests in a building demonstrator in Caceres (Spain) and filled in two questionnaires with their feedback. The results showed that an MR-based platform can involve interested stakeholders in the assessment of renovation design projects, that speeds up the decision-making process and increases the quality of those projects. Moreover, technicians can master the technology quickly, provided that it is included in the current renovation workflow and some technology gaps are covered. However, the main limitations of this study are that these findings are valid for building renovation design only, and the tests were performed in a controlled, yet full scale, experimental environment. Finally, this paper deals with a few open technical issues, such as the efficient alignment of holograms, transformation of BIM models into a format suitable for mixed reality applications and sharing feedbacks in an on-line repository to foster collaboration.},
keywords={Environmental Studies; BIM; Renovation; Mixed Reality; Residential building; Building; Virtual reality; building renovation; MR reliability; real-life tests; sustainable design; user acceptance; Augmented reality; Green buildings; Collaboration; Technicians; Emissions; Workflow; Residential buildings; Residential areas; Architecture; Data analysis; Design; Visualization; Building construction; Onsite; EU directives; Construction; Technology; Renovation & restoration; Energy efficiency; Construction industry; Building management systems; Feasibility studies; Decision making; Sustainability; Designers},
language={English},
url={https://www.proquest.com/scholarly-journals/mixed-reality-application-on-site-assessment/docview/2728545666/se-2},
}

@article{
author={Yen-Ting,Chen and Po-Han Yeh and Yu-Chun,Cheng and Wei-Wen,Su and Hwang,Yih-Shiou and Chen,Henry S. and Yung-Sung,Lee and Su-Chin,Shen},
year={2022},
month={2022},
title={Application and Validation of LUXIE: A Newly Developed Virtual Reality Perimetry Software},
journal={Journal of Personalized Medicine},
volume={12},
number={10},
pages={1560},
note={Name - Chang Gung Memorial Hospital; Copyright - © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-02; SubjectsTermNotLitGenreText - United States--US; Taiwan},
abstract={Purpose: To report the application of LUXIE and validate its reliability by comparing the test results with those of Humphrey Field Analyzer 3 (HFA3). Methods: In this pilot study, we prospectively recruited participants who had received HFA3 SITA standard 30-2 perimetry and tested them with LUXIE on the same day. LUXIE is a software designed for visual field testing cooperating with HTC Vive Pro Eye, a head-mounted virtual reality device with an eye-tracking system. The test stimuli were synchronized with eye movements captured by the eye-tracking system to eliminate fixation loss. The global, hemifields, quadrants, glaucoma hemifield test (GHT) sectors, and point-by-point retinal sensitivities were compared between LUXIE and HFA3. All participants were asked to fill out a post-test user survey. Results: Thirty-eight participants with 65 eyes were enrolled. LUXIE demonstrated good correlations with HFA3 in global (r = 0.81), superior hemifield (r = 0.77), superonasal, superotemporal, and inferonasal quadrants (r = 0.80, 0.78, 0.80). The user survey showed that participants were more satisfied with LUXIE in operating difficulty, comfortability, time perception, concentration, and overall satisfaction. Conclusions: LUXIE demonstrated good correlations with HFA3. Fixation loss could be eliminated in LUXIE with the eye-tracking system. The application of virtual reality devices such as the HTC Vive Pro Eye makes telemedicine and even home-based self-screening visual field tests possible. Key Messages: 1. Virtual reality perimetry is a developing technology that has the potential in telemedicine, and home self-screening visual field tests. 2. LUXIE demonstrated good correlations with Humphrey Field Analyzer 3 in visual field retinal sensitivities.},
keywords={Medical Sciences; head-mounted device; Telehealth; Virtual reality; Humphrey; LUXIE; perimetry; Patients; Eye movements; Software; Eye; Glaucoma; User surveys; Calibration; Retina; Computer applications; Surveys; Receptive field; Visual field; Temporal perception; Telemedicine; Precision medicine; United States--US; Taiwan},
language={English},
url={https://www.proquest.com/scholarly-journals/application-validation-luxie-newly-developed/docview/2728486880/se-2},
}

@article{
author={Mori,Takashi and Ikeda,Koji and Takeshita,Nobuyoshi and Teramura,Koichi and Ito,Masaaki},
year={2022},
month={2022},
title={Validation of a novel virtual reality simulation system with the focus on training for surgical dissection during laparoscopic sigmoid colectomy},
journal={BMC Surgery},
volume={22},
pages={1-8},
note={Copyright - © 2022. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-23; SubjectsTermNotLitGenreText - Japan},
abstract={Background Mastery of technical skills is one of the fundamental goals of surgical training for novices. Meanwhile, performing laparoscopic procedures requires exceptional surgical skills compared to open surgery. However, it is often difficult for trainees to learn through observation and practice only. Virtual reality (VR)-based surgical simulation is expanding and rapidly advancing. A major obstacle for laparoscopic trainees is the difficulty of well-performed dissection. Therefore, we developed a new VR simulation system, Lap-PASS LP-100, which focuses on training to create proper tension on the tissue in laparoscopic sigmoid colectomy dissection. This study aimed to validate this new VR simulation system. Methods A total of 50 participants were asked to perform medial dissection of the meso-sigmoid colon on the VR simulator. Forty-four surgeons and six non-medical professionals working in the National Cancer Center Hospital East, Japan, were enrolled in this study. The surgeons were: laparoscopic surgery experts with > 100 laparoscopic surgeries (LS), 21 were novices with experience < 100 LS, and five without previous experience in LS. The participants’ surgical performance was evaluated by three blinded raters using Global Operative Assessment of Laparoscopic Skills (GOALS). Results There were significant differences (P-values < 0.044) in all GOALS items between the non-medical professionals and surgeons. The experts were significantly superior to the novices in one item of GOALS: efficiency (4(4–5) vs. 4(3–4)], with a 95% confidence interval, p = 0.042). However, both bimanual dexterity and total score in the experts were not statistically different but tended to be higher than in the novices. Conclusions Our study demonstrated a full validation of our new system. This could detect the surgeons' ability to perform surgical dissection and suggest that this VR simulator could be an effective training tool. This surgical VR simulator might have tremendous potential to enhance training for surgeons.},
keywords={Medical Sciences--Surgery; Virtual reality simulator; Postoperative pain; Surgical training; Laparoscopic colorectal surgery; Internship and residency; Haptic feedback; Software; Thoracic surgery; Surgical instruments; Tacit knowledge; Skills; Laparoscopy; Colon; Explicit knowledge; Surgical outcomes; Computer applications; Dissection; Training; Surgical apparatus & instruments; Virtual reality; Simulation; Haptics; Medical personnel; Confidence intervals; Surgery; Endoscopy; Surgeons; Pain; Japan},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-novel-virtual-reality-simulation/docview/2620910132/se-2},
}

@article{
author={Anass,Rahouti and Ruggiero,Lovreglio and Datoussaïd Sélim and Thierry,Descamps},
year={2021/11//},
month={Nov 2021},
title={Prototyping and Validating a Non-immersive Virtual Reality Serious Game for Healthcare Fire Safety Training},
journal={Fire technology},
volume={57},
number={6},
pages={3041-3078},
note={Copyright - © The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature 2021; Last updated - 2024-02-23; SubjectsTermNotLitGenreText - Belgium},
abstract={In a healthcare context, the success of a fire safety procedure in a real-life emergency mainly depends on staff decisions and actions. One of the factors influencing staff decision-making is their training. In most healthcare facilities, safety educators use slide-based lectures as a training tool. Virtual Reality (VR) is gaining fire safety community attention for being an interesting training tool. However, few studies have assessed the effectiveness of VR-based fire safety training simulators compared with a slide-based lecture. The present research proposes a novel non-immersive VR-based training for healthcare fire safety education. This paper describes the prototyping steps required to develop a non-immersive VR serious game (SG) to train the staff of Vincent Van Gogh (VVG) hospital in Belgium. The paper finally validates the VR SG comparing its effectiveness against slide-based lecture training. 78 staff from VVG hospital in Belgium participated in this study. They were divided into two groups: Group A was trained using a slide-based lecture, and Group B was trained using the VR SG. The results indicated that the VR SG was more effective than the slide-based lecture in terms of knowledge acquisition and retention and in terms of self-efficacy increment in short and long terms than the slide-based lecture.},
keywords={Fire Prevention; Virtual reality; Prototype; Immersion; Serious game; Occupational safety and health; Hospital; Fire safety; Knowledge; Self-efficacy; Intrinsic motivation; Health care facilities; Simulators; Fire protection; Immersive virtual reality; Health care; Prototyping; Safety; Knowledge acquisition; Training simulators; Computer applications; Training; Decision making; Safety training; Emergency procedures; Computer & video games; Educational software; Belgium},
isbn={00152684},
language={English},
url={https://www.proquest.com/scholarly-journals/prototyping-validating-non-immersive-virtual/docview/2599273454/se-2},
}

@article{
author={Budiman,E. and Firdaus,M. B. and Hairah,U.},
year={2021/06//},
month={Jun 2021},
title={Augmented Reality Peripheral Performance: Light Intensity, Distance, Occlusion and Marker Testing},
journal={Journal of Physics: Conference Series},
volume={1898},
number={1},
note={Copyright - © 2021. This work is published under http://creativecommons.org/licenses/by/3.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-24},
abstract={Augmented Reality peripherals (ARP) that use marker detection objects have developed rapidly and are implemented in various forms to support the activities of everyday human life. The challenge that is currently being faced is the increasingly widespread application of ARP technology to the reliability of software product performance in detecting objects. This research has developed and implemented ARP in the academic space. The application development method uses the Multimedia Development Life Cycle (MDLC) approach, developed based on the Android operating system, using the Unity 3D Engine and Vuforia SDK. 3D object modelling with Sweet Home 3D. Whereas for testing the reliability of ARP performance in object detection using testing of light intensity, distance, occlusion and marker with each scenario. The research produces augmented reality technology products that are able to offer visualization in the form of interactive 2D and 3D objects in academic rooms that provide information to users about the peripheral layout and division of academic spatial layouts and the good reliability performance.},
keywords={Physics; Peripheral; Visualization; Object detection; Augmented reality; Software reliability; Layouts; Markers; Object recognition; Luminous intensity; Mobile operating systems; Occlusion; Three dimensional models; Life cycle analysis; Multimedia},
isbn={17426588},
language={English},
url={https://www.proquest.com/scholarly-journals/augmented-reality-peripheral-performance-light/docview/2546086424/se-2},
}

@article{
author={Kourtesis,Panagiotis and Collina,Simona and Doumas,Leonidas A. and MacPherson,Sarah E.},
year={2021/02//},
month={Feb 2021},
title={Validation of the Virtual Reality Everyday Assessment Lab (VR-EAL): An Immersive Virtual Reality Neuropsychological Battery with Enhanced Ecological Validity},
journal={Journal of the International Neuropsychological Society : JINS},
volume={27},
number={2},
pages={181-196},
note={Name - University of Edinburgh; Copyright - Copyright © INS. Published by Cambridge University Press, 2020; Last updated - 2024-03-22},
abstract={Objective:The assessment of cognitive functions such as prospective memory, episodic memory, attention, and executive functions benefits from an ecologically valid approach to better understand how performance outcomes generalize to everyday life. Immersive virtual reality (VR) is considered capable of simulating real-life situations to enhance ecological validity. The present study attempted to validate the Virtual Reality Everyday Assessment Lab (VR-EAL), an immersive VR neuropsychological battery, against an extensive paper-and-pencil neuropsychological battery.Methods:Forty-one participants (21 females) were recruited: 18 gamers and 23 non-gamers who attended both an immersive VR and a paper-and-pencil testing session. Bayesian Pearson’s correlation analyses were conducted to assess construct and convergent validity of the VR-EAL. Bayesian t-tests were performed to compare VR and paper-and-pencil testing in terms of administration time, similarity to real-life tasks (i.e., ecological validity), and pleasantness.Results:VR-EAL scores were significantly correlated with their equivalent scores on the paper-and-pencil tests. The participants’ reports indicated that the VR-EAL tasks were significantly more ecologically valid and pleasant than the paper-and-pencil neuropsychological battery. The VR-EAL battery also had a shorter administration time.Conclusion:The VR-EAL appears as an effective neuropsychological tool for the assessment of everyday cognitive functions, which has enhanced ecological validity, a highly pleasant testing experience, and does not induce cybersickness.},
keywords={Medical Sciences--Psychiatry And Neurology; Prospective memory; Ecological validity; Cognitive skill; Virtual reality; Neuropsychology; Episodic memory; Attention; Executive function; Everyday functioning; Memory; Brain damage; Validity; Computer applications; Bayesian analysis; Cognitive ability; Multitasking; Laboratories},
isbn={13556177},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-virtual-reality-everyday-assessment/docview/2488081410/se-2},
}

@article{
author={Setyadi,Rudy and Ranggadara,Indra},
year={2020/02//},
month={Feb 2020},
title={Augmented reality using features accelerated segment test for property catalogue},
journal={TELKOMNIKA},
volume={18},
number={1},
pages={140-147},
note={Copyright - © 2020. This work is published under https://creativecommons.org/licenses/by/3.0 (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-05},
abstract={The FAST algorithm will calculate every pixel on the target image in determining the corner when scanning the home catalog then it will produce a 3D object home to see the real shape design of the house. Augmented reality is a technology that combines two-dimensional or three-dimensional virtual objects into a real environment in real time 7] so there is no boundary between the real world and the virtual world 8]. With the application of the augmented reality, the user can more easily get the information about the home in the form of 3D models by aiming the camera to the marker on the catalog. 2.RESEARCH METHOD 2.1.Multimedia development life cycle This study uses the MDLC (Multimedia Development Life Cycle) method. According to Luther in Nurajizah 20] the development of the multimedia method was carried out based on six stages, arranged systematically as follows: - The first step of this method is Concept.},
keywords={Technology: Comprehensive Works; Augment; 3D modeling; Augmented reality; Reality; Software; Marketing; Research methodology; Houses; Multimedia; Three dimensional models; Accelerated tests; Housing; Algorithms; Target recognition},
isbn={16936930},
language={English},
url={https://www.proquest.com/scholarly-journals/augmented-reality-using-features-accelerated/docview/2379528897/se-2},
}

@article{
author={Jin,Roger and Pilozzi,Alexander and Huang,Xudong},
year={2020},
month={2020},
title={Current Cognition Tests, Potential Virtual Reality Applications, and Serious Games in Cognitive Assessment and Non-Pharmacological Therapy for Neurocognitive Disorders},
journal={Journal of Clinical Medicine},
volume={9},
number={10},
pages={3287},
note={Copyright - © 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-23},
abstract={As the global population ages, the incidence of major neurocognitive disorders (major NCDs), such as the most common geriatric major NCD, Alzheimer’s disease (AD), has grown. Thus, the need for more definitive cognitive assessment or even effective non-pharmacological intervention for age-related NCDs is becoming more and more pressing given that no definitive diagnostics or efficacious therapeutics are currently unavailable for them. We evaluate the current state of the art of cognitive assessment for major NCDs, and then briefly glance ahead at potential application of virtual reality (VR) technologies in major NCD assessment and in cognition training of visuospatial reasoning in a 3D environment, as well as in the alleviation of depression and other symptoms of cognitive disorders. We believe that VR-based technologies have tremendous potentials in cognitive assessment and non-pharmacological therapy for major NCDs.},
keywords={Medical Sciences; aging; Neurocognition; Cognitive disorder; Serious game; Alzheimer's disease; Virtual reality; major neurocognitive disorder; Alzheimer’s disease; cognitive assessment; mild neurocognitive disorder; mini-mental state examination; augmented reality; mixed reality; Patients; Cognitive ability; Memory; Age; Magnetic resonance imaging; Cognition & reasoning; Mental disorders; Clinical medicine; Computer & video games; Educational software},
language={English},
url={https://www.proquest.com/scholarly-journals/current-cognition-tests-potential-virtual-reality/docview/2641145126/se-2},
}

@article{
author={Jayasekera,R. D. M. D. and Xu,X.},
year={2019/12//},
month={Dec 2019},
title={Assembly validation in virtual reality—a demonstrative case},
journal={The International Journal of Advanced Manufacturing Technology},
volume={105},
number={9},
pages={3579-3592},
note={Copyright - © Springer-Verlag London Ltd., part of Springer Nature 2019; Last updated - 2023-11-25},
abstract={Assembly validation is a key part of product design. Current methods, such as physical prototyping are time-consuming and do not offer immediate validation results. Assembly motion simulation systems have been proposed as a solution to this problem. However, widespread adoption of such systems is hindered due to their ties to proprietary computer aided design (CAD) software or expensive and often cumbersome hardware. Recently, virtual/augmented reality (VR/AR) technologies and simulation have been heralded as two of the key enabling factors of Industry 4.0. Collective interests in these technologies by industry and community have brought many low-cost software and hardware tools to the market, which opens a gateway to achieving assembly validation at a much lower cost. This paper presents an assembly validation system that is independent of CAD packages, interoperable and implemented using relatively low-cost and commercially available hardware and software tools. The system features intuitive bare-hand manipulation of part models through a virtual hand model that tracks the hands. Collision detection and physics modelling allow for hand-part and part-part interactions to be natural, thus validating assembly interactions. An assembly feature extraction algorithm has also been implemented to analyse the planar face features of the part models to detect possible mating assembly features between parts concerned. A constraint management system considers identified mating features and determines the allowable motion of parts once constraints are applied and removed. Pulling force is used to facilitate the removal of constraints.},
keywords={Machinery; Virtual reality; Collision detection; Virtual; Theory of constraints; Assembly simulation; Assembly validation; Feature extraction; Industry 4.0; Assembly; Software; Augmented reality; Low cost; Hardware; Product design; Computer aided design--CAD; Prototyping; Motion simulation; Industrial applications; Algorithms; Software development tools},
isbn={02683768},
language={English},
url={https://www.proquest.com/scholarly-journals/assembly-validation-virtual-reality-demonstrative/docview/2490851548/se-2},
}

@article{
author={R,D. M. D. J. and Xu,X.},
year={2019/12//},
month={Dec 2019},
title={Assembly validation in virtual reality—a demonstrative case},
journal={The International Journal of Advanced Manufacturing Technology},
volume={105},
number={9},
pages={3579-3592},
note={Copyright - The International Journal of Advanced Manufacturing Technology is a copyright of Springer, (2019). All Rights Reserved; Last updated - 2023-11-25},
abstract={Assembly validation is a key part of product design. Current methods, such as physical prototyping are time-consuming and do not offer immediate validation results. Assembly motion simulation systems have been proposed as a solution to this problem. However, widespread adoption of such systems is hindered due to their ties to proprietary computer aided design (CAD) software or expensive and often cumbersome hardware. Recently, virtual/augmented reality (VR/AR) technologies and simulation have been heralded as two of the key enabling factors of Industry 4.0. Collective interests in these technologies by industry and community have brought many low-cost software and hardware tools to the market, which opens a gateway to achieving assembly validation at a much lower cost. This paper presents an assembly validation system that is independent of CAD packages, interoperable and implemented using relatively low-cost and commercially available hardware and software tools. The system features intuitive bare-hand manipulation of part models through a virtual hand model that tracks the hands. Collision detection and physics modelling allow for hand-part and part-part interactions to be natural, thus validating assembly interactions. An assembly feature extraction algorithm has also been implemented to analyse the planar face features of the part models to detect possible mating assembly features between parts concerned. A constraint management system considers identified mating features and determines the allowable motion of parts once constraints are applied and removed. Pulling force is used to facilitate the removal of constraints.},
keywords={Machinery; Virtual reality; Collision detection; Virtual; Theory of constraints; Assembly simulation; Assembly validation; Feature extraction; Industry 4.0; Assembly; Software; Augmented reality; Low cost; Hardware; Product design; Computer aided design--CAD; Prototyping; Motion simulation; Industrial applications; Algorithms; Computer simulation; Software development tools},
isbn={02683768},
language={English},
url={https://www.proquest.com/scholarly-journals/assembly-validation-virtual-reality-demonstrative/docview/2320890934/se-2},
}

@article{
author={Kourtesis,Panagiotis and Collina,Simona and Doumas,Leonidas A. A. and MacPherson,Sarah E.},
year={2019/11/26/},
month={2019 Nov 26},
title={Validation of the Virtual Reality Neuroscience Questionnaire: Maximum Duration of Immersive Virtual Reality Sessions Without the Presence of Pertinent Adverse Symptomatology},
journal={Frontiers in Human Neuroscience},
note={Name - University of Edinburgh; Copyright - © 2019. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; People - Parsons, T; Last updated - 2023-11-24; SubjectsTermNotLitGenreText - Italy; Parsons, T; United Kingdom--UK},
abstract={There are major concerns about the suitability of immersive virtual reality (VR) systems (i.e., head-mounted display; HMD) to be implemented in research and clinical settings, because of the presence of nausea, dizziness, disorientation, fatigue, and instability (i.e., VR induced symptoms and effects; VRISE). Research suggests that the duration of a VR session modulates the presence and intensity of VRISE, but there are no suggestions regarding the appropriate maximum duration of VR sessions. The implementation of high-end VR HMDs in conjunction with ergonomic VR software seems to mitigate the presence of VRISE substantially. However, a tool does not currently exist to appraise the quality of software features and VRISE intensity quantitatively. The Virtual Reality Neuroscience Questionnaire (VRNQ) was developed to assess the quality of VR software in terms of user experience, game mechanics, in-game assistance, and VRISE. Forty participants aged between 28 and 43 years were recruited (18 gamers and 22 non-gamers) for the study. They participated in 3 different VR sessions until they felt weary or discomfort and subsequently filled in the VRNQ. Our results demonstrated that VRNQ is a valid tool for assessing VR software as it has good convergent, discriminant, and construct validity. The maximum duration of VR sessions should be between 55-70 minutes to avoid moderate or intense VRISE and, after familiarization with the VR system, while the gaming experience does not affect how long VR sessions should last. Also, while the quality of VR software substantially modulates the maximum duration of VR sessions, age and education do not. Finally, deeper immersion, better quality of graphics and sound, and more helpful in-game instructions and prompts were found to reduce VRISE intensity. The VRNQ facilitates the assessment and reporting of the quality of VR software features and the intensity of VRISE, while its minimum and parsimonious cut-offs may appraise the suitability of VR software for implementation in research and clinical settings. The findings of this study contribute to the establishment of rigorous VR methods that are crucial for the viability of immersive VR as a research and clinical tool in cognitive neuroscience and neuropsychology},
keywords={Medical Sciences--Psychiatry And Neurology; Virtual Reality; Immersion; Head-mounted display; Virtual reality game; Validation; Cybersickness; Neuroscience (Psychology); Neuropsychology; Psychology; VR; VR sickness; VRISE (Virtual Reality Induced Symptoms and Effects); Motion sickness (simulator sickness); Physiology; Research; Software; Computer programs; Nausea; Questionnaires; Neurosciences; Computer applications; Literature reviews; Cognitive ability; Nervous system; United Kingdom--UK; Italy; Parsons, T},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-virtual-reality-neuroscience/docview/2318358052/se-2},
}

@article{
author={R,Dewi A. and Hustinawaty and Jatnika,Ihsan and Medyawati,Henny},
year={2019/03//},
month={Mar 2019},
title={Boundary Value Analysis Testing on Augmented Reality of Indonesian Fruit Recognition at Mekarsari Tourist Park using Cloud Method on Android Mobile Devices},
journal={Journal of Physics: Conference Series},
volume={1196},
number={1},
note={Copyright - © 2019. This work is published under http://creativecommons.org/licenses/by/3.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-28; SubjectsTermNotLitGenreText - Indonesia},
abstract={Software testing is a process of implementing a program with the aim of finding an error. A good test case is if the test has the possibility of finding an uncovered error. A successful test is if the test finds an error that was not initially found. One of the testing types available is black box testing. This paper proposes testing using black box testing technique. The black box testing method consists of several ways including equivalence partitioning, boundary value analysis, comparison testing, sample testing, robustness testing, and others. Among the many methods of testing, Boundary Value Analysis was chosen in this study. Boundary Value Analysis is a method of testing by determining the value of the lower limit and upper limit of the data that will be tested. This test is performed on the functions of Augmented Reality prototype of Indonesia fruit recognition by using the cloud method on Android mobile devices. From testing the distance of marker objects to Android mobile devices on cloud recognition using an Android camera shows that the higher the augmentable rating of the target image and the more the number of markers features detected, the easier the image will be tracked by AR. If the distance between the camera and the real object gets farther away, then the virtual object cannot be displayed. Testing with mobile devices using HSDPA, 3G and WIFI networks connecting a cloud database server to display virtual objects shows the average results of devices that use WIFI networks provide the fastest performance.},
keywords={Physics; Wifi; Augmented reality; Software testing; Markers; Errors; Object recognition; Value analysis; Electronic devices; Cameras; Indonesia},
isbn={17426588},
language={English},
url={https://www.proquest.com/scholarly-journals/boundary-value-analysis-testing-on-augmented/docview/2566088439/se-2},
}

@article{
author={Duncan,Dominique and Garner,Rachael and Zrantchev,Ivan and Ard,Tyler and Newman,Bradley and Saslow,Adam and Wanserski,Emily and Toga,Arthur W.},
year={2019/02//},
month={Feb 2019},
title={Using Virtual Reality to Improve Performance and User Experience in Manual Correction of MRI Segmentation Errors by Non-experts},
journal={Journal of Digital Imaging},
volume={32},
number={1},
pages={97-104},
note={Copyright - Journal of Digital Imaging is a copyright of Springer, (2018). All Rights Reserved; Last updated - 2023-11-27},
abstract={Segmentation of MRI scans is a critical part of the workflow process before we can further analyze neuroimaging data. Although there are several automatic tools for segmentation, no segmentation software is perfectly accurate, and manual correction by visually inspecting the segmentation errors is required. The process of correcting these errors is tedious and time-consuming, so we present a novel method of performing this task in a head-mounted virtual reality interactive system with a new software, Virtual Brain Segmenter (VBS). We provide the results of user testing on 30 volunteers to show the benefits of our tool as a more efficient, intuitive, and engaging alternative compared with the current method of correcting segmentation errors.},
keywords={Medical Sciences--Radiology And Nuclear Medicine; Virtual reality; Segment; Error detection and correction; Magnetic resonance imaging; Segmentation; MRI; Imaging; Quality control; Data processing; Computer programs; Performance enhancement; Neurology; Image segmentation; Medical imaging; Workflow; Brain; Image processing; Computer applications; Neuroimaging; Software; Interactive systems; User experience},
isbn={08971889},
language={English},
url={https://www.proquest.com/scholarly-journals/using-virtual-reality-improve-performance-user/docview/2072559435/se-2},
}

@article{
author={Manuri,Federico and Pizzigalli,Alessandro and Sanna,Andrea},
year={2019},
month={2019},
title={A State Validation System for Augmented Reality Based Maintenance Procedures},
journal={Applied Sciences},
volume={9},
number={10},
note={Copyright - © 2019. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-25},
abstract={...]since part of the environment that the user sees is real, it is not necessary to compute a virtual model of it; secondly, since the user’s physical point of view is preserved, the physical and mental annoyances that usually occur in a detached full-immersive virtual world are avoided. A set of possible high-impact applications for industrial AR were identified by Navab 8] in 2004. ...]the benefits that AR could provide to maintenance, repair and assembly tasks have been thoroughly analyzed by Henderson and Feiner in 3]. Currently, maintenance, repair and assembly are identified as strategic application fields, since the reduction of associated costs represents a key goal in many domains, thus, any technological advancement is carefully considered in order to take the opportunity to reduce these costs. ...]augmented reality is considered one of the nine pillars of technological advancement comprised by the Industry 4.0 paradigm: to provide an exemplification of the impact of such technologies on Industry, it has been evaluated that Industry 4.0 in the next 5–10 years will boost productivity among all German manufacturing sectors by 90 billion euros to 150 billion euros, possibly driving an additional revenue growth of about 30 billion euros a year 9]. A typical maintenance task can benefit from AR since it is possible to provide assistance to the user through digital assets: 3D models, animations, audio tracks and video clips, which are available to the user to better understand how to perform the given task. ...]AR applications for maintenance and repair are often completed by tele-presence systems:},
keywords={Sciences: Comprehensive Works; augmented reality; maintenance procedures; state validation; computer vision; Maintenance; Fourth Industrial Revolution; Assembly; Repair; Machinery; Manufacturing industry; Industrial applications; Virtual communities; Algorithms; Performance evaluation; Domains; Costs; Repair & maintenance},
language={English},
url={https://www.proquest.com/scholarly-journals/state-validation-system-augmented-reality-based/docview/2331445098/se-2},
}

@article{
author={Chiarovano,Elodie and McGarvie,Leigh A. and Szmulewicz,David and MacDougall,Hamish G.},
year={2018/11//},
month={Nov 2018},
title={RETRACTED ARTICLE: Subjective visual vertical in virtual reality (Curator SVV): validation and normative data},
journal={Virtual Reality},
volume={22},
number={4},
pages={315-320},
note={Copyright - © Springer-Verlag London Ltd., part of Springer Nature 2018; Last updated - 2023-12-05},
abstract={Subjective visual vertical (SVV) assesses the ability to perceive verticality, which is a measure of vestibular otolithic function. Vestibular lesions influence this perception of verticality. We developed a method using virtual reality (VR) display and an Android software application named ‘Curator SVV’. The virtual reality SVV (Curator SVV) consisted of ten readily identifiable artworks projected by a Samsung phone S6 which is inserted into a virtual reality headset. In the first study, 20 patients had there SVV assessed with two devices: (1) a commercially available SVV measurement device (VestiTest®) and (2) a virtual reality SVV using the Curator SVV application. In a second study, 32 healthy subjects had their SVV assessed by the Curator SVV application whilst sitting in a chair. In the first study, there was no significant difference (p = 0.44, paired t test and p = 0.01, test of equivalence) between results obtained by Curator SVV and the commercially available device. In the second study, the average angle measured for healthy subjects was 0.00° ± 0.85°. The normal range (mean ± 2 SD) was ± 2° in standard upright position. We were able to demonstrate that the Curator SVV can be readily employed as an objective, non-invasive and affordable means of assessing otolith function in the clinical context. We validated this novel methodology by finding strong quantitative parity between a standard commercial SVV unit and the VR Curator SVV method. Our very lightweight and mobile device can be employed in clinical contexts including at the bedside and in different head and body positions.},
keywords={Computers--Computer Graphics; SVV; Mobile Device; Virtual reality; Otolith; Curator; Upright; Samsung Gear VR; Vestibular},
isbn={13594338},
language={English},
url={https://www.proquest.com/scholarly-journals/retracted-article-subjective-visual-vertical/docview/2728757485/se-2},
}

@article{
author={Nikitenko,M. S. and Zhuravlev,S. S. and Rudometov,S. V. and Neogi,B. and Belyi,A. M.},
year={2018/11//},
month={Nov 2018},
title={Walking support control system algorithms testing with brain-computer interface (BCI) and augmented reality (AR) technology integration},
journal={IOP Conference Series.Earth and Environmental Science},
volume={206},
number={1},
note={Copyright - © 2018. This work is published under http://creativecommons.org/licenses/by/3.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-25},
abstract={The article presents a perspective platform for the creation of robotic complexes for the effective and safe development of hard-to-extract minerals based on the walking support module. It describes the concept of automation control based on combining BCI and AR technology, and a method for testing control algorithms based on the application of the MTSS (Manufacturing and Transportation Simulation System) as part of the hardware and software complex for debugging and testing the applied software of the automated process control system for coal and ore mines. The reported study was partially funded by RFBR according to the research project No. 18-37-00356.},
keywords={Environmental Studies; Mining; Robotics; Automation; Walking; Augmented reality; Brain; Computer programs; Control algorithms; Process control; Control systems; Human-computer interface; Algorithms; Technology; Minerals; Process controls; Implants; Computer applications; Coal mines; Software; Research projects; Automatic control},
isbn={17551307},
language={English},
url={https://www.proquest.com/scholarly-journals/walking-support-control-system-algorithms-testing/docview/2559448067/se-2},
}

@article{
author={Chin,C. S. and Lin,W. P. and Lin,J. Y.},
year={2018/06//},
month={Jun 2018},
title={Experimental validation of open-frame ROV model for virtual reality simulation and control},
journal={Journal of Marine Science and Technology},
volume={23},
number={2},
pages={267-287},
note={Copyright - Journal of Marine Science and Technology is a copyright of Springer, (2017). All Rights Reserved; Last updated - 2023-12-29},
abstract={The hydrodynamic damping and added mass of a remotely operated vehicle (ROV) are difficult to model. This paper provided an intuitive modeling and simulation approach to obtain the hydrodynamic damping and added mass coefficients of an open-frame ROV using computational fluid dynamic (CFD) approach in the preliminary design stage where extensive hydrodynamic test facilities are not available. The software MATLAB™, STAR CCM+™ and WAMIT™ are employed to compute the hydrodynamic damping coefficients and added mass coefficients of the ROV for control system design and virtual reality. Experimental validation for the heave and yaw responses in a water tank shows a close relation and insight to the simulation results for subsequent control system design.},
keywords={Earth Sciences--Oceanography; Modeling; Simulation; Added mass; Virtual reality; Remotely operated vehicle; Yaw; Hydrodynamics; Test facilities; Systems design; Remotely operated vehicles; Computer applications; Design; Test equipment; Computer simulation; Hydrodynamic damping; Modelling; Control systems design; Control; Design engineering; Coefficients; Mass; Damping; Underwater vehicles; Mathematical models; Computational fluid dynamics; Yawing; Unmanned vehicles; Product design},
isbn={09484280},
language={English},
url={https://www.proquest.com/scholarly-journals/experimental-validation-open-frame-rov-model/docview/2041100450/se-2},
}

@article{
author={Karatsidis,Angelos and Richards,Rosie E. and Konrath,Jason M. and Josien C van,den N. and H,Martin S. and Bellusci,Giovanni and Harlaar,Jaap and Veltink,Peter H.},
year={2018},
month={2018},
title={Validation of wearable visual feedback for retraining foot progression angle using inertial sensors and an augmented reality headset},
journal={Journal of Neuroengineering and Rehabilitation},
volume={15},
note={Copyright - Copyright © 2018. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-28},
abstract={BackgroundGait retraining interventions using real-time biofeedback have been proposed to alter the loading across the knee joint in patients with knee osteoarthritis. Despite the demonstrated benefits of these conservative treatments, their clinical adoption is currently obstructed by the high complexity, spatial demands, and cost of optical motion capture systems. In this study we propose and evaluate a wearable visual feedback system for gait retraining of the foot progression angle (FPA).MethodsThe primary components of the system are inertial measurement units, which track the human movement without spatial limitations, and an augmented reality headset used to project the visual feedback in the visual field. The adapted gait protocol contained five different target angles ranging from 15 degrees toe-out to 5 degrees toe-in. Eleven healthy participants walked on an instrumented treadmill, and the protocol was performed using both an established laboratory visual feedback driven by optical motion capture, and the proposed wearable system.Results and conclusionsThe wearable system tracked FPA with an accuracy of 2.4 degrees RMS and ICC=0.94 across all target angles and subjects, when compared to an optical motion capture reference. In addition, the effectiveness of the biofeedback, reflected by the number of steps with FPA value ±2 degrees from the target, was found to be around 50% in both wearable and laboratory approaches. These findings demonstrate that retraining of the FPA using wearable inertial sensing and visual feedback is feasible with effectiveness matching closely an established laboratory method. The proposed wearable setup may reduce the complexity of gait retraining applications and facilitate their transfer to routine clinical practice.},
keywords={Medical Sciences--Psychiatry And Neurology; Osteoarthritis; Biofeedback; Video feedback; Augmented reality; Laboratories; Visual perception; Retraining; Older people; Inertial sensing devices; Sensors; Knee; Treadmills; Gait; Visual fields; Wearable technology; Feet; Feedback; Visual field; Biomedical materials; Human motion; Biocompatibility; Complexity; Inertial platforms; Motion capture},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-wearable-visual-feedback-retraining/docview/2089733221/se-2},
}

@article{
author={Chen,Chwen J. and Lau,Siew Y. and Teh,Chee S.},
year={2015/06//},
month={Jun 2015},
title={A feasible group testing framework for producing usable virtual reality learning applications},
journal={Virtual Reality},
volume={19},
number={2},
pages={129-144},
note={Copyright - Springer-Verlag London 2015; Document feature - ; Last updated - 2023-12-05},
abstract={Designing a usable learning application is one of the key factors in ensuring effective learning. This article introduces modified group usability testing (MGUT) as a feasible framework for evaluating the usability of non-immersive virtual reality (VR) learning applications. Conventionally, usability testing of such learning applications often employs the one-to-one approach in which an evaluator conducts testing with several individual participants. As opposed to the one-to-one approach, the group approach involves several-to-many participants performing tasks simultaneously, with several evaluators observing and interacting with participants. This article describes the complete step-by-step procedure for conducting MGUT to uncover usability problems of a VR learning application that aims to educate its users on fire safety and prevention. It also proposes methods to analyze these usability problems. The effectiveness and efficiency of MGUT was then compared with DGUT, the original group testing technique and cooperative evaluation (CE), which is a typical one-to-one approach. Results indicate that all three techniques are able to reveal usability problems of different usability factors and show similar capability to discover the most critical and serious problems. MGUT is more effective than DGUT as it can collect additional usability problems of various factors and of different levels of severity. MGUT is as effective as CE as both techniques can identify usability problems which are more or less comparable in terms of quantity and quality. As for efficiency, MGUT and DGUT are more efficient than CE as these group testing approaches require lesser testing time, lesser effort in terms of the intensive interaction with participants although with slight more effort in the preparation of the physical setting. In addition, it is also obvious that MGUT and DGUT involve richer participation than CE. MGUT is also more feasible than DGUT as it allows some flexibility in the computer arrangement setting.},
keywords={Computers--Computer Graphics; Group testing; Usability testing; Efficiency; Virtual; Virtual reality; User interface; Interactive learning},
isbn={13594338},
language={English},
url={https://www.proquest.com/scholarly-journals/feasible-group-testing-framework-producing-usable/docview/1686064267/se-2},
}

@article{
author={Manesh,H. F. and Hashemipour,M.},
year={2010},
month={2010},
title={Virtual-reality-based methodology for modelling and verifying shop floor control systems},
journal={Proceedings of the Institution of Mechanical Engineers},
volume={224},
pages={1251-1265},
note={Copyright - Copyright Professional Engineering Publishing Ltd 2010; Document feature - Diagrams; Photographs; Graphs; ; Last updated - 2023-12-03},
abstract={The design and development of shop floor control systems (SFCSs) In automated manufacturing plants requires careful thought to ensure that the manufacturing system successfully satisfies the demands of today's competative marketplace. This paper presents a methodology for the development of SFCSs that is based on virtual reality (VR) in order to assist the system designer at each stage of development. Exploiting VR helps the user to collect valid information quickly and in a correct form by putting the user and the information support elements in direct relation with the operation of the system in a more realistic environment. A VR-SFCS prototype tool is designed as a software system to realize the features outlined in each phase of the methodology. A set of rules and a knowledge base is appended to the methodology to remove any inconsistency that could arise between the material and the information flows during the development. A novel environment for matching the physical and the informational model domains is recommended in order to delineate the system requirements specification. PUBLICATION ABSTRACT]},
keywords={Engineering--Mechanical Engineering; Factory; Software development; Shop floor; Automation; Virtual reality; Manufacturing; Control systems; Software},
isbn={09544054},
language={English},
url={https://www.proquest.com/scholarly-journals/virtual-reality-based-methodology-modelling/docview/871796869/se-2},
}

@article{
author={Won,Mooncheol and Kim,Sung S. and Kang,Byeong B. and Jung,Hyuck J.},
year={2001/09//},
month={Sep 2001},
title={Test bed for vehicle longitudinal control using chassis dynamometer and virtual reality: An application to adaptive cruise control},
journal={KSME International Journal},
volume={15},
number={9},
pages={1248-1256},
note={Copyright - The Korean Society of Mechanical Engineers (KSME) 2001; Last updated - 2023-11-27},
abstract={In this study, a test bed for vehicle longitudinal control is developed using a chassis dynamometer and real time 3-D graphics. The proposed test bed system consist of a chassis dynamometer on which test vehicle can run longitudinally, a video system that shows virtual driver view, and computer that control the test vehicle and realize the real time 3-D graphics. The purpose of the proposed system is to test vehicle longitudinal control and warning algorithms such as Adaptive Cruise Control (ACC), stop and go systems, and collision warning systems. For acceleration and deceleration situations which only need throttle movements, a vehicle longitudinal spacing control algorithm has been tested on the test bed. The spacing control algorithm has been designed based on sliding mode control and road grade estimation scheme which utilizes the vehicle engine torque map and gear shift information.PUBLICATION ABSTRACT]},
keywords={Engineering--Mechanical Engineering; Vehicle; Adaptive cruise control; Cruise control; Chassis dynamometer; Virtual reality; Testbed; 3-D graphics; Product design; Control algorithms; 5240:Software & systems; 7500:Product planning & development},
isbn={12264865},
language={English},
url={https://www.proquest.com/scholarly-journals/test-bed-vehicle-longitudinal-control-using/docview/1020987967/se-2},
}