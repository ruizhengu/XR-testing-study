@inproceedings{10.1145/3377290.3377315,
author = {Nikolov, Ivan},
title = {Testing VR headset cameras for capturing written content},
year = {2020},
isbn = {9781450377744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377290.3377315},
doi = {10.1145/3377290.3377315},
abstract = {Virtual reality (VR) has become an important tool for providing immersive and collaborative teleprensence experiences. The technology has the possibility of bringing people in different geographical places together in an immersive way and makes sharing knowledge, ideas and experience easier. An important evolution in the immersive experience is the introduction of items from the real world into the virtual environment and the creation of a mixed reality experience. We present a pilot study in the use of the built-in head mounted display (HMD) cameras, for capturing parts of the environment and presenting them in VR. Particular emphasis is put on capturing physical written content on flat surfaces and visualizing it in VR for sharing with other users. We test the HTC Vive and Valve Index cameras and compare them to two external solutions by applying optical character recognition (OCR) on captured and rectified images from them. We demonstrate that the Valve Index camera has the potential to be used for capturing readable text for use in shared VR.},
booktitle = {Proceedings of the 23rd International Conference on Academic Mindtrek},
pages = {153–156},
numpages = {4},
keywords = {VR, benchmarking, cameras, image acquisition, image processing, virtual reality},
location = {Tampere, Finland},
series = {AcademicMindtrek '20}
}

@inproceedings{10.1145/3594739.3610698,
author = {Morales Tellez, Arturo and Valdez Gastelum, Mar\'{\i}a Concepci\'{o}n and Castro, Luis A. and Tentori, Monica},
title = {Evaluating the Effect of the Color-Word Stroop Test and VR as a Psychological Stressor},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3610698},
doi = {10.1145/3594739.3610698},
abstract = {Virtual Reality (VR) makes use of psychological stressors to enable users to feel immersed in different domains. Although stressor tests, like the Color-Word Stroop Test (CWST), have been shown to be valid and reliable, there are limited deployments of such stressors that exhibit appropriate immersion and user experience in VR. In this paper, we present the development and evaluation of two VR simulators of the CWST. We conducted a between-subjects study with 27 participants who completed the conventional CWST, a VR-only simulator of the CWST, and a gamified VR simulator of the CWST. We measured and conducted a statistical analysis of participants’ CWST scores, perceived stress, immersion, user experience, playability, and heart rate. Our results show that there are no significant differences in using the two CWST simulators of the VR. We found that users’ heart rate is significantly higher when using the VR simulators than the conventional CWST and that the VR game simulator significantly shows a higher score in immersion than the VR-only simulator. However, users’ perceived stress was significantly less when using the VR game simulator. Finally, we reflect on design insights for stressors tests in VR and discuss directions for future work.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {93–97},
numpages = {5},
keywords = {Sports, Stress, Stroop Color, Virtual Reality},
location = {<conf-loc>, <city>Cancun, Quintana Roo</city>, <country>Mexico</country>, </conf-loc>},
series = {UbiComp/ISWC '23 Adjunct}
}

@article{10.1145/1497561.1497564,
author = {Mukhopadhyay, Rajdeep and Panda, S. K. and Dasgupta, Pallab and Gough, John},
title = {Instrumenting AMS assertion verification on commercial platforms},
year = {2009},
issue_date = {March 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1084-4309},
url = {https://doi.org/10.1145/1497561.1497564},
doi = {10.1145/1497561.1497564},
abstract = {The industry trend appears to be moving towards designs that integrate large digital circuits with multiple analog/RF (radio frequency) interfaces. In the verification of these large integrated circuits, the number of nets that need to be monitored has been growing rapidly. Consequently, the mixed-signal design community has been feeling the need for AMS (Analog and Mixed Signal) assertions that can automatically monitor conformance with expected time-domain behavior and help in debugging deviations from the design intent. The main challenges in providing this support are (a) developing AMS assertion languages or AMS verification libraries, and (b) instrumenting existing commercial simulators to support assertion verification during simulation. In this article, we report two approaches: the first extends the Open Verification Library (OVL) to the AMS domain by integrating a new collection of AMS verification libraries; while the second extends SystemVerilog Assertions (SVA) by augmenting analog predicates into SVA. We demonstrate the use of AMS-OVL on the Cadence Virtuoso environment while emphasizing that our libraries can work in any environment that supports Verilog and Verilog-A. We also report the development of tool support for AMS-SVA using a combination of Cadence NCSIM and Synopsys VCS. We demonstrate the utility of both approaches on the verification of LP3918, an integrated power management unit (PMU) from National Semiconductors. We believe that in the absence of existing EDA (Electronic Design Automation) tools for AMS assertion verification, the proposed approaches of integrating our libraries and our tool sets with existing commercial simulators will be of considerable and immediate practical value.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {apr},
articleno = {21},
numpages = {47},
keywords = {Assertion, OVL, SVA, integrated mixed signal design, simulation, verification library}
}

@inproceedings{10.1109/ASP-DAC47756.2020.9045131,
author = {Sanyal, Sayandeep and Hazra, Aritra and Dasgupta, Pallab and Morrison, Scott and Surendran, Sudhakar and Balasubramanian, Lakshmanan},
title = {The Notion of Cross Coverage in AMS Design Verification},
year = {2020},
isbn = {9781728141237},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASP-DAC47756.2020.9045131},
doi = {10.1109/ASP-DAC47756.2020.9045131},
abstract = {Coverage monitoring is fundamental to design verification. Coverage artifacts are well developed for digital integrated circuits and these aim to cover the discrete state space and logical behaviors of the design. Analog designers are similarly concerned with the operating regions of the design and its response to an infinite and dense input space. Analog variables can influence each other in far more complex ways as compared to digital variables, consequently, the notion of cross coverage, as introduced in the analog context for the first time in this paper, is of high importance in analog design verification. This paper presents the formal syntax and semantics of analog cross coverage artifacts, the methods for evaluating them using our tool kit, and most importantly, the insights that can be gained from such cross coverage analysis.},
booktitle = {Proceedings of the 25th Asia and South Pacific Design Automation Conference},
pages = {217–222},
numpages = {6},
location = {<conf-loc>, <city>Beijing</city>, <country>China</country>, </conf-loc>},
series = {ASPDAC '20}
}

@article{10.1145/3492735,
author = {Zou, Yu and Zubair, Kazi Abu and Alwadi, Mazen and Shadab, Rakin Muhammad and Gandham, Sanjay and Awad, Amro and Lin, Mingjie},
title = {ARES: Persistently Secure Non-Volatile Memory with Processor-transparent and Hardware-friendly Integrity Verification and Metadata Recovery},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1539-9087},
url = {https://doi.org/10.1145/3492735},
doi = {10.1145/3492735},
abstract = {Emerging byte-addressable Non-Volatile Memory (NVM) technology, although promising superior memory density and ultra-low energy consumption, poses unique challenges to achieving persistent data privacy and computing security, both of which are critically important to the embedded and IoT applications. Specifically, to successfully restore NVMs to their working states after unexpected system crashes or power failure, maintaining and recovering all the necessary security-related metadata can severely increase memory traffic, degrade runtime performance, exacerbate write endurance problem, and demand costly hardware changes to off-the-shelf processors.In this article, we designed and implemented ARES, a new FPGA-assisted processor-transparent security mechanism that aims at efficiently and effectively achieving all three aspects of a security triad—confidentiality, integrity, and recoverability—in modern embedded computing. Given the growing prominence of CPU-FPGA heterogeneous computing architectures, ARES leverages FPGA’s hardware reconfigurability to offload performance-critical and security-related functions to the programmable hardware without microprocessors’ involvement. In particular, recognizing that the traditional Merkle tree caching scheme cannot fully exploit FPGA’s parallelism due to its sequential and recursive function calls, we (1) proposed a Merkle tree cache architecture that partitions a unified cache into multiple levels with parallel accesses and (2) further designed a novel Merkle tree scheme that flattened and reorganized the computation in the traditional Merkle tree verification and update processes to fully exploit the parallel cache ports and to fully pipeline time-consuming hashing operations. Beyond that, to accelerate the metadata recovery process, multiple parallel recovery units are instantiated to recover counter metadata and multiple Merkle sub-trees.Our hardware prototype of the ARES system on a Xilinx U200 platform shows that ARES achieved up to 1.4\texttimes{} lower latency and 2.6\texttimes{} higher throughput against the baseline implementation, while metadata recovery time was shortened by 1.8 times. When integrated with an embedded processor, neither hardware changes nor software changes are required. We also developed a theoretical framework to analytically model and explain experimental results.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {feb},
articleno = {11},
numpages = {32}
}

@inproceedings{10.1145/3531073.3531171,
author = {Vona, Francesco and Pieri, Luca and Patti, Alberto and Tafaro, Simone and Saccoccio, Sara and Garzotto, Franca and Romano, Daniele},
title = {Explore 360° VR to Improve the Ecological Validity of Screening Tests on Cognitive Functions},
year = {2022},
isbn = {9781450397193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531073.3531171},
doi = {10.1145/3531073.3531171},
abstract = {Cognitive impairment is a condition that results in a person’s inability to remember, learn, concentrate or make decisions that affect his/her everyday life. The assessment of these deficits is usually performed using standardized paper and pencil or computerized tests within a controlled clinical setting. Many traditionally designed tools show only low to moderate levels of ecological validity, limiting the reliability of the collected measures. The proposed system adapts existing screening tests within an immersive virtual reality environment with 360° video, recreating a familiar setting for the patient. This faithful reproduction of everyday environments and situations can enhance the ecological validity of the assessment procedure while maintaining a standardized stimuli delivery, all in a controlled and safe setting. As a computerized system, virtual reality technology allows an error-free computation of the test scores, here collected by means of accuracy for each task. The system involves many technologies aimed at capturing any kind of user input provided by the patient. Additionally, using a visor with integrated eye-tracker sensor, the system can register the visual exploration pattern adopted by the patient during the task execution, providing information concerning the attentional and visuo-spatial functioning which are not obtainable using traditional assessment procedures. Finally, the results of an exploratory study that was conducted with 11 users on the reliability and usability of the system are presented.},
booktitle = {Proceedings of the 2022 International Conference on Advanced Visual Interfaces},
articleno = {32},
numpages = {5},
keywords = {360video VR screening test, Cognitive Impairment, Eye tracking, Pico Neo 3 Pro Eye},
location = {Frascati, Rome, Italy},
series = {AVI 2022}
}

@inproceedings{10.1145/3500866.3516377,
author = {Probst, Alice and Perelman, Gary and Dubois, Emmanuel and Serrano, Marcos},
title = {Acquisition visuelle en r\'{e}alit\'{e} mixte, depuis et vers une table interactive : Analyse de la transition entre un \'{e}cran virtuel et un \'{e}cran physique: Visual acquisition in mixed reality, from and to an interactive table: Analysis of the transition between a virtual screen and a physical screen},
year = {2022},
isbn = {9781450391894},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3500866.3516377},
doi = {10.1145/3500866.3516377},
abstract = {As part of a project to explore the opportunities and limitations created by the addition of a new interaction space around an interactive table, through an augmented reality headset, this paper aims to better understand the nature and characteristics of the new combined display space, as well as the role of the physical screen in this otherwise virtual environment. We also question the impact of directly superimposing augmented content on the physical screen, or on the contrary of strictly separating the two display environments. To this end, 12 participants performed visual acquisition tasks between these two spaces (tabletop and pure virtual area), with either a physical or virtual display at the tabletop. The results show better performance with strict use of the physical display for the tabletop area and an ability for the user to focus their gaze more towards the surrounding virtual areas.},
booktitle = {Proceedings of the 33rd Conference on l'Interaction Humain-Machine},
articleno = {9},
numpages = {17},
keywords = {Casque semi-transparent, Environnement interactif combin\'{e}, Hybrid interactive environment, Interactive tabletop, See-through Head mounted display, Table interactive},
location = {Namur, Belgium},
series = {IHM '22}
}

@inproceedings{10.1145/2896971.2896976,
author = {Xie, Xiaoyuan and Li, Jiahao and Wang, Chen and Chen, Tsong Yueh},
title = {Looking for an MR? try METWiki today},
year = {2016},
isbn = {9781450341639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896971.2896976},
doi = {10.1145/2896971.2896976},
abstract = {Metamorphic Testing (MT) has been demonstrated to successfully alleviate oracle problems in many areas, including machine learning, compilers, bioinformatics, etc. However, given a new MT task, it is still very challenging to identify enough Metamorphic Relations (MRs) which are key components of MT. Aiming at this problem, we revisited previous MT applications and realized that they could form a very valuable database. Currently there is a lack of efficient link to get testers access these historical data. Therefore, in this paper, we propose to build METWiki, an MR repository, for collection and retrieval of these MRs. By providing exploration and search facilities, testers can find their desired MRs for reuse, reference, or inference. We also illustrate three sample usages of METWiki, which show important illuminations on how MRs can be obtained in practice.},
booktitle = {Proceedings of the 1st International Workshop on Metamorphic Testing},
pages = {1–4},
numpages = {4},
keywords = {METWiki, MR repository, metamorphic relation, metamorphic testing},
location = {Austin, Texas},
series = {MET '16}
}

@inproceedings{10.1145/3460797.3460800,
author = {Jin, Sian and Roy, Sumit and Henderson, Thomas R.},
title = {EESM-log-AR: an efficient error model for OFDM MIMO systems over time-varying channels},
year = {2021},
isbn = {9781450390347},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460797.3460800},
doi = {10.1145/3460797.3460800},
abstract = {Packet-level network simulators such as ns-3 rely on efficient PHY layer abstraction represented by the packet error model for estimating link performance. For complex PHY layer designs - such as operating over frequency-selective MIMO wireless channels - the runtime of the state-of-the-art error model suggested by Task Group of IEEE 802.11ax (TGax) suffers from scaling with MIMO dimensionality and bandwidth. While our prior work proposes a runtime-efficient error model in the context of Independent and Identically Distributed (IID) frequency-selective MIMO channels, here we consider the time-varying frequency-selective MIMO channels that correlate over time. Our new error model is based on the insight that our previous workflow for the IID channel scenario can be extended using autoregressive modeling to the time-correlated case. We validate the hypothesis via link simulation campaigns and show that the runtime and storage complexity of the proposed error model is low compared to existing error models.},
booktitle = {Proceedings of the 2021 Workshop on Ns-3},
pages = {17–24},
numpages = {8},
keywords = {error model, network simulator 3 (ns-3), time-varying channel},
location = {Virtual Event, USA},
series = {WNS3 '21}
}

@inproceedings{10.1145/1450579.1450643,
author = {Perez, Camilo A. and Figueroa, Pablo},
title = {VRPN and Qwerk: fast MR device prototyping and testing},
year = {2008},
isbn = {9781595939517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1450579.1450643},
doi = {10.1145/1450579.1450643},
abstract = {We present a platform that offers designers flexibility on device design, fast prototyping, and integration of new devices to a mixed reality infrastructure. Our solution is based on the integration of a commercial embedded system, the Qwerk, and the Virtual Reality Peripheral Network (VRPN), a network-transparent interface between applications and typical virtual reality (VR) devices. This solution creates a hardware and software layer between new devices and VR applications that facilitate development. We show here a design process for new MR devices. With our hardware and software layer we allow designers concentrate more in the interaction rather than the way sensors are connected. To test our design process and our platform we implement three simple examples.},
booktitle = {Proceedings of the 2008 ACM Symposium on Virtual Reality Software and Technology},
pages = {261–262},
numpages = {2},
keywords = {augmented reality reality, embedded system, prototyping, virtual reality},
location = {Bordeaux, France},
series = {VRST '08}
}

@inproceedings{10.5555/3174304.3175435,
author = {Daskalakis, Constantinos and Dikkala, Nishanth and Kamath, Gautam},
title = {Testing ising models},
year = {2018},
isbn = {9781611975031},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {Given samples from an unknown multivariate distribution p, is it possible to distinguish whether p is the product of its marginals versus p being far from every product distribution? Similarly, is it possible to distinguish whether p equals a given distribution q versus p and q being far from each other? These problems of testing independence and goodness-of-fit have received enormous attention in statistics, information theory, and theoretical computer science, with sample-optimal algorithms known in several interesting regimes of parameters [BFF+01, Pan08, VV17, ADK15, DK16]. Unfortunately, it has also been understood that these problems become intractable in large dimensions, necessitating exponential sample complexity.Motivated by the exponential lower bounds for general distributions as well as the ubiquity of Markov Random Fields (MRFs) in the modeling of high-dimensional distributions, we initiate the study of distribution testing on structured multivariate distributions, and in particular the prototypical example of MRFs: the Ising Model. We demonstrate that, in this structured setting, we can avoid the curse of dimensionality, obtaining sample and time efficient testers for independence and goodness-of-fit. One of the key technical challenges we face along the way is bounding the variance of functions of the Ising model.},
booktitle = {Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {1989–2007},
numpages = {19},
location = {New Orleans, Louisiana},
series = {SODA '18}
}

@article{10.1145/3653696,
author = {Yuan, Ye and Genatempo, Peter and Jin, Qiao and Yarosh, Svetlana},
title = {Field Trial of a Tablet-based AR System for Intergenerational Connections through Remote Reading},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3653696},
doi = {10.1145/3653696},
abstract = {Prior work has explored various technology designs to support intergenerational communications and connections through remote activities such as reading or play. However, few works have explored these technologies outside the family settings. In this work, we aimed to understand how technology can support social connectedness through remote activities, by investigating the use of a tablet-based AR system among older adult volunteers and students for remote reading. We developed the system based on insights from previous research, deployed the system in the field, and observed the use of the system over six months. With the data collected from the field, we present a rich description on the use of the system and the practices that emerged around its usage in a real-world setting. Our findings highlight the importance of supporting an engaging reading experience and context understanding for social connections with the technology design. We provide insights into how such technology can support intergenerational communication and foster social connectedness.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {205},
numpages = {28},
keywords = {children, intergenerational communication, older adults, remote reading, social connection}
}

@inproceedings{10.1145/2901790.2901915,
author = {Djajadiningrat, Tom and Chao, Pei-Yin and Kim, SeYoung and Van Leengoed, Marleen and Raijmakers, Jeroen},
title = {Mime: An AR-based System Helping Patients to Test their Blood at Home},
year = {2016},
isbn = {9781450340311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2901790.2901915},
doi = {10.1145/2901790.2901915},
abstract = {Mime is a tablet-based augmented reality system which guides new chemotherapy patients through testing their blood at home. Starting from the socio-economic push towards home healthcare, we use blood analysis as a case study to illustrate the user experience challenges of unassisted care at home and how AR may support the user. We then show our explorations during an early ideation workshop, using low-fi prototyping and acting out. We also show steps from our making process in which we combine various tools, both physical and virtual, to further our understanding. We conclude with our final demonstrator and the discussions it triggered.},
booktitle = {Proceedings of the 2016 ACM Conference on Designing Interactive Systems},
pages = {347–359},
numpages = {13},
keywords = {augmented reality, home healthcare, manuals},
location = {Brisbane, QLD, Australia},
series = {DIS '16}
}

@inproceedings{10.1145/3583120.3586962,
author = {Hou, Kaiyuan and Xia, Stephen and Bejerano, Emily and Wu, Junyi and Jiang, Xiaofan},
title = {ARSteth: Enabling Home Self-Screening with AR-Assisted Intelligent Stethoscopes},
year = {2023},
isbn = {9798400701184},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583120.3586962},
doi = {10.1145/3583120.3586962},
abstract = {The stethoscope is one of the most important diagnostic tools used by healthcare professionals, through a process called auscultation, to screen patients for abnormalities of the heart and lungs. While there are digital stethoscopes on the market which ease this process, it still takes years of training to properly use these devices to listen for abnormal sounds within the body. We present ARSteth, an intelligent stethoscope platform that improves the accessibility of stethoscopes for the general population, allowing anyone to perform auscultation in the comfort of their own homes. Our platform utilizes a combination of augmented reality (AR), acoustic intelligence, and human-machine interaction to dynamically guide users on where to place the stethoscope on different parts of the body (auscultation points), through visual and audio cues. Through user studies, we show that ARSteth, on average, can guide users within 13.2 mm from optimal auscultation points marked by licensed physicians in 13.09 seconds for each auscultation point. By guiding users towards more effective auscultation points, make preventative health screening more accessible and effective for everyone we are able to achieve higher confidence on classifying heart murmurs.},
booktitle = {Proceedings of the 22nd International Conference on Information Processing in Sensor Networks},
pages = {205–218},
numpages = {14},
keywords = {digital stethoscope, human computer interaction, smart home},
location = {<conf-loc>, <city>San Antonio</city>, <state>TX</state>, <country>USA</country>, </conf-loc>},
series = {IPSN '23}
}

@article{10.5555/3455716.3455741,
author = {Bez\'{a}kov\'{a}, Ivona and Blanca, Antonio and Chen, Zongchen and \v{S}tefankovi\v{c}, Daniel and Vigoda, Eric},
title = {Lower bounds for testing graphical models: colorings and antiferromagnetic Ising models},
year = {2020},
issue_date = {January 2020},
publisher = {JMLR.org},
volume = {21},
number = {1},
issn = {1532-4435},
abstract = {We study the identity testing problem in the context of spin systems or undirected graphical models, where it takes the following form: given the parameter specification of the model M and a sampling oracle for the distribution µM* of an unknown model M*, can we efficiently determine if the two models M and M* are the same? We consider identity testing for both soft-constraint and hard-constraint systems. In particular, we prove hardness results in two prototypical cases, the Ising model and proper colorings, and explore whether identity testing is any easier than structure learning.For the ferromagnetic (attractive) Ising model, Daskalakis et al. (2018) presented a polynomial time algorithm for identity testing. We prove hardness results in the antiferromagnetic (repulsive) setting in the same regime of parameters where structure learning is known to require a super-polynomial number of samples. Specifically, for n-vertex graphs of maximum degree d, we prove that if |β|d = ω(log n) (where β is the inverse temperature parameter), then there is no polynomial running time identity testing algorithm unless RP = NP. In the hard-constraint setting, we present hardness results for identity testing for proper colorings. Our results are based on the presumed hardness of #BIS, the problem of (approximately) counting independent sets in bipartite graphs.},
journal = {J. Mach. Learn. Res.},
month = {jan},
articleno = {25},
numpages = {62},
keywords = {distribution testing, structure learning, graphical models, Ising model, colorings}
}

@inproceedings{10.1145/3607546.3616805,
author = {Rossi, Silvia and Toni, Laura and Cesar, Pablo},
title = {Correlation between Entropy and Prediction Error in VR Head Motion Trajectories},
year = {2023},
isbn = {9798400702808},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607546.3616805},
doi = {10.1145/3607546.3616805},
abstract = {The general understanding of user behaviour has been often overlooked in the field of Virtual Reality (VR) and Extended Reality (XR) at large. In this work, we want to fill this gap by exploring the relationship between the way in which users navigate in immersive content and the predictability of their trajectories. Inspired by works from social science, our key assumption is that there are navigation trajectories that can be accurately predicted, while others exhibit eclectic patterns that are more challenging to anticipate. However, it is not yet clear how to effectively distinguish between these behaviours. In this context, we conduct an extensive data analysis across multiple datasets investigating users' movements in VR. The ultimate goal is to understand if a specific metric from information theory, such as the entropy of trajectory, can be adopted as a discriminating metric between predictable navigation trajectories and unpredictable ones. Our findings reveal that users with highly regular navigation styles tend to exhibit lower entropy, indicating higher predictability of their movements. Conversely, users with more diverse navigation patterns show higher entropy and lower predictability in their trajectories. Answering the question "how can we distinguish users more predictable than others?'' would be crucial for different purposes in future immersive applications such as enabling new modalities for live streaming services but also for the design of more personalised and engaging VR experiences.},
booktitle = {Proceedings of the 2nd International Workshop on Interactive EXtended Reality},
pages = {29–36},
numpages = {8},
keywords = {information theory, motion prediction, trajectory analysis, user behavioural analysis, virtual reality},
location = {<conf-loc>, <city>Ottawa ON</city>, <country>Canada</country>, </conf-loc>},
series = {IXR '23}
}

@inproceedings{10.1145/1140491.1140533,
author = {Riecke, Bernhard E. and Wiener, Jan M.},
title = {Point-to-origin experiments in VR revealed novel qualitative errors in visual path integration},
year = {2006},
isbn = {1595934294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1140491.1140533},
doi = {10.1145/1140491.1140533},
abstract = {Even in state-of-the-art virtual reality (VR) setups, participants often feel lost when navigating through virtual environments. In psychological experiments, such disorientation is often compensated for by extensive training and performance feedback. The current study investigated participants' sense of direction by means of a rapid point-to-origin task without any training or performance feedback. This allowed us to study participants' intuitive spatial orientation processes in VR while minimizing the influence of higher cognitive abilities and compensatory strategies. From an applied perspective, such a paradigm could be employed for evaluating the effectiveness and usability of a given VR setup for enabling natural and unencumbered spatial orientation even for first-time users, which is important for tasks such as architecture walk-throughs, evacuation scenario training, or driving/flight simulators.},
booktitle = {Proceedings of the 3rd Symposium on Applied Perception in Graphics and Visualization},
pages = {156},
numpages = {1},
location = {Boston, Massachusetts, USA},
series = {APGV '06}
}

@inproceedings{10.1145/1179622.1179840,
author = {Riecke, Bernhard E. and Wiener, Jan M.},
title = {Point-to-origin experiments in VR revealed novel qualitative errors in visual path integration},
year = {2006},
isbn = {1595933646},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1179622.1179840},
doi = {10.1145/1179622.1179840},
booktitle = {ACM SIGGRAPH 2006 Research Posters},
pages = {190–es},
location = {Boston, Massachusetts},
series = {SIGGRAPH '06}
}

@inproceedings{10.1145/3027063.3052963,
author = {Fafard, Dylan and Wagemakers, Andrew and Stavness, Ian and Zhou, Qian and Miller, Gregor and Fels, Sidney S.},
title = {Calibration Methods for Effective Fish Tank VR in Multi-screen Displays},
year = {2017},
isbn = {9781450346566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027063.3052963},
doi = {10.1145/3027063.3052963},
abstract = {We present cubic and spherical multi-screen fish tank virtual reality displays that use novel interactive and automatic calibration techniques to achieve convincing 3D effects. The two displays contrast the challenges and benefits of multiple projectors or flat-panel screens, borders or borderless, and the performance of headtrackers. Individuals will be able to subjectively evaluate the visual fidelity of the displays by comparing physical objects to their virtual counterparts, comparing the two displays, and by changing the level of calibration accuracy. They will be able to test the first markerless, interactive, and user-dependent headtracker calibration that promises accurate viewpoint registration without the need for manual measurements. In conjunction with an automatic screen calibration technique, the displays will offer a unique and convincing 3D experience.},
booktitle = {Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
pages = {373–376},
numpages = {4},
keywords = {3d display, calibration, ftvr, multi-screen display},
location = {<conf-loc>, <city>Denver</city>, <state>Colorado</state>, <country>USA</country>, </conf-loc>},
series = {CHI EA '17}
}

@inproceedings{10.1145/3613904.3642213,
author = {Guan, Zhitong and Xiong, Zeyu and Fan, Mingming},
title = {FetchAid: Making Parcel Lockers More Accessible to Blind and Low Vision People With Deep-learning Enhanced Touchscreen Guidance, Error-Recovery Mechanism, and AR-based Search Support},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642213},
doi = {10.1145/3613904.3642213},
abstract = {Parcel lockers have become an increasingly prevalent last-mile delivery method. Yet, a recent study revealed its accessibility challenges to blind and low-vision people (BLV). Informed by the study, we designed FetchAid, a standalone intelligent mobile app assisting BLV in using a parcel locker in real-time by integrating computer vision and augmented reality (AR) technologies. FetchAid first uses a deep network to detect the user’s fingertip and relevant buttons on the touch screen of the parcel locker to guide the user to reveal and scan the QR code to open the target compartment door and then guide the user to reach the door safely with AR-based context-aware audio feedback. Moreover, FetchAid provides an error-recovery mechanism and real-time feedback to keep the user on track. We show that FetchAid substantially improved task accomplishment and efficiency, and reduced frustration and overall effort in a study with 12 BLV participants, regardless of their vision conditions and previous experience.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {39},
numpages = {15},
keywords = {Accessibility, Assistive technology, Augmented reality, Blind and low vision, Computer vision, KuaiDiGui, Mobile devices, Object detection, Package delivery, People with vision impairments},
location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
series = {CHI '24}
}

@inproceedings{10.1145/3281505.3281538,
author = {John, Brendan and Raiturkar, Pallavi and Banerjee, Arunava and Jain, Eakta},
title = {An evaluation of pupillary light response models for 2D screens and VR HMDs},
year = {2018},
isbn = {9781450360869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3281505.3281538},
doi = {10.1145/3281505.3281538},
abstract = {Pupil diameter changes have been shown to be indicative of user engagement and cognitive load for various tasks and environments. However, it is still not the preferred physiological measure for applied settings. This reluctance to leverage the pupil as an index of user engagement stems from the problem that in scenarios where scene brightness cannot be controlled, the pupil light response confounds the cognitive-emotional response. What if we could predict the light response of an individual's pupil, thus creating the opportunity to factor it out of the measurement? In this work, we lay the groundwork for this research by evaluating three models of pupillary light response in 2D, and in a virtual reality (VR) environment. Our results show that either a linear or an exponential model can be fit to an individual participant with an easy-to-use calibration procedure. This work opens several new research directions in VR relating to performance analysis and inspires the use of eye tracking beyond gaze as a pointer and foveated rendering.},
booktitle = {Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology},
articleno = {19},
numpages = {11},
keywords = {eyetracking, light response, pupil dilation, videos, virtual reality},
location = {Tokyo, Japan},
series = {VRST '18}
}

@inproceedings{10.1145/2856400.2876018,
author = {Lee, Sang Ho and Jhung, Junekyo and Lee, Hojun and Cha, Jaekwang and Kim, Shiho},
title = {A technique for matching convergence and accommodation in a fixed screen 3D VR HMD},
year = {2016},
isbn = {9781450340434},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2856400.2876018},
doi = {10.1145/2856400.2876018},
abstract = {A technique for matching both the eye convergence and accommodation in a fixed screen non-see through 3D VR HMD(3 Dimensional Virtual Reality Head mount Display) is presented. The user field test data show that significant improvement in dizziness problems as well as eye comfortability of users. The proposed method may provide a crew for resolution to solve simulator sickness caused by the binocular disparity of 3D VR HMD.},
booktitle = {Proceedings of the 20th ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
pages = {185–186},
numpages = {2},
keywords = {accommodation matching, convergence matching, depth of field, virtual reality},
location = {Redmond, Washington},
series = {I3D '16}
}

@inproceedings{10.1145/3613905.3650773,
author = {Mal, David and Wolf, Erik and D\"{o}llinger, Nina and Botsch, Mario and Wienrich, Carolin and Latoschik, Marc Erich},
title = {From 2D-Screens to VR: Exploring the Effect of Immersion on the Plausibility of Virtual Humans},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650773},
doi = {10.1145/3613905.3650773},
abstract = {Virtual humans significantly contribute to users’ plausible XR experiences. However, it may be not only the congruent rendering of the virtual human but also the degree of immersion having an impact on virtual humans’ plausibility. In a low-immersive desktop-based and a high-immersive VR condition, participants rated realistic and abstract animated virtual humans regarding plausibility, affective appraisal, and social judgments. First, our results confirmed the factor structure of a preliminary virtual human plausibility questionnaire in VR. Further, the appearance and behavior of realistic virtual humans were overall perceived as more plausible compared to abstract virtual humans, an effect that increased with high immersion. Moreover, only for high immersion, realistic virtual humans were rated as more trustworthy and sympathetic than abstract virtual humans. Interestingly, we observed a potential uncanny valley effect for low but not for high immersion. We discuss the impact of a natural perception of anthropomorphic and realistic cues in VR and highlight the potential of immersive technology to elicit distinct effects in virtual humans.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {167},
numpages = {8},
keywords = {Agent, Anthropomorphism, Avatar, Immersion, Presence, Realism},
location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
series = {CHI EA '24}
}

@inproceedings{10.1145/3582700.3582715,
author = {Miyazaki, Atsuko and Okuyama, Takashi and Mori, Hayato and Sato, Kazuhisa and Toshima, Kenta and Hiyama, Atsushi},
title = {Visuospatial abilities and cervical spine range of motion improvement effects of a non-goal-oriented VR travel program at an older adults facility:A pilot randomized controlled trial},
year = {2023},
isbn = {9781450399845},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582700.3582715},
doi = {10.1145/3582700.3582715},
abstract = {Virtual reality (VR) programs using head-mounted displays (HMD) give older adults the opportunity for unrestricted spatial exploration, with greater movement. We conducted a single-blind randomized control trial study to determine the beneficial effects of a non-goal-directed VR traveling program using an HMD on older adults living in an assisted living facility that also caters for people with dementia. Twenty-four participants, with an average age of 88.5 years, were randomly assigned to the VR program group or the control group. The VR group participated in three weekly VR travel sessions of 30 minutes each, for four weeks. The results showed that the VR group not only experienced improvement in simple visuospatial abilities, but also in tasks involving executive function. There was also improvement in vertical and horizontal cervical spine range of motion. However, cervical range of motion in lateral bending was worse in the VR group than in the control group, suggesting a possible effect of the weight of the HMD. Training in wide visual exploration that improves cervical spine range of motion may provide an orientation opportunity to avoid falls among older adults.},
booktitle = {Proceedings of the Augmented Humans International Conference 2023},
pages = {135–146},
numpages = {12},
keywords = {cervical spine range of motion, immersive virtual reality, older adults, visuospatial ability},
location = {<conf-loc>, <city>Glasgow</city>, <country>United Kingdom</country>, </conf-loc>},
series = {AHs '23}
}

@article{10.1145/3486583,
author = {Brickler, David and Babu, Sabarish V.},
title = {An Evaluation of Screen Parallax, Haptic Feedback, and Sensory-Motor Mismatch on Near-Field Perception-Action Coordination in VR},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1544-3558},
url = {https://doi.org/10.1145/3486583},
doi = {10.1145/3486583},
abstract = {Virtual reality (VR) displays have factors such as vergence-accommodation conflicts that negatively impact depth perception and cause users to misjudge distances to select objects. In addition, popular large-screen immersive displays present the depth of any target rendered through screen parallax information of points, which are encapsulated within stereoscopic voxels that are a distinct unit of space dictating how far an object is placed in front of or behind the screen. As they emanate from the viewers’ eyes (left and right center of projection), the density of voxels is higher in front of the screen (in regions of negative screen parallax) than it is behind the screen (in regions of positive screen parallax), implying a higher spatial resolution of depth in front of the screen than behind the screen. Our experiment implements a near-field fine-motor pick-and-place task in which users pick up a ring and place it around a targeted peg. The targets are arranged in a linear configuration of 3, 5, and 7 pegs along the front-and-back axis with the center peg placed in the same depth as the screen. We use this to evaluate how users manipulate objects in positive versus negative screen parallax space by the metrics of efficiency, accuracy, and economy of movement. In addition, we evaluate how users’ performance is moderated by haptic feedback and mismatch between visual and proprioceptive information. Our results reveal that users perform more efficiently in negative screen parallax space and that haptic feedback and visuo-proprioceptive mismatch have effects on placement efficiency. The implications of these findings are described in the later sections of the article.},
journal = {ACM Trans. Appl. Percept.},
month = {oct},
articleno = {20},
numpages = {16},
keywords = {Screen parallax, near-field VR, perception-action, haptics, stereoscopy, voxalization, VR}
}

@inproceedings{10.1145/3568294.3580081,
author = {Wozniak, Maciej K. and Stower, Rebecca and Jensfelt, Patric and Pereira, Andre},
title = {What You See Is (not) What You Get: A VR Framework for Correcting Robot Errors},
year = {2023},
isbn = {9781450399708},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568294.3580081},
doi = {10.1145/3568294.3580081},
abstract = {Many solutions tailored for intuitive visualization or teleoperation of virtual, augmented and mixed (VAM) reality systems are not robust to robot failures, such as the inability to detect and recognize objects in the environment or planning unsafe trajectories. In this paper, we present a novel virtual reality (VR) framework where users can (i) recognize when the robot has failed to detect a real- world object, (ii) correct the error in VR, (iii) modify proposed object trajectories and, (iv) implement behaviors on a real-world robot. Finally, we propose a user study aimed at testing the efficacy of our framework. Project materials can be found in the OSF repository.},
booktitle = {Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {243–247},
numpages = {5},
keywords = {ar, human-robot interaction, perception, robotics, vr},
location = {<conf-loc>, <city>Stockholm</city>, <country>Sweden</country>, </conf-loc>},
series = {HRI '23}
}

@inproceedings{10.1145/965400.965533,
author = {Carroll, Joshua J and Coover, Robert and Greenlee, Shawn and McClain, Andrew and Wardrip-Fruin, Noah},
title = {Screen: bodily interaction with text in immersive VR},
year = {2003},
isbn = {9781450374668},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/965400.965533},
doi = {10.1145/965400.965533},
abstract = {Bodily interaction with text creates new reading experiences by involving the body of the reader. This has been explored in video installation art, but without immersive 3D. Using a virtual reality environment (the Brown University Cave) we are able to make the bodily experience more direct. In our initial piece, Screen, the reader produces three different textual experiences from the same body of text, two of which differ significantly based on how her body is employed to "play" the piece.},
booktitle = {ACM SIGGRAPH 2003 Sketches \&amp; Applications},
pages = {1},
numpages = {1},
location = {San Diego, California},
series = {SIGGRAPH '03}
}

@inproceedings{10.1145/3205851.3205857,
author = {Seo, Kyoungwon and Ryu, Hokyoung},
title = {Nothing is More Revealing than Body Movement: Measuring the Movement Kinematics in VR to Screen Dementia},
year = {2018},
isbn = {9781450356411},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205851.3205857},
doi = {10.1145/3205851.3205857},
abstract = {The inability to complete instrumental activities of daily living (IADL) is the early signs of dementia. Questionnaire-based assessments of IADL are easy to use but prone to subjective bias. Here, we describe a novel virtual reality (VR) test to assess two complex IADL tasks: handling financial transactions and using public transportation. While a subject performs the tasks in a VR setting, a motion capture system traces the position and orientation of the dominant hand and head in a three-dimensional Cartesian coordinate system. Kinematic raw data are collected and converted into kinematic performance measures, i.e., motion trajectory, moving distance, speed. Inclusion of these kinematic measures significantly improved the classification of patients with early dementia.},
booktitle = {Proceedings of the Asian HCI Symposium'18 on Emerging Research Collection},
pages = {21–24},
numpages = {4},
keywords = {Kinematics, dementia, instrumental activities of daily living, movement, virtual reality},
location = {Montreal, QC, Canada},
series = {Asian HCI Symposium'18}
}

@inproceedings{10.1109/ASE.2019.00130,
author = {Li, Chi and Zhou, Min and Gu, Zuxing and Gu, Ming and Zhang, Hongyu},
title = {Ares: inferring error specifications through static analysis},
year = {2020},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00130},
doi = {10.1109/ASE.2019.00130},
abstract = {Misuse of APIs happens frequently due to misunderstanding of API semantics and lack of documentation. An important category of API-related defects is the error handling defects, which may result in security and reliability flaws. These defects can be detected with the help of static program analysis, provided that error specifications are known. The error specification of an API function indicates how the function can fail. Writing error specifications manually is time-consuming and tedious. Therefore, automatic inferring the error specification from API usage code is preferred. In this paper, we present Ares, a tool for automatic inferring error specifications for C code through static analysis. We employ multiple heuristics to identify error handling blocks and infer error specifications by analyzing the corresponding condition logic. Ares is evaluated on 19 real world projects, and the results reveal that Ares outperforms the state-of-the-art tool APEX by 37\% in precision. Ares can also identify more error specifications than APEX. Moreover, the specifications inferred from Ares help find dozens of API-related bugs in well-known projects such as OpenSSL, among them 10 bugs are confirmed by developers.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1174–1177},
numpages = {4},
keywords = {error handling, error specification, static analysis},
location = {San Diego, California},
series = {ASE '19}
}

