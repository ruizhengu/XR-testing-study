@article{P2022549,
title = {Radiomic Features Based Severity Prediction in Dementia MR Images Using Hybrid SSA-PSO Optimizer and Multi-class SVM Classifier},
journal = {IRBM},
volume = {43},
number = {6},
pages = {549-560},
year = {2022},
issn = {1959-0318},
doi = {https://doi.org/10.1016/j.irbm.2022.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S1959031822000574},
author = {Ahana. P and Kavitha. G},
keywords = {Dementia, Biomarker, Optimizer, SSA-PSO, Progression},
abstract = {Objectives: In recent times, MR image is used to detect the dementia diagnostic differences in preclinical stages. Mild cognitive impairment (MCI) is characterized by slight cognitive deficits. This can be categorized into early and late mild cognitive impairment according to extent of episodic cognitive impairment. There is a higher risk of MCI subject to convert into Alzheimers disease. It is observed that there is no appropriate biomarker to find severity changes in dementia. Thus, this work aims to identify appropriate biomarker using radiomic and hybrid social algorithms. Materials: ADNI database is utilized for this study. Grey matter, cerebrospinal fluid, ventricle, hippocampus, brain stem and mid brain regions are examined to extract the radiomic features. This provides local and global tissue changes of these regions. The significant features are obtained using hybrid salp swarm and particle swarm optimization method (SSA-PSO). SVM is adopted to classify the normal and severity groups. The performance of work is validated clinically and statistically. Results: Results show that radiomic features capture anatomical changes for considered regions. The significant features from SSA-PSO show greater causal association and statistical significance for all considered regions. However, hippocampus achieves 88.5% of classification accuracy than other regions in the considered group. The inter class variations of hippocampus gives precise prognosis differences. From the clinical validation, it is also found that the obtained result show high statistical significance (p<0.0001) among the different severity. Conclusion: The proposed work shows promising results in using these biomarkers in detection of dementia and support clinical decisions.}
}
@article{DEVI2023104177,
title = {Effect of situational and instrumental distortions on the classification of brain MR images},
journal = {Biomedical Signal Processing and Control},
volume = {79},
pages = {104177},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2022.104177},
url = {https://www.sciencedirect.com/science/article/pii/S1746809422006310},
author = {Swagatika Devi and Sambit Bakshi and Manmath Narayan Sahoo},
keywords = {Computer aided diagnosis, Convolutional neural network, Data augmentation, Out-of-focus blur, Low resolution images, Motion blur, MR image classification},
abstract = {Magnetic Resonance (MR) images of the brain play key role in exploiting pathological changes and non-invasive investigation of many neuro-degenerative diseases. Computer Aided Diagnosis (CAD) systems assist radiologists in interpreting MR images and classifying them into “normal” and “abnormal” categories. However, reduced strength of the used magnet in the machine or involuntary motions of the patients may lead to degraded MR images, which can negatively affect the performance of CAD system compromising the classification accuracy. This work aims at modeling these types of situations via out-of-focus blur, motion blur, effect of variation in resolution, and a combination of these on brain MR images for validating the impact of image quality on classification performance. To validate this, this article mathematically models the blurs (both individually and simultaneously) by varying the strength of image quality covariates and afterwards Deep Convolutional Neural Networks (DCNN) are employed to train and classify the distorted brain MR images. Besides, a single DCNN is experimented with a good mix of image quality and characteristics to test the reliability of the model for real-life scenario. The CNN models are validated through comprehensive evaluation on both original and degraded versions of brain MR images from two benchmark datasets DS-75 and DS-160 collected by Harvard Medical School as well as a self-collected dataset NITR-DHH. This study reveals that the models are able to classify distorted MR images and hence can be used for assisting the clinicians.}
}
@article{BIGNE2024108104,
title = {Furnishing your home? The impact of voice assistant avatars in virtual reality shopping: A neurophysiological study},
journal = {Computers in Human Behavior},
volume = {153},
pages = {108104},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.108104},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223004557},
author = {Enrique Bigne and Carla Ruiz and Rafael Curras-Perez},
keywords = {Virtual reality, Voice assisted avatars, Arousal, Eye-tracking, Clickstream data},
abstract = {This study provides insights into the informational cues consumers use in virtual reality (VR)-based retail shopping experiences. The aim of the study is to identify the number and type (extrinsic versus intrinsic) of informational cues that most attract consumers' visual attention, and that are most important in their purchase decision-making in a VR store, with special emphasis on the role of voice assistant (VA) avatars. A sample of 152 Spanish consumers participated in a laboratory-based 2 × 2 between-subjects experiment. The study's main stimulus was a recreation, in both 2D and VR, of a living room in a home. The participants were asked to view the recreation using either a computer screen (2D) or a head-mounted display (HMD). Clickstream data, neurophysiological measures (eye-tracking and GSR) and self-reported measures were used to test the hypotheses. We found that consumers used more informational cues in the product choice process in the 2D online store than in the VR store, but that the VR store generated higher flow state; that the type of cue used depended on the type of platform and that the presence of VA avatars did not influence the number of informational cues consumers used but made them pay more visual attention to the products, and evoked higher arousal.}
}
@article{XU2015721,
title = {The accuracy of the Oculus Rift virtual reality head-mounted display during cervical spine mobility measurement},
journal = {Journal of Biomechanics},
volume = {48},
number = {4},
pages = {721-724},
year = {2015},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2015.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0021929015000172},
author = {Xu Xu and Karen B. Chen and Jia-Hua Lin and Robert G. Radwin},
keywords = {Inertial sensors, Motion analysis, Neck range of motion},
abstract = {An inertial sensor-embedded virtual reality (VR) head-mounted display, the Oculus Rift (the Rift), monitors head movement so the content displayed can be updated accordingly. While the Rift may have potential use in cervical spine biomechanics studies, its accuracy in terms of cervical spine mobility measurement has not yet been validated. In the current study, a VR environment was designed to guide participants to perform prescribed neck movements. The cervical spine kinematics was measured by both the Rift and a reference motion tracking system. Comparison of the kinematics data between the Rift and the tracking system indicated that the Rift can provide good estimates on full range of motion (from one side to the other side) during the performed task. Because of inertial sensor drifting, the unilateral range of motion (from one side to neutral posture) derived from the Rift is more erroneous. The root-mean-square errors over a 1-min task were within 10° for each rotation axis. The error analysis further indicated that the inertial sensor drifted approximately 6° at the beginning of a trial during the initialization. This needs to be addressed when using the Rift in order to more accurately measure cervical spine kinematics. It is suggested that the front cover of the Rift should be aligned against a vertical plane during its initialization.}
}
@article{KIM2023107809,
title = {Reduced amount of contamination particle generated by CF4/Ar/O2 plasma corrosion of Y2O3 materials: Influence of defluorination process},
journal = {Materials Science in Semiconductor Processing},
volume = {167},
pages = {107809},
year = {2023},
issn = {1369-8001},
doi = {https://doi.org/10.1016/j.mssp.2023.107809},
url = {https://www.sciencedirect.com/science/article/pii/S1369800123005024},
author = {Minjoong Kim and Eunmi Choi and Jongho So and Seonjeong Maeng and Chin-Wook Chung and Song-Moon Suh and Ju-Young Yun},
keywords = {Contamination particle, Plasma corrosion, Yttrium oxide, Defluorination, Atmospheric plasma spray},
abstract = {Y2O3 coatings during atmospheric plasma spray (APS) processes are used to suppress the corrosion of internal process chamber parts for semiconductor plasma etching. Highly corrosive fluorine-based plasma corrodes the surface, causing contamination particle and process drift, which are the main causes of yield reduction. In this paper, defluorination is proposed to reduce the amount of contamination particle generation by removing the YOxFy layer on the surface of APS-Y2O3 material after plasma etching. After exposure to CF4/Ar/O2 plasma, chemical–mechanical polishing occurred using KOH, surfactant, and piranha solutions, respectively. The highest and lowest defluorination efficiencies were obtained with the piranha and surfactant solutions, respectively. The results were validated by field-emission scanning electron microscopy, energy-dispersive X-ray spectroscopy, and X-ray photoelectron spectroscopy. In particular, the piranha solution generated the lowest amount of contamination particles and lowest amount of etching. In contrast, the thickness reduction due to the defluorination process resulted in the highest breakdown voltage among the surfactant solutions, thereby prompting optimization studies. Finally, the mechanisms of the plasma etching and defluorination processes were derived, and a new method for controlling the amount of contamination particle generation was presented.}
}
@article{ABDELWAHED202425,
title = {Simulating the models of Tsikkou and Wang via mR scheme in chromatography},
journal = {Alexandria Engineering Journal},
volume = {97},
pages = {25-32},
year = {2024},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2024.03.105},
url = {https://www.sciencedirect.com/science/article/pii/S1110016824003600},
author = {Hesham G. Abdelwahed and Refaat Sabry and Mahmoud A.E. Abdelrahman and Kamel Mohamed},
keywords = {Hyperbolic conservation laws, mR technique, Nonlinear chromatography equations, Numerical simulation},
abstract = {We investigate two systems of conservation laws that explain the chemistry process of isolating a single component from a mixture using column chromatography. We design the modified Rusanov (mR) approach for solving these chromatography models. This approach is separated into two phases, the first of which is controlled by a local parameter. The conservation equation is recovered in stage two. This tactic is unambiguous, simple to use, and accurate. Through several test cases, we compare the mR scheme to the Rusanov system and the Lax-Friedrichs scheme. According to the numerical simulation, the proposed mR technique has a high resolution and provides precise simulations for the two chromatographic models with strong shocks and rarefaction. Finally, the mR approach can be utilized to solve a variety of other applicable scientific models.}
}
@article{GANDHAMAL2017110,
title = {Fully automated subchondral bone segmentation from knee MR images: Data from the Osteoarthritis Initiative},
journal = {Computers in Biology and Medicine},
volume = {88},
pages = {110-125},
year = {2017},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2017.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0010482517302329},
author = {Akash Gandhamal and Sanjay Talbar and Suhas Gajre and Ruslan Razak and Ahmad Fadzil M. Hani and Dileep Kumar},
keywords = {Subchondral bone segmentation, Magnetic resonance imaging, Gray-level S-curve transformation, 3D multi-edge overlapping, Boundary correction, Boundary displacement},
abstract = {Knee osteoarthritis (OA) progression can be monitored by measuring changes in the subchondral bone structure such as area and shape from MR images as an imaging biomarker. However, measurements of these minute changes are highly dependent on the accurate segmentation of bone tissue from MR images and it is challenging task due to the complex tissue structure and inadequate image contrast/brightness. In this paper, a fully automated method for segmenting subchondral bone from knee MR images is proposed. Here, the contrast of knee MR images is enhanced using a gray-level S-curve transformation followed by automatic seed point detection using a three-dimensional multi-edge overlapping technique. Successively, bone regions are initially extracted using distance-regularized level-set evolution followed by identification and correction of leakages along the bone boundary regions using a boundary displacement technique. The performance of the developed technique is evaluated against ground truths by measuring sensitivity, specificity, dice similarity coefficient (DSC), average surface distance (AvgD) and root mean square surface distance (RMSD). An average sensitivity (91.14%), specificity (99.12%) and DSC (90.28%) with 95% confidence interval (CI) in the range 89.74–92.54%, 98.93–99.31% and 88.68–91.88% respectively is achieved for the femur bone segmentation in 8 datasets. For tibia bone, average sensitivity (90.69%), specificity (99.65%) and DSC (91.35%) with 95% CI in the range 88.59–92.79%, 99.50–99.80% and 88.68–91.88% respectively is achieved. AvgD and RMSD values for femur are 1.43 ± 0.23 (mm) and 2.10 ± 0.35 (mm) respectively while for tibia, the values are 0.95 ± 0.28 (mm) and 1.30 ± 0.42 (mm) respectively that demonstrates acceptable error between proposed method and ground truths. In conclusion, results obtained in this work demonstrate substantially significant performance with consistency and robustness that led the proposed method to be applicable for large scale and longitudinal knee OA studies in clinical settings.}
}
@article{FAKHRY2024117131,
title = {Smart optimized structural control of onshore wind turbines with MR dampers},
journal = {Engineering Structures},
volume = {299},
pages = {117131},
year = {2024},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2023.117131},
url = {https://www.sciencedirect.com/science/article/pii/S0141029623015468},
author = {Peter Fakhry and Duan Fang and Mohammad Osman Tokhi and Shady Salem},
keywords = {Wind turbine, Magnetorheological dampers, Particle swarm optimization, Edgewise displacement},
abstract = {This paper presents an effective control approach for structural vibration of onshore wind turbines in the edgewise direction. Huge multi mega-watt wind turbines are currently developed to harvest large amounts of energy from the wind. Such designs require the construction of huge slender blades and towers which consequently lead to undesirable structural deformations that hinder the power production and reduce life span of the wind turbine. Many researchers have worked on structural control of wind turbines. However, these efforts neither have resulted in an effective reliable mitigation for deformation of structural elements, nor they have achieved an economical solution in terms of actuators exploitation. The work presented in this paper, however, introduces a particle swarm optimisation-based semi-active controller which exploits magnetorheological dampers to mitigate edgewise blade displacements. Dampers are modelled using neural networks for they are capable of predicting future forces and eliminating control lag. The developed controller is tested at several configurations of actuators placement on a benchmark 5-MW wind turbine. The proposed approach, indeed, showed a significant reduction of over 80% in the peak responses and about 77% of peak-to-peak response of blades against uncontrolled and passive systems which leads to promoting longevity of wind turbines.}
}
@article{LI2022103174,
title = {Myocardial Pathology Segmentation of Multi-modal Cardiac MR Images with a Simple but Efficient Siamese U-shaped Network},
journal = {Biomedical Signal Processing and Control},
volume = {71},
pages = {103174},
year = {2022},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.103174},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421007710},
author = {Weisheng Li and Linhong Wang and Feiyan Li and Sheng Qin and Bin Xiao},
keywords = {Cardiac segmentation, Myocardial pathology segmentation, Multi-modal images},
abstract = {Segmentation of multi-modal myocardial pathology images is a challenging task, due to factors such as the heterogeneity caused by large inter-modality and intra-modality intensity variations in multi-modal images, and the diversity of location, shape, and scale of lesion regions. Existing methods based on multi-modal segmentation cannot effectively integrate and utilize complementary information between multiple modalities, leading to the difficulty in segmenting edema and discontinuous scars. In this paper, we propose a simple but efficient U-shaped network, named Siamese U-Net, to solve these problems. There are two aspects to our method. First, we adopt a multi-modal complementary information exploration network (MCIE-Net) to explore the correlations across multi-modal images and simultaneously segment cardiac structures and myocardial pathology. This method is able to fully leverage complementary information between different modalities. Second, to obtain accurate and continuous segmentation of edema and scars, we use a lesion refinement network (LR-Net) with the same architecture as the MCIE-Net, which extracts lesion features to enhance the fusion of lesion information. We conducted extensive experiments on the MyoPS 2020 and MS-CMRSeg 2019 datasets to demonstrate the effectiveness of our proposed approach. We obtained an average Dice score of 0.734 ± 0.088 for the myocardial edema + scars on the MyoPS 2020 test set, a result which outperformed the state-of-the-art method. These results are a 0.9% improvement over the segmentation results of our previous work, and exceed the results of the winner of the MyoPS 2020 challenge by 0.3%.}
}
@article{VINAYKUMAR2023104415,
title = {Deep belief network Assisted quadratic logit boost classifier for brain tumor detection using MR images},
journal = {Biomedical Signal Processing and Control},
volume = {81},
pages = {104415},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2022.104415},
url = {https://www.sciencedirect.com/science/article/pii/S1746809422008692},
author = {V. {Vinay Kumar} and P. {Grace Kanmani Prince}},
keywords = {Deep Belief Network, Logit Boost, MRI Image, Brain tumor detection, Extracted features and Likelihood measure},
abstract = {Classification is the main work while detecting the brain tumor images. Prior researchers planned to determine the brain tumors via various classification approaches. But, the error rate and detection time of tumor are high. Therefore, brain tumor detection is improved via classification using the Deep Belief Network Assisted Quadratic Logit BoostClassifier (DBNQLBC) technique. The proposed DBNQLBC technique is employed for increasing the accuracy with lesser error and time using classifying the brain images. The features from the input brain MRI images are taken as input in the DBNQLBC technique to carry out the brain tumor detection. DBNQLBC technique comprises the different types of layers namely input layer, hidden layers, and output layer. From the brain MRI images, the input layer gets the features and it is sent to the hidden layer. In the hidden layer, a quadratic logit boostclassifier is applied to classify the extracted features. Boosting classifier uses the quadratic classifier as a sub-classifier to detect the brain tumor through the likelihood measure. The results of sub-classifiers are merged and create a robust one through diminishing logit loss. The Boosting classifier determines the best classification results that provide higher accuracy results. As a result, input MRI images are accurately categorized into normal and abnormal and the outcomes are displayed at the output layer. From this, brain tumor detection is achieved with lower error, time and higher accuracy. Simulation evaluation is carried out using the metrics such as brain tumor detection accuracy, brain tumor detection time, and false-positive rate based on the number of MRI images. The obtained outcomes ensure the presented DBNQLBC technique effectively increases the brain tumor detection accuracy and reduces the time requirement and false-positive rate than the other methods.}
}
@article{LAI202069,
title = {Smart augmented reality instructional system for mechanical assembly towards worker-centered intelligent manufacturing},
journal = {Journal of Manufacturing Systems},
volume = {55},
pages = {69-81},
year = {2020},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520300303},
author = {Ze-Hao Lai and Wenjin Tao and Ming C. Leu and Zhaozheng Yin},
keywords = {Intellegent manufacturing, Augmented reality, Deep learning, Object detection, Region-based Convolutional Neural Networks (R-CNN), Mechanical assembly},
abstract = {Quality and efficiency are crucial indicators of any manufacturing company. Many companies are suffering from a shortage of experienced workers across the production line to perform complex assembly tasks. To reduce time and error in an assembly task, a worker-centered system consisting of multi-modal Augmented Reality (AR) instructions with the support of a deep learning network for tool detection is introduced. The integrated AR is designed to provide on-site instructions including various visual renderings with a fine-tuned Region-based Convolutional Neural Network, which is trained on a synthetic tool dataset. The dataset is generated using CAD models of tools and displayed onto a 2D scene without using real tool images. By experimenting the system to a mechanical assembly of a CNC carving machine, the result of a designed experiment shows that the system helps reduce the time and errors of the given assembly tasks by 33.2 % and 32.4 %, respectively. With the integrated system, an efficient, customizable smart AR instruction system capable of sensing, characterizing requirements, and enhancing worker’s performance has been built and demonstrated.}
}
@article{CHO2014258,
title = {Development of virtual reality proprioceptive rehabilitation system for stroke patients},
journal = {Computer Methods and Programs in Biomedicine},
volume = {113},
number = {1},
pages = {258-265},
year = {2014},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2013.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0169260713003052},
author = {Sangwoo Cho and Jeonghun Ku and Yun Kyung Cho and In Young Kim and Youn Joo Kang and Dong Pyo Jang and Sun I. Kim},
keywords = {Proprioception feedback, Computer based rehabilitation, Virtual Reality, Stroke, upper-extremity limb},
abstract = {In this study, the virtual reality (VR) proprioception rehabilitation system was developed for stroke patients to use proprioception feedback in upper limb rehabilitation by blocking visual feedback. To evaluate its therapeutic effect, 10 stroke patients (onset>3 month) trained proprioception feedback rehabilitation for one week and visual feedback rehabilitation for another week in random order. Proprioception functions were checked before, a week after, and at the end of training. The results show the click count, error distance and total error distance among proprioception evaluation factors were significantly reduced after proprioception feedback training compared to visual feedback training (respectively, p=0.005, p=0.001, and p=0.007). In addition, subjects were significantly improved in conventional behavioral tests after training. In conclusion, we showed the effectiveness and possible use of the VR to recover the proprioception of stroke patients.}
}
@article{FENG2020101118,
title = {An immersive virtual reality serious game to enhance earthquake behavioral responses and post-earthquake evacuation preparedness in buildings},
journal = {Advanced Engineering Informatics},
volume = {45},
pages = {101118},
year = {2020},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2020.101118},
url = {https://www.sciencedirect.com/science/article/pii/S1474034620300872},
author = {Zhenan Feng and Vicente A. González and Robert Amor and Michael Spearpoint and Jared Thomas and Rafael Sacks and Ruggiero Lovreglio and Guillermo Cabrera-Guerrero},
keywords = {Immersive virtual reality, Serious games, Earthquake emergencies, Evacuation training},
abstract = {Enhancing the earthquake behavioral responses and post-earthquake evacuation preparedness of building occupants is beneficial to increasing their chances of survival and reducing casualties after the mainshock of an earthquake. Traditionally, training approaches such as seminars, posters, videos or drills are applied to enhance preparedness. However, they are not highly engaging and have limited sensory capabilities to mimic life-threatening scenarios for the purpose of training potential participants. Immersive Virtual Reality (IVR) and Serious Games (SG) as innovative digital technologies can be used to create training tools to overcome these limitations. In this study, we propose an IVR SG-based training system to improve earthquake behavioral responses and post-earthquake evacuation preparedness. Auckland City Hospital was chosen as a case study to test our IVR SG training system. A set of training objectives based on best evacuation practice has been identified and embedded into several training scenarios of the IVR SG. Hospital staff (healthcare and administrative professionals) and visitors were recruited as participants to be exposed to these training scenarios. Participants’ preparedness has been measured along two dimensions: 1) Knowledge about best evacuation practice; 2) Self-efficacy in dealing with earthquake emergencies. Assessment results showed that there was a significant knowledge and self-efficacy increase after the training. In addition, participants acknowledged that it was easy, helpful, and engaging to learn best evacuation practice knowledge through the IVR SG training system.}
}
@article{GU2023107571,
title = {Cross-modality image translation: CT image synthesis of MR brain images using multi generative network with perceptual supervision},
journal = {Computer Methods and Programs in Biomedicine},
volume = {237},
pages = {107571},
year = {2023},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2023.107571},
url = {https://www.sciencedirect.com/science/article/pii/S0169260723002365},
author = {Xianfan Gu and Yu Zhang and Wen Zeng and Sihua Zhong and Haining Wang and Dong Liang and Zhenlin Li and Zhanli Hu},
keywords = {Computed tomography (CT), Magnetic resonance imaging (MRI), Radiotherapy, MR-To-CT synthesis, Cross-modality, Cycle-consistency},
abstract = {Background: Computed tomography (CT) and magnetic resonance imaging (MRI) are the mainstream imaging technologies for clinical practice. CT imaging can reveal high-quality anatomical and physiopathological structures, especially bone tissue, for clinical diagnosis. MRI provides high resolution in soft tissue and is sensitive to lesions. CT combined with MRI diagnosis has become a regular image-guided radiation treatment plan. Methods: In this paper, to reduce the dose of radiation exposure in CT examinations and ameliorate the limitations of traditional virtual imaging technologies, we propose a Generative MRI-to-CT transformation method with structural perceptual supervision. Even though structural reconstruction is structurally misaligned in the MRI-CT dataset registration, our proposed method can better align structural information of synthetic CT (sCT) images to input MRI images while simulating the modality of CT in the MRI-to-CT cross-modality transformation. Results: We retrieved a total of 3416 brain MRI-CT paired images as the train/test dataset, including 1366 train images of 10 patients and 2050 test images of 15 patients. Several methods (the baseline methods and the proposed method) were evaluated by the HU difference map, HU distribution, and various similarity metrics, including the mean absolute error (MAE), structural similarity index (SSIM), peak signal-to-noise ratio (PSNR), and normalized cross-correlation (NCC). In our quantitative experimental results, the proposed method achieves the lowest MAE mean of 0.147, highest PSNR mean of 19.27, and NCC mean of 0.431 in the overall CT test dataset. Conclusions: In conclusion, both qualitative and quantitative results of synthetic CT validate that the proposed method can preserve higher similarity of structural information of the bone tissue of target CT than the baseline methods. Furthermore, the proposed method provides better HU intensity reconstruction for simulating the distribution of the CT modality. The experimental estimation indicates that the proposed method is worth further investigation.}
}
@article{DUQUETTE2012294,
title = {3D segmentation of abdominal aorta from CT-scan and MR images},
journal = {Computerized Medical Imaging and Graphics},
volume = {36},
number = {4},
pages = {294-303},
year = {2012},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2011.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0895611111001480},
author = {Anthony Adam Duquette and Pierre-Marc Jodoin and Olivier Bouchot and Alain Lalande},
keywords = {AAA segmentation, MRI, CT scan, Graph cut, Volume segmentation},
abstract = {We designed a generic method for segmenting the aneurismal sac of an abdominal aortic aneurysm (AAA) both from multi-slice MR and CT-scan examinations. It is a semi-automatic method requiring little human intervention and based on graph cut theory to segment the lumen interface and the aortic wall of AAAs. Our segmentation method works independently on MRI and CT-scan volumes and has been tested on a 44 patient dataset and 10 synthetic images. Segmentation and maximum diameter estimation were compared to manual tracing from 4 experts. An inter-observer study was performed in order to measure the variability range of a human observer. Based on three metrics (the maximum aortic diameter, the volume overlap and the Hausdorff distance) the variability of the results obtained by our method is shown to be similar to that of a human operator, both for the lumen interface and the aortic wall. As will be shown, the average distance obtained with our method is less than one standard deviation away from each expert, both for healthy subjects and for patients with AAA. Our semi-automatic method provides reliable contours of the abdominal aorta from CT-scan or MRI, allowing rapid and reproducible evaluations of AAA.}
}
@article{BENBELKACEM2013428,
title = {Augmented reality for photovoltaic pumping systems maintenance tasks},
journal = {Renewable Energy},
volume = {55},
pages = {428-437},
year = {2013},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2012.12.043},
url = {https://www.sciencedirect.com/science/article/pii/S0960148113000050},
author = {Samir Benbelkacem and Mahmoud Belhocine and Abdelkader Bellarbi and Nadia Zenati-Henda and Mohamed Tadjine},
keywords = {Augmented reality, Photovoltaic pumping system, Maintenance task, Tracking, User interface},
abstract = {In order to stabilize water supply for remote regions and deserts, it is not only necessary to improve the power generation system, but also to improve its maintenance strategy. Photovoltaic pumping systems need to be maintained periodically. Both maintenance efficiency improvement and reduction of its cost are desired. Augmented Reality (AR) is one of the promising technologies that will be able to improve efficiency in maintenance and reduce human errors. AR expands the surrounding real world by superimposing computer-generated information on a user’s view. It presents the information more intuitively than the legacy interfaces such as paper-based instruction documents. In this paper, an augmented reality platform for photovoltaic pumping system maintenance tasks is proposed. In order to locate the repairer in the working environment and then to overlay the virtual objects, a tracking method is developed. A scenario which takes a user by the hand through maintenance tasks is described. Experiments are conducted in order to evaluate the accuracy and reliability of the proposed tracking method.}
}
@article{LIU2021923,
title = {Gas metal arc welding of high nitrogen stainless steel with Ar–N2-O2 ternary shielding gas},
journal = {Defence Technology},
volume = {17},
number = {3},
pages = {923-931},
year = {2021},
issn = {2214-9147},
doi = {https://doi.org/10.1016/j.dt.2020.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S2214914720303512},
author = {Zeng Liu and Cheng-lei Fan and Zhu Ming and Chao Chen and Ang Liu and Chun-li Yang and San-bao Lin and Lang-ping Wang},
keywords = {High nitrogen stainless steel, Ar–N-O shielding gas, Action mechanism},
abstract = {High nitrogen stainless steel with nitrogen content of 0.75% was welded by gas metal arc welding with Ar–N2-O2 ternary shielding gas. The effect of the ternary shielding gas on the retention and improvement of nitrogen content in the weld was identified. Surfacing test was conducted first to compare the ability of O2 and CO2 in prompting nitrogen dissolution. The nitrogen content of the surfacing metal with O2 is slightly higher than CO2. And then Ar–N2-O2 shielding gas was applied to weld high nitrogen stainless steel. After using N2-containing shielding gas, the nitrogen content of the weld was improved by 0.1 wt%. As N2 continued to increase, the increment of nitrogen content was not obvious, but the ferrite decreased from the top to the bottom. When the proportion of N2 reached 20%, a full austenitic weld was obtained and the tensile strength was improved by 8.7%. Combined with the results of surfacing test and welding test, it is concluded that the main effect of N2 is to inhibit the escape of nitrogen and suppress the nitrogen diffusion from bottom to the top in the molten pool.}
}
@article{COOKSON20141200,
title = {A spatially-distributed computational model to quantify behaviour of contrast agents in MR perfusion imaging},
journal = {Medical Image Analysis},
volume = {18},
number = {7},
pages = {1200-1216},
year = {2014},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2014.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1361841514001091},
author = {A.N. Cookson and J. Lee and C. Michler and R. Chabiniok and E. Hyde and D. Nordsletten and N.P. Smith},
keywords = {Magnetic resonance imaging, Myocardial perfusion, Contrast agent, Finite element method, Idealised modelling},
abstract = {Contrast agent enhanced magnetic resonance (MR) perfusion imaging provides an early, non-invasive indication of defects in the coronary circulation. However, the large variation of contrast agent properties, physiological state and imaging protocols means that optimisation of image acquisition is difficult to achieve. This situation motivates the development of a computational framework that, in turn, enables the efficient mapping of this parameter space to provide valuable information for optimisation of perfusion imaging in the clinical context. For this purpose a single-compartment porous medium model of capillary blood flow is developed which is coupled with a scalar transport model, to characterise the behaviour of both blood-pool and freely-diffusive contrast agents characterised by their ability to diffuse through the capillary wall into the extra-cellular space. A parameter space study is performed on the nondimensionalised equations using a 2D model for both healthy and diseased myocardium, examining the sensitivity of system behaviour to Peclet number, Damköhler number (Da), diffusivity ratio and fluid porosity. Assuming a linear MR signal response model, sample concentration time series data are calculated, and the sensitivity of clinically-relevant properties of these signals to the model parameters is quantified. Both upslope and peak values display significant non-monotonic behaviour with regard to the Damköhler number, with these properties showing a high degree of sensitivity in the parameter range relevant to contrast agents currently in use. However, the results suggest that signal upslope is the more robust and discerning metric for perfusion quantification, in particular for correlating with perfusion defect size. Finally, the results were examined in the context of nonlinear signal response, flow quantification via Fermi deconvolution and perfusion reserve index, which demonstrated that there is no single best set of contrast agent parameters, instead the contrast agents should be tailored to the specific imaging protocol and post-processing method to be used.}
}
@article{XIE2013420,
title = {Spectral analysis of Ar plasma-arc under different experimental parameters},
journal = {Optik},
volume = {124},
number = {5},
pages = {420-424},
year = {2013},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2011.12.051},
url = {https://www.sciencedirect.com/science/article/pii/S0030402612000617},
author = {Weicheng Xie and Wenbo Jiang and Yiqing Gao},
keywords = {Plasma-arc, Emission spectral diagnosis technique, Electron excitated temperature, Influence factor analysis},
abstract = {Electron excitated temperature is one of the most important parameters of Ar plasma-arc. Emission spectrum diagnosis technique has been widely used in the research of electron temperature for its easy operation and small disturbance, where the spectral analysis is the focused content. However, there is still no report about spectral analysis of Ar plasma-arc under different experimental parameters. In this paper, we use the fiber spectrograph for collecting the spectral distribution of the Ar plasma-arc. Then we change the experimental parameters, analyze the influences of the electric current and air current on the spectral distribution. The results show that all these experimental parameters have great influence on the characteristics of spectrum such as spectral line intensity, background signal, etc. It is found that electric current below 100A, air current below 10A/min are good for spectral analysis, while two different wavelengths of 696.5nm and 763.5nm are suitable for temperature field testing and analyzing. This research provides a good foundation for density field, pressure field and velocity field testing and analyzing, it is also beneficial for us to understand the inner mechanism of Ar plasma-arc.}
}
@article{HAM201315,
title = {EPAR: Energy Performance Augmented Reality models for identification of building energy performance deviations between actual measurements and simulation results},
journal = {Energy and Buildings},
volume = {63},
pages = {15-28},
year = {2013},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2013.02.054},
url = {https://www.sciencedirect.com/science/article/pii/S0378778813001485},
author = {Youngjib Ham and Mani Golparvar-Fard},
keywords = {Thermogaphy, Image-based 3D reconstruction, Computational fluid dynamics (CFD), Energy audits},
abstract = {Building energy performance simulation tools such as EnergyPlus, Ecotect, and eQuest are widely used to model energy performance of existing buildings and assess retrofit alternatives. Nevertheless, predictions from simulations typically deviate from actual measurements. Monitoring actual performance and measuring deviations from simulated data in 3D can help improve simulation accuracy through model calibrations, and in turn facilitate identification of energy performance problem. To do that, this paper presents Energy Performance Augmented Reality (EPAR) modeling that leverages collections of unordered digital and thermal imagery, in addition to computational fluid dynamics (CFD) models. First, users collect large numbers of digital and thermal imagery from the building under inspection using a single thermal camera. Through an image-based reconstruction pipeline, actual 3D spatio-thermal models are automatically generated and are superimposed with expected building energy performance models generated using CFD analysis through a user-driven process. The outcomes are EPAR models which visualize actual and expected models in a common 3D environment. Within the EPAR models, actual measurements and simulated results can be systematically compared and analyzed. The method is validated on typical residential and instructional buildings. The results demonstrate that EPAR models facilitate calibration of building energy performance models and support detection and analysis of building performance deviations.}
}
@article{HU2024104139,
title = {Surgical treatment of small recurrent gliomas based on MR imaging examination},
journal = {Medical Engineering & Physics},
volume = {126},
pages = {104139},
year = {2024},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2024.104139},
url = {https://www.sciencedirect.com/science/article/pii/S1350453324000407},
author = {Shukun Hu and Liqian Xie and Yi Zhang},
keywords = {MR, Imaging examination, Microrecurrent glioma, Surgical treatment},
abstract = {Microrecurrent glioma is a common neurological tumor, and the key to its surgical treatment is to accurately evaluate the size, location and degree of recurrence of the lesion. The purpose of this study was to explore the surgical treatment of microrecurrent glioma based on MR Imaging, and to provide accurate and reliable basis for clinical decision-making. Before surgery, detailed MR Imaging tests were performed for each patient to accurately locate and evaluate the characteristics of the lesions. Multimodal imaging examination were arranged to accurate the pre-operation diagnosis. Neuro-navigation is necessary for the operation design and tumor confirmation. Function monitor and intraoperation MR were prepared when necessary.Mini was defined by the size, location and symptoms. In all 5 cases requiring reoperation, total resection was achieved. No systemic and local complications occurred. No permeant neurological dysfunction remained. The average stay time after the operation is days. All patients survived in the recent follow-up. Reoperation of mini recurrent glioma is a good treatment choice. We made little injury to patients, which wouldn't affect their conditions and next therapies. Through MR Imaging, the diagnosis and location of microrecurrent glioma, as well as the relationship with surrounding tissues and the degree of infiltration, provide important information for surgeons to evaluate the resectable lesion. By combining MR And functional imaging results, the blood supply and functional area of the lesion can be monitored in real time during surgery, thereby reducing surgical risk and maximizing the protection of surrounding healthy tissue.}
}
@article{MITTAL2019346,
title = {Deep learning based enhanced tumor segmentation approach for MR brain images},
journal = {Applied Soft Computing},
volume = {78},
pages = {346-354},
year = {2019},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2019.02.036},
url = {https://www.sciencedirect.com/science/article/pii/S1568494619301000},
author = {Mamta Mittal and Lalit Mohan Goyal and Sumit Kaur and Iqbaldeep Kaur and Amit Verma and D. {Jude Hemanth}},
keywords = {Brain tumor MRI, Growing Convolution Neural Network (GCNN), Segmentation, Random forest, Stationary Wavelet Transform (SWT)},
abstract = {Automation in medical industry has become one of the necessities in today’s medical scenario. Radiologists/physicians need such automation techniques for accurate diagnosis and treatment planning. Automatic segmentation of tumor portion from Magnetic Resonance (MR) brain images is a challenging task. Several methodologies have been developed with an objective to enhance the segmentation efficiency of the automated system. However, there is always scope for improvement in the segmentation process of medical image analysis. In this work, deep learning-based approach is proposed for brain tumor image segmentation. The proposed method includes the concept of Stationary Wavelet Transform (SWT) and new Growing Convolution Neural Network (GCNN). The significant objective of this work is to enhance the accuracy of the conventional system. A comparative analysis with Support Vector Machine (SVM) and Convolution Neural Network (CNN) is carried out in this work. The experimental results prove that the proposed technique has outperformed SVM and CNN in terms of accuracy, PSNR, MSE and other performance parameters.}
}
@article{ROSADOTORO201715,
title = {Segmentation of the right ventricle in four chamber cine cardiac MR images using polar dynamic programming},
journal = {Computerized Medical Imaging and Graphics},
volume = {62},
pages = {15-25},
year = {2017},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2017.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0895611117300721},
author = {Jose A. Rosado-Toro and Aiden Abidov and Maria I. Altbach and Isabel B. Oliva and Jeffrey J. Rodriguez and Ryan J. Avery},
keywords = {Four chamber right ventricle segmentation, Polar variance, Polar dynamic programming},
abstract = {The four chamber plane is currently underutilized in the right ventricular segmentation community. Four chamber information can be useful to determine ventricular short axis stacks and provide a rough estimate of the right ventricle in short axis stacks. In this study, we develop and test a semi-automated technique for segmenting the right ventricle in four chamber cine cardiac magnetic resonance images. The three techniques that use minimum cost path algorithms were used. The algorithms are: Dijkstra's shortest path algorithm (Dijkstra), an A* algorithm that uses length, curvature and torsion into an active contour model (ALCT), and a variation of polar dynamic programming (PDP). The techniques are evaluated against the expert traces using 175 cardiac images from 7 patients. The evaluation first looks at mutual overlap metrics and then focuses on clinical measures such as fractional area change (FAC). The mean mutual overlap between the physician's traces ranged from 0.85 to 0.88. Using as reference physician 1′s landmarks and traces (i.e., comparing the traces from physician 1 to the semi-automated segmentation using physician 1′s landmarks), the PDP algorithm has a mean mutual overlap of 0.8970 compared to 0.8912 for ALCT and 0.8879 for Dijkstra. The mean mutual overlap between the BP regions generated by physician 1 and physician 2 landmarks are 0.9674, 0.9605 and 0.9531 for PDP, ALCT and Dijkstra, respectively. The FAC correlation coefficient between the physician's traces ranged from 0.73 to 0.93.}
}
@article{VALVERDE2017446,
title = {Automated tissue segmentation of MR brain images in the presence of white matter lesions},
journal = {Medical Image Analysis},
volume = {35},
pages = {446-457},
year = {2017},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2016.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S1361841516301621},
author = {Sergi Valverde and Arnau Oliver and Eloy Roura and Sandra González-Villà and Deborah Pareto and Joan C. Vilanova and Lluís Ramió-Torrentà and Àlex Rovira and Xavier Lladó},
keywords = {Brain, MRI, Multiple sclerosis, Automatic tissue segmentation},
abstract = {Over the last few years, the increasing interest in brain tissue volume measurements on clinical settings has led to the development of a wide number of automated tissue segmentation methods. However, white matter lesions are known to reduce the performance of automated tissue segmentation methods, which requires manual annotation of the lesions and refilling them before segmentation, which is tedious and time-consuming. Here, we propose a new, fully automated T1-w/FLAIR tissue segmentation approach designed to deal with images in the presence of WM lesions. This approach integrates a robust partial volume tissue segmentation with WM outlier rejection and filling, combining intensity and probabilistic and morphological prior maps. We evaluate the performance of this method on the MRBrainS13 tissue segmentation challenge database, which contains images with vascular WM lesions, and also on a set of Multiple Sclerosis (MS) patient images. On both databases, we validate the performance of our method with other state-of-the-art techniques. On the MRBrainS13 data, the presented approach was at the time of submission the best ranked unsupervised intensity model method of the challenge (7th position) and clearly outperformed the other unsupervised pipelines such as FAST and SPM12. On MS data, the differences in tissue segmentation between the images segmented with our method and the same images where manual expert annotations were used to refill lesions on T1-w images before segmentation were lower or similar to the best state-of-the-art pipeline incorporating automated lesion segmentation and filling. Our results show that the proposed pipeline achieved very competitive results on both vascular and MS lesions. A public version of this approach is available to download for the neuro-imaging community.}
}
@article{SHUANG2015125,
title = {Positive Safety Participation and Assessment by Integrating Sharing Technology with Virtual Reality},
journal = {Procedia Engineering},
volume = {123},
pages = {125-134},
year = {2015},
note = {Selected papers from Creative Construction Conference 2015},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2015.10.069},
url = {https://www.sciencedirect.com/science/article/pii/S1877705815031707},
author = {Dong Shuang and Yin Qin and Li Heng},
keywords = {Personal safety performance, Assessment, Knowledge sharing platform, virtual construction.},
abstract = {Traditional health and safety performance in construction is assessed based on accessible outcomes such as accidents, injuries, illnesses and diseases. This lagging measurement still exists and is used by many industries since it is preferable for data collection, understandable to the majority, objective and valid. Many researchers are starting to treat the performance assessment in a much more proactive way by taking safety climate and culture into consideration. In current practice, as an indispensable part of safety climate/culture, safety participation level is merely evaluated by passive survey questions like “Have you attended the safety training”, which ignores many invisible participation behaviors like safety knowledge transfer and sharing. What's more, although many traditional safety performance assessments are intended to modify construction workers’ safety behavior, study on personal level safety assessment is still absent. To solve the problems above, this study firstly presents a systematic safety performance assessment framework on personal level, including not only traditional lagging indicators, but also positive indicators like participation and attitude. This framework is substantiated by comprehensive literature review. Then a positive safety participation and participation assessment method is designed by integrating sharing technology with virtual reality. The feasibility of this method is tested on a real worksite.}
}
@article{ARRATIALOPEZ2023102925,
title = {WarpPINN: Cine-MR image registration with physics-informed neural networks},
journal = {Medical Image Analysis},
volume = {89},
pages = {102925},
year = {2023},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2023.102925},
url = {https://www.sciencedirect.com/science/article/pii/S1361841523001858},
author = {Pablo {Arratia López} and Hernán Mella and Sergio Uribe and Daniel E. Hurtado and Francisco {Sahli Costabal}},
keywords = {Cardiac strain, Cardiac mechanics, Image registration, Physics-informed neural networks},
abstract = {The diagnosis of heart failure usually includes a global functional assessment, such as ejection fraction measured by magnetic resonance imaging. However, these metrics have low discriminate power to distinguish different cardiomyopathies, which may not affect the global function of the heart. Quantifying local deformations in the form of cardiac strain can provide helpful information, but it remains a challenge. In this work, we introduce WarpPINN, a physics-informed neural network to perform image registration to obtain local metrics of heart deformation. We apply this method to cine magnetic resonance images to estimate the motion during the cardiac cycle. We inform our neural network of the near-incompressibility of cardiac tissue by penalizing the Jacobian of the deformation field. The loss function has two components: an intensity-based similarity term between the reference and the warped template images, and a regularizer that represents the hyperelastic behavior of the tissue. The architecture of the neural network allows us to easily compute the strain via automatic differentiation to assess cardiac activity. We use Fourier feature mappings to overcome the spectral bias of neural networks, allowing us to capture discontinuities in the strain field. The algorithm is tested on synthetic examples and on a cine SSFP MRI benchmark of 15 healthy volunteers, where it is trained to learn the deformation mapping of each case. We outperform current methodologies in landmark tracking and provide physiological strain estimations in the radial and circumferential directions. WarpPINN provides precise measurements of local cardiac deformations that can be used for a better diagnosis of heart failure and can be used for general image registration tasks. Source code is available at https://github.com/fsahli/WarpPINN.}
}
@article{KAYSER2008681,
title = {Leak Before Break procedure: Recent modification of RCC-MR A16 appendix and proposed improvements},
journal = {International Journal of Pressure Vessels and Piping},
volume = {85},
number = {10},
pages = {681-693},
year = {2008},
issn = {0308-0161},
doi = {https://doi.org/10.1016/j.ijpvp.2008.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0308016108000276},
author = {Yann Kayser and Stéphane Marie and Christophe Poussard and Christine Delaval},
keywords = {Leak Before Break, Fatigue, Crack penetration, Cracked pipe, Finite element},
abstract = {This paper presents recent modifications of the Leak Before Break procedure of the A16 appendix from French RCC-MR nuclear code and the improvements that will be proposed. The first part of the study deals with the prediction of the crack size at penetration. In the case of small initial defect the validity of the Master Curve used in the A16 appendix is confirmed for pipes. For large initial defects, a correction to the A16 procedure is proposed to take into account the effect of large initial crack length on its size at penetration. The second part of this paper focuses on the crack shape evolution after penetration, which is characterized by two stages: first straightening of the crack shape and then crack growth at both inner and outer surfaces. This typical behaviour is confirmed by numerical and experimental works for which particular loading conditions have been investigated.}
}
@article{ROLDAN2019305,
title = {A training system for Industry 4.0 operators in complex assemblies based on virtual reality and process mining},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {59},
pages = {305-316},
year = {2019},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2019.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0736584518303685},
author = {Juan Jesús Roldán and Elena Crespo and Andrés Martín-Barrio and Elena Peña-Tapia and Antonio Barrientos},
keywords = {Industry 4.0, Training system, Assemblies, Virtual reality, Process mining},
abstract = {Industry 4.0 aims at integrating machines and operators through network connections and information management. It proposes the use of a set of technologies in industry, such as data analysis, Internet of Things, cloud computing, cooperative robots, and immersive technologies. This paper presents a training system for industrial operators in assembly tasks, which takes advantage of tools such as virtual reality and process mining. First, expert workers use an immersive interface to perform assemblies according to their experience. Then, process mining algorithms are applied to obtain assembly models from event logs. Finally, trainee workers use an improved immersive interface with hints to learn the assemblies that the expert workers introduced in the system. A toy example has been developed with building blocks and tests have been performed with a set of volunteers. The results show that the proposed training system, based on process mining and virtual reality, is competitive against conventional alternatives. Furthermore, user evaluations are better in terms of mental demand, perception, learning, results, and performance.}
}
@article{TSAI2018171,
title = {Augmented reality display based on user behavior},
journal = {Computer Standards & Interfaces},
volume = {55},
pages = {171-181},
year = {2018},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2017.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0920548917300247},
author = {Chung-Hsien Tsai and Jiung-Yao Huang},
keywords = {Augmented reality, Context-aware, Behavior perception, User interface},
abstract = {The development and commercialization of smart glasses in recent years have made the exploration of one's surroundings with mobile augmented reality (MAR) browsers anytime and anywhere more practical. However, users often suffer from issues such as cognitive overload and inconvenient interactions when operating MAR browsers on smart glasses owing to the constraints of the screen resolution and size. To overcome these problems, this paper presents a user-behavior-driven augmented content display approach called iDisplay. First, user behaviors were modeled while the smart glasses were used. A user behavior perception algorithm that infers the current state of the user by crosschecking his/her past behavior and feature data extracted from the built-in sensors of the smart glasses was then developed. Five augmented content display patterns corresponding to the modeled user's behavior states were designed accordingly. To verify that iDisplay can be based upon the perceived user states to adaptively manage the smart glasses display, a prototype system was built to conduct a series of experiments. The experimental results show that iDisplay can accurately infer user states and manage augmented content display accordingly. A user study also shows that iDisplay can successfully reduce the user's cognitive load and split attention when searching for specific point-of-interest information while moving. Furthermore, all subjects claimed that iDisplay causes less dizziness during the experiments than the native overview + detail augmented reality interface.}
}
@article{ZHUANG2022102528,
title = {Cardiac segmentation on late gadolinium enhancement MRI: A benchmark study from multi-sequence cardiac MR segmentation challenge},
journal = {Medical Image Analysis},
volume = {81},
pages = {102528},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2022.102528},
url = {https://www.sciencedirect.com/science/article/pii/S136184152200175X},
author = {Xiahai Zhuang and Jiahang Xu and Xinzhe Luo and Chen Chen and Cheng Ouyang and Daniel Rueckert and Victor M. Campello and Karim Lekadir and Sulaiman Vesal and Nishant RaviKumar and Yashu Liu and Gongning Luo and Jingkun Chen and Hongwei Li and Buntheng Ly and Maxime Sermesant and Holger Roth and Wentao Zhu and Jiexiang Wang and Xinghao Ding and Xinyue Wang and Sen Yang and Lei Li},
keywords = {Multi-sequence, Cardiac MRI segmentation, Benchmark, Challenge},
abstract = {Accurate computing, analysis and modeling of the ventricles and myocardium from medical images are important, especially in the diagnosis and treatment management for patients suffering from myocardial infarction (MI). Late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) provides an important protocol to visualize MI. However, compared with the other sequences LGE CMR images with gold standard labels are particularly limited. This paper presents the selective results from the Multi-Sequence Cardiac MR (MS-CMR) Segmentation challenge, in conjunction with MICCAI 2019. The challenge offered a data set of paired MS-CMR images, including auxiliary CMR sequences as well as LGE CMR, from 45 patients who underwent cardiomyopathy. It was aimed to develop new algorithms, as well as benchmark existing ones for LGE CMR segmentation focusing on myocardial wall of the left ventricle and blood cavity of the two ventricles. In addition, the paired MS-CMR images could enable algorithms to combine the complementary information from the other sequences for the ventricle segmentation of LGE CMR. Nine representative works were selected for evaluation and comparisons, among which three methods are unsupervised domain adaptation (UDA) methods and the other six are supervised. The results showed that the average performance of the nine methods was comparable to the inter-observer variations. Particularly, the top-ranking algorithms from both the supervised and UDA methods could generate reliable and robust segmentation results. The success of these methods was mainly attributed to the inclusion of the auxiliary sequences from the MS-CMR images, which provide important label information for the training of deep neural networks. The challenge continues as an ongoing resource, and the gold standard segmentation as well as the MS-CMR images of both the training and test data are available upon registration via its homepage (www.sdspeople.fudan.edu.cn/zhuangxiahai/0/mscmrseg/).}
}
@article{LAI200097,
title = {A hierarchical neural network algorithm for robust and automatic windowing of MR images},
journal = {Artificial Intelligence in Medicine},
volume = {19},
number = {2},
pages = {97-119},
year = {2000},
note = {Medical Imaging},
issn = {0933-3657},
doi = {https://doi.org/10.1016/S0933-3657(00)00041-5},
url = {https://www.sciencedirect.com/science/article/pii/S0933365700000415},
author = {Shang-Hong Lai and Ming Fang},
keywords = {Medical image display, Human perception, Display parameter estimation, Hierarchical neural networks, Radial basis function, Intelligent fusion},
abstract = {A novel hierarchical neural network based algorithm for automatic adjustment of display window width and center for a wide range of magnetic resonance (MR) images is presented in this paper. The algorithm consists of a feature generator utilizing both wavelet histogram and compact spatial statistical information computed from a MR image, a competitive layer based neural network for clustering MR images into different subclasses, two pairs of a radial basis function (RBF) network and a bi-modal linear estimator for each subclass, as well as a data fusion process using estimates from both estimators to compute the final display parameters. Both estimators can adapt to new kinds of MR images simply by training them with those images, which make the algorithm adaptive and extendable. The RBF based estimator performs very well for images that are similar to those in the training data set. The bi-modal linear estimator provides reasonable estimations for a wide range of images that may not be included in the training data set. The data fusion step makes the final estimation of the display parameters accurate for trained images and robust for the unknown images. The algorithm has been tested on a wide range of MR images and has shown satisfactory results.}
}
@article{LINKA2017477,
title = {T2 MR imaging vs. computational modeling of human articular cartilage tissue functionality},
journal = {Journal of the Mechanical Behavior of Biomedical Materials},
volume = {74},
pages = {477-487},
year = {2017},
issn = {1751-6161},
doi = {https://doi.org/10.1016/j.jmbbm.2017.07.023},
url = {https://www.sciencedirect.com/science/article/pii/S1751616117303090},
author = {Kevin Linka and Mikhail Itskov and Daniel Truhn and Sven Nebelung and Johannes Thüring},
keywords = {Cartilage, MRI, Functional assessment, Loading device, Osteoarthritis, Constitutive modeling},
abstract = {The detection of early stages of cartilage degeneration remains diagnostically challenging. One promising non-invasive approach is to functionally assess the tissue response to loading by serial magnetic resonance (MR) imaging in terms of T2 mapping under simultaneous mechanical loading. As yet, however, it is not clear which cartilage component contributes to the tissue functionality as assessed by quantitative T2 mapping. To this end, quantitative T2 maps of histologically intact cartilage samples (n=8) were generated using a clinical 3.0-T MR imaging system. Using displacement-controlled quasi-static indentation loading, serial T2 mapping was performed at three defined strain levels and loading-induced relative changes were determined in distinct regions-of-interest. Samples underwent conventional biomechanical testing (by unconfined compression) as well as histological assessment (by Mankin scoring) for reference purposes. Moreover, an anisotropic hyperelastic constitutive model of cartilage was implemented into a finite element (FE) code for cross-referencing. In efforts to simulate the evolution of compositional and structural intra-tissue changes under quasi-static loading, the indentation-induced changes in quantitative T2 maps were referenced to underlying changes in cartilage composition and structure. These changes were parameterized as cartilage fluid, proteoglycan and collagen content as well as collagen orientation. On a pixel-wise basis, each individual component correlation with T2 relaxation times was determined by Spearman's ρs and significant correlations were found between T2 relaxation times and all four tissue parameters for all indentation strain levels. Thus, the biological changes in functional MR Imaging parameters such as T2 can further be characterized to strengthen the scientific basis of functional MRI techniques with regards to their perspective clinical applications.}
}
@article{KAPLAN2023103971,
title = {ExHiF: Alzheimer's disease detection using exemplar histogram-based features with CT and MR images},
journal = {Medical Engineering & Physics},
volume = {115},
pages = {103971},
year = {2023},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2023.103971},
url = {https://www.sciencedirect.com/science/article/pii/S1350453323000231},
author = {Ela Kaplan and Mehmet Baygin and Prabal D. Barua and Sengul Dogan and Turker Tuncer and Erman Altunisik and Elizabeth Emma Palmer and U. Rajendra Acharya},
keywords = {ExHiF, Handcrafted feature, LBP, HOG, LPQ, Alzheimer's disease detection},
abstract = {Purpose
The classification of medical images is an important priority for clinical research and helps to improve the diagnosis of various disorders. This work aims to classify the neuroradiological features of patients with Alzheimer's disease (AD) using an automatic hand-modeled method with high accuracy.
Materials and method
This work uses two (private and public) datasets. The private dataset consists of 3807 magnetic resonance imaging (MRI) and computer tomography (CT) images belonging to two (normal and AD) classes. The second public (Kaggle AD) dataset contains 6400 MR images. The presented classification model comprises three fundamental phases: feature extraction using an exemplar hybrid feature extractor, neighborhood component analysis-based feature selection, and classification utilizing eight different classifiers. The novelty of this model is feature extraction. Vision transformers inspire this phase, and hence 16 exemplars are generated. Histogram-oriented gradients (HOG), local binary pattern (LBP) and local phase quantization (LPQ) feature extraction functions have been applied to each exemplar/patch and raw brain image. Finally, the created features are merged, and the best features are selected using neighborhood component analysis (NCA). These features are fed to eight classifiers to obtain highest classification performance using our proposed method. The presented image classification model uses exemplar histogram-based features; hence, it is called ExHiF.
Results
We have developed the ExHiF model with a ten-fold cross-validation strategy using two (private and public) datasets with shallow classifiers. We have obtained 100% classification accuracy using cubic support vector machine (CSVM) and fine k nearest neighbor (FkNN) classifiers for both datasets.
Conclusions
Our developed model is ready to be validated with more datasets and has the potential to be employed in mental hospitals to assist neurologists in confirming their manual screening of AD using MRI/CT images.}
}
@article{JABBARPOUR2022105277,
title = {Unsupervised pseudo CT generation using heterogenous multicentric CT/MR images and CycleGAN: Dosimetric assessment for 3D conformal radiotherapy},
journal = {Computers in Biology and Medicine},
volume = {143},
pages = {105277},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.105277},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522000695},
author = {Amir Jabbarpour and Seied Rabi Mahdavi and Alireza {Vafaei Sadr} and Golbarg Esmaili and Isaac Shiri and Habib Zaidi},
keywords = {MRI-Only radiotherapy, Brain tumors, Unsupervised deep learning, CycleGAN},
abstract = {Purpose
Absorbed dose calculation in magnetic resonance-guided radiation therapy (MRgRT) is commonly based on pseudo CT (pCT) images. This study investigated the feasibility of unsupervised pCT generation from MRI using a cycle generative adversarial network (CycleGAN) and a heterogenous multicentric dataset. A dosimetric analysis in three-dimensional conformal radiotherapy (3DCRT) planning was also performed.
Material and methods
Overall, 87 T1-weighted and 102 T2-weighted MR images alongside with their corresponding computed tomography (CT) images of brain cancer patients from multiple centers were used. Initially, images underwent a number of preprocessing steps, including rigid registration, novel CT Masker, N4 bias field correction, resampling, resizing, and rescaling. To overcome the gradient vanishing problem, residual blocks and mean squared error (MSE) loss function were utilized in the generator and in both networks (generator and discriminator), respectively. The CycleGAN was trained and validated using 70 T1 and 80 T2 randomly selected patients in an unsupervised manner. The remaining patients were used as a holdout test set to report final evaluation metrics. The generated pCTs were validated in the context of 3DCRT.
Results
The CycleGAN model using masked T2 images achieved better performance with a mean absolute error (MAE) of 61.87 ± 22.58 HU, peak signal to noise ratio (PSNR) of 27.05 ± 2.25 (dB), and structural similarity index metric (SSIM) of 0.84 ± 0.05 on the test dataset. T1-weighted MR images used for dosimetric assessment revealed a gamma index of 3%, 3 mm, 2%, 2 mm and 1%, 1 mm with acceptance criteria of 98.96% ± 1.1%, 95% ± 3.68%, 90.1% ± 6.05%, respectively. The DVH differences between CTs and pCTs were within 2%.
Conclusions
A promising pCT generation model capable of handling heterogenous multicenteric datasets was proposed. All MR sequences performed competitively with no significant difference in pCT generation. The proposed CT Masker proved promising in improving the model accuracy and robustness. There was no significant difference between using T1-weighted and T2-weighted MR images for pCT generation.}
}
@article{KNECHT2006S426,
title = {Mechanical properties of the patellar cartilage by an inverse FE approach from MR-monitored compression tests},
journal = {Journal of Biomechanics},
volume = {39},
pages = {S426},
year = {2006},
note = {Abstracts of the 5th World Congress of Biomechanics},
issn = {0021-9290},
doi = {https://doi.org/10.1016/S0021-9290(06)84735-4},
url = {https://www.sciencedirect.com/science/article/pii/S0021929006847354},
author = {S. Knecht and R. Luechinger and E. Stuessi}
}
@article{TUZIKOV20032219,
title = {Evaluation of the symmetry plane in 3D MR brain images},
journal = {Pattern Recognition Letters},
volume = {24},
number = {14},
pages = {2219-2233},
year = {2003},
issn = {0167-8655},
doi = {https://doi.org/10.1016/S0167-8655(03)00049-7},
url = {https://www.sciencedirect.com/science/article/pii/S0167865503000497},
author = {Alexander V. Tuzikov and Olivier Colliot and Isabelle Bloch},
keywords = {Symmetry plane, Symmetry measure, MR brain image, Mid-sagittal plane, Inertia axes, Optimization},
abstract = {Although the brain is not perfectly symmetrical with respect to the mid-sagittal plane, the automatic detection of this plane and of the degree of symmetry is of interest for many anatomical and functional studies. We propose a method for detecting the best symmetry plane in 3D MR brain images. We express this problem as a registration problem and compute a degree of similarity between the image and its reflection with respect to a plane. The best plane is then obtained by maximizing the similarity measure. This optimization is performed using the downhill simplex method and is initialized by a plane obtained from principal inertia axes, which proves to be close to the global optimum. This is demonstrated on several MR brain images. The proposed algorithm is then successfully tested on simulated and real 3D MR brain images. We also investigated the influence of the optimization procedure control parameters on the computation speed and result precision. Preliminary results obtained on CT and SPECT images suggest that the method can be extended to other modalities.}
}
@article{SUNDARESAN2021102215,
title = {Comparison of domain adaptation techniques for white matter hyperintensity segmentation in brain MR images},
journal = {Medical Image Analysis},
volume = {74},
pages = {102215},
year = {2021},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2021.102215},
url = {https://www.sciencedirect.com/science/article/pii/S1361841521002607},
author = {Vaanathi Sundaresan and Giovanna Zamboni and Nicola K. Dinsdale and Peter M. Rothwell and Ludovica Griffanti and Mark Jenkinson},
keywords = {Deep learning, White matter hyperintensities, Domain adaptation, Segmentation},
abstract = {Robust automated segmentation of white matter hyperintensities (WMHs) in different datasets (domains) is highly challenging due to differences in acquisition (scanner, sequence), population (WMH amount and location) and limited availability of manual segmentations to train supervised algorithms. In this work we explore various domain adaptation techniques such as transfer learning and domain adversarial learning methods, including domain adversarial neural networks and domain unlearning, to improve the generalisability of our recently proposed triplanar ensemble network, which is our baseline model. We used datasets with variations in intensity profile, lesion characteristics and acquired using different scanners. For the source domain, we considered a dataset consisting of data acquired from 3 different scanners, while the target domain consisted of 2 datasets. We evaluated the domain adaptation techniques on the target domain datasets, and additionally evaluated the performance on the source domain test dataset for the adversarial techniques. For transfer learning, we also studied various training options such as minimal number of unfrozen layers and subjects required for fine-tuning in the target domain. On comparing the performance of different techniques on the target dataset, domain adversarial training of neural network gave the best performance, making the technique promising for robust WMH segmentation.}
}
@article{SHI2020103367,
title = {The impact of engineering information formats on learning and execution of construction operations: A virtual reality pipe maintenance experiment},
journal = {Automation in Construction},
volume = {119},
pages = {103367},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103367},
url = {https://www.sciencedirect.com/science/article/pii/S092658052030947X},
author = {Yangming Shi and Jing Du and Darrell A. Worthy},
keywords = {Working memory, Engineering information, Cognitive load, Virtual reality, Eye-tracking},
abstract = {Given the increasing complexity of construction tasks, and the growing number of construction operations within confined workplaces, construction workers rely heavily on working memory. In this context, working memory is defined as the short-term and temporary storage of information related to near future events to ensure the seamless execution of construction tasks. Although a strong relationship between engineering information format and task performance has been observed in the relevant literature, there remains an obvious theoretical disagreement—in particular, about the cognitive mechanisms for explaining why different information formats affect working memory development and retrieval in distinct ways. This study presents a human–subject experiment (n = 120) to examine the impact of information format on the performance of a pipe maintenance task, and the implications of cognitive costs in both working memory development (information encoding) and retrieval (information recalling). Participants were required to review the operational instructions for a pipe maintenance task for a short period, and then perform the task from memory. Participants were divided into four groups depending on the format of information they received: 2D isometric drawing of the plate heat exchanger with bulleted-text operational instructions (2D-simple group); 2D isometric drawing of the plate heat exchanger with rich-text operational instruction (2D-complex group); an interactive 3D model of the plate heat exchanger with bulleted-text operational instructions (3D group); or an immersive Virtual Reality (VR) environment with bulleted-text operational instructions (VR group). The results indicated that 3D and VR groups outperformed 2D-simple and 2D-complex groups in both operation time and maintenance accuracy. A further cognitive load analysis (based on surveys and pupil dilation) suggested that the superior performance of these groups is driven by more efficient usage of working memory, measured by how easily the encoded information can be recalled in the operation phase. Larger pupil dilation during encoding, indicative of successful working memory formation, was associated with better subsequent performance. These findings provide more evidence about cognitive mechanisms engaged by different information formats, help to resolve the current theoretical disagreement within the construction literature, and may inspire designs of cognition-driven information systems that can improve working memory in construction workers.}
}
@article{SONG2021103506,
title = {Effectiveness of VR crane training with head-mounted display: Double mediation of presence and perceived usefulness},
journal = {Automation in Construction},
volume = {122},
pages = {103506},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103506},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520310864},
author = {Hayeon Song and Taenyun Kim and Jieun Kim and Dohyun Ahn and Youngcheol Kang},
keywords = {VR, Crane training, Virtual, Self-efficacy, Presence},
abstract = {Virtual reality (VR) has been shown to provide an immersive experience that can promote effective learning. The use of VR with head-mounted displays can be especially ideal for training operators of heavy equipment such as cranes, resulting in cost savings and enhanced safety of apprentices. In this study, a set of VR training systems is introduced for three different types of cranes (i.e., overhead, container, and tower crane), and an experiment is conducted to test their effectiveness. A total of 108 students participated in the experiment. The findings revealed that the VR crane training system significantly enhanced the students' self-efficacy when operating a crane. The underlying mechanism of how the VR crane training improves trainees' level of self-efficacy is also investigated. Double mediation analysis revealed that the change in self-efficacy is driven by usability mediated by the feeling of presence and perceived usefulness.}
}
@article{DANIELSSON201845,
title = {Operators perspective on augmented reality as a support tool in engine assembly},
journal = {Procedia CIRP},
volume = {72},
pages = {45-50},
year = {2018},
note = {51st CIRP Conference on Manufacturing Systems},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2018.03.153},
url = {https://www.sciencedirect.com/science/article/pii/S2212827118303111},
author = {Oscar Danielsson and Anna Syberfeldt and Magnus Holm and Lihui Wang},
keywords = {augmented reality, engine assembly, operator},
abstract = {Augmented Reality (AR) has shown its potential in supporting operators in manufacturing. AR-glasses as a platform both in industrial use are emerging markets, thereby making portable and hands-free AR more and more feasible. An important aspect of integrating AR as a support tool for operators is their acceptance of the technology. This paper presents the results of interviewing operators regarding their view on AR technology in their field and observing them working in automotive engine assembly and how they interact with current instructions. The observations and follow-up questions identified three main aspects of the information that the operators looked at: validating screw torque, their current assembly time, and if something went wrong. The interviews showed that a large amount of the operators were positive towards using AR in assembly. This has given an insight in both the current information interaction the operators do and their view on the potential in using AR. Based on these insights we suggest a mock-up design of an AR-interface for engine assembly to serve as a base for future prototype designs.}
}
@article{HE2016149,
title = {A mass-redistributed finite element method (MR-FEM) for acoustic problems using triangular mesh},
journal = {Journal of Computational Physics},
volume = {323},
pages = {149-170},
year = {2016},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2016.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S0021999116303205},
author = {Z.C. He and Eric Li and G.R. Liu and G.Y. Li and A.G. Cheng},
keywords = {Acoustic, Numerical method, Mass-redistributed finite element method (MR-FEM), Dispersion error},
abstract = {The accuracy of numerical results using standard finite element method (FEM) in acoustic problems will deteriorate with increasing frequency due to the “dispersion error”. Such dispersion error depends on the balance between the “stiffness” and “mass” of discretization equation systems. This paper reports an improved finite element method (FEM) for solving acoustic problems by re-distributing the mass in the mass matrix to “tune” the balance, aiming to minimize the dispersion errors. This is done by shifting the integration point locations when computing the entries of the mass matrix, while ensuring the mass conservation. The new method is verified through the detailed numerical error analysis, and a strategy is also proposed for the best mass redistribution in terms of minimizing dispersion error. The relative dispersion error of present mass-redistributed finite element method (MR-FEM) is found to be much smaller than the FEM solution, in both theoretical prediction and numerical examination. The present MR-FEM works well by using the linear triangular elements that can be generated automatically, which enables automation in computation and saving computational cost in mesh generation. Numerical examples demonstrate the advantages of MR-FEM, in comparison with the standard FEM using the same triangular meshes and quadrilateral meshes.}
}
@article{WRZESIEN2015343,
title = {Treating small animal phobias using a projective-augmented reality system: A single-case study},
journal = {Computers in Human Behavior},
volume = {49},
pages = {343-353},
year = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.01.065},
url = {https://www.sciencedirect.com/science/article/pii/S074756321500093X},
author = {Maja Wrzesien and Cristina Botella and Juana Bretón-López and Eva {del Río González} and Jean-Marie Burkhardt and Mariano Alcañiz and María Ángeles Pérez-Ara},
keywords = {Small animal phobias, Augmented reality, In vivo exposure, Clinical efficacy, Projection systems, Visual displays},
abstract = {In vivo exposure is the evidence based treatment for small animal phobias. However, this type of treatment still present a low treatment seek rate and a high drop-out rate, due to its aversive character for the patients. New technologies such as Virtual Reality (VR) and augmented reality (AR) have started to show their potential in anxiety disorders, including small animal phobia treatment and have demonstrated their efficacy. However, these systems still present limitations regarding the possibility to offer an optimal therapy to the phobia sufferers. This study evaluates the clinical efficacy of new AR exposure therapy – a projection-based system (P-ARET) for small animal phobias in the short (post-treatment), and long term (3- and 12-month follow-up). Four patients diagnosed with cockroach phobia participated in this pilot treatment study. The results show that all patients improved significantly in main outcome measures after the treatment. The study also follows a strategy of benchmarking, in which the results obtained from the evaluation of the P-ARET system in clinical setting are compared with two other clinically validated phobia therapies (traditional, in vivo exposure therapy (IVET); virtual reality exposure therapy (VRET); and AR exposure therapy with the use of a head-mounted display (HMD-ARET). The results indicate that the clinical effectiveness of new projection-based AR system for small animal phobia treatment was comparable to those achieved by the therapeutic conditions in other studies. However, the P-ARET system brings some advantages in terms of patient-therapist communication and more natural interaction with the system.}
}
@article{BAI201598,
title = {Multi-atlas segmentation with augmented features for cardiac MR images},
journal = {Medical Image Analysis},
volume = {19},
number = {1},
pages = {98-109},
year = {2015},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2014.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S136184151400142X},
author = {Wenjia Bai and Wenzhe Shi and Christian Ledig and Daniel Rueckert},
keywords = {Multi-atlas segmentation, Patch-based segmentation, Cardiac image segmentation, Augmented features},
abstract = {Multi-atlas segmentation infers the target image segmentation by combining prior anatomical knowledge encoded in multiple atlases. It has been quite successfully applied to medical image segmentation in the recent years, resulting in highly accurate and robust segmentation for many anatomical structures. However, to guide the label fusion process, most existing multi-atlas segmentation methods only utilise the intensity information within a small patch during the label fusion process and may neglect other useful information such as gradient and contextual information (the appearance of surrounding regions). This paper proposes to combine the intensity, gradient and contextual information into an augmented feature vector and incorporate it into multi-atlas segmentation. Also, it explores the alternative to the K nearest neighbour (KNN) classifier in performing multi-atlas label fusion, by using the support vector machine (SVM) for label fusion instead. Experimental results on a short-axis cardiac MR data set of 83 subjects have demonstrated that the accuracy of multi-atlas segmentation can be significantly improved by using the augmented feature vector. The mean Dice metric of the proposed segmentation framework is 0.81 for the left ventricular myocardium on this data set, compared to 0.79 given by the conventional multi-atlas patch-based segmentation (Coupé et al., 2011; Rousseau et al., 2011). A major contribution of this paper is that it demonstrates that the performance of non-local patch-based segmentation can be improved by using augmented features.}
}
@article{PHELLAN2019184,
title = {A methodology for generating four-dimensional arterial spin labeling MR angiography virtual phantoms},
journal = {Medical Image Analysis},
volume = {56},
pages = {184-192},
year = {2019},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2019.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S1361841519300520},
author = {Renzo Phellan and Thomas Lindner and Michael Helle and Alexandre X. Falcão and Thomas W. Okell and Nils D. Forkert},
keywords = {Angiography, Cerebrovascular imaging, Arterial spin labeling, Blood flow analysis, Phantom models},
abstract = {Four-dimensional arterial spin labeling magnetic resonance angiography (4D ASL MRA) is a non-invasive medical imaging modality that can be used for anatomical and hemodynamic analysis of the cerebrovascular system. However, it generates a considerable amount of data, which is tedious to analyze visually. As an alternative, medical image processing methods can be used to process the data and present measurements of the geometry and blood flow in the cerebrovascular system to the user, such as vessel radius, tortuosity, blood flow volume, and transit time. Nevertheless, evaluating medical image processing methods developed for this modality requires annotated data, which can be time-consuming and expensive to obtain. Alternatively, virtual simulations are a faster and less expensive option that can be used for initial evaluation of image processing methods. The present work proposes a methodology for generating annotated 4D ASL MRA virtual phantoms, in different scenarios with different acquisition parameter settings. In each scenario, the phantoms are generated using real cerebrovascular geometries of healthy volunteers, where blood flow is simulated according to a mathematical model specifically designed to describe the signal observed in 4D ASL MRA images. Realistic noise is added using an homomorphic approach, designed to replicate noise characteristic of multi-coil acquisitions. In order to exemplify the utility of the phantoms, they are used to evaluate the accuracy of a method to estimate blood flow parameter values, such as relative blood volume and transit time, in different scenarios. The estimated values are then compared to its corresponding virtual ground-truth values. The accuracy of the results is ranked according to the average absolute error. The results of the experiments show that blood flow parameters can be more accurately estimated when blood is magnetically labeled for longer periods of time and when the datasets are acquired with higher temporal resolution. In summary, the present work describes a methodology to create annotated virtual phantoms, which represent a useful alternative for initial evaluation of medical image processing methods for 4D ASL MRA images.}
}
@article{DEPACE2020106806,
title = {A systematic review of Augmented Reality interfaces for collaborative industrial robots},
journal = {Computers & Industrial Engineering},
volume = {149},
pages = {106806},
year = {2020},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2020.106806},
url = {https://www.sciencedirect.com/science/article/pii/S0360835220305118},
author = {Francesco {De Pace} and Federico Manuri and Andrea Sanna and Claudio Fornaro},
keywords = {Augmented Reality, Human–robot collaboration, Collaborative robot, Industrial robot, User interface},
abstract = {Industry 4.0 is moving factories towards a high level of collaboration between human workers and industrial robots, with the aim of improving efficiency and productivity. Among other technologies, Augmented Reality (AR) is one of the most researched in recent years to provide novel user interfaces that could easily blend the real world with additional information. This literature review aims at identifying the main strengths and weaknesses of AR with industrial robots in human–robot collaborative scenarios. The term industrial robot is meant according to the ISO 8373:2012 definition. To this end, starting from 3734 initial works, 63 papers have been selected and analysed. The results suggest that AR technology shows its effectiveness also in this particular domain. With respect to traditional approaches, AR systems are faster and more appreciated by users. Nonetheless, the use of AR in human–robot collaborative scenarios is so cutting edge that not all the considered works have properly evaluated the proposed user interfaces. Future research should improve the qualitative evaluation in order to clearly point out both limitations and strengths of the proposed systems, involving also expert users in tests.}
}
@article{GLOGER2018288,
title = {Subject-Specific prior shape knowledge in feature-oriented probability maps for fully automatized liver segmentation in MR volume data},
journal = {Pattern Recognition},
volume = {84},
pages = {288-300},
year = {2018},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2018.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S0031320318302528},
author = {Oliver Gloger and Klaus Tönnies},
keywords = {Expectation maximization, Subject-specific shape model, 3D prior shape level set segmentation, Bayesian probability, Normalized cross correlation, Principal component analysis},
abstract = {Liver segmentation and volumetry in native MR-volume data is an important topic in epidemiological research. Manual liver segmentation is extremely time-consuming and often infeasible requiring automatized methods. Automatic liver segmentation is challenging because of the large variability in liver shape and appearance and the low contrast to neighboring organs. We present a fully automatized liver segmentation framework that uses a sequence of modules based on individualized model knowledge on liver appearance and shape. Liver probability maps are computed that incorporate organ-specific features like MR-intensity distributions, inner-organ MR-differences and liver positions. Probability map generation differentiates automatically between fatty and non-fatty livers. Moreover, we improve an existing technique for prior shape level set segmentation to delineate the liver in tissue-specific liver probability maps and to recognize cystic hepatic tissue. Dice coefficients of 0.937 and low volumetric errors on 35 test data sets confirm the robust segmentation quality of the framework.}
}
@article{SLAMA2023100153,
title = {Res-Net-VGG19: Improved tumor segmentation using MR images based on Res-Net architecture and efficient VGG gliomas grading},
journal = {Applications in Engineering Science},
volume = {16},
pages = {100153},
year = {2023},
issn = {2666-4968},
doi = {https://doi.org/10.1016/j.apples.2023.100153},
url = {https://www.sciencedirect.com/science/article/pii/S2666496823000286},
author = {Amine Ben Slama and Hanene Sahli and Yessine Amri and Hedi Trabelsi},
keywords = {Brain tumor, MRI images, Res-net segmentation, Low-grade gliomas, High-grade gliomas, Classification},
abstract = {Background
The determination of area tumor presents the chief challenge in brain tumor therapy and assessment. Without ionizing radiation, the medical Magnetic Resonance Imaging (MRI) tool has appeared as an essential diagnostic technique for brain cancers. Using 2D MRI images, manual segmentation of brain tumor size is a slow, error-prone task which the performance is extremely depends on operator's experience. In that respect, a consistent totally automated segmentation approach for the brain tumor detection is effectively needed to get a proficient dimension of the tumor size.
Results
In this paper, an effusively computerized scheme for brain tumor detection is proposed by the use of deep convolutional networks. The proposed method was appraised on Brain Tumor Image Segmentation (BRATS 2020) datasets, including 1352 affected by brain tumor.
Conclusion
Cross-validation technique has revealed that our process can attain talented segmentation competently reaching higher accuracy compared to other previous studies.}
}
@article{NICOLAU2009494,
title = {An augmented reality system for liver thermal ablation: Design and evaluation on clinical cases},
journal = {Medical Image Analysis},
volume = {13},
number = {3},
pages = {494-506},
year = {2009},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2009.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S1361841509000103},
author = {S.A. Nicolau and X. Pennec and L. Soler and X. Buy and A. Gangi and N. Ayache and J. Marescaux},
keywords = {Augmented reality, Computer-guided system, Liver punctures, 3D/2D registration, Breathing motion},
abstract = {We present in this paper an augmented reality guidance system for liver thermal ablation in interventional radiology. To show the relevance of our methodology, the system is incrementally evaluated on an abdominal phantom and then on patients in the operating room. The system registers in a common coordinate system a preoperative image of the patient and the position of the needle that the practitioner manipulates. The breathing motion uncertainty is taken into account with a respiratory gating technique: the preoperative image and the guidance step are synchronized on expiratory phases. In order to fulfil the real-time constraints, we have developed and validated algorithms that automatically process and extract feature points. Since the guidance interface is also a major component of the system effectiveness, we validate the overall targeting accuracy on an abdominal phantom. This experiment showed that a practitioner can reach a predefined target with an accuracy of 2mm with an insertion time below one minute. Finally, we propose a passive evaluation protocol of the overall system in the operating room during five interventions on patients. These experiments show that the system can provide a guidance information during expiratory phases with an error below 5mm.}
}
@article{ESTAKHRAJI2023102227,
title = {On the effect of training database size for MR-based synthetic CT generation in the head},
journal = {Computerized Medical Imaging and Graphics},
volume = {107},
pages = {102227},
year = {2023},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2023.102227},
url = {https://www.sciencedirect.com/science/article/pii/S0895611123000459},
author = {Seyed Iman Zare Estakhraji and Ali Pirasteh and Tyler Bradshaw and Alan McMillan},
keywords = {Generative adversarial networks (GAN), Synthetic CT generation, Fine-Tuning, MR-guided radiotherapy},
abstract = {Generation of computed tomography (CT) images from magnetic resonance (MR) images using deep learning methods has recently demonstrated promise in improving MR-guided radiotherapy and PET/MR imaging.
Purpose:
To investigate the performance of unsupervised training using a large number of unpaired data sets as well as the potential gain in performance after fine-tuning with supervised training using spatially registered data sets in generation of synthetic computed tomography (sCT) from magnetic resonance (MR) images.
Materials and methods:
A cycleGAN method consisting of two generators (residual U-Net) and two discriminators (patchGAN) was used for unsupervised training. Unsupervised training utilized unpaired T1-weighted MR and CT images (2061 sets for each modality). Five supervised models were then fine-tuned starting with the generator of the unsupervised model for 1, 10, 25, 50, and 100 pairs of spatially registered MR and CT images. Four supervised training models were also trained from scratch for 10, 25, 50, and 100 pairs of spatially registered MR and CT images using only the residual U-Net generator. All models were evaluated on a holdout test set of spatially registered images from 253 patients, including 30 with significant pathology. sCT images were compared against the acquired CT images using mean absolute error (MAE), Dice coefficient, and structural similarity index (SSIM). sCT images from 60 test subjects generated by the unsupervised, and most accurate of the fine-tuned and supervised models were qualitatively evaluated by a radiologist.
Results:
While unsupervised training produced realistic-appearing sCT images, addition of even one set of registered images improved quantitative metrics. Addition of more paired data sets to the training further improved image quality, with the best results obtained using the highest number of paired data sets (n=100). Supervised training was found to be superior to unsupervised training, while fine-tuned training showed no clear benefit over supervised learning, regardless of the training sample size.
Conclusion:
Supervised learning (using either fine tuning or full supervision) leads to significantly higher quantitative accuracy in the generation of sCT from MR images. However, fine-tuned training using both a large number of unpaired image sets was generally no better than supervised learning using registered image sets alone, suggesting the importance of well registered paired data set for training compared to a large set of unpaired data.}
}
@article{AKHAVANFAR2018102,
title = {Obesity and spinal loads; a combined MR imaging and subject-specific modeling investigation},
journal = {Journal of Biomechanics},
volume = {70},
pages = {102-112},
year = {2018},
note = {2nd International Workshop on Spine Loading and Deformation},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2017.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S0021929017304190},
author = {M.H. Akhavanfar and H. Kazemi and A.H. Eskandari and N. Arjmand},
keywords = {Obesity, Spine loads, MR imaging, Musculoskeletal model, Subject-specific},
abstract = {Epidemiological studies have identified obesity asa possible risk factor for low back disorders. Biomechanical models can help test such hypothesis and shed light on the mechanism involved. A novel subject-specific musculoskeletal-modelling approach is introduced to estimate spinal loads during static activities in five healthy obese (BMI>30kg/m2) and five normal-weight (20<BMI<25kg/m2) individuals. Subjects underwent T1 through S1 MR imaging thereby measuring cross-sectional-area (CSA) and moment arms of trunk muscles together with mass and center of mass (CoM) of T1-L5 segments. MR-based subject-specific models estimated spinal loads using a kinematics/optimization-driven approach. Average CSAs of muscles, moment arms of abdominal muscles, mass and sagittal moment arm of CoM of T1-L5 segments were larger in obese individuals (p<0.05 except for the moment arm of CoMs) but moment arms of their back muscles were similar to those of normal-weight individuals (p>0.05). Heavier subjects did not necessarily have larger muscle moment arms (e.g., they were larger in 64kg (BMI=20.7kg/m2) subject than 78kg (BMI=24.6kg/m2) subject) or greater T1-L5 trunk weight (e.g., the 97kg (BMI=31kg/m2) subject had similar trunk weight as 109kg (BMI=33.3kg/m2) subject). Obese individuals had in average greater spinal loads than normal-weight ones but heavier subjects did not necessarily have greater spinal loads (117kg (BMI=40.0kg/m2) subject had rather similar L5-S1 compression as 105kg (BMI=34.7kg/m2) subject). Predicted L4-L5 intradiscal pressures for the normal-weight subjects ranged close to the measured values (R2=0.85–0.92). Obese individuals did not necessarily have greater IDPs than normal-weight ones.}
}
@article{HE2023106839,
title = {An optimized segmentation convolutional neural network with dynamic energy loss function for 3D reconstruction of lumbar spine MR images},
journal = {Computers in Biology and Medicine},
volume = {160},
pages = {106839},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.106839},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523003049},
author = {Siyuan He and Qi Li and Xianda Li and Mengchao Zhang},
keywords = {Loss function, Lumbar spine 3D reconstruction, MR image Segmentation, Convolutional neural network},
abstract = {3D reconstruction for lumbar spine based on segmentation of Magnetic Resonance (MR) images is meaningful for diagnosis of degenerative lumbar spine diseases. However, spine MR images with unbalanced pixel distribution often cause the segmentation performance of Convolutional Neural Network (CNN) reduced. Designing a composite loss function for CNN is an effective way to enhance the segmentation capacity, yet composition loss values with fixed weight may still cause underfitting in CNN training. In this study, we designed a composite loss function with a dynamic weight, called Dynamic Energy Loss, for spine MR images segmentation. In our loss function, the weight percentage of different loss values could be dynamically adjusted during training, thus CNN could fast converge in earlier training stage and focus on detail learning in the later stage. Two datasets were used in control experiments, and the U-net CNN model with our proposed loss function achieved superior performance with Dice similarity coefficient values of 0.9484 and 0.8284 respectively, which were also verified by the Pearson correlation, Bland-Altman, and intra-class correlation coefficient analysis. Furthermore, to improve the 3D reconstruction based on the segmentation results, we proposed a filling algorithm to generate contextually related slices by computing the pixel-level difference between adjacent slices of segmented images, which could enhance the structural information of tissues between slices, and improve the performance of 3D lumbar spine model rendering. Our methods could help radiologists to build a 3D lumbar spine graphical model accurately for diagnosis while reducing burden of manual image reading.}
}
@article{HU201626,
title = {Stochastic minimax semi-active control for MDOF nonlinear uncertain systems under combined harmonic and wide-band noise excitations using MR dampers},
journal = {International Journal of Non-Linear Mechanics},
volume = {83},
pages = {26-38},
year = {2016},
issn = {0020-7462},
doi = {https://doi.org/10.1016/j.ijnonlinmec.2016.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0020746216300087},
author = {R.C. Hu and H. Xiong and W.L. Jin and W.Q. Zhu},
keywords = {Multi-degrees of freedom nonlinear uncertain systems, Harmonic and wide-band noise excitations, Minimax semi-active control, MR dampers, Stochastic averaging, Dynamical programming},
abstract = {A stochastic minimax semi-active control strategy for multi-degrees-of-freedom (MDOF) strongly nonlinear systems under combined harmonic and wide-band noise excitations is proposed. First, a stochastic averaging procedure is introduced for controlled uncertain strongly nonlinear systems using generalized harmonic functions and the control forces produced by Magneto-rheological (MR) dampers are split into the passive part and the active part. Then, a worst-case optimal control strategy is derived by solving a stochastic differential game problem. The worst-case disturbances and the optimal semi-active controls are obtained by solving the Hamilton–Jacobi–Isaacs (HJI) equations with the constraints of disturbance bounds and MR damper dynamics. Finally, the responses of optimally controlled MDOF nonlinear systems are predicted by solving the Fokker–Planck–Kolmogorov (FPK) equation associated with the fully averaged Itô equations. Two examples are worked out in detail to illustrate the proposed control strategy. The effectiveness of the proposed control strategy is verified by using the results from Monte Carlo simulation.}
}
@article{SPITZLEY2019172,
title = {Feasibility of using a fully immersive virtual reality system for kinematic data collection},
journal = {Journal of Biomechanics},
volume = {87},
pages = {172-176},
year = {2019},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2019.02.015},
url = {https://www.sciencedirect.com/science/article/pii/S0021929019301459},
author = {Kate A. Spitzley and Andrew R. Karduna},
keywords = {Virtual reality, Validation, Kinematics, HTC VIVE, Sensors, VR},
abstract = {Commercially-available Virtual Reality (VR) systems have the potential to be effective tools for simultaneous visual manipulation and kinematic data collection. Previously, these systems have been integrated with research-grade motion capture systems to provide both functionalities; however, they are yet to be used as stand-alone systems for kinematic data collection. The present study aimed to validate the HTC VIVE VR system for kinematic data collection by evaluating the accuracy of its position and orientation signals. The VIVE controller and tracker were each compared to a Polhemus Liberty magnetic tracking system sensor for angular and translational measurement error and signal drift. A sensor from each system was mounted to opposite ends of a rigid segment which was driven through fifty rotations and fifty translations. Mean angular errors for both the VIVE tracker and controller were below 0.4°. Mean translational error for both sensors was below 3 mm. Drift in the Liberty signal components was consistently lower than drift in VIVE components. However, all mean rotational drift measures were below 0.1° and all mean translational measures were below 0.35 mm. These data indicate that the HTC VIVE system has the potential to be a valid and reliable means of kinematic data collection. However, further investigation is necessary to determine the VIVE’s suitability for capturing extremely minute or high-volume movements.}
}
@article{BOCIAN201562,
title = {Experimental identification of the behaviour of and lateral forces from freely-walking pedestrians on laterally oscillating structures in a virtual reality environment},
journal = {Engineering Structures},
volume = {105},
pages = {62-76},
year = {2015},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2015.09.043},
url = {https://www.sciencedirect.com/science/article/pii/S0141029615006264},
author = {Mateusz Bocian and John H.G. Macdonald and Jeremy F. Burn and David Redmill},
keywords = {Bridges, Human–structure interaction, Biomechanics, Inverted pendulum pedestrian model, Self-excited forces, Virtual reality environment},
abstract = {Modelling pedestrian loading on lively structures such as bridges remains a challenge. This is because pedestrians have the capacity to interact with vibrating structures which can lead to amplification of the structural response. Current design guidelines are often inaccurate and limiting as they do not sufficiently acknowledge this effect. This originates in scarcity of data on pedestrian behaviour on vibrating ground and uncertainty as to the accuracy of results from previous experimental campaigns aiming to quantify pedestrian behaviour in this case. To this end, this paper presents a novel experimental setup developed to evaluate pedestrian actions on laterally oscillating ground in the laboratory environment while avoiding the implications of artificiality and allowing for unconstrained gait. A biologically-inspired approach was adopted in its development, relying on appreciation of operational complexities of biological systems, in particular their adaptability and control requirements. In determination of pedestrian forces to the structure consideration was given to signal processing issues which have been neglected in past studies. The results from tests conducted on the setup are related to results from previous experimental investigations and outputs of the inverted pendulum pedestrian model for walking on laterally oscillating ground, which is capable of generating self-excited forces.}
}
@article{KIM20181,
title = {Development of an AR based method for augmentation of 3D CAD data onto a real ship block image},
journal = {Computer-Aided Design},
volume = {98},
pages = {1-11},
year = {2018},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2017.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S001044851730252X},
author = {Daewoon Kim and Jungseo Park and Kwang Hee Ko},
keywords = {Augmented Reality(AR), Camera pose estimation, Ship construction, Image registration},
abstract = {This paper proposes a method for augmenting a 3D CAD model of a ship block onto an image using an augmented reality technique. A two-dimensional image that captures a ship block is obtained using a digital camera. The image is processed to extract a feature of the block for establishing the correspondence between the block in the image and the 3D CAD model. In this work, a rectangular planar region is used as the feature in the image, which is then compared with face components in the CAD model. Once the correspondence is found, the initial pose of the block is computed using the correspondence information, and the CAD model is then augmented onto the image using the initial pose. Next, a registration process is employed to reduce the registration error further using a Lie Algebra-based method, which iteratively approximates the correct pose while reducing the error. As an option, a manual procedure is provided to allow a user to select the corresponding face for initial pose estimation. Real examples are used for testing the proposed method.}
}
@article{WEI2024100121,
title = {Communicating environment protection from plastic waste via VR: Effects of realism and spatial presence on risk perception},
journal = {Telematics and Informatics Reports},
volume = {13},
pages = {100121},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100121},
url = {https://www.sciencedirect.com/science/article/pii/S2772503024000070},
author = {Ran Wei and Shuhua Zhou and Renyi He and Kanni Huang},
keywords = {Virtual reality, Environmental protection, Plastic pollution, Realism, Spatial presence, Pro-environmental attitude},
abstract = {This study tested the utility of virtual reality technologies in building public awareness of an environmental issue—the growing pollution of plastic waste in oceans. We conducted an experiment to test whether viewing of VR video would produce two anticipated immersive experiences (e.g., perceived realism and spatial presence) in severely polluted oceans, and to further examine their effects on participants’ pro-environmental attitudes with regards to reducing plastic waste. Results showed that VR viewing led to higher perceived realism and spatial presence in comparisons with 2D video and audio-only conditions; perceived realism contributed significantly to pro-environmental attitude, whereas spatial presence did not. The higher the perceived realism, the stronger the pro-environmental attitude. Implications of the findings for using VR technologies for effective environmental communication are discussed.}
}
@article{SMIT20103,
title = {A shared-scene-graph image-warping architecture for VR: Low latency versus image quality},
journal = {Computers & Graphics},
volume = {34},
number = {1},
pages = {3-16},
year = {2010},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2009.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0097849309001344},
author = {Ferdi Smit and Robert {van Liere} and Stephan Beck and Bernd Froehlich},
keywords = {Virtual reality, Image-based rendering, Latency},
abstract = {Designing low end-to-end latency system architectures for virtual reality is still an open and challenging problem. We describe the design, implementation and evaluation of a client–server depth-image warping architecture that updates and displays the scene graph at the refresh rate of the display. Our approach works for scenes consisting of dynamic and interactive objects. The end-to-end latency is minimized as well as smooth object motion generated. However, this comes at the expense of image quality inherent to warping techniques. To improve image quality, we present a novel way of detecting and resolving occlusion errors due to warping. Furthermore, we investigate the use of asynchronous data transfers to increase the architecture's performance in a multi-GPU setting. Besides polygonal rendering, we also apply image-warping techniques to iso-surface rendering. Finally, we evaluate the architecture and its design trade-offs by comparing latency and image quality to a conventional rendering system. Our experience with the system confirms that the approach facilitates common interaction tasks such as navigation and object manipulation.}
}
@article{WANG2021325,
title = {Denoising auto-encoding priors in undecimated wavelet domain for MR image reconstruction},
journal = {Neurocomputing},
volume = {437},
pages = {325-338},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.09.086},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221000990},
author = {Siyuan Wang and Junjie Lv and Zhuonan He and Dong Liang and Yang Chen and Minghui Zhang and Qiegen Liu},
keywords = {MRI, Image reconstruction, Undecimated wavelet transform, Denoising autoencoding, Proximal gradient descent},
abstract = {Compressive sensing is an impressive approach for fast MRI. It aims at reconstructing MR image using only a few under-sampled data in k-space, enhancing the efficiency of the data acquisition. In this study, we propose to learn priors based on undecimated wavelet transform and an iterative image reconstruction algorithm. At the stage of prior learning, transformed feature images obtained by undecimated wavelet transform are stacked as an input of denoising autoencoder network (DAE). The highly redundant and multi-scale input enables the correlation of feature images at different channels, which allows a robust network-driven prior. At the iterative reconstruction, the transformed DAE prior is incorporated into the classical iterative procedure by means of proximal gradient algorithm. Experimental comparisons on different sampling trajectories and ratios validated the great potential of the presented algorithm.}
}
@article{KANG2021106875,
title = {Does virtual reality affect behavioral intention? Testing engagement processes in a K-Pop video on YouTube},
journal = {Computers in Human Behavior},
volume = {123},
pages = {106875},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.106875},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221001989},
author = {Seok Kang and Sophia Dove and Hannah Ebright and Serenity Morales and Hyungjoon Kim},
keywords = {Virtual reality, Audience engagement, Celebrity, BTS},
abstract = {The current study tested the effects of a celebrity's virtual reality (VR) video on YouTube on audience transportation, parasocial interaction, identification, worship, and behavioral intention of social campaign participation. In addition to VR effects, fans and nonfans were compared with each other for engagement. The media content of BTS, a Korean pop boy band, was experimented in six groups: VR video with a headset, 360-degree video, 2D video, audio, news article, and control. A posttest only experiment was conducted among 142 participants in total. Results found that the VR with a headset group showed a significant difference from the news article group in transportation into BTS. The VR with a headset group had higher parasocial interaction with BTS than the control group. BTS fans were more likely than nonfans to show significant transportation, parasocial interaction, identification, worship, and behavioral intention.}
}
@article{SINGH2017384,
title = {Experimental and numerical investigation of heat transfer inside two-pass rib roughened duct (AR=1:2) under rotating and stationary conditions},
journal = {International Journal of Heat and Mass Transfer},
volume = {113},
pages = {384-398},
year = {2017},
issn = {0017-9310},
doi = {https://doi.org/10.1016/j.ijheatmasstransfer.2017.05.085},
url = {https://www.sciencedirect.com/science/article/pii/S001793101730162X},
author = {Prashant Singh and Weihong Li and Srinath V. Ekkad and Jing Ren},
keywords = {Rib turbulators, Transient liquid crystal thermography, Rotation, Heat transfer},
abstract = {Heat transfer enhancement inside ribbed channels for turbine blades is a critical phenomenon that impacts overall performance and life of the gas turbine. Present study investigates heat and fluid flow in a rectangular duct with heat transfer enhancement features, under rotating and stationary conditions. The heat transfer data obtained experimentally has been explained using numerical prediction of flow features. Detailed heat transfer coefficients have been measured on the walls of two-pass rectangular duct (AR=1:2) featuring V-shaped rib turbulators, using transient liquid crystal thermography (TLCT). The first pass and second pass featured nine V-shaped ribs each and the bend featured a 90° rib connecting the blade tip underside and the two-pass divider wall. The flow in the first pass was developing in nature. The rib-pitch to rib-height ratio (p/e) was 9.625 and the rib-height to channel hydraulic diameter (e/dh) was 0.125. The baseline case for the rib roughened duct was geometrically identical smooth duct (with no heat transfer enhancement features). Stationary experiments were carried out for Reynolds numbers ranging from 25000 to 75000. The rotation experiments were carried out at 400RPM (Ro=0.036) and 700RPM (Ro=0.063), at Reynolds number of 25000 (Ro=Ωdh/V,Re=Vdh/ν). Also, numerical simulations were performed for a similar test model under similar flow conditions, using realizable k-∊ turbulence model. Detailed discussion on rib induced secondary flows and rotational effects on heat transfer in smooth and rib roughened duct are presented in this paper using results obtained from detailed heat transfer measurements from experiments and fluid dynamics predictions from numerical simulations.}
}
@article{CHEN2022107073,
title = {Deep learning-based medical image segmentation of the aorta using XR-MSF-U-Net},
journal = {Computer Methods and Programs in Biomedicine},
volume = {225},
pages = {107073},
year = {2022},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2022.107073},
url = {https://www.sciencedirect.com/science/article/pii/S0169260722004540},
author = {Weimin Chen and Hongyuan Huang and Jing Huang and Ke Wang and Hua Qin and Kelvin K.L. Wong},
keywords = {XR model, Cardiac aorta segmentation, MSF model, U-Net, CT, MRI},
abstract = {Purpose
This paper proposes a CT images and MRI segmentation technology of cardiac aorta based on XR-MSF-U-Net model. The purpose of this method is to better analyze the patient's condition, reduce the misdiagnosis and mortality rate of cardiovascular disease in inhabitants, and effectively avoid the subjectivity and unrepeatability of manual segmentation of heart aorta, and reduce the workload of doctors.
Method
We implement the X ResNet (XR) convolution module to replace the different convolution kernels of each branch of two-layer convolution XR of common model U-Net, which can make the model extract more useful features more efficiently. Meanwhile, a plug and play attention module integrating multi-scale features Multi-scale features fusion module (MSF) is proposed, which integrates global local and spatial features of different receptive fields to enhance network details to achieve the goal of efficient segmentation of cardiac aorta through CT images and MRI.
Results
The model is trained on common cardiac CT images and MRI data sets and tested on our collected data sets to verify the generalization ability of the model. The results show that the proposed XR-MSF-U-Net model achieves a good segmentation effect on CT images and MRI. In the CT data set, the XR-MSF-U-Net model improves 7.99% in key index DSC and reduces 11.01 mm in HD compared with the benchmark model U-Net, respectively. In the MRI data set, XR-MSF-U-Net model improves 10.19% and reduces 6.86 mm error in key index DSC and HD compared with benchmark model U-Net, respectively. And it is superior to similar models in segmentation effect, proving that this model has significant advantages.
Conclusion
This study provides new possibilities for the segmentation of aortic CT images and MRI, improves the accuracy and efficiency of diagnosis, and hopes to provide substantial help for the segmentation of aortic CT images and MRI.}
}
@article{ALKADRI2021104770,
title = {Utilizing a multilayer perceptron artificial neural network to assess a virtual reality surgical procedure},
journal = {Computers in Biology and Medicine},
volume = {136},
pages = {104770},
year = {2021},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.104770},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521005643},
author = {Sami Alkadri and Nicole Ledwos and Nykan Mirchi and Aiden Reich and Recai Yilmaz and Mark Driscoll and Rolando F. {Del Maestro}},
keywords = {Multilayered artificial neural network, Feature importance, Virtual reality, Surgical simulation, Surgical education, Performance metric, Surgical expertise, Anterior cervical discectomy and fusion},
abstract = {Background
Virtual reality surgical simulators are a safe and efficient technology for the assessment and training of surgical skills. Simulators allow trainees to improve specific surgical techniques in risk-free environments. Recently, machine learning has been coupled to simulators to classify performance. However, most studies fail to extract meaningful observations behind the classifications and the impact of specific surgical metrics on the performance. One benefit from integrating machine learning algorithms, such as Artificial Neural Networks, to simulators is the ability to extract novel insights into the composites of the surgical performance that differentiate levels of expertise.
Objective
This study aims to demonstrate the benefits of artificial neural network algorithms in assessing and analyzing virtual surgical performances. This study applies the algorithm on a virtual reality simulated annulus incision task during an anterior cervical discectomy and fusion scenario.
Design
An artificial neural network algorithm was developed and integrated. Participants performed the simulated surgical procedure on the Sim-Ortho simulator. Data extracted from the annulus incision task were extracted to generate 157 surgical performance metrics that spanned three categories (motion, safety, and efficiency).
Setting
Musculoskeletal Biomechanics Research Lab; Neurosurgical Simulation and Artificial Intelligence Learning Center, McGill University, Montreal, Canada.
Participants
Twenty-three participants were recruited and divided into 3 groups: 11 post-residents, 5 senior and 7 junior residents.
Results
An artificial neural network model was trained on nine selected surgical metrics, spanning all three categories and achieved 80% testing accuracy.
Conclusions
This study outlines the benefits of integrating artificial neural networks to virtual reality surgical simulators in understanding composites of expertise performance.}
}
@incollection{BRAND2012930,
title = {Validation of an absorber model of carbon dioxide capture in an aqueous amine solvent developed based on the SAFT-VR framework},
editor = {Iftekhar A. Karimi and Rajagopalan Srinivasan},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {31},
pages = {930-934},
year = {2012},
booktitle = {11th International Symposium on Process Systems Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-444-59506-5.50017-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780444595065500171},
author = {C.V. Brand and J. Rodríguez and A. Galindo and G. Jackson and C.S. Adjiman},
keywords = {CO capture, reactive separation, SAFT-VR, monoethanolamine},
abstract = {The development of a model of an absorber for the removal of carbon dioxide (CO2) from flue gas using aqueous solutions of monoethanolamine (MEA) is presented. This novel model incorporates state-of-the-art SAFT-VR thermodynamics into a rate-based process model. A characteristic of the proposed approach is that all the reactions are treated within a thermodynamic description, assuming chemical equilibrium throughout. This greatly reduces the amount of experimental data required to model the behaviour of CO2 in the solvent. Furthermore, in contrast with traditional treatments of reactive systems of this type, no enhancement factor is used in the process model. The absorber process model is implemented in the gPROMS software platform and validated using published pilot plant experimental data. The predictive capabilities of the mass transfer correlations used in this model are assessed through a sensitivity analysis and a scaling of the diffusivity in the liquid phase is proposed. The scaling of the diffusivity is transferable to different operating conditions and good predictions are obtained for the composition profiles in the gas and liquid phases.}
}
@article{KIM201729,
title = {AR-based 4D CAD System Using Marker and Markerless Recognition Method},
journal = {Procedia Engineering},
volume = {196},
pages = {29-35},
year = {2017},
note = {Creative Construction Conference 2017, CCC 2017, 19-22 June 2017, Primosten, Croatia},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.07.169},
url = {https://www.sciencedirect.com/science/article/pii/S187770581733028X},
author = {Hyeoun-Seong Kim and  Sangmi-Park and  Sunju-Han and Leen-Seok Kang},
keywords = {Augmented reality (AR), BIM, 4D CAD, Marker, Markerless},
abstract = {Requests for three-dimensional (3D) designs have increased in recent construction projects as the shapes of structures have become more complicated and the difficulties involved in designing buildings have increased. However, most site engineers still prefer two-dimensional (2D) drawings. The main reason for this preference is the difference in reality and operation from the information provided in a 3D presentation. To rectify this mismatch, this study proposed and implemented an augmented reality-based drawing verification system. The proposed system utilizes both marker and markerless recognition methods for efficient operation. Further, a suitable marker generation method is proposed for each recognition method. The results obtained during actual operation of the implemented system verify the efficacy of both the proposed system and the recognition modes. The AR-based drawings verification system suggested in the study can improve the understanding of drawings and it will be more useful for railway construction which is composed of a combination of heterogeneous drawings such as earthwork, track work and electrical work.}
}
@article{KIM2019186,
title = {Influences of augmented reality head-worn display type and user interface design on performance and usability in simulated warehouse order picking},
journal = {Applied Ergonomics},
volume = {74},
pages = {186-193},
year = {2019},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2018.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0003687018303387},
author = {Sunwook Kim and Maury A. Nussbaum and Joseph L. Gabbard},
keywords = {Head-worn display, Augmented reality, User interface, Performance},
abstract = {Limited information is available regarding the effective use of workplace head-worn displays (HWD), especially the choices of HWD types and user interface (UI) designs. We explored how different HWD types and UI designs affect perceived workload, usability, visual discomfort, and job performance during a simulated warehouse job involving order picking and part assembly. Sixteen gender-balanced participants completed the simulated job in all combinations of two HWD types (binocular vs. monocular) and four UIs, the latter of which manipulated information mode (text-vs. graphic-based) and information availability (always-on vs. on-demand); a baseline condition was also completed (paper pick list). Job performance, workload, and usability were more affected by UI designs than HWD type. For example, the graphic-based UI reduced job completion time and number of errors by ∼13% and ∼59%, respectively. Participants had no strong preference for either of the HWD types, suggesting that the physical HWD designs tested are suboptimal.}
}
@article{LAWSON2015240,
title = {The use of virtual reality and physical tools in the development and validation of ease of entry and exit in passenger vehicles},
journal = {Applied Ergonomics},
volume = {48},
pages = {240-251},
year = {2015},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2014.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S000368701400297X},
author = {Glyn Lawson and Paul Herriotts and Louise Malcolm and Katharina Gabrecht and Setia Hermawati},
keywords = {Entry exit, Automotive},
abstract = {Ease of entry and exit is important for creating a positive first impression of a car and increasing customer satisfaction. Several methods are used within vehicle development to optimise ease of entry and exit, including CAD reviews, benchmarking and buck trials. However, there is an industry trend towards digital methods to reduce the costs and time associated with developing physical prototypes. This paper reports on a study of entry strategy in three properties (buck, car, CAVE) in which inconsistencies were demonstrated by people entering a vehicle representation in the CAVE. In a second study industry practitioners rated the CAVE as worse than physical methods for identifying entry and exit issues, and having lower perceived validity and reliability. However, the resource issues associated with building bucks were recognised. Recommendations are made for developing the CAVE and for combinations of methods for use at different stages of a vehicle's development.}
}
@article{SU2017239,
title = {Synthetic holographic display for three — Dimensional optical see —Through augmented reality using a zero-order nulled grating},
journal = {Optik},
volume = {149},
pages = {239-245},
year = {2017},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2017.09.042},
url = {https://www.sciencedirect.com/science/article/pii/S003040261731104X},
author = {Yanfeng Su and Zhijian Cai and Quan Liu and Peiliang Guo and Yifan Lu and Lingyan Shi},
keywords = {Three-dimensional display, Holographic display, Augmented reality, Spatial light modulators, Diffraction gratings},
abstract = {In this paper, a synthetic holographic display system for three-dimensional (3D) optical see-through augmented reality (AR) is proposed and implemented. The system is composed of a synthetic hologram reconstruction module and an optical see-through display module. The synthetic hologram reconstruction module utilizes a spatial light modulator (SLM) to present the virtual 3D image in the form of left and right stereo images, and the parallax angle between two stereo images can be enlarged by the zero-order nulled grating to meet the split angle requirement of normal stereoscopic vision. The virtual reconstructed scene and the real physical world will fuse together through the optical see-through display module. The zero-order nulled grating is specifically designed and fabricated, and its diffraction efficiency is measured. Furthermore, an experimental verification system for the proposed AR 3D display is presented. The experimental results prove that the proposed system can support virtual 3D display without crosstalk, and it is able to generate the realistic augmentation successfully.}
}
@article{SAVAIA202014401,
title = {Experimental Validation of a Hierarchical Suspension Control via MR Damper},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {14401-14406},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.1402},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320318127},
author = {Gianluca Savaia and Matteo Corno and Giulio Panzani and Andrea Sinigaglia and Sergio M. Savaresi},
keywords = {Semi-Active Suspension, Vehicle Dynamics, Automotive Control, Magnetic Suspension, Skyhook},
abstract = {The suspension system has an important impact on vehicle dynamics, comfort and stability; these aspects are conflicting and the objective of an automatic control is to find a compromise. In this paper, the authors present an approach for the control of the vertical dynamics consisting of two layers: a low-level controller which fully exploits the properties of the magneto-rheological damper technology, and a high-level controller based upon a linearized skyhook for the full body control. The controller is experimentally validated on an actual vehicle in two road scenarios, which differ in their frequency excitation.}
}
@article{DALING2023104021,
title = {Assemble it like this! – Is AR- or VR-based training an effective alternative to video-based training in manual assembly?},
journal = {Applied Ergonomics},
volume = {110},
pages = {104021},
year = {2023},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2023.104021},
url = {https://www.sciencedirect.com/science/article/pii/S0003687023000595},
author = {Lea M. Daling and Marisa Tenbrock and Ingrid Isenhardt and Sabine J. Schlittmeier},
keywords = {Virtual reality, Augmented reality, Training and long-term retention},
abstract = {AR- and VR-based training is increasingly being used in the industry to train workers safely and effectively for new tasks. In this study, we investigated and compared the effects of AR-, VR- and video-based training on short- and long-term objective performance measures and subjective evaluations in a manual assembly task. Our results showed that there was no difference between AR-, VR- and video-based training concerning the objective performance measures task completion time and error count. However, in the subjective evaluations VR-based training showed a significantly higher perceived task load and a lower usability rating than the AR- and video-based training regimes. An exploratory analysis additionally revealed partially better results for AR than for VR after adjusting the data for the age of the participants. Future research should further investigate the advantage of AR- and video-based methods over VR when the age and technology experience of participants are taken into account.}
}
@article{ZHANG2015227,
title = {Effective staging of fibrosis by the selected texture features of liver: Which one is better, CT or MR imaging?},
journal = {Computerized Medical Imaging and Graphics},
volume = {46},
pages = {227-236},
year = {2015},
note = {Information Technologies in Biomedicine},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2015.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0895611115001251},
author = {Xuejun Zhang and Xin Gao and Brent J. Liu and Kevin Ma and Wen Yan and Long Liling and Huang Yuhong and Hiroshi Fujita},
abstract = {Purpose
Texture patterns of hepatic fibrosis are one of the important biomarkers to diagnose and classify chronic liver disease from initial to end stage on computed tomography (CT) or magnetic resonance (MR) images. Computer-aided diagnosis (CAD) of liver cirrhosis using texture features has become popular in recent research advances. To date, however, properly selecting effective texture features and image parameters is still mostly undetermined and not well-defined. In this study, different types of datasets acquired from CT and MR images are investigated to select the optimal parameters and features for the proper classification of fibrosis.
Methods
A total of 149 patients were scanned by multi-detector computed tomography (MDCT) and 218 patients were scanned using 1.5T and 3T superconducting MR scanners for an abdominal examination. All cases were verified by needle biopsies as the gold standard of our experiment, ranging from 0 (no fibrosis) to 5 (cirrhosis). For each case, at least four sequenced phase images are acquired by CT or MR scanners: pre-contrast, arterial, portal venous and equilibrium phase. For both imaging modalities, 15 texture features calculated from gray level co-occurrence matrix (GLCM) are extracted within an ROI in liver as one set of input vectors. Each combination of these input subsets is checked by using support vector machine (SVM) with leave-one-case-out method to differentiate fibrosis into two groups: non-cirrhosis or cirrhosis. In addition, 10 ROIs in the liver are manually selected in a disperse manner by experienced radiologist from each sequenced image and each of the 15 features are averaged across the 10 ROIs for each case to reduce the validation time. The number of input items is selected from the various combinations of 15 features, from which the accuracy rate (AR) is calculated by counting the percentage of correct answers on each combination of features aggregated to determine a liver stage score and then compared to the gold standard.
Results
According to the accuracy rate (AR) calculated from each combination, the optimal number of texture features to classify liver fibrosis degree ranges from 4 to 7, no matter which modality was utilized. The overall performance calculated by the average sum of maximum AR value of all 15 features is 66.83% in CT images, while 68.14%, and 71.98% in MR images, respectively; among the 15 texture features, mean gray value and entropy are the most commonly used features in all 3 imaging datasets. The correlation feature has the lowest AR value and was removed as an effective feature in all datasets. AR value tends to increase with the injection of contrast agency, and both CT and MR images reach the highest AR performance during the equilibrium phase.
Conclusions
Comparing the accuracy of classification with two imaging modalities, the MR images have an advantage over CT images with regards to AR performance of the 15 selected texture features, while 3T MRI is better than 1.5T MRI to classify liver fibrosis. Finally, the texture analysis is more effective during equilibrium phase than in any of the other phased images.}
}
@article{PUYOLANTON201796,
title = {A multimodal spatiotemporal cardiac motion atlas from MR and ultrasound data},
journal = {Medical Image Analysis},
volume = {40},
pages = {96-110},
year = {2017},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2017.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S1361841517300890},
author = {Esther Puyol-Antón and Matthew Sinclair and Bernhard Gerber and Mihaela Silvia Amzulescu and Hélène Langet and Mathieu De Craene and Paul Aljabar and Paolo Piro and Andrew P. King},
keywords = {Cardiac motion atlas, Multi-view dimensionality reduction},
abstract = {Cardiac motion atlases provide a space of reference in which the motions of a cohort of subjects can be directly compared. Motion atlases can be used to learn descriptors that are linked to different pathologies and which can subsequently be used for diagnosis. To date, all such atlases have been formed and applied using data from the same modality. In this work we propose a framework to build a multimodal cardiac motion atlas from 3D magnetic resonance (MR) and 3D ultrasound (US) data. Such an atlas will benefit from the complementary motion features derived from the two modalities, and furthermore, it could be applied in clinics to detect cardiovascular disease using US data alone. The processing pipeline for the formation of the multimodal motion atlas initially involves spatial and temporal normalisation of subjects’ cardiac geometry and motion. This step was accomplished following a similar pipeline to that proposed for single modality atlas formation. The main novelty of this paper lies in the use of a multi-view algorithm to simultaneously reduce the dimensionality of both the MR and US derived motion data in order to find a common space between both modalities to model their variability. Three different dimensionality reduction algorithms were investigated: principal component analysis, canonical correlation analysis and partial least squares regression (PLS). A leave-one-out cross validation on a multimodal data set of 50 volunteers was employed to quantify the accuracy of the three algorithms. Results show that PLS resulted in the lowest errors, with a reconstruction error of less than 2.3 mm for MR-derived motion data, and less than 2.5  mm for US-derived motion data. In addition, 1000 subjects from the UK Biobank database were used to build a large scale monomodal data set for a systematic validation of the proposed algorithms. Our results demonstrate the feasibility of using US data alone to analyse cardiac function based on a multimodal motion atlas.}
}
@article{JONES20081629,
title = {Nanostructure and paramagnetic centres in diamond-like carbon: Effect of Ar dilution in PECVD process},
journal = {Diamond and Related Materials},
volume = {17},
number = {7},
pages = {1629-1632},
year = {2008},
note = {Proceedings of Diamond 2007, the 18th European Conference on Diamond, Diamond-Like Materials, Carbon Nanotubes, Nitrides and Silicon Carbide},
issn = {0925-9635},
doi = {https://doi.org/10.1016/j.diamond.2008.02.025},
url = {https://www.sciencedirect.com/science/article/pii/S092596350800191X},
author = {B.J. Jones and S. Wright and R.C. Barklie and J. Tyas and J. Franks and A.J. Reynolds},
keywords = {Diamond-like carbon, Plasma CVD, Defects, Paramagnetic resonance, Surface characterization},
abstract = {Diamond-like carbon (DLC) films were deposited utilising plasma enhanced chemical vapour deposition (PECVD) with acetylene precursor, diluted with 0–45% argon. Electron paramagnetic resonance (EPR) measurements show the presence of one paramagnetic centre with no change in spin population over the range of film deposition conditions. However, the EPR linewidth decreases with increasing argon content of the precursor mix, suggesting an enhancement of motional narrowing due to an increase in electron delocalization, related to an increase in the sp2 cluster size. Atomic force microscopy (AFM) measurements indicate that the surface of the DLC is formed of nanoscale asperities of material. With radii of tens of nanometres for films deposited with zero argon, the size of the features increases with the argon dilution of the acetylene. Energy dispersive X-ray analysis and electrical measurements further elucidate the changes in film structure.}
}
@article{KONAR2020106348,
title = {A Quantum-Inspired Self-Supervised Network model for automatic segmentation of brain MR images},
journal = {Applied Soft Computing},
volume = {93},
pages = {106348},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106348},
url = {https://www.sciencedirect.com/science/article/pii/S156849462030288X},
author = {Debanjan Konar and Siddhartha Bhattacharyya and Tapan Kr. Gandhi and Bijaya Ketan Panigrahi},
keywords = {Quantum computing, Medical image segmentation, Fully Convolutional Neural Network, QIBDS Net, U-Net},
abstract = {The classical self-supervised neural network architectures suffer from slow convergence problem and incorporation of quantum computing in classical self-supervised networks is a potential solution towards it. In this article, a fully self-supervised novel quantum-inspired neural network model referred to as Quantum-Inspired Self-Supervised Network (QIS-Net) is proposed and tailored for fully automatic segmentation of brain MR images to obviate the challenges faced by deeply supervised Convolutional Neural Network (CNN) architectures. The proposed QIS-Net architecture is composed of three layers of quantum neuron (input, intermediate and output) expressed as qbits. The intermediate and output layers of the QIS-Net architecture are inter-linked through bi-directional propagation of quantum states, wherein the image pixel intensities (quantum bits) are self-organized in between these two layers without any external supervision or training. Quantum observation allows to obtain the true output once the superimposed quantum states interact with the external environment. The proposed self-supervised quantum-inspired network model has been tailored for and tested on Dynamic Susceptibility Contrast (DSC) brain MR images from Nature data sets for detecting complete tumor and reported promising accuracy and reasonable dice similarity scores in comparison with the unsupervised Fuzzy C-Means clustering, self-trained QIBDS Net, Opti-QIBDS Net, deeply supervised U-Net and Fully Convolutional Neural Networks (FCNNs).}
}
@article{TIAN201596,
title = {Handling occlusions in augmented reality based on 3D reconstruction method},
journal = {Neurocomputing},
volume = {156},
pages = {96-104},
year = {2015},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2014.12.081},
url = {https://www.sciencedirect.com/science/article/pii/S0925231215000065},
author = {Yuan Tian and Yan Long and Dan Xia and Huang Yao and Jincheng Zhang},
keywords = {Augmented reality, Occlusion handling, 3D reconstruction},
abstract = {The correct relationships between real and virtual objects are of utmost importance to a realistic augmented reality system, in which the occlusion handling method should be able to estimate the spatial relationships between real and virtual objects, as well as handle the mutual occlusion automatically in real-time. To accomplish the above tasks simultaneously, we propose a novel occlusion handling method based on 3D reconstruction, which consists of offline stage and online stage. In the offline stage, we get the depth map of the real scene using a low cost RGB-D camera. Then the 3D coordinate of each point in the global coordinate system are obtained and will be used in the online occlusion handling stage. In the online stage, we design a GPU based 3D point clouds alignment method by using point to tangent plane distance as error metric to accelerate the convergence speed and reduce the iterations. The correct relationships between real and virtual objects are then obtained automatically by comparing each pixel’s Z coordinate value of real objects with that of virtual objects in a smaller region to achieve real-time performance. More specifically, we can judge and handle the mutual occlusion without human interactivity in real time, and experimental results prove its effectiveness.}
}
@article{WANG2023102249,
title = {DC-cycleGAN: Bidirectional CT-to-MR synthesis from unpaired data},
journal = {Computerized Medical Imaging and Graphics},
volume = {108},
pages = {102249},
year = {2023},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2023.102249},
url = {https://www.sciencedirect.com/science/article/pii/S0895611123000678},
author = {Jiayuan Wang and Q.M. Jonathan Wu and Farhad Pourpanah},
keywords = {Medical image synthesis, Generative adversarial network, Cycle consistency loss, Magnetic resonance, Computed tomography images},
abstract = {Magnetic resonance (MR) and computer tomography (CT) images are two typical types of medical images that provide mutually-complementary information for accurate clinical diagnosis and treatment. However, obtaining both images may be limited due to some considerations such as cost, radiation dose and modality missing. Recently, medical image synthesis has aroused gaining research interest to cope with this limitation. In this paper, we propose a bidirectional learning model, denoted as dual contrast cycleGAN (DC-cycleGAN), to synthesize medical images from unpaired data. Specifically, a dual contrast loss is introduced into the discriminators to indirectly build constraints between real source and synthetic images by taking advantage of samples from the source domain as negative samples and enforce the synthetic images to fall far away from the source domain. In addition, cross-entropy and structural similarity index (SSIM) are integrated into the DC-cycleGAN in order to consider both the luminance and structure of samples when synthesizing images. The experimental results indicate that DC-cycleGAN is able to produce promising results as compared with other cycleGAN-based medical image synthesis methods such as cycleGAN, RegGAN, DualGAN, and NiceGAN. Code is available at https://github.com/JiayuanWang-JW/DC-cycleGAN.}
}
@article{MAKRIS2012147,
title = {Semantic-based taxonomy for immersive product design using VR techniques},
journal = {CIRP Annals},
volume = {61},
number = {1},
pages = {147-150},
year = {2012},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2012.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0007850612000108},
author = {Sotiris Makris and Loukas Rentzos and George Pintzos and Dimitris Mavrikios and George Chryssolouris},
keywords = {Design, Virtual reality, Prototyping},
abstract = {This work focuses on the design of products related to the aircraft industry. It combines the functionalities and features of an immersive simulation environment, for product design and review, with the existing knowledge about such products and their components. Effort is put in augmenting simulation and design knowledge on virtual geometries, through XML syntax. An immersive environment is developed, which enables the user to design and review a virtual product through highly usable interfaces coupled with product semantics. The semantics are based on a taxonomy defined by certain characteristics/properties of the geometrical objects and the environment. The concept and implementation is tested in an aircraft cabin design use-case.}
}
@article{WANG2024113244,
title = {Effects of oxygen enrichment on diesel spray flame soot formation in O2/Ar atmosphere},
journal = {Combustion and Flame},
volume = {260},
pages = {113244},
year = {2024},
issn = {0010-2180},
doi = {https://doi.org/10.1016/j.combustflame.2023.113244},
url = {https://www.sciencedirect.com/science/article/pii/S0010218023006181},
author = {Yu Wang and Haifeng Liu and Lei Feng and Noud Maes and Tiegang Fang and Yanqing Cui and Wentao Yi and Bart Somers and Mingfa Yao},
keywords = {Oxygen-enriched combustion, Diesel spray flames, Argon dilution, Two-color pyrometry, Soot, Two-stage Lagrangian (TSL) simulations},
abstract = {In this study, diesel spray combustion at oxygen-enriched conditions (oxygen volume fraction of 21–70 %) with argon dilution is experimentally investigated in a constant-volume combustion chamber. Optical diagnostics are employed to study flame development, stabilization, and soot formation at oxygen-enriched conditions. To further verify the experimental observations, two-stage Lagrangian simulations are used to analyze the effects of oxygen on the formation and oxidation of soot precursors, polycyclic aromatic hydrocarbons. Results show that replacing nitrogen in air by argon leads to a 50 % reduction of the flame lift-off length, an increased soot flame temperature by 300 K, and higher soot concentrations. Flame morphology and structure still follow the classic conventional diesel combustion model in the oxygen range of 21–40 %, while changes are observed when oxygen levels are higher than 50 %. The width and length of the soot flame are shortened, and chemiluminescence from intermediate species like CO dominates the flame natural luminosity at the spray head, where the flame temperature reaches near 3000 K. Soot reduction mechanisms at high-degree oxygen-enrichment conditions are investigated. The intrinsic mixing-limited combustion of diesel sprays leads to unavoidable fuel-rich areas locally, but the shortened flame lift-off length and sufficient oxygen supply confines soot-forming conditions to a smaller, upstream region. The residence time of fuel parcels in this confined soot-forming area is shortened due to the larger local spray velocity. Thereafter, fuel parcels enter a high-temperature fuel-lean region, where the formed soot is oxidized rapidly.}
}
@article{TAHWIA2024136422,
title = {Durability and ecological assessment of low-carbon high-strength concrete with short AR-glass fibers: Effects of high-volume of solid waste materials},
journal = {Construction and Building Materials},
volume = {429},
pages = {136422},
year = {2024},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2024.136422},
url = {https://www.sciencedirect.com/science/article/pii/S0950061824015630},
author = {Ahmed M. Tahwia and Abdelrahman k. Elmansy and Mohamed Abdellatief and Mohamed Abd Elrahman},
keywords = {Ceramic waste powder, Glass powder, Granite waste powder, Durability, CO2 emission},
abstract = {The goal of this research is to improve the mechanical characteristics and durability of concrete while adhering to green and sustainable development principles. Portland cement (PC) was replaced with ceramic waste powder (CWP), glass powder (GP), and granite waste powder (GWP) to create the low-carbon, high-strength concrete (HSC). These materials were incorporated at 0–50% as a partial replacement of PC. The short alkali-resistant (AR-) glass fiber content was added by 1.0% of the PC content. The changes in strength, microstructure, pore structure, as well as ecological assessment of HSCs was investigated. Various experiments on the durability properties and elevated temperature resistance of HSC were performed. The experimental results show that mechanical properties of HSC with 10%GP and 20%GWP were maximally enhanced at 28d, while the mechanical properties of HSC with 50% of all wastes are decreased. It was found also that HSC containing CWP showed significant reductions in carbonation depth (up to 65.89% lower than the control mixture), especially at higher replacement levels. Furthermore, the increment in substitution level of CWP has found an increment in pore volume, resulting in a reduction in preliminary strength performance. It was observed that a 50% substitution level of GP and GWP reduced the water penetration depth by 47.71% and 65.7% compared to the control mixture, respectively. The residual strength after 600 °C exposure for 10%CWP, 10% GP, and 20% GWP retained about 34.10%, 32.32%, and 43.29%, respectively, from their original strength. XRD tests and SEM micrographs showed that adding 10%GP and 20%GWP improve the hydration reactions. Finally, environmental assessments revealed that incorporating CWP, GP, and GWP into HSC led to reduced costs, energy consumption, and carbon footprint.}
}
@article{GIBIINO20132256,
title = {Structured errors in reconstruction methods for Non-Cartesian MR data},
journal = {Computers in Biology and Medicine},
volume = {43},
number = {12},
pages = {2256-2262},
year = {2013},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2013.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0010482513003004},
author = {Fabio Gibiino and Vincenzo Positano and Florian Wiesinger and Giulio Giovannetti and Luigi Landini and Maria Filomena Santarelli},
keywords = {Magnetic resonance imaging, Autocorrelation, Image structures, Non-Cartesian MRI reconstruction, Hyperpolarized C},
abstract = {Background
Reconstruction methods for Non-Cartesian magnetic resonance imaging have often been analyzed using the root mean square error (RMSE). However, RMSE is not able to measure the level of structured error associated with the reconstruction process.
Methods
An index for geometric information loss was presented using the 2D autocorrelation function. The performances of Least Squares Non Uniform Fast Fourier Transform (LS-NUFFT) and gridding reconstruction (GR) methods were compared. The Direct Summation method (DS) was used as reference. For both methods, RMSE and the loss in geometric information were calculated using a digital phantom and a hyperpolarized 13C dataset.
Results
The performance of the geometric information loss index was analyzed in the presence of noise. Comparing to GR, LS-NUFFT obtained a lower RMSE, but its error image appeared more structured. This was observed in both phantom and in vivo experiments.
Discussion
The evaluation of geometric information loss together with the reconstruction error was important for an appropriate performance analysis of the reconstruction methods. The use of geometric information loss was helpful to determine that LS-NUFFT loses relevant information in the reconstruction process, despite the low RMSE.}
}
@article{NEGUT2016414,
title = {Task difficulty of virtual reality-based assessment tools compared to classical paper-and-pencil or computerized measures: A meta-analytic approach},
journal = {Computers in Human Behavior},
volume = {54},
pages = {414-424},
year = {2016},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.08.029},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215301059},
author = {Alexandra Neguţ and Silviu-Andrei Matu and Florin Alin Sava and Daniel David},
keywords = {Virtual reality, Neuropsychological assessment, Task difficulty},
abstract = {Virtual reality-based assessment tools arise as a promising alternative for classic neuropsychological assessment with an increased level of ecological validity. Because virtual reality cognitive measures recreate tasks that resemble with the demands from the real world it is assumed that they require additional cognitive resources and are more difficult than classical paper-and-pencil or computerized measures. Although research has focused on comparing the performance obtained on virtual reality-based measures with classical paper-and-pencil or computerized measures, no meta-analysis has been conducted on this topic. Thirteen studies met our inclusion criteria: assessed any cognitive process using virtual reality and analogous classical or computerized assessment tools of the same process. Based on a random effects model, the results indicated a moderate effect size in favor of classical and computerized tests (g = −0.77) revealing an increased task difficulty in virtual reality. Overall, results from the current meta-analysis point out that cognitive performance obtained in virtual reality is poorer than the one in classical or computerized assessment which might suggest that tasks embedded in virtual reality have an increased level of complexity and difficulty and require additional cognitive resources.}
}
@article{ALKAN2014861,
title = {Comparative MR image analysis for thyroid nodule detection and quantification},
journal = {Measurement},
volume = {47},
pages = {861-868},
year = {2014},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2013.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S026322411300496X},
author = {Ahmet Alkan and Seda Arslan Tuncer and Mucahid Gunay},
keywords = {Thyroid nodule, RBAC, SSRG, CC, ZSI, AER, OE},
abstract = {Nodular disease of the thyroid gland is widespread that affects more women than men. The term thyroid nodule refers to any abnormal growth that forms a lump in the thyroid gland which is located low in the front of the neck, below the Adam’s apple. It is shaped like a butterfly and wraps around the windpipe or trachea. In this paper, we have proposed two segmentation methods for thyroid nodule detection by using magnetic resonance imaging (MRI). These methods are region based active contour (RBAC) and single seeded region growing (SSRG) methods. The pre-processed MR images are segmented and obtained cross sectional areas of nodules are compared with those which are manually identified nodule areas by trained readers. Detection success of both methods is calculated by comparing their segmentation results with the manually obtained one. For this purpose, Correlation Coefficient (CC) and Zijdenbos Similarity Index (ZSI) have been used to have accuracy measures of two methods. Although both methods have acceptable ZSI values, RBAC method has yielded (average 0.938) higher ZSI values than SSRG method (average 0.906). Similar results are obtained by calculating average cross-correlation values (RBAC method: 0.919 and SSRG: 0.911). Also two error analysis methods, namely Area Error Rate (AER) and Overlap Error (OE) rate employed. RBAC method has yielded (average error rate 9.3%) lower AER values than SSRG method (average error rate 18%). Similar results are obtained by calculating average error rate values (RBAC method: 8.9% and SSRG: 16.3%) by using OE. According to the analysis results it can be concluded that RBAC method gives better segmentation accuracy rates in MRI thyroid nodule detection. High accuracy rates are achieved with the algorithms implies that the proposed study can be suitable and have high capability to be used as an image extraction technique that would assist radiologists and otorhinolaryngologists in the thyroid nodule screening by providing accurate value of size.}
}
@article{FANG2022102292,
title = {Distributed cognition based localization for AR-aided collaborative assembly in industrial environments},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {75},
pages = {102292},
year = {2022},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2021.102292},
url = {https://www.sciencedirect.com/science/article/pii/S0736584521001721},
author = {Wei Fang and Wei Fan and Wei Ji and Lei Han and Shuhong Xu and Lianyu Zheng and Lihui Wang},
keywords = {Distributed localization, Augmented reality, Collaborative AR assembly, Scene cognition},
abstract = {The existing (augmented reality) AR-aided assembly is highly associated with AR devices, which mainly provides guidance for one operator, and it is hard to share augmented assembly instructions for large-scale products which require multiple operators working together. To address this problem, the paper proposes a distributed cognition based localization method for AR-aided collaborative assembly. Firstly, a scene cognition using multi-view acquisition about industrial environments is performed with incremental modeling in advance, providing the foundation for the subsequent pose estimate of multi-AR clients. Then, based on feature extracting and matching against the pre-built shop floor model, a pose recovery of AR-aided system is derived from different views of AR operators in a global coordinate system, followed by a distributed motion tracking with the complementary features of visual and inertial data, resulting in a co-located collaborative AR instruction for assembly. Finally, experiments are carried out to validate the proposed method, and experimental results illustrate that the proposed method can achieve distributed cognition-based localization accurately and robustly. Therefore, shared visual communications among multiple operators are synchronized, and assembly status is aware by all the operators.}
}
@article{KANG20112228,
title = {Ar-glass filament material law for arbitrary quasi-static long-term loading},
journal = {Construction and Building Materials},
volume = {25},
number = {5},
pages = {2228-2239},
year = {2011},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2010.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0950061810005192},
author = {Bong-Gu Kang and Joachim Hannawald and Wolfgang Brameshuber},
keywords = {Textile reinforced concrete, Filament tensile test, Long-term loading, Cyclic loading, Strength degradation, Strength degradation simulation, Parameter identification, Hybrid optimisation},
abstract = {The tensile load carrying behaviour of filaments made of alkali-resistant glass, which is the basic component of textile reinforcements used for textile reinforced concrete, was analysed for quasi-static long-term loading. Therefore, tensile tests under cyclic and constant long-term loading at different stress levels, different loading rates and different loading amplitudes were carried out. A strength degradation, which led in some cases to a failure of the specimens during the long-term load, could be observed. A strength degradation model was introduced, whereas different approaches were considered. The model parameters were identified from the experimental data using a hybrid optimisation method. As a direct application of the determined strength degradation law, the fatigue strength limit was calculated for different loading rates.}
}
@article{SPINNER2021102144,
title = {Bayesian inference using hierarchical and spatial priors for intravoxel incoherent motion MR imaging in the brain: Analysis of cancer and acute stroke},
journal = {Medical Image Analysis},
volume = {73},
pages = {102144},
year = {2021},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2021.102144},
url = {https://www.sciencedirect.com/science/article/pii/S1361841521001900},
author = {Georg Ralph Spinner and Christian Federau and Sebastian Kozerke},
keywords = {Intravoxel incoherent motion imaging, Bayesian inference, Cancer, Acute stroke},
abstract = {The intravoxel incoherent motion (IVIM) model allows to map diffusion (D) and perfusion-related parameters (F and D*). Parameter estimation is, however, error-prone due to the non-linearity of the signal model, the limited signal-to-noise ratio (SNR) and the small volume fraction of perfusion in the in-vivo brain. In the present work, the performance of Bayesian inference was examined in the presence of brain pathologies characterized by hypo- and hyperperfusion. In particular, a hierarchical and a spatial prior were combined. Performance was compared relative to conventional segmented least squares regression, hierarchical prior only (non-segmented and segmented data likelihoods) and a deep learning approach. Realistic numerical brain IVIM simulations were conducted to assess errors relative to ground truth. In-vivo, data of 11 central nervous system cancer patients and 9 patients with acute stroke were acquired. The proposed method yielded reduced error in simulations for both the cancer and acute stroke scenarios compared to other methods across the whole investigated SNR range. The contrast-to-noise ratio of the proposed method was better or on par compared to the other techniques in-vivo. The proposed Bayesian approach hence improves IVIM parameter estimation in brain cancer and acute stroke.}
}
@article{ZHU2022105091,
title = {A neuroendoscopic navigation system based on dual-mode augmented reality for minimally invasive surgical treatment of hypertensive intracerebral hemorrhage},
journal = {Computers in Biology and Medicine},
volume = {140},
pages = {105091},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.105091},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521008854},
author = {Tao Zhu and Shan Jiang and Zhiyong Yang and Zeyang Zhou and Yuhua Li and Shixing Ma and Jie Zhuo},
keywords = {Augmented reality, Image-guided intervention, Computer assisted surgery, Neuroendoscopic surgery, Hypertensive intracerebral hemorrhage},
abstract = {Background and objective
Hypertensive intracerebral hemorrhage is characterized by a high rate of morbidity, mortality, disability and recurrence. Neuroendoscopy has been utilized for treatment as an advanced technology. However, traditional neuroendoscopy allows professionals to see only tissue surfaces, and the field of vision is limited, which cannot provide spatial guidance. In this study, an AR-based neuroendoscopic navigation system is proposed to assist surgeons in locating and clearing hematoma.
Methods
The neuroendoscope can be registered through the vector closed loop algorithm. The single-shot method is designed to register medical images with patients precisely. Real-time AR is realized based on video stream fusion. Dual-mode AR navigation is proposed to provide comprehensive guidance from catheter implantation to hematoma removal. A series of experiments is designed to validate the accuracy and significance of this system.
Results
The average root mean square error of the registration between medical images and patients is 0.784 mm, and the variance is 0.1426 mm. The pixel mismatching degrees are less than 1% in different AR modes. In catheter implantation experiments, the average error of distance is 1.28 mm, and the variance is 0.43 mm, while the average error of angles is 1.34°, and the variance is 0.45°. Comparative experiments are also conducted to evaluate the feasibility of this system.
Conclusion
This system can provide stereo images with depth information fused with patients to guide surgeons to locate targets and remove hematoma. It has been validated to have high accuracy and feasibility.}
}
@article{GHASSEMI2020101678,
title = {Deep neural network with generative adversarial networks pre-training for brain tumor classification based on MR images},
journal = {Biomedical Signal Processing and Control},
volume = {57},
pages = {101678},
year = {2020},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2019.101678},
url = {https://www.sciencedirect.com/science/article/pii/S1746809419302599},
author = {Navid Ghassemi and Afshin Shoeibi and Modjtaba Rouhani},
keywords = {Magnetic resonance imaging (MRI), Deep neural networks, Generative adversarial network (GAN), Brain tumor classification},
abstract = {In this paper, a new deep learning method for tumor classification in MR images is presented. A deep neural network is first pre-trained as a discriminator in a generative adversarial network (GAN) on different datasets of MR images to extract robust features and to learn the structure of MR images in its convolutional layers. Then the fully connected layers are replaced and the whole deep network is trained as a classifier to distinguish three tumor classes. The deep neural network classifier has six layers and about 1.7 million weight parameters. Pre-training as a discriminator of a GAN together with other techniques such as data augmentations (image rotation and mirroring) and dropout prevent the network from overtraining on a relatively small dataset. This method is applied to an MRI data set consists of 3064 T1-CE MR images from 233 patients, 13 images from each patient on average, with three different brain tumor types: meningioma (708 images), glioma (1426 images), and pituitary tumor (930 images). 5-Fold cross-validation is used to evaluate the performance of overall design, achieving the highest accuracy as compared to state-of-art methods.}
}
@article{KHORSHIDI20112359,
title = {New autoregressive (AR) order selection criteria based on the prediction error estimation},
journal = {Signal Processing},
volume = {91},
number = {10},
pages = {2359-2370},
year = {2011},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2011.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0165168411001319},
author = {S. Khorshidi and M. Karimi and A.R. Nematollahi},
keywords = {Autoregressive model order selection, Prediction error, Least-Squares-Forward method},
abstract = {The most important problem in data modeling using the AR model is the order selection. Some AR order selection criteria estimate the prediction error and choose the order that minimizes this estimated prediction error. All of these criteria use the same formula for estimating the prediction error from the residual variance for all AR models. However, experimental results show that the relationship between the prediction error and the residual variance depends on the AR model. In this paper, we introduce new formulas for estimating the prediction error using the residual variance. These formulas depend on the AR model, and are obtained through assuming a white Gaussian noise as the input noise to the AR model and assuming that the least-squares-forward (LSF) method is used for estimating the AR coefficients. The performance of the new order selection criteria introduced in this paper is compared with other AR order selection criteria using simulated data. Results show that the new criteria have good performance in estimating the prediction error and in selecting an appropriate order for the AR model.}
}
@article{MIAO2020105132,
title = {Virtual reality-based measurement of ocular deviation in strabismus},
journal = {Computer Methods and Programs in Biomedicine},
volume = {185},
pages = {105132},
year = {2020},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2019.105132},
url = {https://www.sciencedirect.com/science/article/pii/S0169260719309733},
author = {Yinan Miao and Jun Young Jeon and Gyuhae Park and Sang Woo Park and Hwan Heo},
keywords = {Virtual reality, Pupil tracking, Computer vision, Strabismus, Cover tests},
abstract = {Background and objective
Strabismus is an eye movement disorder in which shows the abnormal ocular deviation. Cover tests have mainly been used in the clinical diagnosis of strabismus for treatment. However, the whole process depends on the doctor's level of experience, which could be subjected to several factors. In this study, an automated technique for measurement of ocular deviation using a virtual reality (VR) device is developed.
Methods
A VR display system in which the screens that have the fixation target are changed alternately between on and off stages is used to simulate the normal strabismus diagnosis steps. Patients watch special-designed 3D scenes, and their eye motions are recorded by two infrared (IR) cameras. An image-processing-based pupil tracking technique is then applied to track their eye movement. After recording eye motion, two strategies for strabismus angle estimation are implemented: direct measurement and stepwise approximation. The direct measurement converts the eye movement to a strabismus angle after considering the eyeball diameter, while the stepwise approximation measures the ocular deviation through the feedback calibration process.
Results
Experiments are carried out with various strabismus patients. The results are compared to those of their doctors’ measurement, which shows good agreement.
Conclusions
The results clearly indicate that these techniques could identify ocular deviation with high accuracy and efficiency. The proposed system can be applied in small space and has high tolerance for the unexpected head movements compared with other camera-based system.}
}
@article{TONG2017345,
title = {Retrospective 4D MR image construction from free-breathing slice Acquisitions: A novel graph-based approach},
journal = {Medical Image Analysis},
volume = {35},
pages = {345-359},
year = {2017},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2016.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S136184151630130X},
author = {Yubing Tong and Jayaram K. Udupa and Krzysztof C. Ciesielski and Caiyun Wu and Joseph M. McDonough and David A. Mong and Robert M. Campbell},
keywords = {Dynamic MRI, 4D image construction, Path optimization, Lung imaging, Thoracic insufficiency syndrome},
abstract = {Purpose
Dynamic or 4D imaging of the thorax has many applications. Both prospective and retrospective respiratory gating and tracking techniques have been developed for 4D imaging via CT and MRI. For pediatric imaging, due to radiation concerns, MRI becomes the de facto modality of choice. In thoracic insufficiency syndrome (TIS), patients often suffer from extreme malformations of the chest wall, diaphragm, and/or spine with inability of the thorax to support normal respiration or lung growth (Campbell et al., 2003, Campbell and Smith, 2007), as such patient cooperation needed by some of the gating and tracking techniques are difficult to realize without causing patient discomfort and interference with the breathing mechanism itself. Therefore (ventilator-supported) free-breathing MRI acquisition is currently the best choice for imaging these patients. This, however, raises a question of how to create a consistent 4D image from such acquisitions. This paper presents a novel graph-based technique for compiling the best 4D image volume representing the thorax over one respiratory cycle from slice images acquired during unencumbered natural tidal-breathing of pediatric TIS patients.
Methods
In our approach, for each coronal (or sagittal) slice position, images are acquired at a rate of about 200–300ms/slice over several natural breathing cycles which yields over 2000 slices. A weighted graph is formed where each acquired slice constitutes a node and the weight of the arc between two nodes defines the degree of contiguity in space and time of the two slices. For each respiratory phase, an optimal 3D spatial image is constructed by finding the best path in the graph in the spatial direction. The set of all such 3D images for a given respiratory cycle constitutes a 4D image. Subsequently, the best 4D image among all such constructed images is found over all imaged respiratory cycles. Two types of evaluation studies are carried out to understand the behavior of this algorithm and in comparison to a method called Random Stacking – a 4D phantom study and 10 4D MRI acquisitions from TIS patients and normal subjects. The 4D phantom was constructed by 3D printing the pleural spaces of an adult thorax, which were segmented in a breath-held MRI acquisition.
Results
Qualitative visual inspection via cine display of the slices in space and time and in 3D rendered form showed smooth variation for all data sets constructed by the proposed method. Quantitative evaluation was carried out to measure spatial and temporal contiguity of the slices via segmented pleural spaces. The optimal method showed smooth variation of the pleural space as compared to Random Stacking whose behavior was erratic. The volumes of the pleural spaces at the respiratory phase corresponding to end inspiration and end expiration were compared to volumes obtained from breath-hold acquisitions at roughly the same phase. The mean difference was found to be roughly 3%.
Conclusions
The proposed method is purely image-based and post-hoc and does not need breath holding or external surrogates or instruments to record respiratory motion or tidal volume. This is important and practically warranted for pediatric patients. The constructed 4D images portray spatial and temporal smoothness that should be expected in a consistent 4D volume. We believe that the method can be routinely used for thoracic 4D imaging.}
}
@article{POLVI201633,
title = {SlidAR: A 3D positioning method for SLAM-based handheld augmented reality},
journal = {Computers & Graphics},
volume = {55},
pages = {33-43},
year = {2016},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2015.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0097849315001806},
author = {Jarkko Polvi and Takafumi Taketomi and Goshiro Yamamoto and Arindam Dey and Christian Sandor and Hirokazu Kato},
keywords = {Handheld augmented reality, 3D manipulation, 3D positioning, SLAM, User evaluation},
abstract = {Handheld Augmented Reality (HAR) has the potential to introduce Augmented Reality (AR) to large audiences due to the widespread use of suitable handheld devices. However, many of the current HAR systems are not considered very practical and they do not fully answer to the needs of the users. One of the challenging areas in HAR is the in-situ AR content creation where the correct and accurate positioning of virtual objects to the real world is fundamental. Due to the hardware limitations of handheld devices and possible restrictions in the environment, the correct 3D positioning of objects can be difficult to achieve we are unable to use AR markers or correctly map the 3D structure of the environment. We present SlidAR, a 3D positioning for Simultaneous Localization And Mapping (SLAM) based HAR systems. SlidAR utilizes 3D ray-casting and epipolar geometry for virtual object positioning. It does not require a perfect 3D reconstruction of the environment nor any virtual depth cues. We have conducted a user experiment to evaluate the efficiency of SlidAR method against an existing device-centric positioning method that we call HoldAR. Results showed that SlidAR was significantly faster, required significantly less device movement, and also got significantly better subjective evaluation from the test participants. SlidAR also had higher positioning accuracy, although not significantly.}
}
@article{QIN2021101620,
title = {Attractiveness of game elements, presence, and enjoyment of mobile augmented reality games: The case of Pokémon Go},
journal = {Telematics and Informatics},
volume = {62},
pages = {101620},
year = {2021},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2021.101620},
url = {https://www.sciencedirect.com/science/article/pii/S0736585321000599},
author = {Yan Qin},
keywords = {Game enjoyment, Game elements, Presence, Self-determination theory, Mobile AR game, Pokémon Go},
abstract = {Building on the enjoyment-as-need-satisfaction model, this study examines the attractiveness of various game elements of Pokémon Go to its players and the associations among the attractiveness of game elements, players’ need satisfaction, sense of presence, enjoyment, and length of gameplay. Participants (N = 719) who had played Pokémon Go filled out an online survey. A research model with the aforementioned constructs was tested using structural equation modeling. This study found that autonomy- and relatedness-supportive elements associated with autonomy and relatedness need satisfaction of the player, which related to presence significantly. The satisfaction of autonomy and competence needs related to game enjoyment, which influenced gameplay length. Theoretical and practical implications were discussed.}
}
@article{ZENG2019176,
title = {Eye-around vibration haptics on VR immersion improvement},
journal = {Virtual Reality & Intelligent Hardware},
volume = {1},
number = {2},
pages = {176-184},
year = {2019},
note = {Haptic Interaction},
issn = {2096-5796},
doi = {https://doi.org/10.3724/SP.J.2096-5796.2018.0014},
url = {https://www.sciencedirect.com/science/article/pii/S2096579619300154},
author = {Tao ZENG and Keyu WEI and Yanlin YU and Yi ZHAO},
keywords = {VR immersion, Haptics, Eye tactile feedback, Vibration actuator},
abstract = {Due to the inherent shortcomings of the hardware, the immersion of visual interaction between the user and the virtual reality (VR) equipment is greatly reduced. In this paper, effects of eye-around vibration haptics on improving the VR immersion were studied. The vibration was generated by flexible vibrators whose performance was evaluated by a laser vibrometer. Fitting the vibrators on the human eye area at different positions and derived by different waveforms and frequencies of the input signal, the effects of vibration on the human vision and comfort of the users were verified. Then, with the selected input signals and fitting locations, different kinds of vibration were applied on the eye area cooperating with virtual reality images or videos to evaluate the changes of immersion. Research results provide references to the modeling of eye tactile feedback and the design of relevant tactile device in improving the VR immersion.}
}
@article{YEH2014311,
title = {Machine learning-based assessment tool for imbalance and vestibular dysfunction with virtual reality rehabilitation system},
journal = {Computer Methods and Programs in Biomedicine},
volume = {116},
number = {3},
pages = {311-318},
year = {2014},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2014.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0169260714001667},
author = {Shih-Ching Yeh and Ming-Chun Huang and Pa-Chun Wang and Te-Yung Fang and Mu-Chun Su and Po-Yi Tsai and Albert Rizzo},
keywords = {Vestibular dysfunction, Machine learning, Virtual reality, Assessment},
abstract = {Background and objective
Dizziness is a major consequence of imbalance and vestibular dysfunction. Compared to surgery and drug treatments, balance training is non-invasive and more desired. However, training exercises are usually tedious and the assessment tool is insufficient to diagnose patient's severity rapidly.
Methods
An interactive virtual reality (VR) game-based rehabilitation program that adopted Cawthorne–Cooksey exercises, and a sensor-based measuring system were introduced. To verify the therapeutic effect, a clinical experiment with 48 patients and 36 normal subjects was conducted. Quantified balance indices were measured and analyzed by statistical tools and a Support Vector Machine (SVM) classifier.
Results
In terms of balance indices, patients who completed the training process are progressed and the difference between normal subjects and patients is obvious.
Conclusions
Further analysis by SVM classifier show that the accuracy of recognizing the differences between patients and normal subject is feasible, and these results can be used to evaluate patients’ severity and make rapid assessment.}
}
@article{LAATO2021106816,
title = {Why playing augmented reality games feels meaningful to players? The roles of imagination and social experience},
journal = {Computers in Human Behavior},
volume = {121},
pages = {106816},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.106816},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221001394},
author = {Samuli Laato and Sampsa Rauti and A.K.M. Najmul Islam and Erkki Sutinen},
keywords = {Augmented reality, Location-based games, Meaning, Meaningfulness, Imagination, Pokémon GO},
abstract = {Augmented reality (AR) games such as location-based games add virtual content on top of the real world. We investigate why playing these games feels meaningful to players by focusing on the dimensions of imagination and sociality. We theorise a structural model that we test with data collected from a global sample of players of the popular AR game Pokémon GO (N = 515). Our findings show that nostalgic feelings about Pokémon increased imagining AR content in the real world. Surprisingly, using imagination in this way was a much stronger predictor of affection towards the fictional pokémon creatures than nostalgia. The affection towards the fictional creatures, in turn, increased the meaningfulness of playing. Regarding the social factors, community identification and social self-efficacy increased players' sense of meaningfulness of playing. As our study's main design implications, we highlight the importance of socially shared narratives and harnessing the players' imagination to support a sense of meaningfulness of playing.}
}
@article{SU2018462,
title = {Viewing angle enlargement in holographic augmented reality using an off-axis holographic lens},
journal = {Optik},
volume = {172},
pages = {462-469},
year = {2018},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2018.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0030402618309690},
author = {Yanfeng Su and Zhijian Cai and Wenlong Zou and Lingyan Shi and Feng Zhou and Peiliang Guo and Yifan Lu and Jianhong Wu},
keywords = {Holographic display, Spatial light modulators, Viewing angle, Off-axis holographic lens, Augmented reality},
abstract = {In this paper, a viewing angle enlargement method of holographic display using an off-axis holographic lens is proposed, and verification experiment of viewing angle enlargement is developed by using a single spatial light modulator (SLM) and an off-axis holographic lens fabricated by the holographic recording. The experimental results indicate that the viewing angle of holographic reconstructed image is increased to 11.2°, which is about 3.8 times as wide as the original viewing angle formed by the single SLM only. Furthermore, a see-through holographic display system for augmented reality (AR) is constructed, where virtual image is generated by holographic projection. The real scene and the virtual image will fuse together by using the off-axis holographic lens as the image combiner. The results prove that the proposed system can reconstruct virtual three-dimensional (3D) image with correct depth cues, solve the accommodation-vergence conflict problem effectively, and achieve the holographic AR 3D display effect without visual fatigue.}
}
@article{RAJINIKANTH201787,
title = {Entropy based segmentation of tumor from brain MR images – a study with teaching learning based optimization},
journal = {Pattern Recognition Letters},
volume = {94},
pages = {87-95},
year = {2017},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2017.05.028},
url = {https://www.sciencedirect.com/science/article/pii/S0167865517301915},
author = {V. Rajinikanth and Suresh Chandra Satapathy and Steven Lawrence Fernandes and S. Nachiappan},
abstract = {Image processing plays an important role in various medical applications to support the computerized disease examination. Brain tumor, such as glioma is one of the life threatening cancers in humans and the premature diagnosis will improve the survival rate. Magnetic Resonance Image (MRI) is the widely considered imaging practice to record the glioma for the clinical study. Due to its complexity and varied modality, brain MRI needs the automated assessment technique. In this paper, a novel methodology based on meta-heuristic optimization approach is proposed to assist the brain MRI examination. This approach enhances and extracts the tumor core and edema sector from the brain MRI integrating the Teaching Learning Based Optimization (TLBO), entropy value, and level set / active contour based segmentation. The proposed method is tested on the images acquired using the Flair, T1C and T2 modalities. The experimental work is implemented and is evaluated using the CEREBRIX and BRAINIX dataset. Further, TLBO assisted approach is validated on the MICCAI brain tumor segmentation (BRATS) challenge 2012 dataset and achieved better values of Jaccard index, dice co-efficient, precision, sensitivity, specificity and accuracy. Hence the proposed segmentation approach is clinically significant.}
}
@article{DARBYSHIRE2017178,
title = {Manual control during reactivity transients at the VR-1 reactor – I. Disturbance rejection},
journal = {Nuclear Engineering and Design},
volume = {325},
pages = {178-183},
year = {2017},
issn = {0029-5493},
doi = {https://doi.org/10.1016/j.nucengdes.2017.09.025},
url = {https://www.sciencedirect.com/science/article/pii/S0029549317304715},
author = {A.M. Darbyshire and T. Bily and J.S. Hatherall and K.D. Atkinson},
keywords = {Manual control systems, Human engineering, Human response, Reactor control systems},
abstract = {The description of human operator dynamic characteristics in mathematical terms compatible with control engineering practice is an essential prerequisite to the analytical treatment of manual reactor control systems. Safe reactor operation requires effective operator control through interaction with plant dynamics, manipulators and displays. Traditional static analysis methods consider only specific situations; they fail to adequately explain the mutual interactions between the operator and the reactor plant characteristics. In this paper we investigate the cause-and-effect behaviours of three VR-1 research reactor operators during reactivity disturbance experiments, based on the methods of conventional control engineering techniques. The primary purpose of experiments carried out at the VR-1 training reactor and reported in this paper is the validation of a quasi-linear cause-and-effect operator model.}
}
@article{LU2021101685,
title = {Finding the difference: Measuring spatial perception of planning phases of high-rise urban developments in Virtual Reality},
journal = {Computers, Environment and Urban Systems},
volume = {90},
pages = {101685},
year = {2021},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2021.101685},
url = {https://www.sciencedirect.com/science/article/pii/S0198971521000922},
author = {Xi Lu and Adam Tomkins and Sigrid Hehl-Lange and Eckart Lange},
keywords = {Gaze tracking, Virtual reality, Spatial perception, Planning phase, High-rise, Pearl River Delta},
abstract = {Planning is a process in which the contents of planning is gradually refined. However, research in planning communication and perception is often conducted using contrasting scenarios, e.g. by comparing a with/without case. It is not surprising that drastic differences in planning content and representation result in significant differences in perception. Instead, and as a reflection of sequential and gradually evolving projects in planning practice, we are focusing on two planning phases with only subtle differences (2015 and 2018) for a new high-rise development district in Guangzhou. We introduce 3D gaze-tracking and spatial perception experiments to investigate how participants respond to virtual representations of the two planning phases. The results provide implications for planning and design practice and suggest more substantial roles for the general public in participatory planning processes.}
}
@article{POULETAUT2005415,
title = {Automated analysis of MR image of hip: geometrical evaluation of the Legg–Calvé–Perthes disease},
journal = {Medical Engineering & Physics},
volume = {27},
number = {5},
pages = {415-424},
year = {2005},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2004.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S1350453304002000},
author = {P. Pouletaut and I. Claude and R. Winzenrieth and M.-C. Ho Ba Tho and G. Sebag},
keywords = {Pattern recognition, Segmentation, Discriminant analysis, Legg–Calvé–Perthes disease, Hip joint},
abstract = {This study proposes semi-automatic determination of geometrical features in hip magnetic resonance (MR) images in order to evaluate the Legg–Calvé–Perthes disease (LCPD). Nine anatomical points on a hip image are selected by a clinician; then eight geometrical indexes of the hip joint are calculated: acetabulum head index (AHI), Wiberg angle (VCE), inner acetabular coverage angle (VCI), acetabular inclination angle (HTE), femoral shaft-neck angle (CC′D), circularity (C), convex deficiency factor (CDF) and pillar height deficiency factor (HDF) for the head region. The geometrical parameters are evaluated on 46 hip images of young patients with unilateral LCPD: 23 images concern the affected hip and 23 the unaffected hip. The extraction of the region of interest is done with a seeded region growing method. All the data were centered and reduced, and were subjected to principal component analysis. Supervised classification is applied with discriminant analysis and k-nearest neighbours classification. The AHI appears to be the best discriminant attribute (maximum between-class variance ratio). Cross-validation tests indicate that we can at most reduce the parameters to five (AHI, CC′D, DHF, DCF and VCE). The classification error rate for the linear discriminant method is 12.5%.}
}
@article{LUO2024104386,
title = {Fusion of VMD-AR with adaptive Gaussian mixture particle filtering for pedestrian trajectory tracking},
journal = {Digital Signal Processing},
volume = {146},
pages = {104386},
year = {2024},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2024.104386},
url = {https://www.sciencedirect.com/science/article/pii/S1051200424000113},
author = {Yuheng Luo and Jingyun Xu and Zhiduan Cai and Dongming Jiang},
keywords = {Pedestrian target tracking, Particle filtering, Adaptive mixture Gaussian, Variational mode decomposition, Auto-regressive model},
abstract = {Pedestrian target tracking is a key area in computer vision. This paper tackles the problem of low accuracy in conventional pedestrian target tracking by introducing an Adaptive Mixture Gaussian Particle Filter (AMGPF), which integrates Variational Mode Decomposition and autoregressive models. This method builds upon the traditional particle filter algorithm and introduces several improvements. First, we enhance the particle filter by introducing a mixture Gaussian model to obtain the posterior probability distribution of particles. This representation allows each particle to capture a mixture of possible states, alleviating the problem of particle degeneracy commonly encountered in traditional particle filters. Next, we refine the iterative process of the mixture Gaussian model by employing Bayesian criteria and likelihood function convergence to adaptively control the number of iterations and the Gaussian component count. This optimization helps reduce computational load while improving the model's goodness of fit. Lastly, we introduce variational mode decomposition to process the residual signals. By decomposing and reconstructing these signals, we extract multi-modal motion features. Based on this, we employ an autoregressive model for prediction, combining the predicted trajectory with the original one to effectively enhance tracking accuracy. Experimental results demonstrate that the proposed method significantly improves the precision of pedestrian trajectory prediction and exhibits strong robustness, outperforming traditional methods.}
}