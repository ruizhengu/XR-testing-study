@inproceedings{10.1145/3562939.3565676,
author = {Dzardanova, Elena and Kasapakis, Vlasios and Vosinakis, Spyros and Psarrou, Konstantina},
title = {Sign Language in Immersive VR: Design, Development, and Evaluation of a Testbed Prototype},
year = {2022},
isbn = {9781450398893},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3562939.3565676},
doi = {10.1145/3562939.3565676},
abstract = {Immersive Virtual Reality (IVR) systems support several modalities such as body, finger, eye, and facial expressions tracking, thus they can support sign-language-based communication. The combined utilization of tracking technologies requires careful evaluation to ensure high-fidelity transference of body posture, gestures, and facial expressions in real-time. This paper presents the design, development and evaluation of an IVR system utilizing state-of-the-art tracking options. The system is evaluated by certified sign language teachers to detect usability issues and examine appropriate methodology for large-scale follow-up evaluation by users fluent in sign language.},
booktitle = {Proceedings of the 28th ACM Symposium on Virtual Reality Software and Technology},
articleno = {72},
numpages = {2},
location = {<conf-loc>, <city>Tsukuba</city>, <country>Japan</country>, </conf-loc>},
series = {VRST '22}
}

@inproceedings{10.1145/3531073.3531171,
author = {Vona, Francesco and Pieri, Luca and Patti, Alberto and Tafaro, Simone and Saccoccio, Sara and Garzotto, Franca and Romano, Daniele},
title = {Explore 360° VR to Improve the Ecological Validity of Screening Tests on Cognitive Functions},
year = {2022},
isbn = {9781450397193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531073.3531171},
doi = {10.1145/3531073.3531171},
abstract = {Cognitive impairment is a condition that results in a person’s inability to remember, learn, concentrate or make decisions that affect his/her everyday life. The assessment of these deficits is usually performed using standardized paper and pencil or computerized tests within a controlled clinical setting. Many traditionally designed tools show only low to moderate levels of ecological validity, limiting the reliability of the collected measures. The proposed system adapts existing screening tests within an immersive virtual reality environment with 360° video, recreating a familiar setting for the patient. This faithful reproduction of everyday environments and situations can enhance the ecological validity of the assessment procedure while maintaining a standardized stimuli delivery, all in a controlled and safe setting. As a computerized system, virtual reality technology allows an error-free computation of the test scores, here collected by means of accuracy for each task. The system involves many technologies aimed at capturing any kind of user input provided by the patient. Additionally, using a visor with integrated eye-tracker sensor, the system can register the visual exploration pattern adopted by the patient during the task execution, providing information concerning the attentional and visuo-spatial functioning which are not obtainable using traditional assessment procedures. Finally, the results of an exploratory study that was conducted with 11 users on the reliability and usability of the system are presented.},
booktitle = {Proceedings of the 2022 International Conference on Advanced Visual Interfaces},
articleno = {32},
numpages = {5},
keywords = {360video VR screening test, Cognitive Impairment, Eye tracking, Pico Neo 3 Pro Eye},
location = {<conf-loc>, <city>Frascati, Rome</city>, <country>Italy</country>, </conf-loc>},
series = {AVI '22}
}

@inproceedings{10.1145/3594739.3610698,
author = {Morales Tellez, Arturo and Valdez Gastelum, Mar\'{\i}a Concepci\'{o}n and Castro, Luis A. and Tentori, Monica},
title = {Evaluating the Effect of the Color-Word Stroop Test and VR as a Psychological Stressor},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3610698},
doi = {10.1145/3594739.3610698},
abstract = {Virtual Reality (VR) makes use of psychological stressors to enable users to feel immersed in different domains. Although stressor tests, like the Color-Word Stroop Test (CWST), have been shown to be valid and reliable, there are limited deployments of such stressors that exhibit appropriate immersion and user experience in VR. In this paper, we present the development and evaluation of two VR simulators of the CWST. We conducted a between-subjects study with 27 participants who completed the conventional CWST, a VR-only simulator of the CWST, and a gamified VR simulator of the CWST. We measured and conducted a statistical analysis of participants’ CWST scores, perceived stress, immersion, user experience, playability, and heart rate. Our results show that there are no significant differences in using the two CWST simulators of the VR. We found that users’ heart rate is significantly higher when using the VR simulators than the conventional CWST and that the VR game simulator significantly shows a higher score in immersion than the VR-only simulator. However, users’ perceived stress was significantly less when using the VR game simulator. Finally, we reflect on design insights for stressors tests in VR and discuss directions for future work.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {93–97},
numpages = {5},
keywords = {Sports, Stress, Stroop Color, Virtual Reality},
location = {<conf-loc>, <city>Cancun, Quintana Roo</city>, <country>Mexico</country>, </conf-loc>},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3340764.3345379,
author = {Treskunov, Anastasia and Gerhardt, Emil and Nowottnik, David and Fischer, Ben and Gerhardt, Laurin and S\"{a}ger, Mitja and Geiger, Christian},
title = {ICAROSmuIti - A VR Test Environment for the Development of Multimodal and Multi-User Interaction Concepts},
year = {2019},
isbn = {9781450371988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340764.3345379},
doi = {10.1145/3340764.3345379},
abstract = {English - With 'ICAORSmulti' we present a cooperative Virtual Reality application that was developed for the presentation and validation of multimodal interaction techniques. To have an application scenario at our disposal that is attractive and can be demonstrated at trade shows, we chose a flying-based virtual environment for multiple users. The latter are able to interact and assume different roles. As input devices, we use up to two ICAROS flying machines that were specially designed to simulate a flight in VR. The users can move and navigate through the VR environment in a horizontal position (see figure 1). By means of a head-mounted display (HMD) they can see their virtual surroundings, while the sensor technology attached to the Icaros detects and communicates their movements. Actuator devices such as wind machines, heat lamps and others enable a multimodal output and improve the immersion of the flight simulation. Beyond that, it is also possible to integrate other devices and 3D interaction techniques such as running, climbing etc. into the current scene. All users are able to see each other and to communicate. For the simple development and testing of 3D interaction techniques based on predefined templates in Unity3D, several different components have already been developed and integrated. They are briefly described in this paper and can be tried out in a demonstration at the conference 'Mensch und Computer 2019'. One of the unique features of this project are components that perceive a measurable decline in immersion, e.g. a limitation of the viewing area, the latency or the frame rate.},
booktitle = {Proceedings of Mensch Und Computer 2019},
pages = {909–911},
numpages = {3},
keywords = {3D locomotion, immersive user experience, multimodal interaction, virtual reality},
location = {Hamburg, Germany},
series = {MuC '19}
}

@inproceedings{10.1145/3599640.3599668,
author = {Wang, Juan and He, Chunlin and Bai, Xinye and Li, Qiuhong and Li, Yunhao and Cai, Minghan},
title = {Construction and validation of a junior high school biology laboratory class teaching model based on desktop VR},
year = {2023},
isbn = {9781450399593},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3599640.3599668},
doi = {10.1145/3599640.3599668},
abstract = {In the context of continuous integration of information technology and subject education, more and more educators consider combining VR technology with actual education teaching, and desktop VR technology provides fresh vitality for education teaching as an emerging technology. In junior high school biology experimental teaching, there are problems such as some experimental materials are not easy to obtain, resulting in less-than-ideal experimental effects. Therefore, how to apply desktop VR in junior high school biology laboratory teaching and whether integrating desktop VR into junior high school biology laboratory teaching can help students better master biology knowledge? In this study, the tower of Dell's experience theory is used as the theoretical basis for model construction. Based on the ARCS learning motivation model and the features of desktop VR, a model of junior high school biology laboratory class teaching based on desktop VR is explored. In this study, taking a middle school in China as an example, classes with similar grades were selected as the experimental class and the control class, each with 50 students, and the lesson of middle school biology "Observe the results of flowers" was used as an example for teaching practice. The control class was taught using traditional teaching methods, and the experimental class was taught using the teaching model of middle school biology laboratory class based on desktop VR, and a paper-and-pencil quiz, the Amabile et al. The experimental data were collected in the form of paper-and-pencil tests, learning motivation scales, etc. The statistical analysis of the data led to the conclusion that the model can promote students' learning effectiveness and have different degrees of improvement on students' learning motivation, thus verifying the effectiveness of the desktop VR-based junior high school biology laboratory class teaching model.},
booktitle = {Proceedings of the 9th International Conference on Education and Training Technologies},
articleno = {26},
numpages = {8},
location = {<conf-loc>, <city>Macau</city>, <country>China</country>, </conf-loc>},
series = {ICETT '23}
}

@inproceedings{10.1145/3491101.3519698,
author = {Mitchell, Daxton and Choi, HeeSun},
title = {Assessing the Spatial Distribution of Visual Attention in a Virtual Environment: Development and Validation of a Novel VR-based Attentional Visual Field (AVF) Task},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519698},
doi = {10.1145/3491101.3519698},
abstract = {Visual attention is critical for everyday task performance and safety. The Attentional Visual Field Task (AVF) is an established, computerized method for assessing the distribution of visual attention across a wide visual field. High-fidelity virtual reality (VR) presents an opportunity for more ecological methods for assessing and training visual attention; however, this novel approach has not been examined. We developed a new VR-based AVF task, AVF-VE, using a Head-Mounted Display (HMD) VR device with an integrated eye-tracker, and conducted a study to validate this newly developed visual attention task. We further examined how visual attention is distributed in a virtual visual field. The findings suggest that the VR-based visual attention task is a valid and useful tool that can be used for future attention research and training. Unique characteristics of the spatial distribution of visual attention in the virtual environment observed in the current evaluation study are discussed.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {379},
numpages = {7},
keywords = {Attentional visual field, Head-mounted display, Virtual reality, Visual attention},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@inproceedings{10.1145/1450579.1450643,
author = {Perez, Camilo A. and Figueroa, Pablo},
title = {VRPN and Qwerk: fast MR device prototyping and testing},
year = {2008},
isbn = {9781595939517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1450579.1450643},
doi = {10.1145/1450579.1450643},
abstract = {We present a platform that offers designers flexibility on device design, fast prototyping, and integration of new devices to a mixed reality infrastructure. Our solution is based on the integration of a commercial embedded system, the Qwerk, and the Virtual Reality Peripheral Network (VRPN), a network-transparent interface between applications and typical virtual reality (VR) devices. This solution creates a hardware and software layer between new devices and VR applications that facilitate development. We show here a design process for new MR devices. With our hardware and software layer we allow designers concentrate more in the interaction rather than the way sensors are connected. To test our design process and our platform we implement three simple examples.},
booktitle = {Proceedings of the 2008 ACM Symposium on Virtual Reality Software and Technology},
pages = {261–262},
numpages = {2},
keywords = {augmented reality reality, embedded system, prototyping, virtual reality},
location = {Bordeaux, France},
series = {VRST '08}
}

@inproceedings{10.5555/1402383.1402407,
author = {Pelechano, Nuria and Stocker, Catherine and Allbeck, Jan and Badler, Norman},
title = {Being a part of the crowd: towards validating VR crowds using presence},
year = {2008},
isbn = {9780981738109},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Crowd simulation models are currently lacking a commonly accepted validation method. In this paper, we propose level of presence achieved by a human in a virtual environment (VE) as a metric for virtual crowd behavior. Using experimental evidence from the presence literature and the results of a pilot experiment that we ran, we explore the egocentric features that a crowd simulation model should have in order to achieve high levels of presence and thus be used as a framework for validation of simulated crowd behavior.We implemented four crowd models for our pilot experiment: social forces, rule based, cellular automata and HiDAC. Participants interacted with the crowd members of each model in an immersive virtual environment for the purpose of studying presence in virtual crowds, with the goal of establishing the basis for a future validation method.},
booktitle = {Proceedings of the 7th International Joint Conference on Autonomous Agents and Multiagent Systems - Volume 1},
pages = {136–142},
numpages = {7},
keywords = {crowd simulation, egocentric features, presence},
location = {Estoril, Portugal},
series = {AAMAS '08}
}

@inproceedings{10.1145/2901790.2901915,
author = {Djajadiningrat, Tom and Chao, Pei-Yin and Kim, SeYoung and Van Leengoed, Marleen and Raijmakers, Jeroen},
title = {Mime: An AR-based System Helping Patients to Test their Blood at Home},
year = {2016},
isbn = {9781450340311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2901790.2901915},
doi = {10.1145/2901790.2901915},
abstract = {Mime is a tablet-based augmented reality system which guides new chemotherapy patients through testing their blood at home. Starting from the socio-economic push towards home healthcare, we use blood analysis as a case study to illustrate the user experience challenges of unassisted care at home and how AR may support the user. We then show our explorations during an early ideation workshop, using low-fi prototyping and acting out. We also show steps from our making process in which we combine various tools, both physical and virtual, to further our understanding. We conclude with our final demonstrator and the discussions it triggered.},
booktitle = {Proceedings of the 2016 ACM Conference on Designing Interactive Systems},
pages = {347–359},
numpages = {13},
keywords = {augmented reality, home healthcare, manuals},
location = {Brisbane, QLD, Australia},
series = {DIS '16}
}

@inproceedings{10.1145/2559206.2574810,
author = {Teather, Robert J. and Stuerzlinger, Wolfgang and Pavlovych, Andriy},
title = {Fishtank fitts: a desktop VR testbed for evaluating 3D pointing techniques},
year = {2014},
isbn = {9781450324748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2559206.2574810},
doi = {10.1145/2559206.2574810},
abstract = {We present a desktop or "fish tank" virtual reality system for evaluating 3D selection techniques. Motivated by the successful application of Fitts' law to 2D pointing evaluation, the system provides a testbed for consistent evaluation of 3D point-selection techniques. The primary design consideration of the system was to enable direct and fair comparison between 2D and 3D pointing techniques. To this end, the system presents a 3D version of the ISO 9241-9 pointing task. Targets can be displayed stereoscopically, with head-coupled viewing, and at varying depths. The system also supports various input devices, including the mouse as well as 3D trackers in direct touch and remote pointing modes.},
booktitle = {CHI '14 Extended Abstracts on Human Factors in Computing Systems},
pages = {519–522},
numpages = {4},
keywords = {3d pointing, cursors, fish tank virtual reality, fitts' law},
location = {Toronto, Ontario, Canada},
series = {CHI EA '14}
}

