@article{THAPALIYA2013522,
title = {Level set method with automatic selective local statistics for brain tumor segmentation in MR images},
journal = {Computerized Medical Imaging and Graphics},
volume = {37},
number = {7},
pages = {522-537},
year = {2013},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2013.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0895611113000980},
author = {Kiran Thapaliya and Jae-Young Pyun and Chun-Su Park and Goo-Rak Kwon},
keywords = {Level set method, Active contours, Geodesic active contours, Chan–Vese model, Image segmentation, MR images},
abstract = {The level set approach is a powerful tool for segmenting images. This paper proposes a method for segmenting brain tumor images from MR images. A new signed pressure function (SPF) that can efficiently stop the contours at weak or blurred edges is introduced. The local statistics of the different objects present in the MR images were calculated. Using local statistics, the tumor objects were identified among different objects. In this level set method, the calculation of the parameters is a challenging task. The calculations of different parameters for different types of images were automatic. The basic thresholding value was updated and adjusted automatically for different MR images. This thresholding value was used to calculate the different parameters in the proposed algorithm. The proposed algorithm was tested on the magnetic resonance images of the brain for tumor segmentation and its performance was evaluated visually and quantitatively. Numerical experiments on some brain tumor images highlighted the efficiency and robustness of this method.}
}
@article{SHINDE2018552,
title = {Relative Investigation of Machine Learning Algorithms for Performance Analysis on Brain MR Images},
journal = {Procedia Computer Science},
volume = {143},
pages = {552-562},
year = {2018},
note = {8th International Conference on Advances in Computing & Communications (ICACC-2018)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.10.431},
url = {https://www.sciencedirect.com/science/article/pii/S187705091832129X},
author = {Ashwini.S. Shinde and Veena.V. Desai},
keywords = {Logistic, Support Vector Machine, Cross fold validation, Naïve Bayes, Multi-layer Perceptron, Decision tree},
abstract = {The world is moving exponential towards the technical growth in every field. The most obliging and gifted is the field of Healthcare and medical diagnosis with the advanced techniques of Artificial Intelligence and Machine Learning; it’s a boon to the patients affected by cancer. Brain Tumor is one of the severe syndrome causes for the death of Human beings. Magnetic Resonance Imaging is vital medical diagnosis tool for revealing of tumors. Precise segmentation and classification of the tumors yet relics a puzzling task because of its large structural and spatial erraticism among tumors. In this paper an effort is made to discuss and implement the different Machine Learning classification algorithms on Brain Tumor MR Images for 20 Patients i.e 150*20 Slices of MR Sequences (MR Images) for thirteen attributes (statistical features), using the Dataset of BRATS 2015. Contribution to the heart of technology that can be used for tumor classification exhausting the machine learning algorithms namely the Naive Bayes, Logistic Regression, Multi-layer Perceptron, Support Vector Machine and Decision tree using the Waikato Environment for Knowledge Analysis tool and MATLAB. The experimental outcomes of proposed technique have been assessed for performance and quality examination on magnetic resonance brain images.}
}
@article{JUNG2015902,
title = {Exploration and evaluation of AR, MPCA and KL anomaly detection techniques to embankment dam piezometer data},
journal = {Advanced Engineering Informatics},
volume = {29},
number = {4},
pages = {902-917},
year = {2015},
note = {Collective Intelligence Modeling, Analysis, and Synthesis for Innovative Engineering Decision Making Special Issue of the 1st International Conference on Civil and Building Engineering Informatics},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2015.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1474034615001056},
author = {In-Soo Jung and Mario Berges and James H. Garrett and Barnabas Poczos},
keywords = {Structural health monitoring, Dam safety, Anomaly detection, Statistical techniques},
abstract = {In the U.S., the current practice of analyzing the structural integrity of embankment dams relies primarily on manual a posteriori analysis of instrument data by engineers, leaving much room for improvement through the application of advanced data analysis techniques. In this research, different types of anomaly detection techniques are examined in an effort to propose which data analytics are appropriate for various anomaly scenarios as well as piezometer locations. Moreover, both the parametric (Auto Regressive [AR] and Moving Principal Component Analysis [MPCA]) and nonparametric (Kullback–Leibler Divergence [KL]) techniques are applied in order to test if the widely-held assumptions about piezometer data, i.e., linearity between piezometer data and pool levels, as well as normally distributed piezometer data, are necessary in the anomaly detection task. In general, KL performs better than MPCA and AR, and delivers more consistent results throughout the different piezometers and anomaly scenarios. Given that KL is a nonparametric technique, the authors conclude that the prior assumptions about piezometer data do not always provide the best performance for anomaly prediction.}
}
@article{KUO2008191,
title = {Brain MR images segmentation using statistical ratio: Mapping between watershed and competitive Hopfield clustering network algorithms},
journal = {Computer Methods and Programs in Biomedicine},
volume = {91},
number = {3},
pages = {191-198},
year = {2008},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2008.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0169260708000990},
author = {Wen-Feng Kuo and Chi-Yuan Lin and Yung-Nien Sun},
keywords = {Image segmentation, Region adjacency graph, Watershed, Neural networks},
abstract = {Conventional watershed segmentation methods invariably produce over-segmented images due to the presence of noise or local irregularities in the source images. In this paper, a robust medical image segmentation technique is proposed, which combines watershed segmentation and the competitive Hopfield clustering network (CHCN) algorithm to minimize undesirable over-segmentation. In the proposed method, a region merging method is presented, which is based on employing the region adjacency graph (RAG) to improve the quality of watershed segmentation. The relation of inter-region similarities is then investigated using image mapping in the watershed and CHCN images to determine more appropriate region merging. The performance of the proposed technique is presented through quantitative and qualitative validation experiments on benchmark images. Significant and promising segmentation results were achieved on brain phantom simulated data.}
}
@article{LI2022103174,
title = {Myocardial Pathology Segmentation of Multi-modal Cardiac MR Images with a Simple but Efficient Siamese U-shaped Network},
journal = {Biomedical Signal Processing and Control},
volume = {71},
pages = {103174},
year = {2022},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.103174},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421007710},
author = {Weisheng Li and Linhong Wang and Feiyan Li and Sheng Qin and Bin Xiao},
keywords = {Cardiac segmentation, Myocardial pathology segmentation, Multi-modal images},
abstract = {Segmentation of multi-modal myocardial pathology images is a challenging task, due to factors such as the heterogeneity caused by large inter-modality and intra-modality intensity variations in multi-modal images, and the diversity of location, shape, and scale of lesion regions. Existing methods based on multi-modal segmentation cannot effectively integrate and utilize complementary information between multiple modalities, leading to the difficulty in segmenting edema and discontinuous scars. In this paper, we propose a simple but efficient U-shaped network, named Siamese U-Net, to solve these problems. There are two aspects to our method. First, we adopt a multi-modal complementary information exploration network (MCIE-Net) to explore the correlations across multi-modal images and simultaneously segment cardiac structures and myocardial pathology. This method is able to fully leverage complementary information between different modalities. Second, to obtain accurate and continuous segmentation of edema and scars, we use a lesion refinement network (LR-Net) with the same architecture as the MCIE-Net, which extracts lesion features to enhance the fusion of lesion information. We conducted extensive experiments on the MyoPS 2020 and MS-CMRSeg 2019 datasets to demonstrate the effectiveness of our proposed approach. We obtained an average Dice score of 0.734 ± 0.088 for the myocardial edema + scars on the MyoPS 2020 test set, a result which outperformed the state-of-the-art method. These results are a 0.9% improvement over the segmentation results of our previous work, and exceed the results of the winner of the MyoPS 2020 challenge by 0.3%.}
}
@article{CHEN20172,
title = {Cross contrast multi-channel image registration using image synthesis for MR brain images},
journal = {Medical Image Analysis},
volume = {36},
pages = {2-14},
year = {2017},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2016.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1361841516301852},
author = {Min Chen and Aaron Carass and Amod Jog and Junghoon Lee and Snehashis Roy and Jerry L. Prince},
keywords = {Multi-modal image registration, Multi-channel image registration, Multi-contrast magnetic resonance imaging, Image synthesis, Image processing, Multi-modal imaging, Brain imaging},
abstract = {Multi-modal deformable registration is important for many medical image analysis tasks such as atlas alignment, image fusion, and distortion correction. Whereas a conventional method would register images with different modalities using modality independent features or information theoretic metrics such as mutual information, this paper presents a new framework that addresses the problem using a two-channel registration algorithm capable of using mono-modal similarity measures such as sum of squared differences or cross-correlation. To make it possible to use these same-modality measures, image synthesis is used to create proxy images for the opposite modality as well as intensity-normalized images from each of the two available images. The new deformable registration framework was evaluated by performing intra-subject deformation recovery, intra-subject boundary alignment, and inter-subject label transfer experiments using multi-contrast magnetic resonance brain imaging data. Three different multi-channel registration algorithms were evaluated, revealing that the framework is robust to the multi-channel deformable registration algorithm that is used. With a single exception, all results demonstrated improvements when compared against single channel registrations using the same algorithm with mutual information.}
}
@article{ZHU2021104487,
title = {Detection of deep myometrial invasion in endometrial cancer MR imaging based on multi-feature fusion and probabilistic support vector machine ensemble},
journal = {Computers in Biology and Medicine},
volume = {134},
pages = {104487},
year = {2021},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.104487},
url = {https://www.sciencedirect.com/science/article/pii/S001048252100281X},
author = {Xueliang Zhu and Jie Ying and Haima Yang and Le Fu and Boyang Li and Bin Jiang},
keywords = {Deep myometrial invasion, Feature extraction, Support vector machine, Endometrial cancer, MRI, Ensemble learning},
abstract = {The depth of myometrial invasion affects the treatment and prognosis of patients with endometrial cancer (EC), conventionally evaluated using MR imaging (MRI). However, only a few computer-aided diagnosis methods have been reported for identifying deep myometrial invasion (DMI) using MRI. Moreover, these existing methods exhibit relatively unsatisfactory sensitivity and specificity. This study proposes a novel computerized method to facilitate the accurate detection of DMI on MRI. This method requires only the corpus uteri region provided by humans or computers instead of the tumor region. We also propose a geometric feature called LS to describe the irregularity of the tissue structure inside the corpus uteri triggered by EC, which has not been leveraged for the DMI prediction model in other studies. Texture features are extracted and then automatically selected by recursive feature elimination. Utilizing a feature fusion strategy of strong and weak features devised in this study, multiple probabilistic support vector machines incorporate LS and texture features, which are then merged to form the ensemble model EPSVM. The model performance is evaluated via leave-one-out cross-validation. We make the following comparisons, EPSVM versus the commonly used classifiers such as random forest, logistic regression, and naive Bayes; EPSVM versus the models using LS or texture features alone. The results show that EPSVM attains an accuracy, sensitivity, specificity, and F1 score of 93.7%, 94.7%, 93.3%, and 87.8%, all of which are higher than those of the commonly used classifiers and the models using LS or texture features alone. Compared with the methods in existing studies, EPSVM exhibits high performance in terms of both sensitivity and specificity. Moreover, LS can achieve an accuracy, sensitivity, and specificity of 89.9%, 89.5%, and 90.0%. Thus, the devised geometric feature LS is significant for DMI detection. The fusion of LS and texture features in the proposed EPSVM can provide more reliable prediction. The computer-aided classification based on the proposed method can assist radiologists in accurately identifying DMI on MRI.}
}
@article{ZHAO2023102786,
title = {SpineRegNet: Spine Registration Network for volumetric MR and CT image by the joint estimation of an affine-elastic deformation field},
journal = {Medical Image Analysis},
volume = {86},
pages = {102786},
year = {2023},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2023.102786},
url = {https://www.sciencedirect.com/science/article/pii/S1361841523000476},
author = {Lei Zhao and Shumao Pang and Yangfan Chen and Xiongfeng Zhu and Ziyue Jiang and Zhihai Su and Hai Lu and Yujia Zhou and Qianjin Feng},
keywords = {Deep learning, Spine registration, Affine-elastic registration, Local rigidity constrain},
abstract = {Spine registration for volumetric magnetic resonance (MR) and computed tomography (CT) images plays a significant role in surgical planning and surgical navigation system for the radiofrequency ablation of spine intervertebral discs. The affine transformation of each vertebra and elastic deformation of the intervertebral disc exist at the same time. This situation is a major challenge in spine registration. Existing spinal image registration methods failed to solve the optimal affine-elastic deformation field (AEDF) simultaneously, only consider the overall rigid or elastic alignment with the help of a manual spine mask, and encounter difficulty in meeting the accuracy requirements of clinical registration application. In this study, we propose a novel affine-elastic registration framework named SpineRegNet. The SpineRegNet consists of a Multiple Affine Matrices Estimation (MAME) Module for multiple vertebrae alignment, an Affine-Elastic Fusion (AEF) Module for joint estimation of the overall AEDF, and a Local Rigidity Constraint (LRC) Module for preserving the rigidity of each vertebra. Experiments on T2-weighted volumetric MR and CT images show that the proposed approach achieves impressive performance with mean Dice similarity coefficients of 91.36%, 81.60%, and 83.08% for the mask of the vertebrae on Datasets A-C, respectively. The proposed technique does not require a mask or manual participation during the tests and provides a useful tool for clinical spinal disease surgical planning and surgical navigation systems.}
}
@incollection{SHERMAN2018724,
title = {Chapter 9 - Experience Conception and Design: Applying VR to a Problem},
editor = {William R. Sherman and Alan B. Craig},
booktitle = {Understanding Virtual Reality (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {724-779},
year = {2018},
series = {The Morgan Kaufmann Series in Computer Graphics},
isbn = {978-0-12-800965-9},
doi = {https://doi.org/10.1016/B978-0-12-800965-9.00009-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012800965900009X},
author = {William R. Sherman and Alan B. Craig},
keywords = {Art, Deploy, Design, Education, Engagement, Entertainment, Games, Marketing, Prototype, Training, User Testing, Virtual Reality (VR), Visualization, VR Experience, VR Experience Evaluation},
abstract = {Chapter 9 is where it all comes together. The focus is on how to apply virtual reality (VR) to solve a problem. The problem might range from an engineering problem, or an education problem, how to tell a story, or any number of other types of problems. The first issue at hand is whether or not VR can help you meet your goals. In other words, is VR an appropriate medium? This chapter takes a look at how one conceives of a new VR application, whether it is drawn from a different medium, or from another VR application, or is generated from scratch. As an aid in doing this, we enumerate a number of application areas and provide a number of exemplary VR experiences to inspire, and to show ideas and techniques. Additionally, we address a process for each of these methods. The chapter provides a method and workflow that integrates the following guidelines, each of which is elucidated and expanded:Design deliberately;Prototype;Design with the system in mind;Design with the venue in mind;Design with the audience in mind;Design to engage the audience;Consider social interactions;Consider design tradeoffs;Design the user objective;Design the end of the experience;Employ User testing;Document, deploy, and evaluate the experience. This chapter also provides a perspective on how the VR application development process has changed over time, and how we expect it to change in the future.}
}
@article{QIU2014660,
title = {Dual optimization based prostate zonal segmentation in 3D MR images},
journal = {Medical Image Analysis},
volume = {18},
number = {4},
pages = {660-673},
year = {2014},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2014.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S1361841514000322},
author = {Wu Qiu and Jing Yuan and Eranga Ukwatta and Yue Sun and Martin Rajchl and Aaron Fenster},
keywords = {3D prostate MRI, Zonal segmentation, Convex optimization, Multi-region segmentation},
abstract = {Efficient and accurate segmentation of the prostate and two of its clinically meaningful sub-regions: the central gland (CG) and peripheral zone (PZ), from 3D MR images, is of great interest in image-guided prostate interventions and diagnosis of prostate cancer. In this work, a novel multi-region segmentation approach is proposed to simultaneously segment the prostate and its two major sub-regions from only a single 3D T2-weighted (T2w) MR image, which makes use of the prior spatial region consistency and incorporates a customized prostate appearance model into the segmentation task. The formulated challenging combinatorial optimization problem is solved by means of convex relaxation, for which a novel spatially continuous max-flow model is introduced as the dual optimization formulation to the studied convex relaxed optimization problem with region consistency constraints. The proposed continuous max-flow model derives an efficient duality-based algorithm that enjoys numerical advantages and can be easily implemented on GPUs. The proposed approach was validated using 18 3D prostate T2w MR images with a body-coil and 25 images with an endo-rectal coil. Experimental results demonstrate that the proposed method is capable of efficiently and accurately extracting both the prostate zones: CG and PZ, and the whole prostate gland from the input 3D prostate MR images, with a mean Dice similarity coefficient (DSC) of 89.3±3.2% for the whole gland (WG), 82.2±3.0% for the CG, and 69.1±6.9% for the PZ in 3D body-coil MR images; 89.2±3.3% for the WG, 83.0±2.4% for the CG, and 70.0±6.5% for the PZ in 3D endo-rectal coil MR images. In addition, the experiments of intra- and inter-observer variability introduced by user initialization indicate a good reproducibility of the proposed approach in terms of volume difference (VD) and coefficient-of-variation (CV) of DSC.}
}
@article{WU20073492,
title = {Iterative sliced inverse regression for segmentation of ultrasound and MR images},
journal = {Pattern Recognition},
volume = {40},
number = {12},
pages = {3492-3502},
year = {2007},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2007.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S0031320307002075},
author = {Han-Ming Wu and Henry Horng-Shing Lu},
keywords = {Unsupervised clustering, K-Means, Dimension reduction, Multidimensional scaling, Sliced inverse regression, Nearest mean classifier, Support vector machines},
abstract = {In this study, we propose an integrated approach based on iterative sliced inverse regression (ISIR) for the segmentation of ultrasound and magnetic resonance (MR) images. The approach integrates two stages. The first is the unsupervised clustering which combines multidimensional scaling (MDS) with K-Means. The dimension reduction based on MDS is employed to obtain fewer representative variates as input variables for K-Means. This step intends to generate the initial group labels of the training data for the second stage of supervised segmentation. We then combine the SIR with the nearest mean classifier (NMC) or the support vector machine (SVM) to iteratively update the group labels for supervised segmentation. The method of SIR is introduced by Li [Sliced inverse regression for dimension reduction. J. Am. Stat. Assoc. 86 (1991) 316–342] to explore the effective dimension reduction (e.d.r.) directions from the training data embedded in high-dimensional space. The test data are then projected onto these directions and the classifiers are further applied to classify the test data. The integrated approach based on ISIR is evaluated on simulated and clinical images, which include ultrasound and MR images. The evaluation results indicate that this approach provides an improvement of image segmentation over the methods to be compared without dimension reduction.}
}
@article{LEE20131256,
title = {Breast lesion co-localisation between X-ray and MR images using finite element modelling},
journal = {Medical Image Analysis},
volume = {17},
number = {8},
pages = {1256-1264},
year = {2013},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2013.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S1361841513000856},
author = {Angela W.C. Lee and Vijayaraghavan Rajagopal and Thiranja P. {Babarenda Gamage} and Anthony J. Doyle and Poul M.F. Nielsen and Martyn P. Nash},
keywords = {Breast biomechanical models, Breast image registration, Finite element modelling, Multimodal breast image registration},
abstract = {This paper presents a novel X-ray and MR image registration technique based on individual-specific biomechanical finite element (FE) models of the breasts. Information from 3D magnetic resonance (MR) images was registered to X-ray mammographic images using non-linear FE models subject to contact mechanics constraints to simulate the large compressive deformations between the two imaging modalities. A physics-based perspective ray-casting algorithm was used to generate 2D pseudo-X-ray projections of the FE-warped 3D MR images. Unknown input parameters to the FE models, such as the location and orientation of the compression plates, were optimised to provide the best match between the pseudo and clinical X-ray images. The methods were validated using images taken before and during compression of a breast-shaped phantom, for which 12 inclusions were tracked between imaging modalities. These methods were then applied to X-ray and MR images from six breast cancer patients. Error measures (such as centroid and surface distances) of segmented tumours in simulated and actual X-ray mammograms were used to assess the accuracy of the methods. Sensitivity analysis of the lesion co-localisation accuracy to rotation about the anterior–posterior axis was then performed. For 10 of the 12 X-ray mammograms, lesion localisation accuracies of 14mm and less were achieved. This analysis on the rotation about the anterior–posterior axis indicated that, in cases where the lesion lies in the plane parallel to the mammographic compression plates, that cuts through the nipple, such rotations have relatively minor effects.This has important implications for clinical applicability of this multi-modality lesion registration technique, which will aid in the diagnosis and treatment of breast cancer.}
}
@article{TANKALA2022100105,
title = {A novel depth search based light weight CAR network for the segmentation of brain tumour from MR images},
journal = {Neuroscience Informatics},
volume = {2},
number = {4},
pages = {100105},
year = {2022},
issn = {2772-5286},
doi = {https://doi.org/10.1016/j.neuri.2022.100105},
url = {https://www.sciencedirect.com/science/article/pii/S277252862200067X},
author = {Sreekar Tankala and Geetha Pavani and Birendra Biswal and G. Siddartha and Gupteswar Sahu and N. Bala Subrahmanyam and S. Aakash},
keywords = {Brain tumour, Magnetic Resonance Images (MRI), Light weight channel attention and residual network (LWCAR-Net), Depth Search Block (DSB), BraTs dataset},
abstract = {In this modern era, brain tumour is one of the dreadful diseases that occur due to the growth of abnormal cells or by the accumulation of dead cells in the brain. If these abnormalities are not detected in the early stages, they lead to severe conditions and may cause death to the patients. With the advancement of medical imaging, Magnetic Resonance Images (MRI) are developed to analyze the patients manually. However, this manual screening is prone to errors. To overcome this, a novel depth search-based network termed light weight channel attention and residual network (LWCAR-Net) is proposed by integrating with a novel depth search block (DSB) and a CAR module. The depth search block extracts the pertinent features by performing a series of convolution operations enabling the network to restore low-level information at every stage. On other hand, CAR module in decoding path refines the feature maps to increase the representation and generalization abilities of the network. This allows the network to locate the brain tumor pixels from MRI images more precisely. The performance of the depth search based LWCAR-Net is estimated by testing on different globally available datasets like BraTs 2020 and Kaggle LGG dataset. This method achieved a sensitivity of 95%, specificity of 99%, the accuracy of 99.97%, and dice coefficient of 95% respectively. Furthermore, the proposed model outperformed the existing state-of-the-art models like U-Net++, SegNet, etc by achieving an AUC of 98% in segmenting the brain tumour cells.}
}
@article{ZHANG2020346,
title = {Compressed sensing MR image reconstruction via a deep frequency-division network},
journal = {Neurocomputing},
volume = {384},
pages = {346-355},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219317126},
author = {Jiulou Zhang and Yunbo Gu and Hui Tang and Xiaoqing Wang and Youyong Kong and Yang Chen and Huazhong Shu and Jean-Louis Coatrieux},
keywords = {Magnetic resonance imaging, Compressed sensing, Iterative reconstruction, Deep learning, Convolutional neural network},
abstract = {Compressed sensing MRI (CS-MRI) is considered as a powerful technique for decreasing the scan time of MRI while ensuring the image quality. However, state of the art reconstruction algorithms are still subjected to two challenges including terrible parameters tuning and image details loss resulted from over-smoothing. In this paper, we propose a deep frequency-division network (DFDN) to face these two image reconstruction issues. The proposed DFDN approach applies a deep iterative reconstruction network (DIRN) to replace the regularization terms and the corresponding parameters by a stacked convolution neural network (CNN). And then multiple DIRN blocks are cascaded continuously as one deeper neural network. Data consistency (DC) layer is incorporated after each DIRN block to correct the k-space data of intermediate results. Image content loss is computed after each DC layer and frequency-division loss is gained by weighting the high frequency loss and low frequency loss after each DIRN block. The combination of image content loss and frequency-division loss is considered as the total loss for constraining the network training procedure. Validations of the proposed method have been performed on two brain datasets. Visual results and quantitative evaluations show that the proposed DFDN algorithm has better performance in sparse MRI reconstruction than other comparative methods.}
}
@article{ARROYAVETOBON201573,
title = {AIR-MODELLING: A tool for gesture-based solid modelling in context during early design stages in AR environments},
journal = {Computers in Industry},
volume = {66},
pages = {73-81},
year = {2015},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2014.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0166361514001857},
author = {Santiago Arroyave-Tobón and Gilberto Osorio-Gómez and Juan F. Cardona-McCormick},
keywords = {Augmented reality, Modelling in context, Solid modelling, Conceptual design, Hand gestures, Natural interfaces},
abstract = {Augmented reality (AR) technologies are just being used as interface in CAD tools allowing the user to perceive 3D models over a real environment. The influence of the use of AR in the conceptualization of products whose configuration, shape and dimensions depend mainly on the context remains unexplored. We aimed to prove that modelling in AR environments allows to use the context in real-time as an information input for making the iterative design process more efficient. In order to prove that, we developed a tool called AIR-MODELLING in which the designer is able to create virtual conceptual products by hand gestures meanwhile he/she is interacting directly with the real scenario. We conducted a test for comparing designers’ performance using AIR-MODELLING and a traditional CAD system. We obtained an average reduction of 44% on the modeling time in 76% of the cases. We found that modelling in AR environments using the hands as interface allows the designer to quickly and efficiently conceptualize potential solutions using the spatial restrictions of the context as an information input in real-time. Additionally, modelling in a natural scale, directly over the real scene, prevents the designer from drawing his/her attention on dimensional details and allows him/her to focus on the product itself and its relation with the environment.}
}
@article{GINTERS201380,
title = {Markerless Outdoor AR-RFID Solution for Logistics},
journal = {Procedia Computer Science},
volume = {25},
pages = {80-89},
year = {2013},
note = {2013 International Conference on Virtual and Augmented Reality in Education},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913012155},
author = {Egils Ginters and Arnis Cirulis and Gatis Blums},
keywords = {Augmented reality (AR), Radio-frequency identification (RFID), logistics, markerless tracking},
abstract = {The main objective of this paper is to describe the logistics processes improvement by use of AR (augmented reality) and hybrid RFID (Radio-frequency identification) technologies in outdoor environment. Augmented reality and RFID nowadays are well known and widespread technologies. It is possible to achieve functional and perspective system by merging these technologies together. The paper provides theoretical characteristics of logistics, RFID, AR technologies and offers theoretical model for idea implementation and approbation. Model depicts markerless AR-RFID solution for outdoor object tracking and 3D model visualization. Also physical structure and basic calculations are offered to provide necessary fundamentals for development of test platform and pilot product. Provision of outdoor object tracking and 3D model visualization may significantly impact and improve logistics processes in varies of fields.}
}
@article{SHAHZAD201744,
title = {Fully-automatic left ventricular segmentation from long-axis cardiac cine MR scans},
journal = {Medical Image Analysis},
volume = {39},
pages = {44-55},
year = {2017},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2017.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S1361841517300567},
author = {Rahil Shahzad and Qian Tao and Oleh Dzyubachyk and Marius Staring and Boudewijn P.F. Lelieveldt and Rob J. {van der Geest}},
keywords = {Atlas-based segmentation, Registration, Cardiac MRI, Left ventricular segmentation, Long-axis cine MRI},
abstract = {With an increasing number of large-scale population-based cardiac magnetic resonance (CMR) imaging studies being conducted nowadays, there comes the mammoth task of image annotation and image analysis. Such population-based studies would greatly benefit from automated pipelines, with an efficient CMR image analysis workflow. The purpose of this work is to investigate the feasibility of using a fully-automatic pipeline to segment the left ventricular endocardium and epicardium simultaneously on two orthogonal (vertical and horizontal) long-axis cardiac cine MRI scans. The pipeline is based on a multi-atlas-based segmentation approach and a spatio-temporal registration approach. The performance of the method was assessed by: (i) comparing the automatic segmentations to those obtained manually at both the end-diastolic and end-systolic phase, (ii) comparing the automatically obtained clinical parameters, including end-diastolic volume, end-systolic volume, stroke volume and ejection fraction, with those defined manually and (iii) by the accuracy of classifying subjects to the appropriate risk category based on the estimated ejection fraction. Automatic segmentation of the left ventricular endocardium was achieved with a Dice similarity coefficient (DSC) of 0.93 on the end-diastolic phase for both the vertical and horizontal long-axis scan; on the end-systolic phase the DSC was 0.88 and 0.85, respectively. For the epicardium, a DSC of 0.94 and 0.95 was obtained on the end-diastolic vertical and horizontal long-axis scans; on the end-systolic phase the DSC was 0.90 and 0.88, respectively. With respect to the clinical volumetric parameters, Pearson correlation coefficient (R) of 0.97 was obtained for the end-diastolic volume, 0.95 for end-systolic volume, 0.87 for stroke volume and 0.84 for ejection fraction. Risk category classification based on ejection fraction showed that 80% of the subjects were assigned to the correct risk category and only one subject (< 1%) was more than one risk category off. We conclude that the proposed automatic pipeline presents a viable and cost-effective alternative for manual annotation.}
}
@article{GALAMBOS201568,
title = {Design, programming and orchestration of heterogeneous manufacturing systems through VR-powered remote collaboration},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {33},
pages = {68-77},
year = {2015},
note = {Special Issue on Knowledge Driven Robotics and Manufacturing},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2014.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0736584514000738},
author = {Péter Galambos and Ádám Csapó and Péter Zentay and István Marcell Fülöp and Tamás Haidegger and Péter Baranyi and Imre J. Rudas},
keywords = {Virtual reality/augmented reality, Mixed virtual and physical reality, Remote collaboration, Virtual commissioning, Future internet, Cognitive infocommunications},
abstract = {Modern manufacturing systems are often composed of a variety of highly customized units and specifically designed manufacturing cells. Optimization of assembly and training of staff requires a series of demo installations and excessive use of costly operational resources. In some cases, components are located at different sites, making the orchestration of the whole system even more difficult. Virtual Reality (VR) collaboration environments offer a solution by enabling high fidelity testing and training of complex manufacturing systems. On the other hand, such platforms are difficult to implement in an engineering perspective, as they are required to provide reliable, standard interfaces towards both robotic components and human operators. The VirCA (Virtual Collaboration Arena) platform is a software framework that supports various means of collaboration through the use of 3D augmented/virtual reality as a communication medium. VirCA offers functions for the high-level interoperability of heterogeneous components in a wide range of domains, spanning from research & development, through remote education to orchestration and management of industrial processes in manufacturing applications. This paper provides an overview of the industrial requirements behind high-fidelity virtual collaboration and demonstrates how the VirCA platform meets these requirements. Use cases are provided to illustrate the usability of the platform.}
}
@article{KARIM201695,
title = {Evaluation of state-of-the-art segmentation algorithms for left ventricle infarct from late Gadolinium enhancement MR images},
journal = {Medical Image Analysis},
volume = {30},
pages = {95-107},
year = {2016},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2016.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S1361841516000050},
author = {Rashed Karim and Pranav Bhagirath and Piet Claus and R. {James Housden} and Zhong Chen and Zahra Karimaghaloo and Hyon-Mok Sohn and Laura {Lara Rodríguez} and Sergio Vera and Xènia Albà and Anja Hennemuth and Heinz-Otto Peitgen and Tal Arbel and Miguel A. {Gonzàlez Ballester} and Alejandro F. Frangi and Marco Götte and Reza Razavi and Tobias Schaeffter and Kawal Rhode},
keywords = {Late Gadolinium enhancement, Segmentation, Algorithm benchmarking},
abstract = {Studies have demonstrated the feasibility of late Gadolinium enhancement (LGE) cardiovascular magnetic resonance (CMR) imaging for guiding the management of patients with sequelae to myocardial infarction, such as ventricular tachycardia and heart failure. Clinical implementation of these developments necessitates a reproducible and reliable segmentation of the infarcted regions. It is challenging to compare new algorithms for infarct segmentation in the left ventricle (LV) with existing algorithms. Benchmarking datasets with evaluation strategies are much needed to facilitate comparison. This manuscript presents a benchmarking evaluation framework for future algorithms that segment infarct from LGE CMR of the LV. The image database consists of 30 LGE CMR images of both humans and pigs that were acquired from two separate imaging centres. A consensus ground truth was obtained for all data using maximum likelihood estimation. Six widely-used fixed-thresholding methods and five recently developed algorithms are tested on the benchmarking framework. Results demonstrate that the algorithms have better overlap with the consensus ground truth than most of the n-SD fixed-thresholding methods, with the exception of the Full-Width-at-Half-Maximum (FWHM) fixed-thresholding method. Some of the pitfalls of fixed thresholding methods are demonstrated in this work. The benchmarking evaluation framework, which is a contribution of this work, can be used to test and benchmark future algorithms that detect and quantify infarct in LGE CMR images of the LV. The datasets, ground truth and evaluation code have been made publicly available through the website: https://www.cardiacatlas.org/web/guest/challenges.}
}
@article{VINURAJKUMAR2022103093,
title = {An Enhanced Fuzzy Segmentation Framework for extracting white matter from T1-weighted MR images},
journal = {Biomedical Signal Processing and Control},
volume = {71},
pages = {103093},
year = {2022},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.103093},
url = {https://www.sciencedirect.com/science/article/pii/S174680942100690X},
author = {S. Vinurajkumar and S. Anandhavelu},
keywords = {Fuzzy clustering, Magnetic resonance imaging, Segmentation, White matter},
abstract = {Background
White matter atrophy computed from Magnetic Resonance (MR) images is a clinical indication of a broad spectrum of neurological disorders. Accurate segmentation of white matter from MR images is necessary to estimate the white matter volume. Most of the techniques in literature used for the segmentation of white matter are computationally slow. The repeatability of segmentation results and consistency of performance on different input images are often poor.
Objectives
A computationally simple fuzzy clustering technique termed Enhanced Fuzzy Segmentation Framework (EFSF) for segmenting the white matter from the T1-Weighted MR images is proposed in this paper.
Methodology
IN EFSF, the fuzzy membership function and prototype value are derived from the generic objective function of FCM using the method of Lagrange’s multiplier. The membership and prototype values are updated iteratively. The clustered image is obtained by replacing each grey level in the input image with the prototype value of the cluster with the largest membership value in the corresponding row of the fuzzy partition matrix. The pixels in the clustered image whose values are equal to the largest prototype value belong to the white matter region.
Results
On 100 test images, the Dice Similarity Index (DSI) and the computational time (in sec) shown by EFSF are 0.8051 ± 0.0577 and 0.6522 ± 0.0502, respectively.
Conclusion
EFSF offers high segmentation accuracy and is computationally fast. Segmentation results offered by EFSF have good repeatability on the same MR slice and consistency on MR slices from various regions of the brain.}
}
@article{MITTAL2019346,
title = {Deep learning based enhanced tumor segmentation approach for MR brain images},
journal = {Applied Soft Computing},
volume = {78},
pages = {346-354},
year = {2019},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2019.02.036},
url = {https://www.sciencedirect.com/science/article/pii/S1568494619301000},
author = {Mamta Mittal and Lalit Mohan Goyal and Sumit Kaur and Iqbaldeep Kaur and Amit Verma and D. {Jude Hemanth}},
keywords = {Brain tumor MRI, Growing Convolution Neural Network (GCNN), Segmentation, Random forest, Stationary Wavelet Transform (SWT)},
abstract = {Automation in medical industry has become one of the necessities in today’s medical scenario. Radiologists/physicians need such automation techniques for accurate diagnosis and treatment planning. Automatic segmentation of tumor portion from Magnetic Resonance (MR) brain images is a challenging task. Several methodologies have been developed with an objective to enhance the segmentation efficiency of the automated system. However, there is always scope for improvement in the segmentation process of medical image analysis. In this work, deep learning-based approach is proposed for brain tumor image segmentation. The proposed method includes the concept of Stationary Wavelet Transform (SWT) and new Growing Convolution Neural Network (GCNN). The significant objective of this work is to enhance the accuracy of the conventional system. A comparative analysis with Support Vector Machine (SVM) and Convolution Neural Network (CNN) is carried out in this work. The experimental results prove that the proposed technique has outperformed SVM and CNN in terms of accuracy, PSNR, MSE and other performance parameters.}
}
@article{DOMINGUEZ2008407,
title = {Modeling and application of MR dampers in semi-adaptive structures},
journal = {Computers & Structures},
volume = {86},
number = {3},
pages = {407-415},
year = {2008},
note = {Smart Structures},
issn = {0045-7949},
doi = {https://doi.org/10.1016/j.compstruc.2007.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S004579490700082X},
author = {A. Dominguez and R. Sedaghati and I. Stiharu},
keywords = {Controllable fluids, Magnetorheological fluid, MR damper, Semi-active control, Adaptive structure, Modeling and simulation},
abstract = {The developing of technology has discovered new materials which have been applied to improve the performance of structures. The researchers have recently increased the attention in controllable fluids and its applications. Magnetorhelological (MR) dampers are devices that employ rheological fluids to modify their mechanical properties. Their mechanical simplicity, high dynamic range, lower power requirements, large force capacity, robustness and safe manner operation in case of fail have made them attractive devices to semi-active control in civil, aerospace and automotive applications. The characteristics of the MR damper change when the rheological fluid is exposed to a magnetic field changing its stiffness and damping coefficients. A non-linear new model based on the Bouc–Wen model, is employed to simulate the hysteresis behavior of the damper. The model considers the frequency, amplitude and current excitation as dependent variables. The finite element model (FEM) of the MR damper element has also been developed based on the proposed model. Subsequently finite element of the adaptive structure embedded with MR dampers has been established and the non-linear response of the whole structure is obtained. Experimental work was carried out to validate the simulations. For this study, a cantilever 3-D space truss structure with 4 bays exposed to different excitations has been considered in which one of the members has been substituted by the MR damper. A good agreement has been observed between the simulations and experimental data.}
}
@article{VALVERDE2017446,
title = {Automated tissue segmentation of MR brain images in the presence of white matter lesions},
journal = {Medical Image Analysis},
volume = {35},
pages = {446-457},
year = {2017},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2016.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S1361841516301621},
author = {Sergi Valverde and Arnau Oliver and Eloy Roura and Sandra González-Villà and Deborah Pareto and Joan C. Vilanova and Lluís Ramió-Torrentà and Àlex Rovira and Xavier Lladó},
keywords = {Brain, MRI, Multiple sclerosis, Automatic tissue segmentation},
abstract = {Over the last few years, the increasing interest in brain tissue volume measurements on clinical settings has led to the development of a wide number of automated tissue segmentation methods. However, white matter lesions are known to reduce the performance of automated tissue segmentation methods, which requires manual annotation of the lesions and refilling them before segmentation, which is tedious and time-consuming. Here, we propose a new, fully automated T1-w/FLAIR tissue segmentation approach designed to deal with images in the presence of WM lesions. This approach integrates a robust partial volume tissue segmentation with WM outlier rejection and filling, combining intensity and probabilistic and morphological prior maps. We evaluate the performance of this method on the MRBrainS13 tissue segmentation challenge database, which contains images with vascular WM lesions, and also on a set of Multiple Sclerosis (MS) patient images. On both databases, we validate the performance of our method with other state-of-the-art techniques. On the MRBrainS13 data, the presented approach was at the time of submission the best ranked unsupervised intensity model method of the challenge (7th position) and clearly outperformed the other unsupervised pipelines such as FAST and SPM12. On MS data, the differences in tissue segmentation between the images segmented with our method and the same images where manual expert annotations were used to refill lesions on T1-w images before segmentation were lower or similar to the best state-of-the-art pipeline incorporating automated lesion segmentation and filling. Our results show that the proposed pipeline achieved very competitive results on both vascular and MS lesions. A public version of this approach is available to download for the neuro-imaging community.}
}
@article{BAI2019157,
title = {Resistor-capacitor (RC) operator-based hysteresis model for magnetorheological (MR) dampers},
journal = {Mechanical Systems and Signal Processing},
volume = {117},
pages = {157-169},
year = {2019},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2018.07.050},
url = {https://www.sciencedirect.com/science/article/pii/S0888327018304539},
author = {Xian-Xu Bai and Fei-Long Cai and Peng Chen},
keywords = {Magnetorheological fluids, Magnetorheological damper, Hysteresis model, Rate independent, Nonlinearity, Resistor-capacitor circuit},
abstract = {Aiming at efficiently and precisely describing and predicting the rate-independent nonlinear hysteresis characteristics of magnetorheological (MR) dampers, this paper investigates a resistor-capacitor (RC) operator-based hysteresis model for MR dampers. The model is under the frame of the “restructured model” proposed by Bai et al. (“Principle and validation of modified hysteretic models for magnetorheological dampers,” Smart Materials and Structures, 24(8), 085014, 2015) with the RC operator substituting the Bouc-Wen operator. The essence of the RC operator is the theoretical generalization of the hysteresis phenomenon that the RC circuit presents in charging and discharging processes. In detail, a virtual displacement variable and updating laws for reference points are employed. The virtual displacement keeps positive in uploading (i.e., RC circuit in charging process) while negative in downloading (i.e., RC circuit in discharging process). The hysteresis output is achieved through applying algebraic expressions, which realizes the RC operator. Based on the experimental results of a MR damper, the comparison and analysis of the RC operator-based model and the Bouc-Wen operator-based hysteresis models, including the Bouc-Wen model and the restructured model, are conducted.}
}
@article{SHENG201973,
title = {Improved parallel MR imaging with accurate coil sensitivity estimation using iterative adaptive support},
journal = {Biomedical Signal Processing and Control},
volume = {51},
pages = {73-81},
year = {2019},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2019.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S1746809419300370},
author = {Jinhua Sheng and Bocheng Wang and Yangjie Ma and Qingqiang Liu and Weixiang Liu and Bin Chen and Meiling Shao},
keywords = {Sensitivity maps, SC SENSE, Joint estimation, Penalty function, Parallel MRI},
abstract = {Estimation of sensitivity profile in SENSE-like methods plays a crucial role in reconstruction. The self-calibration of sensitivity eliminates the separate calibrating scan and therefore reduces imaging time. However, sensitivity estimation by zero-filling in each column outside region of the object introduces inaccuracy and artifacts into the results, especially for the image periphery. Noise and error may propagate to reconstruction. In this paper, based on the method of joint sensitivity estimation and image reconstruction, penalty theory was used to reformulate the objective function to refine the sensitivity maps in each coil. The proposed method was tested on various data sets and in vivo brain data were shown for comparison. By suppressing the background and enhancing sensitivity maps in the region of interest through iterations, the quality of reconstructed image improved significantly, especially when a rather large reduction factor was used.}
}
@article{WANG2021101250,
title = {The role of user-centered AR instruction in improving novice spatial cognition in a high-precision procedural task},
journal = {Advanced Engineering Informatics},
volume = {47},
pages = {101250},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101250},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621000057},
author = {Zhuo Wang and Xiaoliang Bai and Shusheng Zhang and Mark Billinghurst and Weiping He and Yang Wang and Dong Han and Gong Chen and Jianghong Li},
keywords = {Augmented reality, User-centered design, Spatial cognition, Precision},
abstract = {AR instruction is a kind of virtual information presented on a human–computer interface. It allows users to view the geometric state, spatial relationship, operation method, and other information involved in the physical task, to form the spatial cognition of the current interaction process. At present, AR instructions cannot support high-precision procedural tasks. The reason is that the existing research work is to use visual elements to express the spatial relationship of physical tasks, without considering transforming the long-term accumulated potential experience of advanced users into a series of effective visual features and interaction modes, to promote the new users to quickly conceive the task intention. In this paper, a user-centered AR instruction(UcAI) is defined and tested for the first time in a procedural task. The control experiment and behavior analysis of 30 participants designing two tasks with different operation precision show that UcAI is more beneficial to improve the user's spatial cognitive ability than conventional AR instruction. Especially in the high-precision operation task, UcAI plays an important role. Our research results have a certain guiding significance for advanced AR instruction design, which extends AR technology to physical tasks with high cognitive complexity.}
}
@article{ZHANG2018549,
title = {Atlas-based reconstruction of high performance brain MR data},
journal = {Pattern Recognition},
volume = {76},
pages = {549-559},
year = {2018},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2017.11.025},
url = {https://www.sciencedirect.com/science/article/pii/S003132031730479X},
author = {Mingli Zhang and Christian Desrosiers and Caiming Zhang},
keywords = {Multi-subject MRI, Weighted TV, Sparse representation, ADMM},
abstract = {Image priors based on total variation (TV) and nonlocal patch similarity have shown to be powerful techniques for the reconstruction of magnetic resonance (MR) images from undersampled k-space measurements. However, due to the uniform regularization of gradients, standard TV approaches often over-smooth edges in the image, resulting in the loss of important details. This paper proposes a novel compressed sensing method which combines both external and internal information for the high-performance reconstruction of MRI data. A probabilistic atlas is used to model the spatial distribution of gradients that correspond to various anatomical structures in the image. This atlas is then employed to control the level of gradient regularization at each image location, within a weighted TV regularization prior. The proposed method also leverages the redundancy of nonlocal similar patches through a sparse representation model. Experiments on T1-weighted images from the ABIDE dataset show the proposed method to outperform state-of-the-art approaches, for different sampling rates and noise levels.}
}
@article{ZHUANG2022102528,
title = {Cardiac segmentation on late gadolinium enhancement MRI: A benchmark study from multi-sequence cardiac MR segmentation challenge},
journal = {Medical Image Analysis},
volume = {81},
pages = {102528},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2022.102528},
url = {https://www.sciencedirect.com/science/article/pii/S136184152200175X},
author = {Xiahai Zhuang and Jiahang Xu and Xinzhe Luo and Chen Chen and Cheng Ouyang and Daniel Rueckert and Victor M. Campello and Karim Lekadir and Sulaiman Vesal and Nishant RaviKumar and Yashu Liu and Gongning Luo and Jingkun Chen and Hongwei Li and Buntheng Ly and Maxime Sermesant and Holger Roth and Wentao Zhu and Jiexiang Wang and Xinghao Ding and Xinyue Wang and Sen Yang and Lei Li},
keywords = {Multi-sequence, Cardiac MRI segmentation, Benchmark, Challenge},
abstract = {Accurate computing, analysis and modeling of the ventricles and myocardium from medical images are important, especially in the diagnosis and treatment management for patients suffering from myocardial infarction (MI). Late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) provides an important protocol to visualize MI. However, compared with the other sequences LGE CMR images with gold standard labels are particularly limited. This paper presents the selective results from the Multi-Sequence Cardiac MR (MS-CMR) Segmentation challenge, in conjunction with MICCAI 2019. The challenge offered a data set of paired MS-CMR images, including auxiliary CMR sequences as well as LGE CMR, from 45 patients who underwent cardiomyopathy. It was aimed to develop new algorithms, as well as benchmark existing ones for LGE CMR segmentation focusing on myocardial wall of the left ventricle and blood cavity of the two ventricles. In addition, the paired MS-CMR images could enable algorithms to combine the complementary information from the other sequences for the ventricle segmentation of LGE CMR. Nine representative works were selected for evaluation and comparisons, among which three methods are unsupervised domain adaptation (UDA) methods and the other six are supervised. The results showed that the average performance of the nine methods was comparable to the inter-observer variations. Particularly, the top-ranking algorithms from both the supervised and UDA methods could generate reliable and robust segmentation results. The success of these methods was mainly attributed to the inclusion of the auxiliary sequences from the MS-CMR images, which provide important label information for the training of deep neural networks. The challenge continues as an ongoing resource, and the gold standard segmentation as well as the MS-CMR images of both the training and test data are available upon registration via its homepage (www.sdspeople.fudan.edu.cn/zhuangxiahai/0/mscmrseg/).}
}
@article{LI2009384,
title = {Deformation invariant attribute vector for deformable registration of longitudinal brain MR images},
journal = {Computerized Medical Imaging and Graphics},
volume = {33},
number = {5},
pages = {384-398},
year = {2009},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2009.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0895611109000275},
author = {Gang Li and Lei Guo and Tianming Liu},
keywords = {Deformable registration, Longitudinal imaging, Brain MRI, Deformation invariant attribute vector},
abstract = {This paper presents a novel approach to define deformation invariant attribute vector (DIAV) for each voxel in 3D brain image for the purpose of anatomic correspondence detection. The DIAV method is validated by using synthesized deformation in 3D brain MRI images. Both theoretic analysis and experimental studies demonstrate that the proposed DIAV is invariant to general nonlinear deformation. Moreover, our experimental results show that the DIAV is able to capture rich anatomic information around the voxels and exhibit strong discriminative ability. The DIAV has been integrated into a deformable registration algorithm for longitudinal brain MR images, and the results on both simulated and real brain images are provided to demonstrate the good performance of the proposed registration algorithm based on matching of DIAVs.}
}
@article{SUINESIAPUTRA201450,
title = {A collaborative resource to build consensus for automated left ventricular segmentation of cardiac MR images},
journal = {Medical Image Analysis},
volume = {18},
number = {1},
pages = {50-62},
year = {2014},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2013.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1361841513001217},
author = {Avan Suinesiaputra and Brett R. Cowan and Ahmed O. Al-Agamy and Mustafa A. Elattar and Nicholas Ayache and Ahmed S. Fahmy and Ayman M. Khalifa and Pau Medrano-Gracia and Marie-Pierre Jolly and Alan H. Kadish and Daniel C. Lee and Ján Margeta and Simon K. Warfield and Alistair A. Young},
keywords = {Segmentation challenge, Consensus images, LV myocardium},
abstract = {A collaborative framework was initiated to establish a community resource of ground truth segmentations from cardiac MRI. Multi-site, multi-vendor cardiac MRI datasets comprising 95 patients (73 men, 22 women; mean age 62.73±11.24years) with coronary artery disease and prior myocardial infarction, were randomly selected from data made available by the Cardiac Atlas Project (Fonseca et al., 2011). Three semi- and two fully-automated raters segmented the left ventricular myocardium from short-axis cardiac MR images as part of a challenge introduced at the STACOM 2011 MICCAI workshop (Suinesiaputra et al., 2012). Consensus myocardium images were generated based on the Expectation–Maximization principle implemented by the STAPLE algorithm (Warfield et al., 2004). The mean sensitivity, specificity, positive predictive and negative predictive values ranged between 0.63 and 0.85, 0.60 and 0.98, 0.56 and 0.94, and 0.83 and 0.92, respectively, against the STAPLE consensus. Spatial and temporal agreement varied in different amounts for each rater. STAPLE produced high quality consensus images if the region of interest was limited to the area of discrepancy between raters. To maintain the quality of the consensus, an objective measure based on the candidate automated rater performance distribution is proposed. The consensus segmentation based on a combination of manual and automated raters were more consistent than any particular rater, even those with manual input. The consensus is expected to improve with the addition of new automated contributions. This resource is open for future contributions, and is available as a test bed for the evaluation of new segmentation algorithms, through the Cardiac Atlas Project (www.cardiacatlas.org).}
}
@article{SHI201750,
title = {Individual refinement of attenuation correction maps for hybrid PET/MR based on multi-resolution regional learning},
journal = {Computerized Medical Imaging and Graphics},
volume = {60},
pages = {50-57},
year = {2017},
note = {Computational Methods for Molecular Imaging},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2016.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0895611116301033},
author = {Kuangyu Shi and Sebastian Fürst and Liang Sun and Mathias Lukas and Nassir Navab and Stefan Förster and Sibylle I. Ziegler},
keywords = {PET/MR, Attenuation correction, Multi-resolution, Machine learning},
abstract = {PET/MR is an emerging hybrid imaging modality. However, attenuation correction (AC) remains challenging for hybrid PET/MR in generating accurate PET images. Segmentation-based methods on special MR sequences are most widely recommended by vendors. However, their accuracy is usually not high. Individual refinement of available certified attenuation maps may be helpful for further clinical applications. In this study, we proposed a multi-resolution regional learning (MRRL) scheme to utilize the internal consistency of the patient data. The anatomical and AC MR sequences of the same subject were employed to guide the refinement of the provided AC maps. The developed algorithm was tested on 9 patients scanned consecutively with PET/MR and PET/CT (7 [18F]FDG and 2 [18F]FET). The preliminary results showed that MRRL can improve the accuracy of segmented attenuation maps and consequently the accuracy of PET reconstructions.}
}
@article{HU2015332,
title = {Population-based prediction of subject-specific prostate deformation for MR-to-ultrasound image registration},
journal = {Medical Image Analysis},
volume = {26},
number = {1},
pages = {332-344},
year = {2015},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2015.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S1361841515001486},
author = {Yipeng Hu and Eli Gibson and Hashim Uddin Ahmed and Caroline M. Moore and Mark Emberton and Dean C. Barratt},
keywords = {Statistical shape modelling, Organ motion, Tissue deformation, Kernel regression, Image registration},
abstract = {Statistical shape models of soft-tissue organ motion provide a useful means of imposing physical constraints on the displacements allowed during non-rigid image registration, and can be especially useful when registering sparse and/or noisy image data. In this paper, we describe a method for generating a subject-specific statistical shape model that captures prostate deformation for a new subject given independent population data on organ shape and deformation obtained from magnetic resonance (MR) images and biomechanical modelling of tissue deformation due to transrectal ultrasound (TRUS) probe pressure. The characteristics of the models generated using this method are compared with corresponding models based on training data generated directly from subject-specific biomechanical simulations using a leave-one-out cross validation. The accuracy of registering MR and TRUS images of the prostate using the new prostate models was then estimated and compared with published results obtained in our earlier research. No statistically significant difference was found between the specificity and generalisation ability of prostate shape models generated using the two approaches. Furthermore, no statistically significant difference was found between the landmark-based target registration errors (TREs) following registration using different models, with a median (95th percentile) TRE of 2.40 (6.19) mm versus 2.42 (7.15) mm using models generated with the new method versus a model built directly from patient-specific biomechanical simulation data, respectively (N = 800; 8 patient datasets; 100 registrations per patient). We conclude that the proposed method provides a computationally efficient and clinically practical alternative to existing complex methods for modelling and predicting subject-specific prostate deformation, such as biomechanical simulations, for new subjects. The method may also prove useful for generating shape models for other organs, for example, where only limited shape training data from dynamic imaging is available.}
}
@article{SUNDARESAN2021102215,
title = {Comparison of domain adaptation techniques for white matter hyperintensity segmentation in brain MR images},
journal = {Medical Image Analysis},
volume = {74},
pages = {102215},
year = {2021},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2021.102215},
url = {https://www.sciencedirect.com/science/article/pii/S1361841521002607},
author = {Vaanathi Sundaresan and Giovanna Zamboni and Nicola K. Dinsdale and Peter M. Rothwell and Ludovica Griffanti and Mark Jenkinson},
keywords = {Deep learning, White matter hyperintensities, Domain adaptation, Segmentation},
abstract = {Robust automated segmentation of white matter hyperintensities (WMHs) in different datasets (domains) is highly challenging due to differences in acquisition (scanner, sequence), population (WMH amount and location) and limited availability of manual segmentations to train supervised algorithms. In this work we explore various domain adaptation techniques such as transfer learning and domain adversarial learning methods, including domain adversarial neural networks and domain unlearning, to improve the generalisability of our recently proposed triplanar ensemble network, which is our baseline model. We used datasets with variations in intensity profile, lesion characteristics and acquired using different scanners. For the source domain, we considered a dataset consisting of data acquired from 3 different scanners, while the target domain consisted of 2 datasets. We evaluated the domain adaptation techniques on the target domain datasets, and additionally evaluated the performance on the source domain test dataset for the adversarial techniques. For transfer learning, we also studied various training options such as minimal number of unfrozen layers and subjects required for fine-tuning in the target domain. On comparing the performance of different techniques on the target dataset, domain adversarial training of neural network gave the best performance, making the technique promising for robust WMH segmentation.}
}
@article{ILUNGAMBUYAMBA201784,
title = {Localized active contour model with background intensity compensation applied on automatic MR brain tumor segmentation},
journal = {Neurocomputing},
volume = {220},
pages = {84-97},
year = {2017},
note = {Recent Research in Medical Technology Based on Multimedia and Pattern Recognition},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2016.07.057},
url = {https://www.sciencedirect.com/science/article/pii/S092523121630902X},
author = {Elisee Ilunga-Mbuyamba and Juan Gabriel Avina–Cervantes and Arturo Garcia–Perez and Rene de Jesus Romero–Troncoso and Hugo Aguirre–Ramos and Ivan Cruz–Aceves and Claire Chalopin},
keywords = {Active contours, Brain tumor, Image segmentation, Intensity compensation, Level set, Multimodal images, Magnetic resonance imaging},
abstract = {This paper presents a Localized Active Contour Model (LACM) integrating an additional step of background intensity compensation. The region-based active contour models that use statistical intensity information are more sensitive to the high mean intensity distance between consecutive regions. In Magnetic Resonance Imaging (MRI) this distance is great between the foreground and the background, hence it leads to an incorrect delineation of the target. In order to resolve this problem, an automatic process is introduced in our model for balancing the mean intensity distance between an image foreground and its background. The aim is to minimize the attraction effect of the active contour model to the undesired borderlines defined by these two mentioned image regions. By using this approach not only the obtained accuracy outperforms the traditional localized mean separation active contour model, but also it reduces the computation time of the segmentation task. In addition, this method was efficiently applied on automatic brain tumor segmentation in multimodal MRI data. The Hierarchical Centroid Shape Descriptor (HCSD) was used for detecting the region of interest i.e. abnormal tissue so as to automatically initialize the active contour. The validation of experiments was carried out on synthetic images and the quantitative evaluation was performed on the BRATS2012 database. Finally, the accuracy achieved by the proposed method was compared to the localized mean separation intensity, the localized Chan-Vese, the local Gaussian distribution fitting and the local binary fitting models by using the Dice coefficient, Sensitivity, Specificity and the Hausdorff distance. The computation time of the methods was also measured for comparison purposes. The obtained results show that the proposed model outperforms the accuracy of the selected state of the art methods. Moreover, it is also faster than the comparative methods in the medical image segmentation task.}
}
@article{LIN20111036,
title = {Adaptive pixon represented segmentation (APRS) for 3D MR brain images based on mean shift and Markov random fields},
journal = {Pattern Recognition Letters},
volume = {32},
number = {7},
pages = {1036-1043},
year = {2011},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2011.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167865511000596},
author = {Lei Lin and Daniel Garcia-Lorenzo and Chong Li and Tianzi Jiang and Christian Barillot},
keywords = {MRI segmentation, Markov random field, Adaptive mean shift, Pixon-representation, EM algorithm},
abstract = {In this paper, we proposed an adaptive pixon represented segmentation (APRS) algorithm for 3D magnetic resonance (MR) brain images. Different from traditional method, an adaptive mean shift algorithm was adopted to adaptively smooth the query image and create a pixon-based image representation. Then K-means algorithm was employed to provide an initial segmentation by classifying the pixons in image into a predefined number of tissue classes. By using this segmentation as initialization, expectation-maximization (EM) iterations composed of bias correction, a priori digital brain atlas information, and Markov random field (MRF) segmentation were processed. Pixons were assigned with final labels when the algorithm converges. The adoption of bias correction and brain atlas made the current method more suitable for brain image segmentation than the previous pixon based segmentation algorithm. The proposed method was validated on both simulated normal brain images from BrainWeb and real brain images from the IBSR public dataset. Compared with some other popular MRI segmentation methods, the proposed method exhibited a higher degree of accuracy in segmenting both simulated and real 3D MRI brain data. The experimental results were numerically assessed using Dice and Tanimoto coefficients.}
}
@article{BARNHILL2017133,
title = {Nonlinear multiscale regularisation in MR elastography: Towards fine feature mapping},
journal = {Medical Image Analysis},
volume = {35},
pages = {133-145},
year = {2017},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2016.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S136184151630041X},
author = {Eric Barnhill and Lyam Hollis and Ingolf Sack and Jürgen Braun and Peter R. Hoskins and Pankaj Pankaj and Colin Brown and Edwin J.R. {van Beek} and Neil Roberts},
keywords = {Elastography, Magnetic resonance elastography, Wave inversion, Complex dualtree wavelet, Denoising},
abstract = {Fine-featured elastograms may provide additional information of radiological interest in the context of in vivo elastography. Here a new image processing pipeline called ESP (Elastography Software Pipeline) is developed to create Magnetic Resonance Elastography (MRE) maps of viscoelastic parameters (complex modulus magnitude |G*| and loss angle ϕ) that preserve fine-scale information through nonlinear, multi-scale extensions of typical MRE post-processing techniques. Methods: A new MRE image processing pipeline was developed that incorporates wavelet-domain denoising, image-driven noise estimation, and feature detection. ESP was first validated using simulated data, including viscoelastic Finite Element Method (FEM) simulations, at multiple noise levels. ESP images were compared with MDEV pipeline images, both in the FEM models and in three ten-subject cohorts of brain, thigh, and liver acquisitions. ESP and MDEV mean values were compared to 2D local frequency estimation (LFE) mean values for the same cohorts as a benchmark. Finally, the proportion of spectral energy at fine frequencies was quantified using the Reduced Energy Ratio (RER) for both ESP and MDEV. Results: Blind estimates of added noise (σ) were within 5.3% ± 2.6% of prescribed, and the same technique estimated σ in the in vivo cohorts at 1.7 ± 0.8%. A 5 × 5 × 5 truncated Gabor filter bank effectively detects local spatial frequencies at wavelengths λ ≤ 10px. For FEM inversions, mean |G*| of hard target, soft target, and background remained within 8% of prescribed up to σ=20%, and mean ϕ results were within 10%, excepting hard target ϕ, which required redrawing around a ring artefact to achieve similar accuracy. Inspection of FEM |G*| images showed some spatial distortion around hard target boundaries and inspection of ϕ images showed ring artefacts around the same target. For the in vivo cohorts, ESP results showed mean correlation of R=0.83 with MDEV and liver stiffness estimates within 7% of 2D-LFE results. Finally, ESP showed statistically significant increase in fine feature spectral energy as measured with RER for both |G*| (p<1×10−9) and ϕ (p<1×10−3). Conclusion: Information at finer frequencies can be recovered in ESP elastograms in typical experimental conditions, however scatter- and boundary-related artefacts may cause the fine features to have inaccurate values. In in vivo cohorts, ESP delivers an increase in fine feature spectral energy, and better performance with longer wavelengths, than MDEV while showing similar stability and robustness.}
}
@article{HAMBARDE201919,
title = {Radiomics for peripheral zone and intra-prostatic urethra segmentation in MR imaging},
journal = {Biomedical Signal Processing and Control},
volume = {51},
pages = {19-29},
year = {2019},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2019.01.024},
url = {https://www.sciencedirect.com/science/article/pii/S1746809419300254},
author = {Praful Hambarde and Sanjay N. Talbar and Nilesh Sable and Abhishek Mahajan and Satishkumar S. Chavan and Meenakshi Thakur},
keywords = {Peripheral zone of prostate, Intra-prostatic urethra, Prostate gland, Nonnegative matrix factorization, Self organizing maps, T2 weighted MR images, Dice similarity coefficient},
abstract = {Automatic peripheral zone (PZ) and intra-prostatic urethra segmentation has clinical significance in analysis of prostate health management. It is interesting and much challenging task due to heterogeneous and inconsistent pixel intensities around prostate boundary and changes in a shape of the actual prostate capsule from patient to patient. The traditional methods of detection and delineation for glandular prostate gland using magnetic resonance imaging (MRI) involve expertise of radiologists and it is expensive in terms of time and accuracy. This paper proposes a novel technique for automate segmentation of PZ of prostate and intra-prostatic urethra. The technique is based on radiomics extraction using nonnegative matrix factorization (NMF) and segmentation using the self organizing maps (SOMs). The proposed framework is evaluated using 52 axial T2 weighted (T2w) MR images. The dice similarity coefficient (DSC) is calculated to measure the similarity between segmentation results and ground truth images. The proposed algorithm is compared with the conventional K-means (KM) clustering and fuzzy C-means (FCM) clustering approaches of the segmentation. The proposed scheme is shown to be superior based on subjective and objective evaluation analysis. The average percentage of DSC for PZ and intra-prostatic urethra segmentation is 87.33% and 85.55%, respectively using the proposed technique.}
}
@article{AGHABIGLOU2021106151,
title = {Projection-Based cascaded U-Net model for MR image reconstruction},
journal = {Computer Methods and Programs in Biomedicine},
volume = {207},
pages = {106151},
year = {2021},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2021.106151},
url = {https://www.sciencedirect.com/science/article/pii/S016926072100225X},
author = {Amir Aghabiglou and Ender M. Eksioglu},
keywords = {Magnetic resonance imaging, Image reconstruction, Deep learning, Cascaded networks, U-Net, Updated data consistency},
abstract = {Background and Objective
Background and Objective: Recent studies in deep learning reveal that the U-Net stands out among the diverse set of deep models as an effective network structure, especially for imaging inverse problems. Initially, the U-Net model was developed to solve segmentation problems for biomedical images while using an annotated dataset. In this paper, we will study a novel application of the U-Net structure for the important inverse problem of MRI reconstruction. Deep networks are particularly efficient for the speed-up of the MR image reconstruction process by decreasing the data acquisition time, and they can significantly reduce the aliasing artifacts caused by the undersampling in the k-space. Our aim is to develop a novel and efficient cascaded U-Net framework for reconstructing MR images from undersampled k-space data. The new framework should have improved reconstruction performance when compared to competing methodologies.
Methods
In this paper, a novel cascaded framework utilizing the U-Net as a sub-block is being proposed. The introduced U-Net cascade structure is applied to the magnetic resonance image reconstruction problem. The connection between the cascaded U-Nets is realized in the form of a recently developed projection-based updated data consistency layer. The novel structure is implemented in the PyTorch environment, which is one of the standards for deep learning implementations. The recently created fastMRI dataset which forms an important benchmark for MRI reconstruction is used for training and testing purposes.
Results
We present simulation results comparing the novel method with a variety of competitive deep networks. The new cascaded U-Net structures PSNR performance stands on average 1.28 dB higher than the baseline U-Net. The improvement, when compared to the standard CNN, is on average 3.32 dB.
Conclusions
The proposed cascaded U-Net configuration results in an improved reconstruction performance when compared to the CNN, the cascaded CNN, and also the singular U-Net structures, where the singular U-Net forms the baseline reconstruction method from the fastMRI package. The use of the projection-based updated data consistency layer also leads to improved quantitative (including SSIM, PSNR, and NMSE results) and qualitative results when compared to the use of the conventional data consistency layer.}
}
@article{BAI201598,
title = {Multi-atlas segmentation with augmented features for cardiac MR images},
journal = {Medical Image Analysis},
volume = {19},
number = {1},
pages = {98-109},
year = {2015},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2014.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S136184151400142X},
author = {Wenjia Bai and Wenzhe Shi and Christian Ledig and Daniel Rueckert},
keywords = {Multi-atlas segmentation, Patch-based segmentation, Cardiac image segmentation, Augmented features},
abstract = {Multi-atlas segmentation infers the target image segmentation by combining prior anatomical knowledge encoded in multiple atlases. It has been quite successfully applied to medical image segmentation in the recent years, resulting in highly accurate and robust segmentation for many anatomical structures. However, to guide the label fusion process, most existing multi-atlas segmentation methods only utilise the intensity information within a small patch during the label fusion process and may neglect other useful information such as gradient and contextual information (the appearance of surrounding regions). This paper proposes to combine the intensity, gradient and contextual information into an augmented feature vector and incorporate it into multi-atlas segmentation. Also, it explores the alternative to the K nearest neighbour (KNN) classifier in performing multi-atlas label fusion, by using the support vector machine (SVM) for label fusion instead. Experimental results on a short-axis cardiac MR data set of 83 subjects have demonstrated that the accuracy of multi-atlas segmentation can be significantly improved by using the augmented feature vector. The mean Dice metric of the proposed segmentation framework is 0.81 for the left ventricular myocardium on this data set, compared to 0.79 given by the conventional multi-atlas patch-based segmentation (Coupé et al., 2011; Rousseau et al., 2011). A major contribution of this paper is that it demonstrates that the performance of non-local patch-based segmentation can be improved by using augmented features.}
}
@article{FARQUHAR2023109489,
title = {Marconi-Rosenblatt Framework for Intelligent Networks (MR-iNet Gym): For Rapid Design and Implementation of Distributed Multi-agent Reinforcement Learning Solutions for Wireless Networks},
journal = {Computer Networks},
volume = {222},
pages = {109489},
year = {2023},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2022.109489},
url = {https://www.sciencedirect.com/science/article/pii/S1389128622005230},
author = {Collin Farquhar and Swatantra Kafle and Kian Hamedani and Anu Jagannath and Jithin Jagannath},
keywords = {Machine learning, Reinforcement learning, Wireless network, CDMA, Ns-3, OpenAI gym, LPD/I networks, Power and frequency control},
abstract = {We present the Marconi-Rosenblatt Framework for Intelligent Networks (MR-iNet Gym) an open-source architecture designed for accelerating research and development of novel reinforcement learning applied to distributed wireless networks. To ensure an end-to-end architecture, we leverage the existing work of ns3-gym, a software package that allows for using ns-3, a wireless network simulator, as an environment within the OpenAI Gym framework for RL. In addition to this, we have implemented the first known custom CDMA module for ns-3 as well as a framework for RL models with a core suite of implemented algorithms. The software framework capturing the interaction between wireless transceiver (agent) and RL decision engine has been designed to maximize the ease-of-use when testing different RL algorithms and models. In the rest of the paper, we describe these new software components and demonstrate some of the results and capabilities that can be achieved when used in conjunction with the existing open-source ecosystem.}
}
@article{CASCINI2020103308,
title = {Exploring the use of AR technology for co-creative product and packaging design},
journal = {Computers in Industry},
volume = {123},
pages = {103308},
year = {2020},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2020.103308},
url = {https://www.sciencedirect.com/science/article/pii/S016636152030542X},
author = {Gaetano Cascini and Jamie O'Hare and Elies Dekoninck and Niccolo Becattini and Jean-François Boujut and Fatma {Ben Guefrache} and Iacopo Carli and Giandomenico Caruso and Lorenzo Giunta and Federico Morosi},
keywords = {Spatial augmented reality, Co-creation, Design representation, Co-design, Prototype},
abstract = {Extended Reality technologies, including Virtual Reality (VR) and Augmented Reality (AR), are being applied in a wide variety of industrial applications, but their use within design practice remains very limited, despite some promising research activities in this area over the last 20 years. At the same time, design practice has been evolving to place greater emphasis on the role of the client or end-user in the design process through ‘co-creative design’ activities. Whilst offering many benefits, co-creative design activities also present challenges, notably in the communication between designers and non-designers, which can hinder innovation. In this paper, we investigate the potential of a novel, projection-based AR system for the creation of design representations to support co-creative design sessions. The technology is tested through benchmarking experiments and in-situ trials conducted with two industrial partners. Performance metrics and qualitative feedback are used to evaluate the effectiveness of the new technology in supporting co-creative design sessions. Overall, AR technology allows quick, real-time modifications to the surfaces of a physical prototype to try out new ideas. Consequently, designers perceive the possibility to enhance the collaboration with the end-users participating in the session. Moreover, the quality and novelty of ideas generated whilst using projection-based AR outperform conventional sessions or handheld display AR sessions. Whilst the results of these early trials are not conclusive, the results suggest that projection-based AR design representations provide a promising approach to supporting co-creative design sessions.}
}
@article{TIAN202184,
title = {Interactive prostate MR image segmentation based on ConvLSTMs and GGNN},
journal = {Neurocomputing},
volume = {438},
pages = {84-93},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.05.121},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221001053},
author = {Zhiqiang Tian and Xiaojian Li and Zhang Chen and Yaoyue Zheng and Hongcheng Fan and Zhongyu Li and Ce Li and Shaoyi Du},
keywords = {Medical image segmentation, Gated graph neural network, Long short term memory, User interaction},
abstract = {Accurate segmentation of the prostate on magnetic resonance (MR) images plays an important role for prostate cancer diagnosis and treatment. Although many automated prostate segmentation methods have been proposed, the performance still faces several challenges, which includes large variability in prostate shape, unclear boundary, and complex intensity distribution. Therefore, the results obtained from the automated methods should be further refined by users to get a more accurate and reliable segmentation. In this paper, we propose an end-to-end interactive segmentation method to refine the automated results. A convolutional long short term memory (convLSTM) module and a gated graph neural network (GGNN) are presented in the proposed method for prostate segmentation in both automated and interactive manners. A boundary loss is proposed to train our model. We evaluated the proposed method on two public available datasets and one in–house dataset. Experimental results show that the proposed convLSTM module could obtain a DSC of 91.78% on the test dataset, which outperforms eight state-of-the-art methods. A further 1.5% improvements can be obtained by user interactions based on the GGNN. The segmentation time including user interactions and inference time was 2.3 min on average for segmenting one volume.}
}
@article{LI201841,
title = {3D multi-scale FCN with random modality voxel dropout learning for Intervertebral Disc Localization and Segmentation from Multi-modality MR Images},
journal = {Medical Image Analysis},
volume = {45},
pages = {41-54},
year = {2018},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2018.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S1361841518300136},
author = {Xiaomeng Li and Qi Dou and Hao Chen and Chi-Wing Fu and Xiaojuan Qi and Daniel L. Belavý and Gabriele Armbrecht and Dieter Felsenberg and Guoyan Zheng and Pheng-Ann Heng},
keywords = {Multi-modality, Magnetic resonance imaging, Intervertebral discs, Localization, Segmentation, Deep learning, Dropout},
abstract = {Intervertebral discs (IVDs) are small joints that lie between adjacent vertebrae. The localization and segmentation of IVDs are important for spine disease diagnosis and measurement quantification. However, manual annotation is time-consuming and error-prone with limited reproducibility, particularly for volumetric data. In this work, our goal is to develop an automatic and accurate method based on fully convolutional networks (FCN) for the localization and segmentation of IVDs from multi-modality 3D MR data. Compared with single modality data, multi-modality MR images provide complementary contextual information, which contributes to better recognition performance. However, how to effectively integrate such multi-modality information to generate accurate segmentation results remains to be further explored. In this paper, we present a novel multi-scale and modality dropout learning framework to locate and segment IVDs from four-modality MR images. First, we design a 3D multi-scale context fully convolutional network, which processes the input data in multiple scales of context and then merges the high-level features to enhance the representation capability of the network for handling the scale variation of anatomical structures. Second, to harness the complementary information from different modalities, we present a random modality voxel dropout strategy which alleviates the co-adaption issue and increases the discriminative capability of the network. Our method achieved the 1st place in the MICCAI challenge on automatic localization and segmentation of IVDs from multi-modality MR images, with a mean segmentation Dice coefficient of 91.2% and a mean localization error of 0.62 mm. We further conduct extensive experiments on the extended dataset to validate our method. We demonstrate that the proposed modality dropout strategy with multi-modality images as contextual information improved the segmentation accuracy significantly. Furthermore, experiments conducted on extended data collected from two different time points demonstrate the efficacy of our method on tracking the morphological changes in a longitudinal study.}
}
@article{KARAYEGEN2021102458,
title = {Brain tumor prediction on MR images with semantic segmentation by using deep learning network and 3D imaging of tumor region},
journal = {Biomedical Signal Processing and Control},
volume = {66},
pages = {102458},
year = {2021},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.102458},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421000550},
author = {Gökay Karayegen and Mehmet Feyzi Aksahin},
keywords = {Semantic segmentation, Deep learning network, 3D imaging},
abstract = {When it comes to medical image segmentation on brain MR images, using deep learning techniques has a significant impact to predict tumor existence. Manual segmentation of a brain tumor is a time-consuming task and depends on knowledge and experience of physicians. In this paper, we present a semantic segmentation method by utilizing convolutional neural network to automatically segment brain tumor on 3D Brain Tumor Segmentation (BraTS) image data sets that comprise four different imaging modalities (T1, T1C, T2 and Flair). In addition, our study includes 3D imaging of whole brain and comparison between ground truth and predicted labels in 3D. In order to obtain exact tumor region and dimensions such as height, width and depth, this method was successfully applied and images were displayed different planes including sagittal, coronal and axial. Evaluation results of semantic segmentation which was executed by a deep learning network are significantly promising in terms of tumor prediction. Mean prediction ratio was determined as 91.718. Mean IoU (Intersection over Union) and Mean BF score were calculated as 86.946 and 92.938, respectively. Finally, dice scores of the test images were showed significant similarity between ground truth and predicted labels. As a result, both semantic segmentation metrics and 3D imaging can be interpreted as meaningful for diagnosing brain tumor accurately.}
}
@article{YANG201860,
title = {Neural multi-atlas label fusion: Application to cardiac MR images},
journal = {Medical Image Analysis},
volume = {49},
pages = {60-75},
year = {2018},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2018.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S136184151830553X},
author = {Heran Yang and Jian Sun and Huibin Li and Lisheng Wang and Zongben Xu},
keywords = {Multi-atlas label fusion, Left ventricle segmentation, Deep fusion net, Atlas selection},
abstract = {Multi-atlas segmentation approach is one of the most widely-used image segmentation techniques in biomedical applications. There are two major challenges in this category of methods, i.e., atlas selection and label fusion. In this paper, we propose a novel multi-atlas segmentation method that formulates multi-atlas segmentation in a deep learning framework for better solving these challenges. The proposed method, dubbed deep fusion net (DFN), is a deep architecture that integrates a feature extraction subnet and a non-local patch-based label fusion (NL-PLF) subnet in a single network. The network parameters are learned by end-to-end training for automatically learning deep features that enable optimal performance in a NL-PLF framework. The learned deep features are further utilized in defining a similarity measure for atlas selection. By evaluating on two public cardiac MR datasets of SATA-13 and LV-09 for left ventricle segmentation, our approach achieved 0.833 in averaged Dice metric (ADM) on SATA-13 dataset and 0.95 in ADM for epicardium segmentation on LV-09 dataset, comparing favorably with the other automatic left ventricle segmentation methods. We also tested our approach on Cardiac Atlas Project (CAP) testing set of MICCAI 2013 SATA Segmentation Challenge, and our method achieved 0.815 in ADM, ranking highest at the time of writing.}
}
@article{NORI2015316,
title = {Perspective changing in WalCT and VR-WalCT: A gender difference study [WalCT – VR-WalCT: Gender differences]},
journal = {Computers in Human Behavior},
volume = {53},
pages = {316-323},
year = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215300273},
author = {Raffaella Nori and Laura Piccardi and Agnese Pelosi and Daniele {De Luca} and Francesca Frasca and Fiorella Giusberti},
keywords = {Corsi test, Change perspective, Virtual reality, Gender differences, Orientation dependence},
abstract = {We compared the ability of men and women to remember a path from different points of view both in “real” (WalCT) and in virtual reality environments (VR-WalCT). The main aim of the study was to compare the effects of real and virtual reality on recalling environment. A secondary aim was to detect the presence of gender-related differences in the two environments. On the basis of the literature, we did not expect differences between real and virtual WalCT. Moreover, we expected that men would perform better in both environments. Eighty college students (40 men) were assigned to real or virtual environments and had to learn four different paths and then to recall them from 8 different points of view. Results showed that when people have to remember a path from different points of view it is more difficult in a virtual than in a real environment, and that in a real environment women performed best. The results are discussed considering the different spatial strategy used by men and women to recall spatial information and on the basis of visuo-spatial working memory load.}
}
@article{ROULLIER2007239,
title = {Fuzzy algorithms: Application to adipose tissue quantification on MR images},
journal = {Biomedical Signal Processing and Control},
volume = {2},
number = {3},
pages = {239-247},
year = {2007},
note = {IFAC Symposia on Biomedical Systems Modelling & Control},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2007.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S1746809407000481},
author = {Vincent Roullier and Christine Cavaro-Ménard and Guillaume Calmon and Christophe Aubé},
keywords = {Fuzzy methods, FGcM, MRI, Medical image analysis},
abstract = {Metabolic syndrome, which is related to abdominal obesity, is a fast growing disease in our western countries. Its presence greatly increases the risk of developing cardiovascular diseases. The accumulation of visceral adipose tissue plays a key role in the development of the metabolic syndrome. The increase of waist circumference is one of the five criteria of the metabolic syndrome diagnosis. But this increase can be due to visceral or subcutaneous adipose tissues. And these adipose tissues do not play the same rule in metabolic syndrome. The purpose of this study was to develop software for automatic and reliable quantification of visceral and subcutaneous adipose tissues, to detect patient with high risk to develop metabolic syndrome and to follow the evolution of adipose tissue repartition after treatment. A gradient echo magnetic resonance (MR) technique is used, with a TE such that fat and water are opposed in phase. The developed process is based on two fuzzy algorithms. First, we fuzzy generalized clustering algorithms allow to merge pixels according to their intensities. Then, fuzzy connectedness algorithm allows to merge pixels according to cost function related to distance, gradient distance and intensities. A validation is performed with a comparison between expert results made by manual drawing and purpose-made software results. Our software provides an automatic and reliable method to segment visceral and subcutaneous adipose tissue and additionally avoids in some case the problem of inhomogeneity of signal intensity.}
}
@article{SINGH2018281,
title = {Ripplet domain fusion approach for CT and MR medical image information},
journal = {Biomedical Signal Processing and Control},
volume = {46},
pages = {281-292},
year = {2018},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2018.05.042},
url = {https://www.sciencedirect.com/science/article/pii/S1746809418301502},
author = {Sneha Singh and R.S. Anand},
keywords = {Multimodal, Image fusion, Ripplet transform, CT, MR, Spatial frequency},
abstract = {Multimodal medical image fusion (MIF) plays an important role as an assistant for medical professionals by providing a better visualization of diagnostic information using different imaging modalities. The process of image fusion helps the radiologists in the precise diagnosis of several critical diseases and its treatment. In this paper, the proposed framework presents a fusion approach for multimodal medical images that utilize both the features extracted by the discrete ripplet transform (DRT) and pulse coupled neural network. The DRT having different features and a competent depiction of the image coefficients provides several directional high-frequency subband coefficients. The DRT decomposition can preserve more detailed information present in the reference images and further enhance the visualization of the fused images. Firstly, the DRT is applied to decompose the reference images into several low and high-frequency subimage coefficients that are fused by computing the novel sum modified Laplacian and novel modified spatial frequency motivated pulse coupled neural model. This model is used to preserve the redundant information also. Finally, fused images are reconstructed by applying the inverse DRT. The performance of the proposed fusion approach is validated by extensive simulation on the different CT-MR image datasets. Experimental results demonstrate that the proposed method provides the better fused images in terms of visual quality along with the quantitative measures as compared to several existing fusion approaches.}
}
@article{INOUSSA201259,
title = {Nonlinear time series modeling and prediction using functional weights wavelet neural network-based state-dependent AR model},
journal = {Neurocomputing},
volume = {86},
pages = {59-74},
year = {2012},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2012.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0925231212000963},
author = {Garba Inoussa and Hui Peng and Jun Wu},
keywords = {Wavelet networks, Functional weights wavelet network, Modeling, Prediction, Nonlinear time series, Optimization, Autoregression},
abstract = {This paper presents a Functional Weights Wavelet Neural Network-based state-dependent AR (FWWNN-AR) model with the main objective to address the modeling and prediction problem of nonlinear time series. The FWWNN-AR model is a state-dependent autoregressive (SD-AR) model, which has its coefficients approximated by a set of Functional Weights Wavelet Neural Network (FWWNN). The FWWNN is an enhanced type of wavelet neural network comprising of five layers: input, wavelet, product, output and functional weight layer that computes the weights as function of inputs thus making the weights to vary with the inputs and to share the dynamics with the wavelet compartment. The FWWNN-AR model possesses both the advantages of the state-dependent AR model in the description of nonlinear dynamics using few nodes and of the FWWNN in functional approximation considering mutually the time and frequency spaces. It learns the nonlinear dynamics from three distinct levels: AR level, Wavelet compartment level and functional weights level. A Structured Nonlinear Parameter Optimization Method (SNPOM) is applied to estimate the FWWNN-AR model parameters. This learning approach divides the parameter search space into linear and nonlinear subspaces and centers the search in the nonlinear subspace, but at each iteration in the optimization process, a search in the nonlinear (or linear) subspace is executed on the basis of the estimated values just obtained in linear (or nonlinear) subspace. The search in the nonlinear subspace uses a method similar to the Levemberg–Marquardt Method (LMM), and the search in the linear subspace uses the Least Square Method (LSM). The proposed model is validated by comparing its performances and effectiveness with those achieved by some well known models on both generated and real nonlinear time series.}
}
@article{KIM20181,
title = {Development of an AR based method for augmentation of 3D CAD data onto a real ship block image},
journal = {Computer-Aided Design},
volume = {98},
pages = {1-11},
year = {2018},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2017.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S001044851730252X},
author = {Daewoon Kim and Jungseo Park and Kwang Hee Ko},
keywords = {Augmented Reality(AR), Camera pose estimation, Ship construction, Image registration},
abstract = {This paper proposes a method for augmenting a 3D CAD model of a ship block onto an image using an augmented reality technique. A two-dimensional image that captures a ship block is obtained using a digital camera. The image is processed to extract a feature of the block for establishing the correspondence between the block in the image and the 3D CAD model. In this work, a rectangular planar region is used as the feature in the image, which is then compared with face components in the CAD model. Once the correspondence is found, the initial pose of the block is computed using the correspondence information, and the CAD model is then augmented onto the image using the initial pose. Next, a registration process is employed to reduce the registration error further using a Lie Algebra-based method, which iteratively approximates the correct pose while reducing the error. As an option, a manual procedure is provided to allow a user to select the corresponding face for initial pose estimation. Real examples are used for testing the proposed method.}
}
@article{SUHIR20142594,
title = {Three-step concept (TSC) in modeling microelectronics reliability (MR): Boltzmann–Arrhenius–Zhurkov (BAZ) probabilistic physics-of-failure equation sandwiched between two statistical models},
journal = {Microelectronics Reliability},
volume = {54},
number = {11},
pages = {2594-2603},
year = {2014},
issn = {0026-2714},
doi = {https://doi.org/10.1016/j.microrel.2014.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0026271414001978},
author = {E. Suhir},
keywords = {Microelectronics reliability, Reliability prediction, Physics of failure, Predictive modeling, Probabilistic design for reliability},
abstract = {When encountering a particular reliability problem at the design, fabrication, testing, or an operation stage of a product’s life, and considering the use of predictive modeling to assess the seriousness and the likely consequences of the a detected failure, one has to choose whether a statistical, or a physics-of-failure-based, or a suitable combination of these two major modeling tools should be employed to address the problem of interest and to decide on how to proceed. A three-step concept (TSC) is suggested as a possible way to go in such a situation. The classical statistical Bayes’ formula can be used at the first step in this concept as a technical diagnostics tool. Its objective is to identify, on the probabilistic basis, the faulty (malfunctioning) device(s) from the obtained signals (“symptoms of faults”). The recently suggested physics-of-failure-based Boltzmann–Arrhenius–Zhurkov’s (BAZ) model and particularly the multi-parametric BAZ model can be employed at the second step to assess the remaining useful life (RUL) of the faulty device(s). If the RUL is still long enough, no action might be needed; if it is not, corrective restoration action becomes necessary. In any event, after the first two steps are carried out, the device is put back into operation (testing), provided that the assessed probability of its continuing failure-free operation is found to be satisfactory. If the operational failure nonetheless occurs, the third, technical diagnostics step should be undertaken to update reliability. Statistical beta-distribution, in which the probability of failure is treated as a random variable, is suggested to be used at this step. While various statistical methods and approaches, including Bayes’ formula and beta-distribution, are well known and widely used in numerous applications for many decades, the BAZ model was introduced in the microelectronics reliability (MR) area only several years ago. Its attributes are addressed and discussed therefore in some detail. The suggested concept is illustrated by a numerical example geared to the use of the prognostics-and-health-monitoring (PHM) effort in actual operation, such as, e.g., en-route flight mission.}
}
@article{ZHANG2022107233,
title = {Modeling of glioma growth using modified reaction-diffusion equation on brain MR images},
journal = {Computer Methods and Programs in Biomedicine},
volume = {227},
pages = {107233},
year = {2022},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2022.107233},
url = {https://www.sciencedirect.com/science/article/pii/S0169260722006149},
author = {Yanying Zhang and Peter X. Liu and Wenguo Hou},
keywords = {Glioma growth, Reaction-diffusion equation, Inverse distance weight, Parameter space},
abstract = {Background and Objective: Modeling of glioma growth and evolution is of key importance for cancer diagnosis, predicting clinical progression and improving treatment outcomes of neurosurgery. However, existing models are unable to characterize spatial variations of the proliferation and infiltration of tumor cells, making it difficult to achieve accurate prediction of tumor growth. Methods: In this paper, a new growth model of brain tumor using a reaction-diffusion equation on brain magnetic resonance images is proposed. Both the heterogeneity of brain tissue and the density of tumor cells are used to estimate the proliferation and diffusion coefficients of brain tumor cells. The diffusion coefficient that characterizes tumor diffusion and infiltration is calculated based on the ratio of tissues (white and gray matter), while the proliferation coefficient is evaluated using the spatial gradient of tumor cells. In addition, a parameter space is constructed using inverse distance weighted interpolation to describe the spatial distribution of proliferation coefficient.Results: The glioma growth predicted by the proposed model were tested by comparing with the real magnetic resonance images of the patients. Experiments and simulation results show that the proposed method achieves accurate modeling of glioma growth. The interpolation-based growth model has higher average dice score of 0.0647 and 0.0545, and higher average Jaccard index of 0.0673 and 0.0573, respectively, compared to the uniform- and gradient-based growth models. Conclusions: The experimental results demonstrate the feasibility of calculating the proliferation and diffusion coefficients of the growth model based on patient-specific anatomy. The parameter space that characterizes spatial distribution of proliferation and diffusion coefficients is established and incorporated into the simulation of glioma growth. It enables to obtain patient-specific models about glioma growth by estimating and calibrating only a few model parameters.}
}
@article{GINNIS20101045,
title = {VELOS: A VR platform for ship-evacuation analysis},
journal = {Computer-Aided Design},
volume = {42},
number = {11},
pages = {1045-1058},
year = {2010},
note = {Computer aided ship design: Some recent results and steps ahead in theory, methodology and practice},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2009.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0010448509002322},
author = {A.I. Ginnis and K.V. Kostas and C.G. Politis and P.D. Kaklis},
keywords = {Design for safety, Evacuation analysis, Ship-passenger safety, Virtual reality, Ship design},
abstract = {“Virtual Environment for Life On Ships” (VELOS) is a multi-user Virtual Reality (VR) system that aims to support designers to assess (early in the design process) passenger and crew activities on a ship for both normal and hectic conditions of operations and to improve ship design accordingly. This article focuses on presenting the novel features of VELOS related to both its VR and evacuation-specific functionalities. These features include: (i) capability of multiple users’ immersion and active participation in the evacuation process, (ii) real-time interactivity and capability for making on-the-fly alterations of environment events and crowd-behavior parameters, (iii) capability of agents and avatars to move continuously on decks, (iv) integrated framework for both the simplified and advanced method of analysis according to the IMO/MSC 1033 Circular, (v) enrichment of the ship geometrical model with a topological model suitable for evacuation analysis, (vi) efficient interfaces for the dynamic specification and handling of the required heterogeneous input data, and (vii) post-processing of the calculated agent trajectories for extracting useful information for the evacuation process. VELOS evacuation functionality is illustrated using three evacuation test cases for a ro–ro passenger ship.}
}
@article{LEE20181958,
title = {What drives stickiness in location-based AR games? An examination of flow and satisfaction},
journal = {Telematics and Informatics},
volume = {35},
number = {7},
pages = {1958-1970},
year = {2018},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2018.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0736585318303435},
author = {Chun-Hsiung Lee and Hsiu-Sen Chiang and Kuo-Lun Hsiao},
keywords = {Flow, Satisfaction, Augmented reality games, Location-based services, Game stickiness},
abstract = {Although location-based augmented reality (AR) games are popular in recent years, the motivates of the game’s stickiness still need further investigation. The main goal of this research is to investigate the antecedents of the game’s stickiness. This research develops a conceptual model and hypotheses based on the theory of flow and satisfaction to investigate the antecedents. An online questionnaire was developed and distributed on popular websites to collect data, and 1028 usable responses are collected from the players of Pokémon Go in Taiwan. The eleven hypotheses and control variables were validated by using structural equation modeling (SEM) techniques. Among the antecedents of the game’s stickiness in the model, the flow and satisfaction were found to have strong direct effects. The effects of control variables (age, gender, platform, game experience, and in-app expense) on the stickiness were significant as well. Moreover, telepresence, challenge, perceived control, curiosity, and concentration all have direct influences on the flow. Only perceived currency and responsiveness were found to have a direct impact on players’ satisfaction. The model demonstrated good explanatory power for flow and stickiness in the context of location-based AR game. The proposed model can provide insights to location-based AR game developers to design their games and marketing strategies.}
}
@article{MILENKOVIC201555,
title = {Automated breast-region segmentation in the axial breast MR images},
journal = {Computers in Biology and Medicine},
volume = {62},
pages = {55-64},
year = {2015},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2015.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0010482515001195},
author = {Jana Milenković and Olga Chambers and Maja {Marolt Mušič} and Jurij Franc Tasič},
keywords = {Breast MRI, Breast-region segmentation, Tunable Gabor filter, Shortest-path search, Cost function},
abstract = {Purpose
The purpose of this study was to develop a robust breast-region segmentation method independent from the visible contrast between the breast region and surrounding chest wall and skin.
Materials and methods
A fully-automated method for segmentation of the breast region in the axial MR images is presented relying on the edge map (EM) obtained by applying a tunable Gabor filter which sets its parameters according to the local MR image characteristics to detect non-visible transitions between different tissues having a similar MRI signal intensity. The method applies the shortest-path search technique by incorporating a novel cost function using the EM information within the border-search area obtained based on the border information from the adjacent slice. It is validated on 52 MRI scans covering the full American College of Radiology Breast Imaging-Reporting and Data System (BI-RADS) breast-density range.
Results
The obtained results indicate that the method is robust and applicable for the challenging cases where a part of the fibroglandular tissue is connected to the chest wall and/or skin with no visible contrast, i.e. no fat presence, between them compared to the literature methods proposed for the axial MR images. The overall agreement between automatically- and manually-obtained breast-region segmentations is 96.1% in terms of the Dice Similarity Coefficient, and for the breast-chest wall and breast-skin border delineations it is 1.9mm and 1.2mm, respectively, in terms of the Mean-Deviation Distance.
Conclusion
The accuracy, robustness and applicability for the challenging cases of the proposed method show its potential to be incorporated into computer-aided analysis systems to support physicians in their decision making.}
}
@article{MALGINA20131364,
title = {Inhomogeneity correction and fat-tissue extraction in MR images of FacioScapuloHumeral muscular Dystrophy},
journal = {Pattern Recognition Letters},
volume = {34},
number = {12},
pages = {1364-1371},
year = {2013},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2013.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167865513001918},
author = {O. Malgina and A. Praznikar and J.F. Tasic},
keywords = {Magnetic resonance imaging, Fat tissue, Muscle tissue, Bias field, Inhomogeneity correction},
abstract = {The paper proposes an automatic algorithm for the fat- and muscle-tissue delineation in the Magnetic Resonance Image data of the patient’s leg with FacioScapuloHumeral muscular Dystrophy. The algorithm corrects the tissue inhomogeneity with a novel method that produces good results with low computation time and complexity. The estimated bias field is modelled as a multiplicative noise and uses low-pass filtering to obtain smoothness of the form. To reduce the impact of the background low-level intensity on the object high-level intensity, the background is remodified. The inhomogeneity correction method is validated by comparing its results with those of a simulated ground-truth image. In the segmentation procedure, fuzzy c-mean clustering is used. The segmentation results of the automatic algorithm are comparable to the medical-specialist annotations with a similarity index above 0.91, indicating an excellent result of the proposed automatic processing.}
}
@article{TARTARE2014702,
title = {Spectral clustering applied for dynamic contrast-enhanced MR analysis of time–intensity curves},
journal = {Computerized Medical Imaging and Graphics},
volume = {38},
number = {8},
pages = {702-713},
year = {2014},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2014.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0895611114001207},
author = {Guillaume Tartare and Denis Hamad and Mustapha Azahaf and Philippe Puech and Nacim Betrouni},
keywords = {Curves analysis, Dynamic contrast-enhanced (DCE)–magnetic resonance imaging (MRI), Non-parametric analysis, Spectral clustering},
abstract = {Dynamic contrast-enhanced (DCE)–magnetic resonance imaging (MRI) represents an emerging method for the prediction of biomarker responses in cancer. However, DCE images remain difficult to analyze and interpret. Although pharmacokinetic approaches, which involve multi-step processes, can provide a general framework for the interpretation of these data, they are still too complex for robust and accurate implementation. Therefore, statistical data analysis techniques were recently suggested as another valid interpretation strategy for DCE–MRI. In this context, we propose a spectral clustering approach for the analysis of DCE–MRI time–intensity signals. This graph theory-based method allows for the grouping of signals after spatial transformation. Subsequently, these data clusters can be labeled following comparison to arterial signals. Here, we have performed experiments with simulated (i.e., generated via pharmacokinetic modeling) and clinical (i.e., obtained from patients scanned during prostate cancer diagnosis) data sets in order to demonstrate the feasibility and applicability of this kind of unsupervised and non-parametric approach.}
}
@article{SENER201631,
title = {Bayesian segmentation of human facial tissue using 3D MR-CT information fusion, resolution enhancement and partial volume modelling},
journal = {Computer Methods and Programs in Biomedicine},
volume = {124},
pages = {31-44},
year = {2016},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2015.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0169260715002692},
author = {Emre Şener and Erkan U. Mumcuoglu and Salih Hamcan},
keywords = {Image segmentation, Information fusion, Partial volume, Resolution enhancement, Superresolution, Human facial tissue},
abstract = {Background
Accurate segmentation of human head on medical images is an important process in a wide array of applications such as diagnosis, facial surgery planning, prosthesis design, and forensic identification.
Objectives
In this study, a Bayesian method for segmentation of facial tissues is presented. Segmentation classes include muscle, bone, fat, air and skin.
Methods
The method presented incorporates information fusion from multiple modalities, modelling of image resolution (measurement blurring), image noise, two priors helping to reduce noise and partial volume. Image resolution modelling employed facilitates resolution enhancement and superresolution capabilities during image segmentation. Regularization based on isotropic and directional Markov Random Field priors is integrated. The Bayesian model is solved iteratively yielding tissue class labels at every voxel of the image. Sub-methods as variations of the main method are generated by using a combination of the models.
Results
Testing of the sub-methods is performed on two patients using single modality three-dimensional (3D) image (magnetic resonance, MR or computerized tomography, CT) as well as registered MR-CT images with information fusion. Numerical, visual and statistical analyses of the methods are conducted. High segmentation accuracy values are obtained by the use of image resolution and partial volume models as well as information fusion from MR and CT images. The methods are also compared with our Bayesian segmentation method proposed in a previous study. The performance is found to be similar to our previous Bayesian approach, but the presented methods here eliminates ad hoc parameter tuning needed by the previous approach which is system and data acquisition setting dependent.
Conclusions
The Bayesian approach presented provides resolution enhanced segmentation of very thin structures of the human head. Meanwhile, free parameters of the algorithm can be adjusted for different imaging systems and data acquisition settings in a more systematic way as compared with our previous study.}
}
@article{CHAKRABORTY2021101252,
title = {Time-series data optimized AR/ARMA model for frugal spectrum estimation in Cognitive Radio},
journal = {Physical Communication},
volume = {44},
pages = {101252},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2020.101252},
url = {https://www.sciencedirect.com/science/article/pii/S1874490720303293},
author = {Debashis Chakraborty and Salil Kr. Sanyal},
keywords = {Spectrum Estimation, Goodness of fit, Convex optimization, AR/ARMA, AIC–BIC, WARP board},
abstract = {Wideband and agile Spectrum Estimation (SE) is a fundamental component of the Cognitive Radio (CR) system. However, CR systems generally utilize the classical sensing techniques for SE due to heteroscedasticity of the available spectrum. Unfortunately, analysis of the Time-series data for SE using a testbed is rare to find out. A novel Goodness-of-Fit (GoF) based accurate SE technique for CR system has been proposed in this work involving Time-series data samples generated from Field Programmable Gate Array (FPGA) based Wireless open Access Radio Protocol (WARP) testbed having a sampling frequency of 40 MHz. Anderson–Darling (AD) rejection based Null-Hypothesis testing has been employed to implement the CR system within a frequency range of 9 kHz to 10 MHz. 1 MHz sinusoidal signal has been generated by the testbed for digital transmission/reception through Radio Board 1 and 3. Statistical parameters like Mean Square Error (MSE), Final Prediction Error (FPE), Loss Function and Fit(%) of the received samples adjudicate the Convex optimization of the data length. Akaike Information Criteria (AIC) and Bayesian Information Criteria (BIC) are responsible for the selection of the Auto Regressive Moving Average (ARMA) (3,2) model for optimal signal processing. Finally, the Power Spectral Density (PSD) confirms the superiority of the proposed work with the most optimized data length and lag order in real-time. Computation of complexities of the proposed algorithms also indicates a parsimonious choice of the model.}
}
@article{SUNDARESAN2021102184,
title = {Triplanar ensemble U-Net model for white matter hyperintensities segmentation on MR images},
journal = {Medical Image Analysis},
volume = {73},
pages = {102184},
year = {2021},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2021.102184},
url = {https://www.sciencedirect.com/science/article/pii/S1361841521002309},
author = {Vaanathi Sundaresan and Giovanna Zamboni and Peter M. Rothwell and Mark Jenkinson and Ludovica Griffanti},
keywords = {Deep learning, White matter hyperintensities, U-Nets, Segmentation, MRI},
abstract = {White matter hyperintensities (WMHs) have been associated with various cerebrovascular and neurodegenerative diseases. Reliable quantification of WMHs is essential for understanding their clinical impact in normal and pathological populations. Automated segmentation of WMHs is highly challenging due to heterogeneity in WMH characteristics between deep and periventricular white matter, presence of artefacts and differences in the pathology and demographics of populations. In this work, we propose an ensemble triplanar network that combines the predictions from three different planes of brain MR images to provide an accurate WMH segmentation. In the loss functions the network uses anatomical information regarding WMH spatial distribution in loss functions, to improve the efficiency of segmentation and to overcome the contrast variations between deep and periventricular WMHs. We evaluated our method on 5 datasets, of which 3 are part of a publicly available dataset (training data for MICCAI WMH Segmentation Challenge 2017 - MWSC 2017) consisting of subjects from three different cohorts, and we also submitted our method to MWSC 2017 to be evaluated on the unseen test datasets. On evaluating our method separately in deep and periventricular regions, we observed robust and comparable performance in both regions. Our method performed better than most of the existing methods, including FSL BIANCA, and on par with the top ranking deep learning methods of MWSC 2017.}
}
@article{NOBLE2011877,
title = {An atlas-navigated optimal medial axis and deformable model algorithm (NOMAD) for the segmentation of the optic nerves and chiasm in MR and CT images},
journal = {Medical Image Analysis},
volume = {15},
number = {6},
pages = {877-884},
year = {2011},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2011.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S136184151100051X},
author = {Jack H. Noble and Benoit M. Dawant},
keywords = {Optic nerves, Chiasm, Optimal paths, Radiation therapy, Model-based segmentation},
abstract = {In recent years, radiation therapy has become the preferred treatment for many types of head and neck tumors. To plan the procedure, vital structures, including the optic nerves and chiasm, must be identified using CT/MR imagery. In this work we present a novel method for automatically localizing the optic nerves and chiasm using a tubular structure localization algorithm in which a statistical model and image registration are used to incorporate a priori local intensity and shape information. The method results in mean Dice coefficients of 0.8 when compared to manual segmentations over ten test cases. This suggests that our method is more accurate than existing techniques developed for the segmentation of these structures.}
}
@article{XUE2022102346,
title = {2D probabilistic undersampling pattern optimization for MR image reconstruction},
journal = {Medical Image Analysis},
volume = {77},
pages = {102346},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2021.102346},
url = {https://www.sciencedirect.com/science/article/pii/S1361841521003911},
author = {Shengke Xue and Zhaowei Cheng and Guangxu Han and Chaoliang Sun and Ke Fang and Yingchao Liu and Jian Cheng and Xinyu Jin and Ruiliang Bai},
keywords = {Magnetic resonance imaging, Undersampling, Probability distribution, Deep learning},
abstract = {With 3D magnetic resonance imaging (MRI), a tradeoff exists between higher image quality and shorter scan time. One way to solve this problem is to reconstruct high-quality MRI images from undersampled k-space. There have been many recent studies exploring effective k-space undersampling patterns and designing MRI reconstruction methods from undersampled k-space, which are two necessary steps. Most studies separately considered these two steps, although in theory, their performance is dependent on each other. In this study, we propose a joint optimization model, trained end-to-end, to simultaneously optimize the undersampling pattern in the Fourier domain and the reconstruction model in the image domain. A 2D probabilistic undersampling layer was designed to optimize the undersampling pattern and probability distribution in a differentiable manner. A 2D inverse Fourier transform layer was implemented to connect the Fourier domain and the image domain during the forward and back propagation. Finally, we discovered an optimized relationship between the probability distribution of the undersampling pattern and its corresponding sampling rate. Further testing was performed using 3D T1-weighted MR images of the brain from the MICCAI 2013 Grand Challenge on Multi-Atlas Labeling dataset and locally acquired brain 3D T1-weighted MR images of healthy volunteers and contrast-enhanced 3D T1-weighted MR images of high-grade glioma patients. The results showed that the recovered MR images using our 2D probabilistic undersampling pattern (with or without the reconstruction network) significantly outperformed those using the existing start-of-the-art undersampling strategies for both qualitative and quantitative comparison, suggesting the advantages and some extent of the generalization of our proposed method.}
}
@article{BADSHAH2023105344,
title = {Feature extraction from MR images for detection of brain and breast tumors through mathematical modeling},
journal = {Biomedical Signal Processing and Control},
volume = {86},
pages = {105344},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2023.105344},
url = {https://www.sciencedirect.com/science/article/pii/S1746809423007772},
author = {Noor Badshah and Hena Rabbani and Hadia Atta and Muhammad Abeer Irfan and Ali Ahmad},
keywords = {Fuzzy membership function, Intensity inhomogeneity, Multi-scale, Pseudo level set function, Deep learning, CNN},
abstract = {Segmentation of medical images is a critical step to distinguish different regions, especially tumor. The presence of severe intensity inhomogeneity in Magnetic Resonance Imaging (MRI) and Mammogram images makes it difficult to assess and detect the boundaries of tumor. Tumor detection in medical images measures and identifies the structure of the tumor. This challenging task of extracting tumor i.e., region of interest is achieved by proposing a novel fuzzy selective model. The proposed model is mainly based on selective segmentation to detect the tumor in medical images. This model is based on the local Gaussian distribution as a fitting term with fuzzy logic to handle uncertainty and irregular borders in medical images. Due to the usage of fuzzy membership functions, it avoids local minima and converges to the tumor boundary rapidly and efficiently. In addition, to obtain more information of a local intensity, the idea of multi-scale modeling is incorporated to achieve significant results. The proposed segmentation model is applied to diverse MRI and Mammogram datasets containing both the intensity inhomogeneity and noisy images, this data is collected from local hospitals and the ground truths are created by the experts. The extensive simulation results show that the proposed segmentation method significantly outperforms existing state-of-the-art techniques using both the qualitative and quantitative assessment. Loss functions play very important role in CNN architectures, and is well studied research area. In the second part of the paper, we will be introducing a new loss function, which is introduced in the first part of the paper. Deep active contour architectures based Chan-Vese loss function works well in images with homogeneity and may not work well in images with intensity inhomogeneity. We proposed an architecture, whose loss function will be based on this new proposed model. The proposed model is used as a loss function in a newly introduced CNN architecture, which has produced improved results. The results of the new architecture are compared with other existing methods used for segmentation of medical images.}
}
@article{ZHENG2017327,
title = {Evaluation and comparison of 3D intervertebral disc localization and segmentation methods for 3D T2 MR data: A grand challenge},
journal = {Medical Image Analysis},
volume = {35},
pages = {327-344},
year = {2017},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2016.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S1361841516301530},
author = {Guoyan Zheng and Chengwen Chu and Daniel L. Belavý and Bulat Ibragimov and Robert Korez and Tomaž Vrtovec and Hugo Hutt and Richard Everson and Judith Meakin and Isabel Lŏpez Andrade and Ben Glocker and Hao Chen and Qi Dou and Pheng-Ann Heng and Chunliang Wang and Daniel Forsberg and Aleš Neubert and Jurgen Fripp and Martin Urschler and Darko Stern and Maria Wimmer and Alexey A. Novikov and Hui Cheng and Gabriele Armbrecht and Dieter Felsenberg and Shuo Li},
keywords = {Intervertebral disc, MRI, Localization, Segmentation, Challenge, Evaluation},
abstract = {The evaluation of changes in Intervertebral Discs (IVDs) with 3D Magnetic Resonance (MR) Imaging (MRI) can be of interest for many clinical applications. This paper presents the evaluation of both IVD localization and IVD segmentation methods submitted to the Automatic 3D MRI IVD Localization and Segmentation challenge, held at the 2015 International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI2015) with an on-site competition. With the construction of a manually annotated reference data set composed of 25 3D T2-weighted MR images acquired from two different studies and the establishment of a standard validation framework, quantitative evaluation was performed to compare the results of methods submitted to the challenge. Experimental results show that overall the best localization method achieves a mean localization distance of 0.8 mm and the best segmentation method achieves a mean Dice of 91.8%, a mean average absolute distance of 1.1 mm and a mean Hausdorff distance of 4.3 mm, respectively. The strengths and drawbacks of each method are discussed, which provides insights into the performance of different IVD localization and segmentation methods.}
}
@article{SOLOMON200676,
title = {Segmentation of brain tumors in 4D MR images using the hidden Markov model},
journal = {Computer Methods and Programs in Biomedicine},
volume = {84},
number = {2},
pages = {76-85},
year = {2006},
note = {Medical Image Segmentation Special Issue},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2006.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0169260706001970},
author = {Jeffrey Solomon and John A. Butman and Arun Sood},
keywords = {Brain tumor, Expectation-maximization, Hidden Markov model, Software},
abstract = {Tumor size is an objective measure that is used to evaluate the effectiveness of anticancer agents. Responses to therapy are categorized as complete response, partial response, stable disease and progressive disease. Implicit in this scheme is the change in the tumor over time; however, most tumor segmentation algorithms do not use temporal information. Here we introduce an automated method using probabilistic reasoning over both space and time to segment brain tumors from 4D spatio-temporal MRI data. The 3D expectation-maximization method is extended using the hidden Markov model to infer tumor classification based on previous and subsequent segmentation results. Spatial coherence via a Markov Random Field was included in the 3D spatial model. Simulated images as well as patient images from three independent sources were used to validate this method. The sensitivity and specificity of tumor segmentation using this spatio-temporal model is improved over commonly used spatial or temporal models alone.}
}
@article{JUNG2012131,
title = {Efficient mobile AR technology using scalable recognition and tracking based on server-client model},
journal = {Computers & Graphics},
volume = {36},
number = {3},
pages = {131-139},
year = {2012},
note = {Novel Applications of VR},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2012.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0097849312000052},
author = {Jinki Jung and Jaewon Ha and Sang-Wook Lee and Francisco A. Rojas and Hyun S. Yang},
keywords = {Augmented Reality, Mobile devices, Scalable recognition, Server-client model, Optimization},
abstract = {Advancements in mobile devices and vision technology have enabled mobile Augmented Reality (AR) to be serviced in real-time using natural features. However, in viewing AR while moving around in the real world, users often encounter new and diverse target objects. Whether the AR system is scalable to the number of target objects is a very crucial issue for mobile AR services in the real world. This scalability, however, has been severely limited because of the small internal storage capacity and memory of the mobile devices. In this paper, a new framework is proposed that achieves scalability for mobile AR. The scalability is achieved with a bag-of-visual-words based recognition module on the server side that is connected to the clients, which are mobile devices, through a conventional Wi-Fi network. On the client side, the coarse-to-fine tracking module enables robust tracking performance with natural features in real-time. In this study, we optimized modules in mobile devices for expediting pose-tracking processing and simultaneously enabled 3D rendering and animation in real-time. We also propose an efficient recognition method in which metadata are provided by the sensors of mobile devices. In the experiment, it takes approximately 0.2s for the cold start of an AR service initiated on a 10K object database with a recognition accuracy of 99.87%, which should be acceptable for a variety of real-world mobile AR applications.}
}
@article{MIHALYI20151,
title = {Robust 3D object modeling with a low-cost RGBD-sensor and AR-markers for applications with untrained end-users},
journal = {Robotics and Autonomous Systems},
volume = {66},
pages = {1-17},
year = {2015},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2015.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0921889015000135},
author = {Rãzvan-George Mihalyi and Kaustubh Pathak and Narunas Vaskevicius and Tobias Fromm and Andreas Birk},
keywords = {Object modeling, RGBD sensor, Augmented Reality (AR) marker, Pose uncertainty, Graph-SLAM},
abstract = {An approach for generating textured 3D models of objects without the need for complex infrastructure such as turn-tables or high-end sensors on precisely controlled rails is presented. The method is inexpensive as it uses only a low-cost RGBD sensor, e.g., Microsoft Kinect or ASUS Xtion, and Augmented Reality (AR) markers printed on paper sheets. The sensor can be moved by hand by an untrained person and the AR-markers can be arbitrarily placed in the scene, thus allowing the modeling of objects of a large range of sizes. Due to the use of the simple AR markers, the method is significantly more robust than just using the RGBD sensor or a monocular camera alone and it hence avoids the typical need for manual post-processing of alternative approaches like Kinect-Fusion, 123D Catch, Photosynth, or similar. This article has two main contributions: First, the development of a simple, inexpensive method for the quick and easy digitization of physical objects is presented. Second, the development of an uncertainty model for AR-marker pose estimation is introduced. The latter is of interest beyond the object modeling application presented here. The uncertainty model is used in a graph-based relaxation method to improve model-consistency. Realistic modeling of various objects, such as parcels, sport balls, coffee sacks, human dolls, etc., is experimentally demonstrated. Good model-accuracy is shown for several ground-truth objects with simple geometries and known dimensions. Furthermore, it is shown that the models obtained using the uncertainty model have fewer errors than the ones obtained without it.}
}
@article{POLONI2021126,
title = {Brain MR image classification for Alzheimer’s disease diagnosis using structural hippocampal asymmetrical attributes from directional 3-D log-Gabor filter responses},
journal = {Neurocomputing},
volume = {419},
pages = {126-135},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.07.102},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220312972},
author = {Katia M. Poloni and Italo A. {Duarte de Oliveira} and Roger Tam and Ricardo J. Ferrari},
keywords = {Structural hippocampal asymmetries, 3D log-Gabor filters, Alzheimer’s disease, Magnetic resonance imaging, MR image classification},
abstract = {Alzheimer’s disease (AD) is a progressive and irreversible neurodegenerative condition whose development is characterized by lateralized brain atrophies. In AD, the hippocampus is the first brain structure to present atrophy, which, although to a lesser extent, is also a precursor to the broader asymmetrical development of the human brain. Structural magnetic resonance (MR) imaging is capable of detecting the disease-induced anatomical changes in the brain, thus aiding the diagnosis of AD. MR image attributes extracted from the hippocampal regions are commonly used for the AD classification task. However, most of the published methods do not explore hippocampal asymmetries for image classification. In this study, we propose a new technique for performing the classification of MR images for AD using only hippocampal asymmetrical attributes. By using the new proposed asymmetry index (AI), we assessed the attributes and the ones that passed the analysis of variance test, i.e., showing statistically mean differences among the classes (CN, MCI, and AD), were selected for classification. As a result of our study, the statistical analysis of our AI has shown a significant increase in hippocampal asymmetry as disease progress (CN < MCI < AD). Moreover, for the classification using clinical MR images, we obtained accuracy values of 69.44% and 82.59%; and AUC values of 0.76 and 0.9 for CN × MCI and CN × AD, respectively. Last, we found the results of our asymmetry analysis consistent with other statistical assessments and our classification results, using only asymmetry attributes comparable to (or even higher than) existing hippocampus studies.}
}
@article{KONAR2020106348,
title = {A Quantum-Inspired Self-Supervised Network model for automatic segmentation of brain MR images},
journal = {Applied Soft Computing},
volume = {93},
pages = {106348},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106348},
url = {https://www.sciencedirect.com/science/article/pii/S156849462030288X},
author = {Debanjan Konar and Siddhartha Bhattacharyya and Tapan Kr. Gandhi and Bijaya Ketan Panigrahi},
keywords = {Quantum computing, Medical image segmentation, Fully Convolutional Neural Network, QIBDS Net, U-Net},
abstract = {The classical self-supervised neural network architectures suffer from slow convergence problem and incorporation of quantum computing in classical self-supervised networks is a potential solution towards it. In this article, a fully self-supervised novel quantum-inspired neural network model referred to as Quantum-Inspired Self-Supervised Network (QIS-Net) is proposed and tailored for fully automatic segmentation of brain MR images to obviate the challenges faced by deeply supervised Convolutional Neural Network (CNN) architectures. The proposed QIS-Net architecture is composed of three layers of quantum neuron (input, intermediate and output) expressed as qbits. The intermediate and output layers of the QIS-Net architecture are inter-linked through bi-directional propagation of quantum states, wherein the image pixel intensities (quantum bits) are self-organized in between these two layers without any external supervision or training. Quantum observation allows to obtain the true output once the superimposed quantum states interact with the external environment. The proposed self-supervised quantum-inspired network model has been tailored for and tested on Dynamic Susceptibility Contrast (DSC) brain MR images from Nature data sets for detecting complete tumor and reported promising accuracy and reasonable dice similarity scores in comparison with the unsupervised Fuzzy C-Means clustering, self-trained QIBDS Net, Opti-QIBDS Net, deeply supervised U-Net and Fully Convolutional Neural Networks (FCNNs).}
}
@article{AOKI201547,
title = {AR based ornament design system for 3D printing},
journal = {Journal of Computational Design and Engineering},
volume = {2},
number = {1},
pages = {47-54},
year = {2015},
issn = {2288-4300},
doi = {https://doi.org/10.1016/j.jcde.2014.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S2288430014000062},
author = {Hiroshi Aoki and Jun Mitani and Yoshihiro Kanamori and Yukio Fukui},
keywords = {3DCG, Modeling, Augmented reality, 3D printing, Voxel, Octet truss},
abstract = {In recent years, 3D printers have become popular as a means of outputting geometries designed on CAD or 3D graphics systems. However, the complex user interfaces of standard 3D software can make it difficult for ordinary consumers to design their own objects. Furthermore, models designed on 3D graphics software often have geometrical problems that make them impossible to output on a 3D printer. We propose a novel AR (augmented reality) 3D modeling system with an air-spray like interface. We also propose a new data structure (octet voxel) for representing designed models in such a way that the model is guaranteed to be a complete solid. The target shape is based on a regular polyhedron, and the octet voxel representation is suitable for designing geometrical objects having the same symmetries as the base regular polyhedron. Finally, we conducted a user test and confirmed that users can intuitively design their own ornaments in a short time with a simple user interface.}
}
@article{TAKENAKA20192355,
title = {Development of a support system for reviewing and learning historical events by active simulation using AR markers},
journal = {Procedia Computer Science},
volume = {159},
pages = {2355-2363},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.410},
url = {https://www.sciencedirect.com/science/article/pii/S187705091931614X},
author = {Hiroki Takenaka and 　Masato Soga},
keywords = {Japanese history, Learning support, AR, Historical review},
abstract = {There are a lot of people who are not good at learning history, since they are simply trying to memory terms. Certainly, memorization of terms is also necessary, but just reading and remembering words does not mean that they understand history, and it is difficult to keep in memories. The most important thing in learning history is to know the flow of what caused an event, what process it took and what kind of result was caused. However, it is difficult for those who do not know this to notice on their own, and a new teaching material that can learn historical facts is necessary. In this research, we set up a system to learn by tracing the flow of historical facts, using Sekigahara battle in Japanese history as a test case, and remove the weak consciousness in learning in Japanese history. In addition, we aim to increase learner’s interest in Japanese history and improve learning motivation. In addition, we aimed to be able to deepen understanding by introducing AR marker into the system, seeing it and moving it by hand. In order to confirm that the system is useful, 12 subjects used this system, and they answered a questionnaire about their feelings.}
}
@article{CHATTERJEE2022105321,
title = {ReconResNet: Regularised residual learning for MR image reconstruction of Undersampled Cartesian and Radial data},
journal = {Computers in Biology and Medicine},
volume = {143},
pages = {105321},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.105321},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522001135},
author = {Soumick Chatterjee and Mario Breitkopf and Chompunuch Sarasaen and Hadya Yassin and Georg Rose and Andreas Nürnberger and Oliver Speck},
keywords = {MRI, MR Image reconstruction, Undersampled MRI, Undersampled MR Reconstruction, Radial sampling reconstruction, Deep learning},
abstract = {MRI is an inherently slow process, which leads to long scan time for high-resolution imaging. The speed of acquisition can be increased by ignoring parts of the data (undersampling). Consequently, this leads to the degradation of image quality, such as loss of resolution or introduction of image artefacts. This work aims to reconstruct highly undersampled Cartesian or radial MR acquisitions, with better resolution and with less to no artefact compared to conventional techniques like compressed sensing. In recent times, deep learning has emerged as a very important area of research and has shown immense potential in solving inverse problems, e.g. MR image reconstruction. In this paper, a deep learning based MR image reconstruction framework is proposed, which includes a modified regularised version of ResNet as the network backbone to remove artefacts from the undersampled image, followed by data consistency steps that fusions the network output with the data already available from undersampled k-space in order to further improve reconstruction quality. The performance of this framework for various undersampling patterns has also been tested, and it has been observed that the framework is robust to deal with various sampling patterns, even when mixed together while training, and results in very high quality reconstruction, in terms of high SSIM (highest being 0.990 ± 0.006 for acceleration factor of 3.5), while being compared with the fully sampled reconstruction. It has been shown that the proposed framework can successfully reconstruct even for an acceleration factor of 20 for Cartesian (0.968 ± 0.005) and 17 for radially (0.962 ± 0.012) sampled data. Furthermore, it has been shown that the framework preserves brain pathology during reconstruction while being trained on healthy subjects.}
}
@article{FU201847,
title = {Sparse deformation prediction using Markove Decision Processes (MDP) for Non-rigid registration of MR image},
journal = {Computer Methods and Programs in Biomedicine},
volume = {162},
pages = {47-59},
year = {2018},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2018.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S0169260718300506},
author = {Tianyu Fu and Qin Li and Jianjun Zhu and Danni Ai and Yong Huang and Hong Song and Yurong Jiang and Yongtian Wang and Jian Yang},
keywords = {Deformation prediction, Markove decision processes, Patch-wise registration, MR image},
abstract = {Background and Objective
A framework of sparse deformation prediction using Markove Decision Processes is proposed for achieving a rapid and accurate registration by providing a suitable initial deformation.
Methods
In the proposed framework, the tree is built based on the training set for each patch from the template image. The template patch is considered as the root. The node is the patch group in which multiple similar patches are extracted around a key point on the training image. Given the linkages between patch groups in the tree, MDP is introduced to select the optimal path with highest registration accuracy from each training patch to the template patch. The deformation between them is estimated along the selected path by patch-wise registration which can be realized by a non-learning-based method. Given the patches on a testing image, their best matching patches are fast chosen from the training patches and the corresponding deformations constitute a sparse deformation. A dense deformation for the entire test image is subsequently interpolated and used as an initial deformation for further registration.
Results
With the non-learning-based registration as the baseline method, the proposed framework is evaluated using three datasets of inter-subject brain MR images with three learning-based methods. Experimental results of the non-learning-based method using the proposed framework reveal that the computation time is reduced by fivefold after using the proposed framework. And, with the same baseline method, the proposed framework demonstrates the higher accuracy than three learning-based methods which predicts the initial deformation at image scale. The mean Dice of three datasets for the tissues of the brain are 73.52%, 70.73% and 64.82%, respectively.
Conclusions
The proposed framework rapidly registers the inter-subject brains and achieves the high mean Dice for the tissues of the brain.}
}
@article{ZHANG2015130,
title = {MR image super-resolution reconstruction using sparse representation, nonlocal similarity and sparse derivative prior},
journal = {Computers in Biology and Medicine},
volume = {58},
pages = {130-145},
year = {2015},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2014.12.023},
url = {https://www.sciencedirect.com/science/article/pii/S0010482515000025},
author = {Di Zhang and Jiazhong He and Yun Zhao and Minghui Du},
keywords = {Magnetic resonance imaging, Super-resolution, Sparse representation, Sparse derivative prior, Nonlocal similarity},
abstract = {In magnetic resonance (MR) imaging, image spatial resolution is determined by various instrumental limitations and physical considerations. This paper presents a new algorithm for producing a high-resolution version of a low-resolution MR image. The proposed method consists of two consecutive steps: (1) reconstructs a high-resolution MR image from a given low-resolution observation via solving a joint sparse representation and nonlocal similarity L1-norm minimization problem; and (2) applies a sparse derivative prior based post-processing to suppress blurring effects. Extensive experiments on simulated brain MR images and two real clinical MR image datasets validate that the proposed method achieves much better results than many state-of-the-art algorithms in terms of both quantitative measures and visual perception.}
}
@article{XIANG201831,
title = {Deep embedding convolutional neural network for synthesizing CT image from T1-Weighted MR image},
journal = {Medical Image Analysis},
volume = {47},
pages = {31-44},
year = {2018},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2018.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S1361841518301257},
author = {Lei Xiang and Qian Wang and Dong Nie and Lichi Zhang and Xiyao Jin and Yu Qiao and Dinggang Shen},
keywords = {Image synthesis, Deep convolutional neural network, Embedding block},
abstract = {Recently, more and more attention is drawn to the field of medical image synthesis across modalities. Among them, the synthesis of computed tomography (CT) image from T1-weighted magnetic resonance (MR) image is of great importance, although the mapping between them is highly complex due to large gaps of appearances of the two modalities. In this work, we aim to tackle this MR-to-CT synthesis task by a novel deep embedding convolutional neural network (DECNN). Specifically, we generate the feature maps from MR images, and then transform these feature maps forward through convolutional layers in the network. We can further compute a tentative CT synthesis from the midway of the flow of feature maps, and then embed this tentative CT synthesis result back to the feature maps. This embedding operation results in better feature maps, which are further transformed forward in DECNN. After repeating this embedding procedure for several times in the network, we can eventually synthesize a final CT image in the end of the DECNN. We have validated our proposed method on both brain and prostate imaging datasets, by also comparing with the state-of-the-art methods. Experimental results suggest that our DECNN (with repeated embedding operations) demonstrates its superior performances, in terms of both the perceptive quality of the synthesized CT image and the run-time cost for synthesizing a CT image.}
}
@article{FU2021101845,
title = {Biomechanically constrained non-rigid MR-TRUS prostate registration using deep learning based 3D point cloud matching},
journal = {Medical Image Analysis},
volume = {67},
pages = {101845},
year = {2021},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2020.101845},
url = {https://www.sciencedirect.com/science/article/pii/S1361841520302097},
author = {Yabo Fu and Yang Lei and Tonghe Wang and Pretesh Patel and Ashesh B. Jani and Hui Mao and Walter J. Curran and Tian Liu and Xiaofeng Yang},
keywords = {MR-TRUS, Image registration, Point cloud matching, Finite element, Deep learning},
abstract = {A non-rigid MR-TRUS image registration framework is proposed for prostate interventions. The registration framework consists of a convolutional neural networks (CNN) for MR prostate segmentation, a CNN for TRUS prostate segmentation and a point-cloud based network for rapid 3D point cloud matching. Volumetric prostate point clouds were generated from the segmented prostate masks using tetrahedron meshing. The point cloud matching network was trained using deformation field that was generated by finite element analysis. Therefore, the network implicitly models the underlying biomechanical constraint when performing point cloud matching. A total of 50 patients’ datasets were used for the network training and testing. Alignment of prostate shapes after registration was evaluated using three metrics including Dice similarity coefficient (DSC), mean surface distance (MSD) and Hausdorff distance (HD). Internal point-to-point registration accuracy was assessed using target registration error (TRE). Jacobian determinant and strain tensors of the predicted deformation field were calculated to analyze the physical fidelity of the deformation field. On average, the mean and standard deviation were 0.94±0.02, 0.90±0.23 mm, 2.96±1.00 mm and 1.57±0.77 mm for DSC, MSD, HD and TRE, respectively. Robustness of our method to point cloud noise was evaluated by adding different levels of noise to the query point clouds. Our results demonstrated that the proposed method could rapidly perform MR-TRUS image registration with good registration accuracy and robustness.}
}
@article{KIM2016162,
title = {Robust semi-automated quantification of cardiac MR perfusion using level set: Application to hypertrophic cardiomyopathy patient data},
journal = {Computers in Biology and Medicine},
volume = {71},
pages = {162-173},
year = {2016},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2016.02.014},
url = {https://www.sciencedirect.com/science/article/pii/S0010482516300439},
author = {Yoon-Chul Kim and Sung Mok Kim and Yeon Hyeon Choe},
keywords = {MRI, Dynamic contrast enhanced imaging, Myocardial perfusion, Image segmentation},
abstract = {Background
Recently there have been several clinical MR perfusion studies in patients with hypertrophic cardiomyopathy (HCM) who may suffer from myocardial ischemia due to coronary microvascular dysfunction. In these studies, data analysis relied on a manual procedure of tracing epicardial and endocardial borders. The goal of this work is to develop and validate a robust semi-automated analysis method for myocardial perfusion quantification in clinical HCM data.
Method
Dynamic multi-slice stress perfusion MRI data were acquired from 18 HCM patients. The proposed semi-automated method required user input of two landmark selections: LV center point and RV insertion point. Automated segmentations of the endocardial and epicardial borders were performed in three short-axis slices using distance regularized level set evolution on RV, LV, and myocardial enhancement frames.
Results
The proposed automated epicardial border detection method resulted in average radial distance errors of 7.5%, 9.5%, and 11.6% in basal, mid, and apical slices, respectively, when compared to manual tracing of the borders as a reference. In linear regression analysis, the highest correlation of myocardial upslope measurements was observed between the manual method and the proposed method in the anterolateral section (r=0.964), and the lowest correlation was observed in the inferoseptal section (r=0.866).
Conclusion
The proposed semi-automated method for myocardial MR perfusion quantification is feasible in HCM patients who typically show (1) irregular myocardial shape and (2) low image contrast between the myocardium and its surrounding regions due to coronary microvascular disease.}
}
@article{GHASSEMI2020101678,
title = {Deep neural network with generative adversarial networks pre-training for brain tumor classification based on MR images},
journal = {Biomedical Signal Processing and Control},
volume = {57},
pages = {101678},
year = {2020},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2019.101678},
url = {https://www.sciencedirect.com/science/article/pii/S1746809419302599},
author = {Navid Ghassemi and Afshin Shoeibi and Modjtaba Rouhani},
keywords = {Magnetic resonance imaging (MRI), Deep neural networks, Generative adversarial network (GAN), Brain tumor classification},
abstract = {In this paper, a new deep learning method for tumor classification in MR images is presented. A deep neural network is first pre-trained as a discriminator in a generative adversarial network (GAN) on different datasets of MR images to extract robust features and to learn the structure of MR images in its convolutional layers. Then the fully connected layers are replaced and the whole deep network is trained as a classifier to distinguish three tumor classes. The deep neural network classifier has six layers and about 1.7 million weight parameters. Pre-training as a discriminator of a GAN together with other techniques such as data augmentations (image rotation and mirroring) and dropout prevent the network from overtraining on a relatively small dataset. This method is applied to an MRI data set consists of 3064 T1-CE MR images from 233 patients, 13 images from each patient on average, with three different brain tumor types: meningioma (708 images), glioma (1426 images), and pituitary tumor (930 images). 5-Fold cross-validation is used to evaluate the performance of overall design, achieving the highest accuracy as compared to state-of-art methods.}
}
@article{CHENOUNE2005607,
title = {Segmentation of cardiac cine-MR images and myocardial deformation assessment using level set methods},
journal = {Computerized Medical Imaging and Graphics},
volume = {29},
number = {8},
pages = {607-616},
year = {2005},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2005.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0895611105000820},
author = {Y. Chenoune and E. Deléchelle and E. Petit and T. Goissen and J. Garot and A. Rahmouni},
keywords = {Cardiac cine-MRI, Level set method, Segmentation, Contour matching, Cardiac deformation analysis},
abstract = {In this paper, we present an original method to assess the deformations of the left ventricular myocardium on cardiac cine-MRI. First, a segmentation process, based on a level set method is directly applied on a 2D+t dataset to detect endocardial contours. Second, the successive segmented contours are matched using a procedure of global alignment, followed by a morphing process based on a level set approach. Finally, local measurements of myocardial deformations are derived from the previously determined matched contours. The validation step is realized by comparing our results to the measurements achieved on the same patients by an expert using the semi-automated HARP reference method on tagged MR images.}
}
@article{BASNET2021103063,
title = {A deep dense residual network with reduced parameters for volumetric brain tissue segmentation from MR images},
journal = {Biomedical Signal Processing and Control},
volume = {70},
pages = {103063},
year = {2021},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.103063},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421006601},
author = {Ramesh Basnet and M. Omair Ahmad and M.N.S. Swamy},
keywords = {Brain tissue, Convolutional neural network, Deep learning, Magnetic resonance imaging, Segmentation},
abstract = {Deep convolutional neural networks (DCNN) have proven to be the state-of-the-art methods for brain tissue segmentation; however, their complex architectures, and the large number of parameters make them computationally expensive and difficult to optimize. In this paper, a novel 3D DCNN architecture, which is built upon the U-Net structure, is presented for compact feature representation and efficient parameter reduction in order to segment the brain tissues into white matter, gray matter, and cerebrospinal fluid (Code is available at: https://github.com/basnetr/U-DenseResNet). The basic idea in the proposed method is to use densely connected convolutional layers and residual skip-connections in order to increase the representation capacity, improve the gradient flow, facilitate easier and better learning, and reduce the number of parameters of the network. The loss functions, cross-entropy, dice similarity, and a combination of the two are used for the training of the proposed network. Experimental results show that the proposed approach provides the best performance on the test dataset of the single-modality IBSR18 dataset containing MR scans of diverse age groups and competitive performance on the multi-modality brain tissue segmentation challenge, iSeg-2017, containing MR scans of infants while reducing, for both the datasets, the parameters ranging from 40% to 98% compared to that of the other deep-learning based architectures. The proposed method significantly reduces the number of parameters of DCNNs while still providing high degree of accuracy. The proposed method can be used for the study of brain structure and development, in detecting a wide range of abnormal tissues, to aid diagnosis, and for guiding surgical procedures.}
}
@article{LELIEVELDT20001,
title = {Anatomical Modeling with Fuzzy Implicit Surface Templates: Application to Automated Localization of the Heart and Lungs in Thoracic MR Volumes},
journal = {Computer Vision and Image Understanding},
volume = {80},
number = {1},
pages = {1-20},
year = {2000},
issn = {1077-3142},
doi = {https://doi.org/10.1006/cviu.2000.0864},
url = {https://www.sciencedirect.com/science/article/pii/S1077314200908646},
author = {Boudewijn P.F. Lelieveldt and Milan Sonka and Lizann Bolinger and Thomas D. Scholz and Hein Kayser and Rob {van der Geest} and Johan H.C. Reiber},
abstract = {In this paper, a novel model-driven segmentation approach for thoracic MR-images is presented. The goal of this work is to coarsely, but fully automatically localize the boundary surfaces of the heart and lungs in thoracic MR sets. The major organs in the thorax are described in a three-dimensional analytical model template by combining a set of fuzzy implicit surfaces by means of constructive solid geometry and formulating model registration as an energy minimization. The method has been validated on 20 thoracic MR volumes from two centers (patients and normal subjects). On average 90% of the contour length of the heart and lung contours was localized with sufficient accuracy (average positional error 6 mm) to automatically provide the initial conditions for a subsequently applied locally accurate segmentation method.}
}
@article{GE201960,
title = {Multi-stream multi-scale deep convolutional networks for Alzheimer’s disease detection using MR images},
journal = {Neurocomputing},
volume = {350},
pages = {60-69},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.04.023},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219305478},
author = {Chenjie Ge and Qixun Qu and Irene Yu-Hua Gu and Asgeir Store Jakola},
keywords = {Alzheimer’s disease detection, MR images, Deep learning, Deep convolutional networks, Multi-scale feature learning, Feature fusion, Tissue region, Feature boosting and dimension reduction},
abstract = {This paper addresses the issue of Alzheimer’s disease (AD) detection from Magnetic Resonance Images (MRIs). Existing AD detection methods rely on global feature learning from the whole brain scans, while depending on the tissue types, AD related features in different tissue regions, e.g. grey matter (GM), white matter (WM), and cerebrospinal fluid (CSF), show different characteristics. In this paper, we propose a deep learning method for multi-scale feature learning based on segmented tissue areas. A novel deep 3D multi-scale convolutional network scheme is proposed to generate multi-resolution features for AD detection. The proposed scheme employs several parallel 3D multi-scale convolutional networks, each applying to individual tissue regions (GM, WM and CSF) followed by feature fusions. The proposed fusion is applied in two separate levels: the first level fusion is applied on different scales within the same tissue region, and the second level is on different tissue regions. To further reduce the dimensions of features and mitigate overfitting, a feature boosting and dimension reduction method, XGBoost, is utilized before the classification. The proposed deep learning scheme has been tested on a moderate open dataset of ADNI (1198 scans from 337 subjects), with excellent test performance on randomly partitioned datasets (best 99.67%, average 98.29%), and good test performance on subject-separated partitioned datasets (best 94.74%, average 89.51%). Comparisons with state-of-the-art methods are also included.}
}
@article{LUCENA201948,
title = {Convolutional neural networks for skull-stripping in brain MR imaging using silver standard masks},
journal = {Artificial Intelligence in Medicine},
volume = {98},
pages = {48-58},
year = {2019},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2019.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0933365718305177},
author = {Oeslle Lucena and Roberto Souza and Letícia Rittner and Richard Frayne and Roberto Lotufo},
keywords = {Silver standard masks, Convolutional neural network (CNN), Skull-stripping, Data augmentation},
abstract = {Manual annotation is considered to be the “gold standard” in medical imaging analysis. However, medical imaging datasets that include expert manual segmentation are scarce as this step is time-consuming, and therefore expensive. Moreover, single-rater manual annotation is most often used in data-driven approaches making the network biased to only that single expert. In this work, we propose a CNN for brain extraction in magnetic resonance (MR) imaging, that is fully trained with what we refer to as “silver standard” masks. Therefore, eliminating the cost associated with manual annotation. Silver standard masks are generated by forming the consensus from a set of eight, public, non-deep-learning-based brain extraction methods using the Simultaneous Truth and Performance Level Estimation (STAPLE) algorithm. Our method consists of (1) developing a dataset with “silver standard” masks as input, and implementing (2) a tri-planar method using parallel 2D U-Net-based convolutional neural networks (CNNs) (referred to as CONSNet). This term refers to our integrated approach, i.e., training with silver standard masks and using a 2D U-Net-based architecture. We conducted our analysis using three public datasets: the Calgary-Campinas-359 (CC-359), the LONI Probabilistic Brain Atlas (LPBA40), and the Open Access Series of Imaging Studies (OASIS). Five performance metrics were used in our experiments: Dice coefficient, sensitivity, specificity, Hausdorff distance, and symmetric surface-to-surface mean distance. Our results showed that we outperformed (i.e., larger Dice coefficients) the current state-of-the-art skull-stripping methods without using gold standard annotation for the CNNs training stage. CONSNet is the first deep learning approach that is fully trained using silver standard data and is, thus, more generalizable. Using these masks, we eliminate the cost of manual annotation, decreased inter-/intra-rater variability, and avoided CNN segmentation overfitting towards one specific manual annotation guideline that can occur when gold standard masks are used. Moreover, once trained, our method takes few seconds to process a typical brain image volume using modern a high-end GPU. In contrast, many of the other competitive methods have processing times in the order of minutes.}
}
@article{ISKANDER2019102883,
title = {Using biomechanics to investigate the effect of VR on eye vergence system},
journal = {Applied Ergonomics},
volume = {81},
pages = {102883},
year = {2019},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2019.102883},
url = {https://www.sciencedirect.com/science/article/pii/S0003687018302904},
author = {Julie Iskander and Mohammed Hossny and Saeid Nahavandi},
keywords = {Virtual reality, Eye vergence movement, Eye tracking, Biomechanical simulation, Extraocular muscles},
abstract = {Vergence-accommodation conflict (VAC) is the main contributor to visual fatigue during immersion in virtual environments. Many studies have investigated the effects of VAC using 3D displays and expensive complex apparatus and setup to create natural and conflicting viewing conditions. However, a limited number of studies targeted virtual environments simulated using modern consumer-grade VR headsets. Our main objective, in this work, is to test how the modern VR headsets (VR simulated depth) could affect our vergence system, in addition to investigating the effect of the simulated depth on the eye-gaze performance. The virtual scenario used included a common virtual object (a cube) in a simple virtual environment with no constraints placed on the head and neck movement of the subjects. We used ocular biomechanics and eye tracking to compare between vergence angles in matching (ideal) and conflicting (real) viewing conditions. Real vergence angle during immersion was significantly higher than ideal vergence angle and exhibited higher variability which leads to incorrect depth cues that affects depth perception and also leads to visual fatigue for prolonged virtual experiences. Additionally, we found that as the simulated depth increases, the ability of users to manipulate virtual objects with their eyes decreases, thus, decreasing the possibilities of interaction through eye gaze. The biomechanics model used here can be further extended to study muscular activity of eye muscles during immersion. It presents an efficient and flexible assessment tool for virtual environments.}
}
@article{ZHANG201859,
title = {KaraKter: An autonomously interacting Karate Kumite character for VR-based training and research},
journal = {Computers & Graphics},
volume = {72},
pages = {59-69},
year = {2018},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2018.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0097849318300086},
author = {Liang Zhang and Guido Brunnett and Katharina Petri and Marco Danneberg and Steffen Masik and Nicole Bandow and Kerstin Witte},
keywords = {Virtual reality, Virtual character, Motion generation, Sports simulation},
abstract = {We report on the creation of an autonomous Karate Kumite character (KaraKter) that can be used for VR based training and research in Karate Kumite. For the real time interaction with KaraKter, a human athlete is tracked in a virtual environment. KaraKter moves in Karate specific ways, approaches the athlete and realizes adequate attacks depending on the behavior of the human. KaraKter passed tests on functionality and performance and has been evaluated by high ranking Karate experts. The evaluation showed that the athletes accept KaraKter as an actual opponent. All experts rated the system to be useful in the training of Karate Kumite.}
}
@article{BATHEN2009135,
title = {Combining clinical assessment scores and in vivo MR spectroscopy neurometabolites in very low birth weight adolescents},
journal = {Artificial Intelligence in Medicine},
volume = {47},
number = {2},
pages = {135-146},
year = {2009},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2009.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0933365709000554},
author = {Tone F. Bathen and Gro C. {Christensen Løhaugen} and Ann-Mari Brubakk and Ingrid S. Gribbestad and David E. Axelson and Jon Skranes},
keywords = {In vivo MRS, Very low birth weight, Clinical assessments, Outer product analysis, Support vector machines, Probabilistic neural networks},
abstract = {Summary
Objective
Very low birth weight (VLBW) survivors are at increased risk of neurological impairments that may persist into adolescence and adulthood. The aims of this study were to identify the most important clinical assessments that characterize differences between VLBW and control adolescents, and to look at the relationship between clinical assessments and the metabolites in in vivo MR spectra.
Methods
At 14–15 years of age, 54 VLBW survivors and 64 term controls were examined clinically. Several neuropsychological and motor assessments were performed. The magnetic resonance (MR) brain spectra were acquired from volumes localized in the left frontal lobe and contained mainly white matter.
Results
Probabilistic neural networks and support vector machines demonstrated that clinical assessments rendered a possibility of the classification of VLBW versus control adolescents. The most important clinical assessments in this classification were visual–motor integration, motor coordination, stroop test, full scale IQ, and grooved pegboard. Through the use of outer product analysis-partial least squares discriminant analysis on a subset of adolescents (n=36), the clinical assessments found to most strongly correlate with the spectral data were the global assessment scale, Wisconsin card sorting test, full scale IQ, grooved pegboard test, and motor coordination test. Clinical assessments that relate to spectral data may be especially dependent on an intact microstructure in frontal white matter.}
}
@article{SHUAI2011750,
title = {AR-model-based adaptive detection of range-spread targets in compound Gaussian clutter},
journal = {Signal Processing},
volume = {91},
number = {4},
pages = {750-758},
year = {2011},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2010.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0165168410003361},
author = {Xiaofei Shuai and Lingjiang Kong and Jianyu Yang},
keywords = {Range-spread targets, Compound Gaussian clutter, AR progress, Maximum likelihood estimation (MLE), Generalized likelihood ratio test (GLRT)},
abstract = {In this paper, we consider the problem of adaptive detection for range-spread targets with known Doppler and unknown complex amplitude in compound Gaussian clutter. The speckle component of the clutter is modeled as an autoregressive (AR) process. By using the generalized likelihood ratio test (GLRT) approach, we will first estimate the AR parameters and the unknown complex amplitude, and then propose an adaptive AR-based GLR detector. The performance assessments are presented too. The computer simulations show that the proposed detector, without a priori information of the covariance matrix, has the same asymptotical performances as the two-step GLR-based detector with known covariance matrix.}
}
@article{ZHANG201558,
title = {Detection of Alzheimer's disease and mild cognitive impairment based on structural volumetric MR images using 3D-DWT and WTA-KSVM trained by PSOTVAC},
journal = {Biomedical Signal Processing and Control},
volume = {21},
pages = {58-73},
year = {2015},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2015.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S1746809415000932},
author = {Yudong Zhang and Shuihua Wang and Preetha Phillips and Zhengchao Dong and Genlin Ji and Jiquan Yang},
keywords = {Magnetic resonance imaging, Multiclass SVM, Kernel SVM, Particle swarm optimization, Time-varying acceleration-coefficient},
abstract = {Background
We proposed a novel classification system to distinguish among elderly subjects with Alzheimer's disease (AD), mild cognitive impairment (MCI), and normal controls (NC), based on 3D magnetic resonance imaging (MRI) scanning.
Methods
The method employed 3D data of 178 subjects consisting of 97 NCs, 57 MCIs, and 24 ADs. First, all these 3D MR images were preprocessed with atlas-registered normalization to form an averaged volumetric image. Then, 3D discrete wavelet transform (3D-DWT) was used to extract wavelet coefficients the volumetric image. The triplets (energy, variance, and Shannon entropy) of all subbands coefficients of 3D-DWT were obtained as feature vector. Afterwards, principle component analysis (PCA) was applied for feature reduction. On the basic of the reduced features, we proposed nine classification methods: three individual classifiers as linear SVM, kernel SVM, and kernel SVM trained by PSO with time-varying acceleration-coefficient (PSOTVAC), with three multiclass methods as Winner-Takes-All (WTA), Max-Wins-Voting, and Directed Acyclic Graph.
Results
The 5-fold cross validation results showed that the “WTA-KSVM+PSOTVAC” performed best over the OASIS benchmark dataset, with overall accuracy of 81.5% among all proposed nine classifiers. Moreover, the method “WTA-KSVM+PSOTVAC” exceeded significantly existing state-of-the-art methods (accuracies of which were less than or equal to 74.0%).
Conclusion
We validate the effectiveness of 3D-DWT. The proposed approach has the potential to assist in early diagnosis of ADs and MCIs.}
}
@article{FRINDEL2014144,
title = {A 3-D spatio-temporal deconvolution approach for MR perfusion in the brain},
journal = {Medical Image Analysis},
volume = {18},
number = {1},
pages = {144-160},
year = {2014},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2013.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1361841513001485},
author = {Carole Frindel and Marc C. Robini and David Rousseau},
keywords = {Acute stroke, Perfusion weighted MRI, Deconvolution, Spatio-temporal model, Tissue outcome prediction},
abstract = {We propose an original spatio-temporal deconvolution approach for perfusion-weighted MRI applied to cerebral ischemia. The regularization of the underlying inverse problem is achieved with spatio-temporal priors and the resulting optimization problem is solved by half-quadratic minimization. Our approach offers strong convergence guarantees, including when the spatial priors are non-convex. Moreover, experiments on synthetic data and on real data collected from subjects with ischemic stroke show significant performance improvements over the standard approaches—namely, temporal deconvolution based on either truncated singular-value decomposition or ℓ2-regularization—in terms of various performance measures.}
}
@article{BARRA2002185,
title = {Segmentation of fat and muscle from MR images of the thigh by a possibilistic clustering algorithm},
journal = {Computer Methods and Programs in Biomedicine},
volume = {68},
number = {3},
pages = {185-193},
year = {2002},
issn = {0169-2607},
doi = {https://doi.org/10.1016/S0169-2607(01)00172-9},
url = {https://www.sciencedirect.com/science/article/pii/S0169260701001729},
author = {Vincent Barra and Jean-Yves Boire},
keywords = {Body composition, MR imaging, Fuzzy clustering, Physical training},
abstract = {Physical training is proved to induce changes in physical capacity and body composition. We propose in this article a fast, unsupervised and fully three-dimensional automatic method to extract muscle and fat volumes from magnetic resonance images of thighs in order to assess these changes. The technique relies on the use of a fuzzy clustering algorithm and post-processings to trustfully process the body composition of thighs. Results are compared on 11 healthy voluntary elderly people with those provided on the same data by a validated method already published, and its reliability is assessed on repeated measures on three subjects. The two methods statistically agree when computing muscle and fat volumes, and clinical implications of this fully automatic method are important for medicine, physical conditioning, weight-loss programs and predictions of optimal body weight.}
}
@article{ZHOU2018904,
title = {Prediction of a New Kind of MR Data},
journal = {Procedia Computer Science},
volume = {131},
pages = {904-910},
year = {2018},
note = {Recent Advancement in Information and Communication Technology:},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.04.299},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918306793},
author = {Hong Zhou and Shenghui Zhao},
keywords = {MR, LSTM, Data Prediction},
abstract = {In the field of TD-LTE network problem analysis, compared with traditional methods such as DT(Driver Test) and CQT(Call Quality Test), MR (Measurement Report) has the advantages of comprehensive information and high efficiency, begins to get more and more attention and application. In order to solve the problem of limited open time of measurement data acquisition system, a data prediction method based on LSTM (Long Short-Term Memory) model is proposed. Selecting part of the MR parameters as the experimental object, training LSTM Model with measurement data in a district of Beijing. Experimental results show that the proposed method can predict MR data accurately. Compared with the traditional prediction model ARIMA (Autoregressive Integrated Moving Average Model), this method has lower prediction error and more stable generalization ability.}
}
@article{MALCZEWSKI2020100302,
title = {Super-Resolution with compressively sensed MR/PET signals at its input},
journal = {Informatics in Medicine Unlocked},
volume = {18},
pages = {100302},
year = {2020},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2020.100302},
url = {https://www.sciencedirect.com/science/article/pii/S2352914819304186},
author = {Krzysztof Malczewski},
keywords = {MRI, PET, Super-resolution, Compressed sensing},
abstract = {The aim of this paper is to present a highly effective Magnetic Resonance Imaging- Positron Emission Tomography (MR/PET) image reconstruction strategy allowing for simultaneous resolution enhancing and scanning time minimisation. The presented algorithm employs the combined sparsity, compressed sensing (CS) theory and super resolution to achieve high-resolution output maintaining data collecting steps at the lowest possible levels. This paper presents a very promising application of super-resolution of highly sensitively compressed MR/PET raw data. The presented algorithm nests image priors, deblurring, and a discrete dense displacement sampling for the deformable registration of high-resolution images at its core. Data from preliminary trials can also be valuable in providing background information useful in reducing examinations times. In accordance with expectations, the presented algorithm can enhance image resolution without any hardware modifications. However, the motion estimation algorithm can drastically eliminate diagnostic image artifacts that increase the chances of a correct diagnosis. The robustness of the suggested algorithm was subjected to state-of-the art image resolution enhancement algorithms: 3D kernel regression, Enhanced Deep Residual Networks for Single Image Super-Resolution, Image Super-Resolution Using Very Deep Residual Channel Attention Networks, Residual Dense Network for Image Super-Resolution. It is worth underlining that combining Compressed Sensing with its conjugate symmetry, as well as Partial Fourier methodology leads to data acquisition acceleration when compared to the different and unmodified k-space sampling patterns. It can be clearly seen that the obtained improvements have led to much better sharpness, edge interpretations, and contrast. Moreover, the accomplishments have been validated by PSNR. In accordance with expectations, the presented algorithm is able to enhance image resolution without any hardware adjustments. Besides the resolution tradeoffs, this method is able to minimise motion artifacts what is especially important for effective physician-to-physician communication and unbiased diagnosis.}
}
@article{NAKIB2012152,
title = {A framework for analysis of brain cine MR sequences},
journal = {Computerized Medical Imaging and Graphics},
volume = {36},
number = {2},
pages = {152-168},
year = {2012},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2011.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0895611111001224},
author = {Amir Nakib and Patrick Siarry and Philippe Decq},
keywords = {Image registration, Image segmentation, Fractional differentiation, Deformation model, Dynamic optimization, Evolutionary algorithm},
abstract = {In this paper, we propose a framework to automate the assessment of the movements of a third cerebral ventricle in a cine MR sequence. Indeed, the goal of this assessment is to build an atlas of the movements of the healthy ventricles in the context of the hydrocephalus pathology. This approach is composed of two phases: a contour extraction, using fractional integration and a registration method, based on dynamic evolutionary optimization. The first phase of the framework is based on the fractional integration thresholding, that allows delineating the contours of the area of interest. In order to track over time each point of the primitive and achieve the assessment of the deformation, a matching method, based on a new dynamic optimization algorithm, called Dynamic Covariance Matrix Adaptation Evolution Strategy (D-CMAES), is used. The obtained results for quantification have been clinically validated by an expert and compared to those presented in the literature.}
}
@article{SHARMA20221,
title = {The design and evaluation of an AR-based serious game to teach programming},
journal = {Computers & Graphics},
volume = {103},
pages = {1-18},
year = {2022},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2022.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0097849322000024},
author = {Vandit Sharma and Kaushal Kumar Bhagat and Huai-Hsuan Huang and Nian-Shing Chen},
keywords = {Augmented Reality, Computational thinking, Learning Analytics, Gamification, Feedback design, System usability},
abstract = {The ubiquity of smartphone and tablet devices, combined with the increasing availability of serious games, has enabled students to learn various abstract concepts in an appealing and convenient manner. While several researchers have explored the use of Augmented Reality (AR) in serious games, many of these games have not been critically explained or evaluated. To that end, we employed game-based learning methodologies and Game Learning Analytics (GLA) to systematize the design and evaluation of an AR-based serious game to teach programming. We evaluated our game for usability and effectiveness by conducting a user study on twenty-seven undergraduate students. The evaluation primarily consisted of a learning test conducted twice – before and after playing the game – along with a usability questionnaire that players completed after playing the game. Our results showed that players made significant progress after playing the game. The game helped players improve their basic programming skills, especially for the group having lower prior programming skills. The results highlighted various ways in which GLA can be used to benefit different stakeholders in the game. Based on players’ qualitative responses, we also identified several areas of improvement, most prominently the trade-off between ease of use and game complexity. We provide suggestions and discuss implications for future work.}
}
@article{SONG20101,
title = {An automated three-dimensional plus time registration framework for dynamic MR renography},
journal = {Journal of Visual Communication and Image Representation},
volume = {21},
number = {1},
pages = {1-8},
year = {2010},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2009.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1047320309001291},
author = {Ting Song and Vivian S. Lee and Qun Chen and Henry Rusinek and Andrew F. Laine},
keywords = {MR renography, Dynamic MR, 3D plus time registration, Dynamic contrast-enhanced imaging, Wavelet representation, Anisotropic diffusion, Fourier-based registration, Automated respiratory motion correction, WRFT},
abstract = {Dynamic contrast-enhanced 3D images of the kidneys, or 3D MR renography, has the potential for broad clinical applications, but suffers from respiratory motion that limits analysis and interpretation. Manual registration is prohibitively labor-intensive. In this paper, a fully automated technique, Wavelet Representation and the Fourier Transform (WRFT) method, that corrects for translation and rotation motion in 3D MR renography is presented. The method was composed by anisotropic denoising, wavelet-based feature extraction, and Fourier-based registration. This was first evaluated on a set of simulated MR renography images with defined degrees of kidney motion. The method was then tested on 24 clinical patient MR renography data sets. Results of clinical testing were compared with the results obtained using a mutual information registration method. Based on intrarenal time-intensity curves, our method showed robust and consistent agreement with the results of manually coregistered data sets.}
}
@article{MIHCIN2017125,
title = {Methodology on quantification of sonication duration for safe application of MR guided focused ultrasound for liver tumour ablation},
journal = {Computer Methods and Programs in Biomedicine},
volume = {152},
pages = {125-130},
year = {2017},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2017.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S016926071730158X},
author = {Senay Mihcin and Ioannis Karakitsios and Nhan Le and Jan Strehlow and Daniel Demedts and Michael Schwenke and Sabrina Haase and Tobias Preusser and Andreas Melzer},
keywords = {MR guided FUS, Computer control of laboratory machines and device, Safety, Protocol development, Quality Management Systems, Experiment and measurement technics, medical device legislation, Sonication duration},
abstract = {Background and objective
Magnetic Resonance Guided Focused Ultrasound (MRgFUS) for liver tumour ablation is a challenging task due to motion caused by breathing and occlusion due the ribcage between the transducer and the tumour. To overcome these challenges, a novel system for liver tumour ablation during free breathing has been designed.
Methods
The novel TRANS-FUSIMO Treatment System (TTS, EUFP7) interacts with a Magnetic Resonance (MR) scanner and a focused ultrasound transducer to sonicate to a moving target in liver. To meet the requirements of ISO 13485; a quality management system for medical device design, the system needs to be tested for certain process parameters. The duration of sonication and, the delay after the sonication button is activated, are among the parameters that need to be quantified for efficient and safe ablation of tumour tissue. A novel methodology is developed to quantify these process parameters. A computerised scope is programmed in LabVIEW to collect data via hydrophone; where the coordinates of fiber-optic sensor assembly was fed into the TRANS-FUSIMO treatment software via Magnetic Resonance Imaging (MRI) to sonicate to the tip of the sensor, which is synchronised with the clock of the scope, embedded in a degassed water tank via sensor assembly holder. The sonications were executed for 50 W, 100 W, 150 W for 10 s to quantify the actual sonication duration and the delay after the emergency stop by two independent operators for thirty times. The deviation of the system from the predefined specs was calculated. Student's-T test was used to investigate the user dependency.
Results
The duration of sonication and the delay after the sonication were quantified successfully with the developed method. TTS can sonicate with a maximum deviation of 0.16 s (Std 0.32) from the planned duration and with a delay of 14 ms (Std 0.14) for the emergency stop. Student's T tests indicate that the results do not depend on operators (p > .05).
Conclusion
The evidence obtained via this protocol is crucial for translation- of-research into the clinics for safe application of MRgFUS. The developed protocol could be used for system maintenance in compliance with quality systems in clinics for daily quality assurance routines.}
}
@article{CACKOWSKI2023102799,
title = {ImUnity: A generalizable VAE-GAN solution for multicenter MR image harmonization},
journal = {Medical Image Analysis},
volume = {88},
pages = {102799},
year = {2023},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2023.102799},
url = {https://www.sciencedirect.com/science/article/pii/S1361841523000609},
author = {Stenzel Cackowski and Emmanuel L. Barbier and Michel Dojat and Thomas Christen},
keywords = {Brain, Deep Adversarial Network, Data harmonization, Self-supervised learning, Radiomic features},
abstract = {ImUnity is an original 2.5D deep-learning model designed for efficient and flexible MR image harmonization. A VAE-GAN network, coupled with a confusion module and an optional biological preservation module, uses multiple 2D slices taken from different anatomical locations in each subject of the training database, as well as image contrast transformations for its training. It eventually generates ‘corrected’ MR images that can be used for various multi-center population studies. Using 3 open source databases (ABIDE, OASIS and SRPBS), which contain MR images from multiple acquisition scanner types or vendors and a large range of subjects ages, we show that ImUnity: (1) outperforms state-of-the-art methods in terms of quality of images generated using traveling subjects; (2) removes sites or scanner biases while improving patients classification; (3) harmonizes data coming from new sites or scanners without the need for an additional fine-tuning and (4) allows the selection of multiple MR reconstructed images according to the desired applications. Tested here on T1-weighted images, ImUnity could be used to harmonize other types of medical images.}
}
@article{SABIDUSSI2021102220,
title = {Recurrent inference machines as inverse problem solvers for MR relaxometry},
journal = {Medical Image Analysis},
volume = {74},
pages = {102220},
year = {2021},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2021.102220},
url = {https://www.sciencedirect.com/science/article/pii/S1361841521002656},
author = {E.R. Sabidussi and S. Klein and M.W.A. Caan and S. Bazrafkan and A.J. {den Dekker} and J. Sijbers and W.J. Niessen and D.H.J. Poot},
keywords = {Quantitative MRI, Relaxometry, Deep learning, Mapping, Recurrent inference machines},
abstract = {In this paper, we propose the use of Recurrent Inference Machines (RIMs) to perform T1 and T2 mapping. The RIM is a neural network framework that learns an iterative inference process based on the signal model, similar to conventional statistical methods for quantitative MRI (QMRI), such as the Maximum Likelihood Estimator (MLE). This framework combines the advantages of both data-driven and model-based methods, and, we hypothesize, is a promising tool for QMRI. Previously, RIMs were used to solve linear inverse reconstruction problems. Here, we show that they can also be used to optimize non-linear problems and estimate relaxometry maps with high precision and accuracy. The developed RIM framework is evaluated in terms of accuracy and precision and compared to an MLE method and an implementation of the Residual Neural Network (ResNet). The results show that the RIM improves the quality of estimates compared to the other techniques in Monte Carlo experiments with simulated data, test-retest analysis of a system phantom, and in-vivo scans. Additionally, inference with the RIM is 150 times faster than the MLE, and robustness to (slight) variations of scanning parameters is demonstrated. Hence, the RIM is a promising and flexible method for QMRI. Coupled with an open-source training data generation tool, it presents a compelling alternative to previous methods.}
}
@article{UNLU201037,
title = {Computerized method for nonrigid MR-to-PET breast-image registration},
journal = {Computers in Biology and Medicine},
volume = {40},
number = {1},
pages = {37-53},
year = {2010},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2009.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0010482509001942},
author = {M.Z. Unlu and A. Krol and A. Magri and J.A. Mandel and W. Lee and K.G. Baum and E.D. Lipson and I.L. Coman and D.H. Feiglin},
keywords = {MR-to-PET nonrigid breast-image registration, FEM-based soft tissue multimodality nonrigid image registration},
abstract = {We have developed and tested a new simple computerized finite element method (FEM) approach to MR-to-PET nonrigid breast-image registration. The method requires five–nine fiducial skin markers (FSMs) visible in MRI and PET that need to be located in the same spots on the breast and two on the flanks during both scans. Patients need to be similarly positioned prone during MRI and PET scans. This is accomplished by means of a low gamma-ray attenuation breast coil replica used as the breast support during the PET scan. We demonstrate that, under such conditions, the observed FSM displacement vectors between MR and PET images, distributed piecewise linearly over the breast volume, produce a deformed FEM mesh that reasonably approximates nonrigid deformation of the breast tissue between the MRI and PET scans. This method, which does not require a biomechanical breast tissue model, is robust and fast. Contrary to other approaches utilizing voxel intensity-based similarity measures or surface matching, our method works for matching MR with pure molecular images (i.e. PET or SPECT only). Our method does not require a good initialization and would not be trapped by local minima during registration process. All processing including FSMs detection and matching, and mesh generation can be fully automated. We tested our method on MR and PET breast images acquired for 15 subjects. The procedure yielded good quality images with an average target registration error below 4mm (i.e. well below PET spatial resolution of 6–7mm). Based on the results obtained for 15 subjects studied to date, we conclude that this is a very fast and a well-performing method for MR-to-PET breast-image nonrigid registration. Therefore, it is a promising approach in clinical practice. This method can be easily applied to nonrigid registration of MRI or CT of any type of soft-tissue images to their molecular counterparts such as obtained using PET and SPECT.}
}
@article{ZHAN201691,
title = {MR image bias field harmonic approximation with histogram statistical analysis},
journal = {Pattern Recognition Letters},
volume = {83},
pages = {91-98},
year = {2016},
note = {Geometric, topological and harmonic trends to image processing},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2016.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0167865516000568},
author = {Shu Zhan and Xiong Yang},
keywords = {MRI, Energy function, Bias field correction, Harmonic approximation, Statistical analysis},
abstract = {This study investigates a method to correct the intensity inhomogeneity field of magnetic resonance image. The algorithm takes full advantage of the properties of the magnetic resonance image, namely, the piecewise character (piecewise constant and piecewise smooth) of true image which characterizes a physical property of the tissue anatomical structure and the smoothly varying property of bias field which accounts for the intensity inhomogeneity. An energy function was constructed by embedding this characters into the image model. We can get the estimation of bias field and the segmentation of tissue by minimizing the energy function. The initial parameter of energy function is calculated automatically by statistical analysis. By mixing the fitting basis function with cosine function and polynomial function, we can obtain an accurate approximation of the bias field. A comparative performance evaluation is carried out over a large set of experiments using synthetic magnetic resonance data. Besides, a set of tests on real prostate magnetic resonance image with severe intensity inhomogeneity field is shown to demonstrate the validity of our method.}
}