@article{
author={García García,Miguel and Sauer,Yannick and Watson,Tamara and Wahl,Siegfried},
year={2024/03//},
month={Mar 2024},
title={Virtual reality (VR) as a testing bench for consumer optical solutions: a machine learning approach (GBR) to visual comfort under simulated progressive addition lenses (PALs) distortions},
journal={Virtual Reality},
volume={28},
number={1},
pages={36},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-14},
abstract={For decades, manufacturers have attempted to reduce or eliminate the optical aberrations that appear on the progressive addition lens’ surfaces during manufacturing. Besides every effort made, some of these distortions are inevitable given how lenses are fabricated, where in fact, astigmatism appears on the surface and cannot be entirely removed, or where non-uniform magnification becomes inherent to the power change across the lens. Some presbyopes may refer to certain discomfort when wearing these lenses for the first time, and a subset of them might never adapt. Developing, prototyping, testing and purveying those lenses into the market come at a cost, which is usually reflected in the retail price. This study aims to test the feasibility of virtual reality (VR) for testing customers’ satisfaction with these lenses, even before getting them onto production. VR offers a controlled environment where different parameters affecting progressive lens comforts, such as distortions, image displacement or optical blurring, can be inspected separately. In this study, the focus was set on the distortions and image displacement, not taking blur into account. Behavioural changes (head and eye movements) were recorded using the built-in eye tracker. We found participants were significantly more displeased in the presence of highly distorted lens simulations. In addition, a gradient boosting regressor was fitted to the data, so predictors of discomfort could be unveiled, and ratings could be predicted without performing additional measurements.},
keywords={Computers--Computer Graphics; Astigmatism; Lenses; Virtual reality; Machine learning; Eye movements; Blurring; Discomfort; Prototyping},
isbn={13594338},
language={English},
url={https://www.proquest.com/scholarly-journals/virtual-reality-vr-as-testing-bench-consumer/docview/2921365135/se-2},
}

@article{
author={Warchoł,Jan and Tetych,Anna and Tomaszewski,Robert and Kowalczyk,Bartłomiej and Olchowik,Grażyna},
year={2024},
month={2024},
title={Virtual Reality-Induced Modification of Vestibulo–Ocular Reflex Gain in Posturography Tests},
journal={Journal of Clinical Medicine},
volume={13},
number={10},
pages={2742},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-05-24},
abstract={Background: The aim of the study was to demonstrate the influence of virtual reality (VR) exposure on postural stability and determine the mechanism of this influence. Methods: Twenty-six male participants aged 21–23 years were included, who underwent postural stability assessment twice before and after a few minute of single VR exposure. The VR projection was a computer-generated simulation of the surrounding scenery. Postural stability was assessed using the Sensory Organization Test (SOT), using Computerized Dynamic Posturography (CDP). Results: The findings indicated that VR exposure affects the visual and vestibular systems. Significant differences (p < 0.05) in results before and after VR exposure were observed in tests on an unstable surface. It was confirmed that VR exposure has a positive influence on postural stability, attributed to an increase in the sensory weight of the vestibular system. Partial evidence suggested that the reduction in vestibulo-ocular reflex (VOR) reinforcement may result in an adaptive shift to the optokinetic reflex (OKR). Conclusions: By modifying the process of environmental perception through artificial sensory simulation, the influence of VR on postural stability has been demonstrated. The validity of this type of research is determined by the effectiveness of VR techniques in the field of vestibular rehabilitation.},
keywords={Medical Sciences; virtual reality; posturography; vestibulo–ocular reflex; optokinetic reflex; Sensory Organization Test; Motor ability; Eye movements; Nervous system; Retina; Questionnaires; Statistical analysis},
language={English},
url={https://www.proquest.com/scholarly-journals/virtual-reality-induced-modification-vestibulo/docview/3059450723/se-2},
}

@article{
author={Rodriguez-Garcia,Bruno and José Miguel Ramírez-Sanz and Miguel-Alonso,Ines and Bustillo,Andres},
year={2024},
month={2024},
title={Enhancing Learning of 3D Model Unwrapping through Virtual Reality Serious Game: Design and Usability Validation},
journal={Electronics},
volume={13},
number={10},
pages={1972},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-05-24},
abstract={Given the difficulty of explaining the unwrapping process through traditional teaching methodologies, this article presents the design, development, and validation of an immersive Virtual Reality (VR) serious game, named Unwrap 3D Virtual: Ready (UVR), aimed at facilitating the learning of unwrapping 3D models. The game incorporates animations to aid users in understanding the unwrapping process, following Mayer’s Cognitive Theory of Multimedia Learning and Gamification principles. Structured into four levels of increasing complexity, users progress through different aspects of 3D model unwrapping, with the final level allowing for result review. A sample of 53 students with experience in 3D modeling was categorized based on device (PC or VR) and previous experience (XP) in VR, resulting in Low-XP, Mid-XP, and High-XP groups. Hierarchical clustering identified three clusters, reflecting varied user behaviors. Results from surveys assessing game experience, presence, and satisfaction show higher immersion reported by VR users despite greater satisfaction being observed in the PC group due to a bug in the VR version. Novice users exhibited higher satisfaction, which was attributed to the novelty effect, while experienced users demonstrated greater control and proficiency.},
keywords={Electronics; virtual reality; learning; unwrapping; 3D model; usability; satisfaction; serious game; education; hierarchical cluster; Cluster analysis; User experience; Games; Educational objectives; User satisfaction; Clustering; Immersive virtual reality; Three dimensional models; Questionnaires; Gamification; Cultural heritage; Multimedia},
language={English},
url={https://www.proquest.com/scholarly-journals/enhancing-learning-3d-model-unwrapping-through/docview/3059443730/se-2},
}

@article{
author={Papagiannis,Georgios and Triantafyllou,Αthanasios and Yiannopoulou,Konstantina G. and Georgoudis,George and Kyriakidou,Maria and Gkrilias,Panagiotis and Skouras,Apostolos Z. and Bega,Xhoi and Stasinopoulos,Dimitrios and Matsopoulos,George and Syringas,Pantelis and Tselikas,Nikolaos and Zestas,Orestis and Potsika,Vassiliki and Pardalis,Athanasios and Papaioannou,Christoforos and Protopappas,Vasilios and Malizos,Nikolas and Tachos,Nikolaos and Fotiadis,Dimitrios I.},
year={2024},
month={2024},
title={Ηand dexterities assessment in stroke patients based on augmented reality and machine learning through a box and block test},
journal={Scientific Reports (Nature Publisher Group)},
volume={14},
number={1},
pages={10598},
note={Copyright - © The Author(s) 2024. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-05-09},
abstract={A popular and widely suggested measure for assessing unilateral hand motor skills in stroke patients is the box and block test (BBT). Our study aimed to create an augmented reality enhanced version of the BBT (AR-BBT) and evaluate its correlation to the original BBT for stroke patients. Following G-power analysis, clinical examination, and inclusion–exclusion criteria, 31 stroke patients were included in this study. AR-BBT was developed using the Open Source Computer Vision Library (OpenCV). The MediaPipe's hand tracking library uses a palm and a hand landmark machine learning model to detect and track hands. A computer and a depth camera were employed in the clinical evaluation of AR-BBT following the principles of traditional BBT. A strong correlation was achieved between the number of blocks moved in the BBT and the AR-BBT on the hemiplegic side (Pearson correlation = 0.918) and a positive statistically significant correlation (p = 0.000008). The conventional BBT is currently the preferred assessment method. However, our approach offers an advantage, as it suggests that an AR-BBT solution could remotely monitor the assessment of a home-based rehabilitation program and provide additional hand kinematic information for hand dexterities in AR environment conditions. Furthermore, it employs minimal hardware equipment.},
keywords={Sciences: Comprehensive Works; Augmented reality; Machine learning; Motor skill; Correlation; Stroke; Diagnostic techniques; Statistical analysis; Learning algorithms},
language={English},
url={https://www.proquest.com/scholarly-journals/ηand-dexterities-assessment-stroke-patients-based/docview/3052296214/se-2},
}

@article{
author={Williams,Lisa A. and Tzelios,Kallie and Masser,Barbara and Thijsen,Amanda and van Dongen,Anne and Davison,Tanya E.},
year={2024},
month={2024},
title={A virtual reality paradigm simulating blood donation serves as a platform to test interventions to promote donation},
journal={Scientific Reports (Nature Publisher Group)},
volume={14},
number={1},
pages={10334},
note={Copyright - © The Author(s) 2024. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-05-07},
abstract={Effective interventions that support blood donor retention are needed. Yet, integrating an intervention into the time-pressed and operationally sensitive context of a blood donation center requires justification for disruptions to an optimized process. This research provides evidence that virtual reality (VR) paradigms can serve as a research environment in which interventions can be tested prior to being delivered in blood donation centers. Study 1 (N = 48) demonstrated that 360°-video VR blood donation environments elicit a similar profile of emotional experience to a live donor center. Presence and immersion were high, and cybersickness symptoms low. Study 2 (N = 134) was an experiment deploying the 360°-video VR environments to test the impact of an intervention on emotional experience and intentions to donate. Participants in the intervention condition who engaged in a suite of tasks drawn from the process model of emotion regulation (including attentional deployment, positive reappraisal, and response modulation) reported more positive emotion than participants in a control condition, which in turn increased intentions to donate blood. By showing the promise for benefitting donor experience via a relatively low-cost and low-resource methodology, this research supports the use of VR paradigms to trial interventions prior to deployment in operationally-context field settings.},
keywords={Sciences: Comprehensive Works; Emotions; Blood; Blood donors; Computer applications; Blood & organ donations; Deployment; Virtual reality; Intervention},
language={English},
url={https://www.proquest.com/scholarly-journals/virtual-reality-paradigm-simulating-blood/docview/3051220237/se-2},
}

@article{
author={Everard,Gauthier and Burton,Quentin and Van de Sype,Vincent and Thérèse,Ntabuhashe B. and Auvinet,Edouard and Edwards,Martin G. and Batcho,Charles S. and Lejeune,Thierry},
year={2024},
month={2024},
title={Extended reality to assess post-stroke manual dexterity: contrasts between the classic box and block test, immersive virtual reality with controllers, with hand-tracking, and mixed-reality tests},
journal={Journal of Neuroengineering and Rehabilitation},
volume={21},
pages={1-15},
note={Name - Leap Motion; Copyright - © 2024. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-04-13; SubjectsTermNotLitGenreText - Belgium},
abstract={BackgroundRecent technological advancements present promising opportunities to enhance the frequency and objectivity of functional assessments, aligning with recent stroke rehabilitation guidelines. Within this framework, we designed and adapted different manual dexterity tests in extended reality (XR), using immersive virtual reality (VR) with controllers (BBT-VR-C), immersive VR with hand-tracking (BBT-VR-HT), and mixed-reality (MD-MR).ObjectiveThis study primarily aimed to assess and compare the validity of the BBT-VR-C, BBT-VR-HT and MD-MR to assess post-stroke manual dexterity. Secondary objectives were to evaluate reliability, usability and to define arm kinematics measures.MethodsA sample of 21 healthy control participants (HCP) and 21 stroke individuals with hemiparesis (IHP) completed three trials of the traditional BBT, the BBT-VR-C, BBT-VR-HT and MD-MR. Content validity of the different tests were evaluated by asking five healthcare professionals to rate the difficulty of performing each test in comparison to the traditional BBT. Convergent validity was evaluated through correlations between the scores of the traditional BBT and the XR tests. Test-retest reliability was assessed through correlations between the second and third trial and usability was assessed using the System Usability Scale (SUS). Lastly, upper limb movement smoothness (SPARC) was compared between IHP and HCP for both BBT-VR test versions.ResultsFor content validity, healthcare professionals rated the BBT-VR-HT (00–1]) and BBT-MR (00–1]) as equally difficult to the traditional BBT, whereas they rated BBT-VR-C as more difficult than the traditional BBT (10–2]). For IHP convergent validity, the Pearson tests demonstrated larger correlations between the scores of BBT and BBT-VR-HT (r = 0.94;p < 0.001), and BBT and MD-MR (r = 0.95;p < 0.001) than BBT and BBT-VR-C (r = 0.65;p = 0.001). BBT-VR-HT and MD-MR usability were both rated as excellent, with median SUS scores of 8357.5–91.3] and 8353.8–92.5] respectively. Excellent reliability was found for the BBT-VR-C (ICC = 0.96;p < 0.001), BBT-VR-HT (ICC = 0.96;p < 0.001) and BBT-MR (ICC = 0.99;p < 0.001). The usability of the BBT-VR-C was rated as good with a median SUS of 7043.8–83.8]. Upper limb movements of HCP were significantly smoother than for IHP when completing either the BBT-VR-C (t = 2.05;p = 0.043) and the BBT-VR-HT (t = 5.21;p < 0.001).ConclusionThe different XR manual tests are valid, short-term reliable and usable tools to assess post-stroke manual dexterity.Trial registrationhttps://clinicaltrials.gov/ct2/show/NCT04694833; Unique identifier: NCT04694833, Date of registration: 11/24/2020.},
keywords={Medical Sciences--Psychiatry And Neurology; Stroke; Virtual reality; Augmented reality; Upper Extremity; Patient Outcome Assessment; Reliability analysis; Kinematics; Hand (anatomy); Immersive virtual reality; Health care; Osteonectin; Reliability; Motor ability; Rehabilitation; Computer applications; Manual dexterity; Feedback; Evaluation; Correlation; Haptics; Validity; Smoothness; Convergence; Tracking control; Controllers; Mixed reality; Paresis; Belgium},
language={English},
url={https://www.proquest.com/scholarly-journals/extended-reality-assess-post-stroke-manual/docview/3037874141/se-2},
}

@article{
author={Müller,Fabian and Koch,Michael and Hasse,Alexander},
year={2024},
month={2024},
title={User Study to Validate the Performance of an Offline Robot Programming Method That Enables Robot-Independent Kinesthetic Instruction through the Use of Augmented Reality and Motion Capturing},
journal={Robotics},
volume={13},
number={3},
pages={35},
note={Name - National Aeronautics & Space Administration--NASA; Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-28},
abstract={The paper presents a novel offline programming (OLP) method based on programming by demonstration (PbD), which has been validated through user study. PbD is a programming method that involves physical interaction with robots, and kinesthetic teaching (KT) is a commonly used online programming method in industry. However, online programming methods consume significant robot resources, limiting the speed advantages of PbD and emphasizing the need for an offline approach. The method presented here, based on KT, uses a virtual representation instead of a physical robot, allowing independent programming regardless of the working environment. It employs haptic input devices to teach a simulated robot in augmented reality and uses automatic path planning. A benchmarking test was conducted to standardize equipment, procedures, and evaluation techniques to compare different PbD approaches. The results indicate a 47% decrease in programming time when compared to traditional KT methods in established industrial systems. Although the accuracy is not yet at the level of industrial systems, users have shown rapid improvement, confirming the learnability of the system. User feedback on the perceived workload and the ease of use was positive. In conclusion, this method has potential for industrial use due to its learnability, reduction in robot downtime, and applicability across different robot sizes and types.},
keywords={Computers--Robotics; robot programming; programming by demonstration; motion capture; augmented reality; performance evaluation; user study; Teaching; Accuracy; Working conditions; Collaboration; On-line programming; Input devices; Questionnaires; Robots; Programming; Industrial applications; Methods},
language={English},
url={https://www.proquest.com/scholarly-journals/user-study-validate-performance-offline-robot/docview/3003377613/se-2},
}

@article{
author={Alex,Martino C. and Verna,Valeria and Marucci,Matteo and Tavernese,Aurora and Magnotti,Luisa and Matano,Alessandro and Chiara D’Acunto and Paolucci,Stefano and Morone,Giovanni and Betti,Viviana and Tramontano,Marco},
year={2024},
month={2024},
title={Immersive Virtual Reality for Treatment of Unilateral Spatial Neglect via Eye-Tracking Biofeedback: RCT Protocol and Usability Testing},
journal={Brain Sciences},
volume={14},
number={3},
pages={283},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-27},
abstract={About one-third of stroke survivors present unilateral spatial neglect (USN) that negatively impacts the rehabilitation outcome. We reported the study protocol and usability results of an eye-tracking (ET) biofeedback immersive virtual reality (iVR) protocol. Healthy controls and stroke patients with and without USN underwent a single session of the three iVR tasks. The system usability scale (SUS), adverse events (AEs), and ET data were collected and analyzed via parametric analysis. Twelve healthy controls (six young adults and six older adults) and seven patients with a diagnosis of single ischemic stroke (four without USN and three with confirmed diagnosis of USN) completed the usability investigation. SUS results showed good acceptability of the system for healthy controls and stroke patients without USN. ET results showed a lower performance for patients with USN concerning healthy controls and stroke patients without USN, in particular in the exploration of the left visual field. The results showed that the proposed iVR-ET biofeedback protocol is a safe and well-tolerated technique in patients with USN. The real-time feedback can induce a performance response supporting its investigation such as a treatment approach.},
keywords={Medical Sciences--Psychiatry And Neurology; visual deficits; eye movements; stroke rehabilitation; exergaming; neurorehabilitation; neglect; Patients; Usability; Stroke; Young adults; Ischemia; Biofeedback; Rehabilitation; Feedback; Neglect syndromes; Computer applications; Ethics; Visual field; Diagnosis; Virtual reality},
language={English},
url={https://www.proquest.com/scholarly-journals/immersive-virtual-reality-treatment-unilateral/docview/2993159847/se-2},
}

@article{
author={Gazit,Noa and Ben-Gal,Gilad and Eliashar,Ron},
year={2024},
month={2024},
title={Development and validation of an objective virtual reality tool for assessing technical aptitude among potential candidates for surgical training},
journal={BMC Medical Education},
volume={24},
pages={1-17},
note={Copyright - © 2024. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-04-17; SubjectsTermNotLitGenreText - Computer Simulation; Basic Skills; Validity; Spatial Ability; Depth Perception; Work Sample Tests; Teaching Methods; Academic Achievement; Surgery; Environmental Influences; Evidence; Simulation; Feedback (Response); Aptitude Tests; Psychometrics; Educational Assessment; Test Content; Computer Assisted Instruction; Skill Analysis},
abstract={BackgroundGood technical skills are crucial for surgeons. Yet although surgical training programs strive to assess technical aptitude when selecting surgical residents, valid assessments of such aptitude are still lacking. Surgical simulators have been proposed as a potentially effective tool for this purpose. The current study aims to develop a technical aptitude test using a virtual reality surgical simulator, and to validate its use for the selection of surgical residents.MethodsThe study had three phases. In Phase 1, we developed an initial version of the technical aptitude test using the Lap-X-VR laparoscopic simulator. In Phases 2 and 3 we refined the test and collected empirical data to evaluate four main sources of validity evidence (content, response process, internal structure, and relationships with other variables), and to evaluate the feasibility and acceptability of the test. Specifically, Phase 2 comprised a review of the test by 30 senior surgeons, and in Phase 3 a revised version of the test was administered to 152 interns to determine its psychometric properties.ResultsBoth the surgeons and interns rated the test as highly relevant for selecting surgical residents. Analyses of the data obtained from the trial administration of the test supported the appropriateness of the score calculation process and showed good psychometric properties, including reliability (α = 0.83) and task discrimination (mean discrimination = 0.5, SD = 0.1). The correlations between test scores and background variables revealed significant correlations with gender, surgical simulator experience, and video game experience (ps < 0.001). These variables, however, explained together only 10% of the variance in test scores.ConclusionsWe describe the systematic development of an innovative virtual reality test for assessing technical aptitude in candidates for surgical training, and present evidence for its validity, feasibility and acceptability. Further validation is required to support the application of the test for selection, as well as to discern the impact of gender, surgical simulator experience, and video game experience on the fairness of test results. However, the test appears to be a promising tool that may help training programs assess the suitability of candidates for surgical training.},
keywords={Medical Sciences; Selection; Assessment; Surgical training; Technical skills; Aptitude; Validation; Surgeons; Training; Laparoscopy; Motor ability; Surgical outcomes; Feedback; Virtual reality; Skills; Validity; Surgery; Medical education; Basic Skills; Psychometrics; Computer Assisted Instruction; Work Sample Tests; Environmental Influences; Spatial Ability; Test Content; Skill Analysis; Simulation; Educational Assessment; Aptitude Tests; Computer Simulation; Depth Perception; Academic Achievement; Evidence; Teaching Methods; Feedback (Response)},
language={English},
url={https://www.proquest.com/scholarly-journals/development-validation-objective-virtual-reality/docview/2956853915/se-2},
}

@article{
author={Shen,Jiabin and Clinton,Alex J. and Penka,Jeffrey and Gregory,Megan E. and Sova,Lindsey and Pfeil,Sheryl and Patterson,Jeremy and Maa,Tensing},
year={2024},
month={2024},
title={Smartphone-Based Virtual and Augmented Reality Implicit Association Training (VARIAT) for Reducing Implicit Biases Toward Patients Among Health Care Providers: App Development and Pilot Testing},
journal={JMIR Serious Games},
volume={12},
note={Copyright - © 2024. This work is licensed under https://creativecommons.org/licenses/by/4.0/" target="_blank">https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-14},
abstract={Background:Implicit bias is as prevalent among health care professionals as among the wider population and is significantly associated with lower health care quality.Objective:The study goal was to develop and evaluate the preliminary efficacy of an innovative mobile app, VARIAT (Virtual and Augmented Reality Implicit Association Training), to reduce implicit biases among Medicaid providers.Methods:An interdisciplinary team developed 2 interactive case-based training modules for Medicaid providers focused on implicit bias related to race and socioeconomic status (SES) and sexual orientation and gender identity (SOGI), respectively. The simulations combine experiential learning, facilitated debriefing, and game-based educational strategies. Medicaid providers (n=18) participated in this pilot study. Outcomes were measured on 3 domains: training reactions, affective knowledge, and skill-based knowledge related to implicit biases in race/SES or SOGI.Results:Participants reported high relevance of training to their job for both the race/SES module (mean score 4.75, SD 0.45) and SOGI module (mean score 4.67, SD 0.50). Significant improvement in skill-based knowledge for minimizing health disparities for lesbian, gay, bisexual, transgender, and queer patients was found after training (Cohen d=0.72; 95% CI −1.38 to −0.04).Conclusions:This study developed an innovative smartphone-based implicit bias training program for Medicaid providers and conducted a pilot evaluation on the user experience and preliminary efficacy. Preliminary evidence showed positive satisfaction and preliminary efficacy of the intervention.},
keywords={Medical Sciences; implicit bias; health care; Medicaid; virtual reality; augmented reality; smartphone; mHealth; mobile app; innovative; implicit bias training program; sexual orientation; sexual orientations; gender identity; gender identities; gender preferences; gender preference; efficacy; health care providers; health care provider; socioeconomic; mobile application; training; XR; extended reality; Patients; Socioeconomic factors; Smartphones; Educational objectives; Minority & ethnic groups; Medical personnel; Design; Immersive learning; Bias},
language={English},
url={https://www.proquest.com/scholarly-journals/smartphone-based-virtual-augmented-reality/docview/2956705267/se-2},
}

@article{
author={Jui-Che Tu and Xi-Hui,Jia},
year={2024},
month={2024},
title={A Study on Immersion and Intention to Pay in AR Broadcasting: Validating and Expanding the Hedonic Motivation System Adoption Mode},
journal={Sustainability},
volume={16},
number={5},
pages={2040},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-13},
abstract={With the rapid growth of online entertainment live streaming, how to continuously innovate and achieve long-term sustainability has become a major challenge for the industry. Augmented reality (AR) technology offers users immersive interactive experiences and potentially addresses this challenge. The aim of this study is to explore how AR technology influences key components of user online experience—immersion and intention to pay—using survey data. Building upon the Hedonic Motivation System Adoption Model (HMSAM), this research incorporates aesthetic variables to theoretically expand the model in order to gain a deeper understanding of the mechanisms influencing user behavior. A questionnaire survey was conducted to collect 450 valid samples. Detailed analysis was conducted using structural equation modeling. The findings confirm that aesthetic design significantly impacts users’ judgments of content value and perceived ease of use, generating positive effects at the perceptual level. Additionally, AR applications enhance the quality of user experience, thereby stimulating intrinsic motivations such as curiosity and joy. Further analysis indicates that users’ curiosity and perceived behavioral control directly influence the level of immersion and intention to pay. Overall, the research results offer important insights into industry applications. This study successfully expands the HMSAM theoretically by incorporating aesthetic variables to enhance the explanatory power of user judgment mechanisms. The analytical framework proposed aids in understanding the potential mechanisms of new technologies on customer experience and commercial value creation. The research findings provide guidelines for technological design and marketing strategies of streaming platforms.},
keywords={Environmental Studies; online entertainment; live broadcasting; immersion; intention to pay; augmented reality; Consumer behavior; Motivation; Consumers; User experience; Perceptions; Webcasting; Content creation; Shopping; Willingness to pay; Electronic commerce; Streaming media; Virtual reality; Aesthetics; Museums},
language={English},
url={https://www.proquest.com/scholarly-journals/study-on-immersion-intention-pay-ar-broadcasting/docview/2955913488/se-2},
}

@article{
author={Margull,Nicholas and Parsley,Doug and Somiari,Ibubeleye and Zhao,Linghao and Cao,Mingyuan and Koumoulis,Dimitrios and Liu,Paul K. T. and Manousiouthakis,Vasilios I. and Tsotsis,Theodore T.},
year={2024},
month={2024},
title={Field-Scale Testing of a High-Efficiency Membrane Reactor (MR)—Adsorptive Reactor (AR) Process for H2 Generation and Pre-Combustion CO2 Capture},
journal={Membranes},
volume={14},
number={2},
pages={51},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-24; SubjectsTermNotLitGenreText - United States--US},
abstract={The study objective was to field-validate the technical feasibility of a membrane- and adsorption-enhanced water gas shift reaction process employing a carbon molecular sieve membrane (CMSM)-based membrane reactor (MR) followed by an adsorptive reactor (AR) for pre-combustion CO2 capture. The project was carried out in two different phases. In Phase I, the field-scale experimental MR-AR system was designed and constructed, the membranes, and adsorbents were prepared, and the unit was tested with simulated syngas to validate functionality. In Phase II, the unit was installed at the test site, field-tested using real syngas, and a technoeconomic analysis (TEA) of the technology was completed. All project milestones were met. Specifically, (i) high-performance CMSMs were prepared meeting the target H2 permeance (>1 m3/(m2.hbar) and H2/CO selectivity of >80 at temperatures of up to 300 °C and pressures of up to 25 bar with a 2.5 wt.% and an attrition rate of <0.2; (iii) TEA showed that the MR-AR technology met the CO2 capture goals of 95% CO2 purity at a cost of electricity (COE) 30% less than baseline approaches.},
keywords={Engineering; membrane reactor (MR); adsorptive reactor (AR); H2 generation; CO2 capture; carbon molecular sieve membrane; Combustion; Adsorbents; Reactors; Membranes; Water gas; Adsorptivity; Membrane reactors; Carbon dioxide; Work capacity; Synthesis gas; Shift reaction; Carbon sequestration; Molecular sieves; Capital costs; Technology assessment; Temperature; Cost control; Enhanced oil recovery; Coal; United States--US},
language={English},
url={https://www.proquest.com/scholarly-journals/field-scale-testing-high-efficiency-membrane/docview/2930983363/se-2},
}

@article{
author={Johnson,Diego and Mamani,Brayan and Salas,Cesar},
year={2024},
month={2024},
title={CollabVR: VR Testing for Increasing Social Interaction between College Students},
journal={Computers},
volume={13},
number={2},
pages={40},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-23},
abstract={The impact of the COVID-19 pandemic on education has accelerated the shift in learning paradigms toward synchronous and asynchronous online approaches, significantly reducing students’ social interactions. This study introduces CollabVR, as a social virtual reality (SVR) platform designed to improve social interaction among remote university students through extracurricular activities (ECAs). Leveraging technologies such as Unity3D for the development of the SVR environment, Photon Unity Networking for real-time participant connection, Oculus Quest 2 for immersive virtual reality experience, and AWS for efficient and scalable system performance, it aims to mitigate this social interaction deficit. The platform was tested using the sociability scale of Kreijns et al., comparing it with traditional online platforms. Results from a focus group in Lima, Peru, with students participating in online ECAs, demonstrated that CollabVR significantly improved participants perceived social interaction, with a mean of 4.65 ± 0.49 compared to traditional platforms with a mean of 2.35 ± 0.75, fostering a sense of community and improving communication. The study highlights the potential of CollabVR as a powerful tool to overcome socialization challenges in virtual learning environments, suggesting a more immersive and engaging approach to distance education.},
keywords={Computers; social virtual reality; virtual learning environments; social interaction; college students; remote education; extracurricular activities; higher education; Students; Collaboration; Computer assisted instruction--CAI; Socialization; Communication; Education; Social factors; Immersive virtual reality; Pandemics; Virtual reality; Distance learning; Colleges & universities; Virtual environments; Skills},
language={English},
url={https://www.proquest.com/scholarly-journals/collabvr-vr-testing-increasing-social-interaction/docview/2930561252/se-2},
}

@article{
author={Montuori,Rosario and Nastri,Elide and Piluso,Vincenzo and Pisapia,Alessandro and Todisco,Paolo},
year={2024},
month={2024},
title={Application and Validation of a Simplified Approach to Evaluate the Seismic Performances of Steel MR-Frames},
journal={Applied Sciences},
volume={14},
number={3},
pages={1037},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-09},
abstract={The main aim of this work is to validate the application of a simplified performance-based method for assessing the seismic performance of steel buildings, focusing particularly on Moment Resisting Frames (MRFs) through nonlinear analyses. This simplified method defines the capacity curve of a structure through elastic and rigid-plastic analyses, calibrated by regression analyses conducted on 420 structures. To assess its accuracy, the method was compared with other analytical approaches, including incremental dynamic analyses (IDA) provided by existing codes. These analyses were performed on both real structures and simulated designs, considering recent and older codes. The comparison of capacity results derived from code-based approaches and IDA, aligned with the limit states outlined in current codes, showcased the high reliability of the proposed simplified assessment approach.},
keywords={Sciences: Comprehensive Works; moment resisting frames; structural capacity; performance-based assessment; simplified methods; IDA analysis; Design; Methods; Seismic engineering; Equilibrium; Ductility},
language={English},
url={https://www.proquest.com/scholarly-journals/application-validation-simplified-approach/docview/2923930802/se-2},
}

@article{
author={Alhumaid,Majed M. and Said,Mohamed A. and Adnan,Yuhanis and Khoo,Selina},
year={2024},
month={2024},
title={Cross-Cultural Adaptation and Validation of the Arabic Version of the Physical Activity Scale for Individuals with Physical Disabilities in Saudi Arabia (PASIPD-AR)},
journal={Healthcare},
volume={12},
number={2},
pages={179},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-27; SubjectsTermNotLitGenreText - Saudi Arabia},
abstract={This study aimed to cross-culturally adapt and validate the Arabic version of the Physical Activity Scale for Individuals with Physical Disabilities (PASIPD) with Saudi Arabian participants. The study encompassed four distinct stages: (i) translation and subsequent back-translation; (ii) a preliminary assessment aimed at evaluating the quality of the translated scale; (iii) an assessment of the reliability of the measures employed; and (iv) a comprehensive examination of the validity of the measures. A sample of Saudi Arabian participants with physical disabilities (N = 206) took part, ranging in age from 18 to 70 years old, with an average age of 39.56 years and a standard deviation of 12.16. The findings obtained from the reliability tests indicated a notable level of internal consistency and stability. Experts and confirmatory factor analysis were employed to establish the face, content, and construct validity. The findings of the assessment of the Arabic version of PASIPD demonstrated a satisfactory degree of reliability and validity, rendering it suitable for implementation within the Saudi Arabian setting.},
keywords={Medical Sciences; physical activity; health; physical disability; reliability; translation; validation; scale; Exercise; Physical fitness; Life expectancy; Wheelchairs; Performance evaluation; People with disabilities; Disability; Systematic review; Americans with Disabilities Act 1990-US; Mobility; Spinal cord injuries; Questionnaires; Saudi Arabia},
language={English},
url={https://www.proquest.com/scholarly-journals/cross-cultural-adaptation-validation-arabic/docview/2918740823/se-2},
}

@article{
author={Martinez,Kim and Checa,David and Bustillo,Andres},
year={2024},
month={2024},
title={Development of the Engagement Playability and User eXperience (EPUX) Metric for 2D-Screen and VR Serious Games: A Case-Study Validation of Hellblade: Senua’s Sacrifice},
journal={Electronics},
volume={13},
number={2},
pages={281},
note={Copyright - © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-23},
abstract={Research into the design of serious games still lacks metrics to evaluate engagement with the experience so that users can achieve the learning aims. This study presents the new EPUX metric, based on playability and User eXperience (UX) elements, to measure the capability of any serious game to maintain the attention of players. The metric includes (1) playability aspects: game items that affect the emotions of users and that constitute the different layers of the game, i.e., mechanics, dynamics and aesthetics; and (2) UX features: motivation, meaningful choices, usability, aesthetics and balance both in the short and in the long term. The metric is also adapted to evaluate virtual reality serious games (VR-SGs), so that changes may be considered to features linked to playability and UX. The case study for the assessment of the EPUX metric is Hellblade, developed in two versions: one for 2D-screens and the other for VR devices. The comparison of the EPUX metric scores for both versions showed that (1) some VR dynamics augmented the impact of gameplay and, in consequence, engagement capacity; and (2) some game design flaws were linked to much lower scores. Among those flaws were low numbers of levels, missions, and items; no tutorial to enhance usability; and lack of strategies and rewards to increase motivation in the long term.},
keywords={Electronics; serious games; game design; game evaluation; game engagement; virtual reality; Research; Collaboration; User experience; Games; Aesthetics; Design; Mechanics; Motivation; Evaluation; Computer & video games; Educational software},
language={English},
url={https://www.proquest.com/scholarly-journals/development-engagement-playability-user/docview/2918725269/se-2},
}

@article{
author={Muurling,Marijn and de Boer,Casper and Vairavan,Srinivasan and Harms,Robbert L. and Chadha,Antonella S. and Tarnanas,Ioannis and Luis,Estefania V. and Religa,Dorota and Gjestsen,Martha T. and Galluzzi,Samantha and Ibarria Sala,Marta and Koychev,Ivan and Hausner,Lucrezia and Gkioka,Mara and Aarsland,Dag and Visser,Pieter J. and Brem,Anna-Katharine},
year={2023/12//},
month={Dec 2023},
title={Augmented reality versus standard tests to assess cognition and function in early Alzheimer’s disease},
journal={NPJ Digital Medicine},
volume={6},
number={1},
pages={234},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-04},
abstract={Augmented reality (AR) apps, in which the virtual and real world are combined, can recreate instrumental activities of daily living (IADL) and are therefore promising to measure cognition needed for IADL in early Alzheimer’s disease (AD) both in the clinic and in the home settings. The primary aim of this study was to distinguish and classify healthy controls (HC) from participants with AD pathology in an early AD stage using an AR app. The secondary aims were to test the association of the app with clinical cognitive and functional tests and investigate the feasibility of at-home testing using AR. We furthermore investigated the test-retest reliability and potential learning effects of the task. The digital score from the AR app could significantly distinguish HC from preclinical AD (preAD) and prodromal AD (proAD), and preAD from proAD, both with in-clinic and at-home tests. For the classification of the proAD group, the digital score (AUCclinic_visit = 0.84 0.75–0.93], AUCat_home = 0.77 0.61–0.93]) was as good as the cognitive score (AUC = 0.85 0.78–0.93]), while for classifying the preAD group, the digital score (AUCclinic_visit = 0.66 0.53–0.78], AUCat_home = 0.76 0.61–0.91]) was superior to the cognitive score (AUC = 0.55 0.42–0.68]). In-clinic and at-home tests moderately correlated (rho = 0.57, p < 0.001). The digital score was associated with the clinical cognitive score (rho = 0.56, p < 0.001). No learning effects were found. Here we report the AR app distinguishes HC from otherwise healthy Aβ-positive individuals, both in the outpatient setting and at home, which is currently not possible with standard cognitive tests.},
keywords={Medical Sciences--Computer Applications; Augmented reality; Cognition & reasoning; Activities of daily living; Alzheimer's disease; Medical tests},
language={English},
url={https://www.proquest.com/scholarly-journals/augmented-reality-versus-standard-tests-assess/docview/2903154371/se-2},
}

@article{
author={Jae,Woo O. and Kim,Ji E.},
year={2023/12//},
month={Dec 2023},
title={Effectiveness of a virtual reality application-based education programme on patient safety management for nursing students: A pre-test–post-test study},
journal={Nursing Open},
volume={10},
number={12},
pages={7622-7630},
note={Name - World Health Organization; Copyright - © 2023. This work is published under http://creativecommons.org/licenses/by-nc-nd/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-14; SubjectsTermNotLitGenreText - South Korea},
abstract={AimsWe aimed to develop a virtual reality-based smartphone application that improves patient safety competency among nursing students in terms of knowledge, attitudes and confidence in patient safety management. We also sought to evaluate the effects and utility of the application in improving patient safety competency.DesignA parallel, randomized controlled pre- and post-test trial was conducted to test the effects of knowledge, attitudes and performance confidence in patient safety management.MethodsParticipants were randomly allocated to the experimental (n = 22), in which nursing students received a two-week mobile web-based training programme covering key topics in patient safety management or the control group (n = 22), in which nursing students received a training booklet. Participants completed a pre-test and two post-test questionnaires to assess the program's impact. The evaluation tools were patient safety management knowledge, attitude and patient safety management performance confidence scale. Data analysis was performed using descriptive statistics, homogeneity test for pre-test, unpaired t-test and repeated measures ANOVA.ResultsPatient safety competency in the experimental group improved significantly in terms of knowledge (from 11.68 to 18.55, p < 0.000), attitude (from 3.38 to 4.01; p < 0.005) and performance confidence (from 3.93 to 4.52; p < 0.000) compared with the control group. Our findings suggest that mobile app-based education using virtual reality may be effective in enhancing patient safety management in nursing education.},
keywords={Medical Sciences--Nurses And Nursing; competency; education programme; nursing students; patient safety; Students; Nursing education; Smartphones; Safety management; Clinical medicine; Knowledge; Likert scale; Safety training; Attitudes; Virtual reality; Nurses; Health services; South Korea},
language={English},
url={https://www.proquest.com/scholarly-journals/effectiveness-virtual-reality-application-based/docview/2889483139/se-2},
}

@article{
author={Birrenbach,T. and Wespi,R. and Hautz,W. E. and Berger,J. and Schwab,P. R. and Papagiannakis,G. and Exadaktylos,A. K. and Sauter,T. C.},
year={2023/12//},
month={Dec 2023},
title={Development and usability testing of a fully immersive VR simulation for REBOA training},
journal={International Journal of Emergency Medicine (Online)},
volume={16},
number={1},
pages={67},
note={Name - National Aeronautics & Space Administration--NASA; Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-27},
abstract={BackgroundResuscitative endovascular balloon occlusion of the aorta (REBOA) is a potentially life-saving procedure for bleeding trauma patients. Being a rare and complex procedure performed in extreme situations, repetitive training of REBOA teams is critical. Evidence-based guidelines on how to train REBOA are missing, although simulation-based training has been shown to be effective but can be costly and complex. We aimed to determine the feasibility and acceptance of REBOA training using a fully immersive virtual reality (VR) REBOA simulation, as well as assess the confidence in conducting the REBOA procedure before and after the training.MethodsProspective feasibility pilot study of prehospital emergency physicians and paramedics in Bern, Switzerland, from November 2020 until March 2021. Baseline characteristics of trainees, prior training and experience in REBOA and with VR, variables of media use (usability: system usability scale, immersion/presence: Slater-Usoh-Steed, workload: NASA-TLX, user satisfaction: USEQ) as well as confidence prior and after VR training were accessed.ResultsREBOA training in VR was found to be feasible without relevant VR-specific side-effects. Usability (SUS median 77.5, IQR 71.3–85) and sense of presence and immersion (Slater-Usoh-Steed median 4.8, IQR 3.8–5.5) were good, the workload without under-nor overstraining (NASA-TLX median 39, IQR 32.8–50.2) and user satisfaction high (USEQ median 26, IQR 23–29). Confidence of trainees in conducting REBOA increased significantly after training (p < 0.001).ConclusionsProcedural training of the REBOA procedure in immersive virtual reality is possible with a good acceptance and high usability. REBOA VR training can be an important part of a training curriculum, with the virtual reality-specific advantages of a time- and instructor-independent learning.},
keywords={Medical Sciences--Orthopedics And Traumatology; Simulation; Usability; Workloads; User satisfaction; Virtual reality},
language={English},
url={https://www.proquest.com/scholarly-journals/development-usability-testing-fully-immersive-vr/docview/2873641264/se-2},
}

@article{
author={Kim,Ko W. and Choi,Jong D. and Chin,Juhee and Lee,Byung H. and Choi,Jee H. and Na,Duk L.},
year={2023/11/23/},
month={2023 Nov 23},
title={Development and preliminary validation of a virtual reality memory test for assessing visuospatial memory},
journal={Frontiers in Aging Neuroscience},
note={Copyright - © 2023. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-24},
abstract={Background: Visuospatial memory impairment is a common symptom of Alzheimer's disease; however, conventional visuospatial memory tests are insufficient to fully reflect visuospatial memory impairment in daily life.To address patients' difficulties in locating and recalling misplaced objects, we introduced a novel visuospatial memory test, the Hidden Objects Test (HOT), conducted in a virtual environment. We categorized HOT scores into prospective memory, item free-recall, place free-recall, item recognition, and place-item matching scores. To validate the VR memory test, we compared HOT scores among individuals with Alzheimer's disease (AD), amnestic mild cognitive impairment (aMCI), and normal controls (NC), and also compared these scores with those of conventional neuropsychological tests. We tracked the participants' movement paths in the virtual environment and assessed basic features, such as total distance, duration, and speed. Additionally, we performed walking trajectory pattern mining such as outlier and stay-point detection.We designed and implemented the HOT to simulate a house's living room and assess participants' ability to locate hidden objects. Our preliminary results showed that the total HOT score differed among 17 patients with AD, 14 with aMCI, and 15 NC (p <0.001). The total HOT score correlated positively with conventional memory test scores (p <0.001). Walking trajectories showed that patients with AD and aMCI wandered rather than going straight to the hidden objects. In terms of basic features, the total duration was significantly greater in AD than in NC (p = 0.008). In terms of trajectory pattern mining, the number of outliers, which were over 95% of the estimated trajectory, was significantly higher in AD than in NC (p = 0.002). The number of stay points, an index in which participants stayed in the same position for more than 2 s, was significantly higher in patients with AD and aMCI compared with NC (AD vs. NC: p = 0.003, aMCI vs. NC: p = 0.019).The HOT simulating real life showed potential as an ecologically valid test for assessing visuospatial memory function in daily life. Walking trajectory analysis suggested that patients with AD and aMCI wandered rather than going straight toward the hidden objects.},
keywords={Medical Sciences--Psychiatry And Neurology; Alzheimer's disease; virtual reality; spatial memory; spatial navigation; head mounted display; Memory; Computer applications; Furniture; Cognitive ability; Neurodegenerative diseases},
isbn={16634365},
language={English},
url={https://www.proquest.com/scholarly-journals/development-preliminary-validation-virtual/docview/2892775639/se-2},
}

@article{
year={2023},
month={2023},
title={ERRATUM TO RAPOSO ET AL. "INCREASING AWARENESS AND EMPATHY AMONG UNIVERSITY STUDENTS THROUGH IMMERSIVE EXERCISES – TESTING OF THE VIRTUAL REALITY APPLICATION: A PILOT STUDY" (MED PR. 2023;74(3):187–97)},
journal={Medycyna pracy},
volume={74},
number={6},
pages={549},
note={Copyright - © 2023. This work is published under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-26},
keywords={Occupational Health And Safety},
isbn={04655893},
language={English},
url={https://www.proquest.com/scholarly-journals/erratum-raposo-et-al-increasing-awareness-empathy/docview/2916458699/se-2},
}

@article{
author={Kim,Jessica S. and Jonas,Nicholas and Rizvi,Tasneem Z. and Lin,Zhibang and Plewa,Deanna and Ricard,Caroline and Cheah,Yee L. and Simon,Caroline J. and Wright,Valena},
year={2023/10//},
month={Oct 2023},
title={Validation of a multidisciplinary virtual reality (VR) robotic surgical curriculum},
journal={Journal of Robotic Surgery},
volume={17},
number={5},
pages={2495-2502},
note={Copyright - © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2023. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law; Last updated - 2024-01-27},
abstract={The objective is to identify whether trainees demonstrate improvement in a standardized knot-tying task as assessed by Global Evaluative Assessment of Robotic Skills (GEARS) score after completion of a virtual reality (VR) robotic curriculum. An IRB-exempt prospective study was conducted with surgical trainees from August 2021 to February 2023. Participants initially performed a baseline robotic suturing task in which they were instructed to tie interrupted square knots in 10 min. Participants then completed a virtual reality simulation curriculum involving 23 exercises until they achieved 90% proficiency on all tasks. Participants then repeated the suturing task. Pre- and post-curriculum suturing tasks were recorded, de-identified, and scored by expert graders using a GEARS score. Trainees from three academic centers were invited to participate. Medical students (MS1–MS3) and surgical residents from gynecology, urology, and general surgery were invited to participate. Twenty-five trainees completed the pre-curriculum suturing task, the VR curriculum, and the post-curriculum suturing task. Trainees demonstrated significant improvement in their post-test GEARS score by 2.43 points (p < 0.05) and were able to tie three additional knots within 10 min after completion of the curriculum (p < 0.05). Trainees also demonstrated a faster time to complete first knot (114 s improvement, p < 0.05) after completion of the curriculum. All participants agreed or strongly agreed that completion of the robotic curriculum helped them feel more comfortable using the robotic console, and improved their robotic surgical skills. Surgical trainees and medical students with limited prior robotic surgical experience demonstrated objective improvement after completion of a standardized VR curriculum.},
keywords={Medical Sciences--Surgery; Simulation; Surgeons; Gears; Urology; Sutures; Virtual reality; Curricula; Gynecology; Robotic surgery; Training; Knots; Skills; Medical students; Students},
isbn={18632483},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-multidisciplinary-virtual-reality-vr/docview/2918716969/se-2},
}

@article{
author={Gomindes,Austin R. and Adeeko,Elizabeth S. and Khatri,Chetan and Ahmed,Imran and Sehdev,Simran and Carlos,William J. and Ward,Thomas and Leverington,James and Debenham,Luke and Metcalfe,Andrew and Ward,Jayne},
year={2023/09//},
month={September 2023},
title={Use of Virtual Reality in the Education of Orthopaedic Procedures: A Randomised Control Study in Early Validation of a Novel Virtual Reality Simulator},
journal={Cureus},
volume={15},
number={9},
pages={1},
note={Date created - 2023-10-27; Date revised - 2024-02-02; SuppNotes - Conflict of Interest: The authors have declared that no competing interests exist. Cited By: Otolaryngol Head Neck Surg. 2022 Apr;166(4):753-759 34313515] Acta Orthop. 2014 Aug;85(4):403-7 24786902] Niger Med J. 2012 Oct;53(4):184-91 23661875] Acta Orthop. 2015;86(6):695-701 26168925] BJOG. 2012 Aug;119(9):1040-8 22676644] J Med Syst. 2016 Apr;40(4):104 26888655] J Pharmacol Pharmacother. 2010 Jul;1(2):100-7 21350618] J Bone Joint Surg Am. 1995 Jul;77(7):1058-64 7608228] Adv Physiol Educ. 2020 Dec 1;44(4):550-553 32880485] Am J Transl Res. 2017 Sep 15;9(9):3867-3880 28979666] Ann Surg. 2022 Apr 1;275(4):632-639 35261388] Biomed Hub. 2017 Aug 05;2(2):1-5 31988910] Acta Orthop. 2015;86(5):616-21 25885171] Acta Orthop. 2018 Aug;89(4):380-385 29745741] JRSM Open. 2016 Feb 18;7(3):2054270416632703 26981257] Reg Anesth Pain Med. 2019 Jul 18;: 31320504] Am J Surg. 2012 Nov;204(5):724-31 22608671] J Obstet Gynaecol Can. 2013 Apr;35(4):355-361 23660044] Ann Surg. 2022 Apr 1;275(4):640 35081563] J Bone Joint Surg Br. 2008 Apr;90(4):494-9 18378926] Int J Surg. 2020 Jul;79:319-320 32502708] Cochrane Database Syst Rev. 2012 Jun 13;(6):CD008237 22696375] J Am Coll Surg. 2001 Nov;193(5):479-85 11708503] J Arthroplasty. 2019 Oct;34(10):2278-2283 31056442] Adv Orthop. 2019 Sep 2;2019:2586034 31565441] J Neuroeng Rehabil. 2017 Jun 7;14(1):53 28592282] Acta Orthop. 2020 Dec;91(6):669-674 32539590] JB JS Open Access. 2017 Nov 02;2(4):e0022 30229226] JBJS Rev. 2020 Jun;8(6):e1900167 33006464] Front Neurosci. 2009 May 01;3(1):52-9 19753097] Turk J Med Sci. 2021 Jan 10;51(3):1179-1190 33421972] Int J Surg. 2012;10(3):163-6 22366646] Br J Clin Psychol. 1992 Sep;31(3):301-6 1393159] J Surg Educ. 2020 Jul - Aug;77(4):969-977 32035854] Int J Surg. 2015 Jan;13:60-64 25463761] Evid Based Complement Alternat Med. 2022 Aug 11;2022:1373170 35990836] Med Educ. 2001 Dec;35 Suppl 1:70-8 11895257] Surgery. 2012 Apr;151(4):493-501 22088818] J Surg Educ. 2018 Sep - Oct;75(5):1150-1158 29449162] Acta Orthop. 2018 Dec;89(6):689-695 30326762] Arch Surg. 2009 Apr;144(4):371-6 19380652] J Craniofac Surg. 2020 Sep;31(6):1811-1814 32310866] Ann Surg. 2002 Oct;236(4):458-63; discussion 463-4 12368674; Last updated - 2024-02-08},
abstract={Background Virtual reality (VR) simulation is a potential solution to the barriers surgical trainees are facing. There needs to be validation for its implementation within current training. We aimed to compare VR simulation to traditional methods in acquiring surgical skills for a TFN-ADVANCED™ Proximal Femoral Nailing System (TFNA; DePuy Synthes, Auckland, New Zealand) femoral nailing system. Methods Thirty-one surgical trainees were randomised to two groups: traditional-training group (control group) and a VR-training group (intervention group) for insertion of a short cephalomedullary TFNA nail. Both groups then inserted the same TFNA system into saw-bone femurs. Surveys evaluated validity of the relevant activities, perception of simulation, confidence, stress and anxiety. The primary outcomes were tip-apex distance (TAD) and user anxiety/confidence levels. Secondary outcomes included number of screw- and nail-guidewire insertion attempts, the time taken to complete and user validity of the VR system. Results There was no statistical difference in TAD between the intervention and control groups (9mm vs 15mm, p=0.0734). The only TAD at risk of cut-out was in the control group (25mm). There was no statistical difference in time taken (2547.5ss vs 2395ss, p=0.668), nail guide-wire attempts (two for both groups, p=0.355) and screw guide-wire attempts (one for both groups, p=0.702). The control group versus intervention had higher anxiety levels (50% vs 33%) and had lower confidence (61% vs 84%). Interpretation There was no objective difference in performance on a saw-bone model between groups. However, this VR simulator resulted in more confidence and lower anxiety levels whilst performing a simulated TFNA. Whilst further studies with larger sample sizes and exploration of transfer validity to the operating theatre are required, this study does indicate potential benefits of VR within surgical training.},
keywords={haptics; orthopaedics & traumatology; skills and simulation training; tfn-advanced proximal femoral nailing system (tfna); training effect; virtual augmented reality; virtual reality in medical education; virtual reality simulation},
isbn={2168-8184, 2168-8184},
language={English},
url={https://www.proquest.com/scholarly-journals/use-virtual-reality-education-orthopaedic/docview/2883572769/se-2},
}

@article{
author={Bishop,Ronald and Best,Talitha},
year={2023},
month={2023},
title={Mental Workload and Task Performance: A Test of the Relative Efficiency of Virtual Reality Training Scenarios},
journal={The e - Journal of Business Education & Scholarship of Teaching},
volume={17},
number={2},
pages={8-16},
note={Name - National Aeronautics & Space Administration--NASA; Copyright - Copyright Australian Business Education Research Association 2023; Last updated - 2024-04-10; SubjectsTermNotLitGenreText - Thinking Skills; Aviation Education; Flight Training; Learning Processes; Student Experience; Educational Environment},
abstract={The purpose of this paper is to evaluation the efficiency of the aviation flight instruction of two different flight training simulations undertaken in virtual reality conditions. The method involves the use of a model developed by Pass and Van Merriënboer (1993) that combines the measures of mental workload with that of task performance through standardisation involving conversion to z scores, and these in turn derive what is referred to as the relative condition efficiency. There were eight participants who undertook aviation flight training in two different modes, a General Aviation Aircraft (GA) and the other a Recreational Aircraft (RA). The results of the study were that the GA simulation was of Low-instructional efficiency, because there was High Mental Workload (0.80) which was accompanied by Low-task performance (-0.08). The RA simulation was found to be of High-instructional efficiency, because there was High-task Performance (0.44) which was combined with High Mental Workload (0.25).},
keywords={Education; Aircraft; Physiology; Simulation; Memory; Aviation; Cognitive load; Cognitive ability; Workloads; Virtual reality; Learning; Cognition & reasoning; Efficiency; Flight training; Student Experience; Thinking Skills; Educational Environment; Aviation Education; Learning Processes; 61151:Technical and Trade Schools; 92711:Space Research and Technology},
language={English},
url={https://www.proquest.com/scholarly-journals/mental-workload-task-performance-test-relative/docview/2878446395/se-2},
}

@article{
author={Chiarovano,Elodie and McGarvie,Leigh A. and Szmulewicz,David and MacDougall,Hamish G.},
year={2023/06//},
month={Jun 2023},
title={Retraction Note: Subjective visual vertical in virtual reality (Curator SVV): validation and normative data},
journal={Virtual Reality},
volume={27},
number={2},
pages={1567},
note={Copyright - © Springer-Verlag London Ltd., part of Springer Nature 2022; Last updated - 2023-06-05},
keywords={Computers--Computer Graphics},
isbn={13594338},
language={English},
url={https://www.proquest.com/scholarly-journals/retraction-note-subjective-visual-vertical/docview/2821745582/se-2},
}

@article{
author={Dong,Ying and Liu,Xiaoyu and Tang,Min and Huo,Hongqiang and Chen,Duo and Wu,Zhixin and An,Ran and Fan,Yubo},
year={2023/06//},
month={Jun 2023},
title={A haptic-feedback virtual reality system to improve the Box and Block Test (BBT) for upper extremity motor function assessment},
journal={Virtual Reality},
volume={27},
number={2},
pages={1199-1219},
note={Copyright - © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2022. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law; Last updated - 2023-06-03},
abstract={The Box and Block Test (BBT) has been widely used to assess gross upper extremity (UE) motor function. We designed a haptic-feedback virtual reality (VR) system, named the VBBT, to improve the BBT for more specific assessments. The VBBT task required users to move virtual blocks from one compartment of a virtual box to the other within one minute. The focus of this pilot study was to examine the validity, reliability and motivation of the novel assessment. Totally, 113 healthy subjects and 16 post-stroke patients were recruited for a thorough evaluation. We found that scores of the BBT and VBBT were significantly correlated, both of which declined as participants’ age. The normative ranges of kinematic metrics in different age groups were used to identify deficiencies in UE motor function involving smoothness, hand dexterity and motion efficiency. Also, a significant correlation between the VBBT and Action Research Arm Test (ARAT) (|r|≥ 0.56) indicated concurrent validity of the novel assessment. Test–retest results indicated that the VBBT assessment had high reliability (ICCs = 0.62–0.80). The Intrinsic Motivation Inventory results showed that the VBBT was given higher scores for the enjoyment (p < 0.05) and completion effort (p < 0.05) than that for the BBT, indicating patients have greater motivation in the VBBT assessment. In conclusion, the VBBT can provide validated, reliable and motivative assessment for UE motor function with kinematic metrics. It suggests that the haptic-feedback VR contributes to the BBT in specific assessments of UE motor function.},
keywords={Computers--Computer Graphics; Virtual Box and Block Test; Haptic device; Stroke; Validity; Reliability; Motivation; Kinematics; Haptics; Assessments; Smoothness; Virtual reality; Feedback; User requirements},
isbn={13594338},
language={English},
url={https://www.proquest.com/scholarly-journals/haptic-feedback-virtual-reality-system-improve/docview/2821745426/se-2},
}

@article{
author={Schneider,Ingrid and Rannow,Brett and Gupta,Angela and Russell,Matt and Windmuller-Campione,Marcella},
year={2023/06//},
month={Jun 2023},
title={What Really Works? Testing Augmented and Virtual Reality Messaging in Terrestrial Invasive Species Management Communications to Impact Visitor Preferences and Deter Visitor Displacement},
journal={Environmental management},
volume={71},
number={6},
pages={1199-1212},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-31; SubjectsTermNotLitGenreText - Agrilus planipennis},
abstract={Natural resource management is rapidly shifting to incorporate a deeper understanding of ecological processes and functioning, including attention to invasive species. The shift to understand public perceptions of resource management and invasives is much slower. Information influences both landscape preference and behaviors. Theory suggests that increasingly engaging information should have concurrently greater impacts. This research tested the effect of increasingly engaging information on visitor preferences and intentions to return to landscapes treated in response to emerald ash borer (EAB; Agrilus planipennis). Park visitors in a midwestern-U.S. state randomly received one of four messages about forest management in response to EAB (control, photo, augmented reality (AR) and virtual reality (VR)). Messaging impacted preferences for three of the four management approaches, but significant changes in displacement intentions emerged in only one of the four. Specifically, VR and AR increased preferences for complete harvest compared to photos/text, but not differently from those who received no information. VR significantly lowered preferences for select harvest with natural regeneration. The photo/text treatment increased preference for select harvest with planted trees over no information. Any information reduced displacement in response to a photo depicting “select harvest, planted trees.” Subsequently judicious use of advanced communications like VR can optimize increasing scarce resources and maintain or optimize ecological services. Future research directions across geographic and content areas are recommended.},
keywords={Environmental Studies; Emerald ash borer; Forest management; Invasive species; Virtual reality; Augmented reality; Advanced communication technologies; Stakeholder; Natural resources; Trees; Preferences; Introduced species; Displacement; Natural resource management; Computer applications; Resource management; Landscape; Nonnative species; Environmental management; Agrilus planipennis},
isbn={0364-152X},
language={English},
url={https://www.proquest.com/scholarly-journals/what-really-works-testing-augmented-virtual/docview/2813457815/se-2},
}

@article{
author={Raposo,Rui and Vairinhos,Má and Laska-LeŚNiewicz,Anna and Sztobryn-Giercuszkiewicz,Joanna},
year={2023},
month={2023},
title={INCREASING AWARENESS AND EMPATHY AMONG UNIVERSITY STUDENTS THROUGH IMMERSIVE EXERCISES – TESTING OF THE VIRTUAL REALITY APPLICATION: A PILOT STUDY},
journal={Medycyna pracy},
volume={74},
number={3},
pages={187-197},
note={Copyright - © 2023. This work is published under https://creativecommons.org/licenses/by-nc/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-09-20},
abstract={For educational purposes, VR products should provide learning value 2]. ...]additional tests are added to check the achievements and progress of students in particular subjects and topics. The VR simulates the experience of a designed challenging situation in a non-real environment, in first-person point of view. ...]it provides a safe training environment and a possibility for learning while experiencing something unusual for a user in the real world. In this article, the authors focus on the impact of the VR exercises on the level of empathy among participants of the pilot study and changing their approach to people with disabilities and various physical limitations. ...]the carried testing sessions allowed to gather valuable user feedback to improve the final version of the VR application and elaborate tasks in the created virtual environment. According to Adams 14], autonomously from purely perceptive immersion, in narrative immersion the user creates emotional and affective connections with the characters, and for that reason feels involved in a story.},
keywords={Occupational Health And Safety; Universal design; Higher education; Research methodology; Empathy; University students; Usability testing; Pilot projects; Emotions; Personality; Virtual reality; Engineers},
isbn={04655893},
language={English},
url={https://www.proquest.com/scholarly-journals/increasing-awareness-empathy-among-university/docview/2866477372/se-2},
}

@article{
author={Finnegan,Sarah L. and Freeman,Daniel and Sergeant,Martin and Taylor,Stephen and Pattinson,Kyle T. S.},
year={2023/04//},
month={Apr 2023},
title={Breathlessness in a virtual world: An experimental paradigm testing how discrepancy between VR visual gradients and pedal resistance during stationary cycling affects breathlessness perception},
journal={PLoS One},
volume={18},
number={4},
note={Name - Oxford University; Copyright - © 2023 Finnegan et al. This is an open access article distributed under the terms of the Creative Commons Attribution License: http://creativecommons.org/licenses/by/4.0/ (the “License”), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-01; SubjectsTermNotLitGenreText - United Kingdom--UK},
abstract={Introduction The sensation of breathlessness is often attributed to perturbations in cardio-pulmonary physiology, leading to changes in afferent signals. New evidence suggests that these signals are interpreted in the light of prior "expectations". A misalignment between afferent signals and expectations may underly unexplained breathlessness. Using a novel immersive virtual reality (VR) exercise paradigm, we investigated whether manipulating an individual’s expectation of effort (determined by a virtual hill gradient) may alter their perception of breathlessness, independent from actual effort (the physical effort of cycling). Methods Nineteen healthy volunteers completed a single experimental session where they exercised on a cycle ergometer while wearing a VR headset. We created an immersive virtual cycle ride where participants climbed up 100 m hills with virtual gradients of 4%, 6%, 8%, 10% and 12%. Each virtual hill gradient was completed twice: once with a 4% cycling ergometer resistance and once with a 6% resistance, allowing us to dissociate expected effort (virtual hill gradient) from actual effort (power). At the end of each hill, participants reported their perceived breathlessness. Linear mixed effects models were used to examine the independent contribution of actual effort and expected effort to ratings of breathlessness (0–10 scale). Results Expectation of effort (effect estimate ± std. error, 0.63 ± 0.11, P < 0.001) and actual effort (0.81 ± 0.21, P < 0.001) independently explained subjective ratings of breathlessness, with comparable contributions of 19% and 18%, respectively. Additionally, we found that effort expectation accounted for 6% of participants’ power and was a significant, independent predictor (0.09 ± 0.03; P = 0.001). Conclusions An individuals’ expectation of effort is equally important for forming perceptions of breathlessness as the actual effort required to cycle. A new VR paradigm enables this to be experimentally studied and could be used to re-align breathlessness and enhance training programmes.},
keywords={Sciences: Comprehensive Works; Exercise; Shortness of breath; Expectation; Power; Effort; Virtual reality; Sensory perception; Anxiety; Emotions; Questionnaires; Sensory cues; Sports and exercise medicine; Misalignment; Ratings; Perceptions; Brain research; Immersive virtual reality; Perturbation; Cycles; Medical research; Sensory neurons; Perception; Likert scale; Computer applications; Sensation; Bicycling; United Kingdom--UK},
language={English},
url={https://www.proquest.com/scholarly-journals/breathlessness-virtual-world-experimental/docview/2804274128/se-2},
}

@article{
author={Bos,Paula and Martens,Roland M. and de Graaf,Pim and Jasperse,Bas and van Griethuysen, Joost J. M. and Boellaard,Ronald and Leemans,C. R. and Beets-Tan,Regina and van de Wiel, Mark A. and van den Brekel, Michiel W. M. and Castelijns,Jonas A.},
year={2023/04//},
month={Apr 2023},
title={External validation of an MR-based radiomic model predictive of locoregional control in oropharyngeal cancer},
journal={European radiology},
volume={33},
number={4},
pages={2850-2860},
note={Copyright - © The Author(s), under exclusive licence to European Society of Radiology 2022. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law; Last updated - 2023-11-24},
abstract={ObjectivesTo externally validate a pre-treatment MR-based radiomics model predictive of locoregional control in oropharyngeal squamous cell carcinoma (OPSCC) and to assess the impact of differences between datasets on the predictive performance.MethodsRadiomic features, as defined in our previously published radiomics model, were extracted from the primary tumor volumes of 157 OPSCC patients in a different institute. The developed radiomics model was validated using this cohort. Additionally, parameters influencing performance, such as patient subgroups, MRI acquisition, and post-processing steps on prediction performance will be investigated. For this analysis, matched subgroups (based on human papillomavirus (HPV) status of the tumor, T-stage, and tumor subsite) and a subgroup with only patients with 4-mm slice thickness were studied. Also the influence of harmonization techniques (ComBat harmonization, quantile normalization) and the impact of feature stability across observers and centers were studied. Model performances were assessed by area under the curve (AUC), sensitivity, and specificity.ResultsPerformance of the published model (AUC/sensitivity/specificity: 0.74/0.75/0.60) drops when applied on the validation cohort (AUC/sensitivity/specificity: 0.64/0.68/0.60). The performance of the full validation cohort improves slightly when the model is validated using a patient group with comparable HPV status of the tumor (AUC/sensitivity/specificity: 0.68/0.74/0.60), using patients acquired with a slice thickness of 4 mm (AUC/sensitivity/specificity: 0.67/0.73/0.57), or when quantile harmonization was performed (AUC/sensitivity/specificity: 0.66/0.69/0.60).ConclusionThe previously published model shows its generalizability and can be applied on data acquired from different vendors and protocols. Harmonization techniques and subgroup definition influence performance of predictive radiomics models.Key Points• Radiomics, a noninvasive quantitative image analysis technique, can support the radiologist by enhancing diagnostic accuracy and/or treatment decision-making.• A previously published model shows its generalizability and could be applied on data acquired from different vendors and protocols.},
keywords={Medical Sciences--Radiology And Nuclear Medicine; Oropharyngeal neoplasms; Magnetic resonance imaging; Oropharyngeal cancer; Human papillomavirus infection; Quantile normalization; Radiomics; Prognosis; Machine learning; Treatment outcome; Feature extraction; Patients; Human papillomavirus; Tumors; Image analysis; Data acquisition; Performance prediction; Image enhancement; Subgroups; Cancer; Squamous cell carcinoma; Predictive control; Image processing; Stability analysis; Decision making; Thickness; Medical prognosis; Throat cancer},
isbn={09387994},
language={English},
url={https://www.proquest.com/scholarly-journals/external-validation-mr-based-radiomic-model/docview/2787045716/se-2},
}

@article{
author={Zhao,Qianfeng and Liu,Bo and Sun,Qiushi and Jin,Yiqiang},
year={2023/03//},
month={Mar 2023},
title={Development and validation of a cost-effective virtual reality educational tool to reduce anxiety and improve set-up accuracy in radiotherapy patients},
journal={Cancer Medicine},
volume={12},
number={5},
pages={6161-6169},
note={Copyright - © 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-22},
abstract={PurposeThis study proposes a cost-effective method for educating radiotherapy patients through an immersive virtual reality (VR) system.MethodsThe VR educational tool comprises VR glasses, a handheld controller, the scientific knowledge of radiotherapy, radiotherapy demonstration, and an audio introduction. To verify its efficacy, 120 radiotherapy patients with tumors were prospectively enrolled and divided into the control group or VR intervention group. After the first treatment, set-up errors, including three translation errors and three rotation errors, were recorded in six directions. In addition, participants were required to complete a questionnaire before radiotherapy to assess anxiety and understanding degrees. The questionnaire was scored using a five-point Likert Scale. Finally, Spearman's rank correlation test was used to evaluate set-up errors and questionnaire scores.ResultsThe set-up errors are significantly reduced in AP, SI, total translation, Roll and total rotation in the intervention group compared with the control group (p < 0.05). The scores are higher in the intervention group than in the control group in question 1 (2.1 ± 0.58 vs. 3.3 ± 0.55), question 2 (1.3 ± 0.44 vs. 2.5 ± 0.65), question 4 (2.2 ± 0.65 vs. 3.2 ± 0.82), question 5 (1.8 ± 0.59 vs. 3.1 ± 0.79), and all subscales (5.5 ± 1.2 vs. 8.9 ± 1.3 and 6.4 ± 1.3 vs. 9.2 ± 1.5). The scores of high, moderate, and low correlation are 47 (74%), 15 (23%), and 2 (3%) for the control group and 44 (69%), 17 (26%), and 3 (5%) for the intervention group, respectively.ConclusionThe VR educational tool can significantly improve comprehension and reduce anxiety. There is a strong correlation between set-up errors and questionnaire scores. The VR educational tool may help reduce set-up errors for radiotherapy patients.},
keywords={Medical Sciences--Oncology; patient education; Understanding; Anxiety; Questionnaire; Radiotherapy; Virtual reality; set-up accuracy; VR education; Radiation therapy; Audio equipment; Computer applications; Translation; Cancer therapies; Knowledge; Questionnaires},
language={English},
url={https://www.proquest.com/scholarly-journals/development-validation-cost-effective-virtual/docview/2788587988/se-2},
}

@article{
year={2023/03//},
month={Mar 2023},
title={Erratum: “A Clinical Validation of the MR-Compatible Delta4 QA System in a 0.35 tesla MR linear accelerator”},
journal={Journal of Applied Clinical Medical Physics},
volume={24},
number={3},
note={Copyright - © 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-03-16},
keywords={Medical Sciences--Experimental Medicine, Laboratory Technique},
language={English},
url={https://www.proquest.com/scholarly-journals/erratum-clinical-validation-mr-compatible-delta4/docview/2787119288/se-2},
}

@article{
author={Wei,Qiurong and Chen,Zeli and Tang,Yehuan and Chen,Weicui and Zhong,Liming and Mao,Liting and Hu,Shaowei and Wu,Yuankui and Deng,Kan and Yang,Wei and Liu,Xian},
year={2023/03//},
month={Mar 2023},
title={External validation and comparison of MR-based radiomics models for predicting pathological complete response in locally advanced rectal cancer: a two-centre, multi-vendor study},
journal={European radiology},
volume={33},
number={3},
pages={1906-1917},
note={Copyright - © The Author(s), under exclusive licence to European Society of Radiology 2022. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law; Last updated - 2023-11-23},
abstract={ObjectivesThe aim of this study was two-fold: (1) to develop and externally validate a multiparameter MR-based machine learning model to predict the pathological complete response (pCR) in locally advanced rectal cancer (LARC) patients after neoadjuvant chemoradiotherapy (nCRT), and (2) to compare different classifiers’ discriminative performance for pCR prediction.MethodsThis retrospective study includes 151 LARC patients divided into internal (centre A, n = 100) and external validation set (centre B, n = 51). The clinical and MR radiomics features were derived to construct clinical, radiomics, and clinical-radiomics model. Random forest (RF), support vector machine (SVM), logistic regression (LR), K-nearest neighbor (KNN), naive Bayes (NB), and extreme gradient boosting (XGBoost) were used as classifiers. The predictive performance was assessed using the receiver operating characteristic (ROC) curve.ResultsEleven radiomics and four clinical features were chosen as pCR-related signatures. In the radiomics model, the RF algorithm achieved 74.0% accuracy (an AUC of 0.863) and 84.4% (an AUC of 0.829) in the internal and external validation sets. In the clinical-radiomics model, RF algorithm exhibited high and stable predictive performance in the internal and external validation datasets with an AUC of 0.906 (87.3% sensitivity, 73.7% specificity, 76.0% accuracy) and 0.872 (77.3% sensitivity, 88.2% specificity, 86.3% accuracy), respectively. RF showed a better predictive performance than the other classifiers in the external validation datasets of three models.ConclusionsThe multiparametric clinical-radiomics model combined with RF algorithm is optimal for predicting pCR in the internal and external sets, and might help improve clinical stratifying management of LARC patients.Key Points• A two-centre study showed that radiomics analysis of pre- and post-nCRT multiparameter MR images could predict pCR in patients with LARC.• The combined model was superior to the clinical and radiomics model in predicting pCR in locally advanced rectal cancer.• The RF classifier performed best in the current study.},
keywords={Medical Sciences--Radiology And Nuclear Medicine; Rectal neoplasm; Machine learning; Colorectal cancer; Radiomics; XGBoost; Magnetic resonance imaging; Neoadjuvant therapy; Accuracy; Datasets; Performance prediction; Sensitivity; Algorithms; Support vector machines; Cancer; Classifiers; Rectum; Chemoradiotherapy},
isbn={09387994},
language={English},
url={https://www.proquest.com/scholarly-journals/external-validation-comparison-mr-based-radiomics/docview/2777162513/se-2},
}

@article{
author={Sullivan,Lindsay and McKenzie,Lara B. and Roberts,Kristin and Recker,Robyn and Schwebel,David C. and Pommering,Thomas and Yang,Jingzhen},
year={2023},
month={2023},
title={A Virtual Reality App Intervention to Improve Concussion Recognition and Reporting in Athletes Aged 9 to 12 Years: Development and Pilot Testing},
journal={JMIR Formative Research},
volume={7},
note={Copyright - © 2023. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-26; SubjectsTermNotLitGenreText - United States--US},
abstract={Background:Existing concussion education programs for preteen athletes typically do not result in sustained improvements in concussion symptom recognition or reporting behaviors. Virtual reality (VR) technology offers an innovative tool that may improve concussion symptom recognition and reporting behaviors among preteen athletes.Objective:We aimed to describe the design and development of a VR concussion education app, Make Play Safe (MPS), and present findings on the usability and preliminary efficacy of MPS in improving concussion recognition and reporting intentions among soccer athletes aged 9-12 years.Methods:A collaborative user-centered design process was implemented to develop and evaluate MPS, a semi-immersive VR concussion education app designed to address two behavioral outcomes in preteen athletes aged 9-12 years: (1) recognizing concussion and (2) reporting concussion. The development of MPS occurred in three phases: (1) design and development, (2) usability testing, and (3) preliminary efficacy testing. During phase 1, consultations were completed with 6 experts. Additionally, 5 interviews with children who had a history of concussion were conducted to collect feedback about the proof of concept of MPS. During phase 2, a participatory workshop with 11 preteen athletes and a small group discussion with 6 parents and 2 coaches were conducted to explore the usefulness and acceptability of MPS from the perspective of end users. Finally, phase 3 included preliminary efficacy testing with 33 soccer athletes aged 9-12 years to examine changes in concussion-related knowledge, attitudes, and reporting intentions from pre- to postintervention. The data generated from each phase of this study informed the development of the final version of the proof of concept of the VR concussion education app, MPS.Results:Experts positively rated the features of MPS and noted that the design and content were innovative and age-appropriate. Preteens with a history of concussion indicated the scenarios and symptoms portrayed in the app represented well what they experienced while concussed. Further, they stated that the app would be an engaging way for children to learn about concussions. The 11 healthy children in the workshop perceived the app positively, noting that the scenarios were informative and engaging. Results from preliminary efficacy testing revealed increases in many athletes’ knowledge and reporting intentions from pre- to postintervention. Others demonstrated no significant changes or a decrease in knowledge, attitudes, or reporting intentions from pre- to postintervention. Group-level changes in concussion knowledge and intention to report concussions were statistically significant (P<.05), while changes in attitudes toward reporting concussions were not (P=.08).Conclusions:Results suggest VR technology may be an effective and efficient tool to equip preteen athletes with the requisite knowledge and skills to recognize and report future concussions. Further research is recommended to examine the use of VR as an effective strategy to improve concussion-reporting behaviors in preteen athletes.},
keywords={Medical Sciences; concussion; education; sports; athlete; athletic; virtual reality; youth; child; pediatric; head injury; symptom reporting; symptom recognition; patient education; brain injury; user experience; user centered design; Usability; Experiential learning; Participation; Design; Feedback; Soccer; Pediatrics; Interviews; Teenagers; Traumatic brain injury; United States--US},
language={English},
url={https://www.proquest.com/scholarly-journals/virtual-reality-app-intervention-improve/docview/2918539371/se-2},
}

@article{
author={Se,Young K. and Park,Jinseok and Choi,Hojin and Loeser,Martin and Ryu,Hokyoung and Seo,Kyoungwon},
year={2023},
month={2023},
title={Digital Marker for Early Screening of Mild Cognitive Impairment Through Hand and Eye Movement Analysis in Virtual Reality Using Machine Learning: First Validation Study},
journal={Journal of Medical Internet Research},
volume={25},
number={1},
note={Name - Hanyang University; Copyright - © 2023. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-05-28},
abstract={Background:With the global rise in Alzheimer disease (AD), early screening for mild cognitive impairment (MCI), which is a preclinical stage of AD, is of paramount importance. Although biomarkers such as cerebrospinal fluid amyloid level and magnetic resonance imaging have been studied, they have limitations, such as high cost and invasiveness. Digital markers to assess cognitive impairment by analyzing behavioral data collected from digital devices in daily life can be a new alternative. In this context, we developed a “virtual kiosk test” for early screening of MCI by analyzing behavioral data collected when using a kiosk in a virtual environment.Objective:We aimed to investigate key behavioral features collected from a virtual kiosk test that could distinguish patients with MCI from healthy controls with high statistical significance. Also, we focused on developing a machine learning model capable of early screening of MCI based on these behavioral features.Methods:A total of 51 participants comprising 20 healthy controls and 31 patients with MCI were recruited by 2 neurologists from a university hospital. The participants performed a virtual kiosk test—developed by our group—where we recorded various behavioral data such as hand and eye movements. Based on these time series data, we computed the following 4 behavioral features: hand movement speed, proportion of fixation duration, time to completion, and the number of errors. To compare these behavioral features between healthy controls and patients with MCI, independent-samples 2-tailed t tests were used. Additionally, we used these behavioral features to train and validate a machine learning model for early screening of patients with MCI from healthy controls.Results:In the virtual kiosk test, all 4 behavioral features showed statistically significant differences between patients with MCI and healthy controls. Compared with healthy controls, patients with MCI had slower hand movement speed (t49=3.45; P=.004), lower proportion of fixation duration (t49=2.69; P=.04), longer time to completion (t49=–3.44; P=.004), and a greater number of errors (t49=–3.77; P=.001). All 4 features were then used to train a support vector machine to distinguish between healthy controls and patients with MCI. Our machine learning model achieved 93.3% accuracy, 100% sensitivity, 83.3% specificity, 90% precision, and 94.7% F1-score.Conclusions:Our research preliminarily suggests that analyzing hand and eye movements in the virtual kiosk test holds potential as a digital marker for early screening of MCI. In contrast to conventional biomarkers, this digital marker in virtual reality is advantageous as it can collect ecologically valid data at an affordable cost and in a short period (5-15 minutes), making it a suitable means for early screening of MCI. We call for further studies to confirm the reliability and validity of this approach.},
keywords={Medical Sciences--Computer Applications; Alzheimer disease; biomarkers; dementia; digital markers; eye movement; hand movement; machine learning; mild cognitive impairment; screening; virtual reality; Alzheimer's disease; Eye movements; Time series; Activities of daily living; Magnetic resonance imaging; Neuropsychology; Cognitive ability; Statistical significance; Cerebrospinal fluid; Cognitive impairment; Neurologists; Validation studies; Biological markers; Fixation; Medical screening; Cognitive-behavioral factors; Reliability; Behavior; Tests; Executive function},
language={English},
url={https://www.proquest.com/scholarly-journals/digital-marker-early-screening-mild-cognitive/docview/2917629629/se-2},
}

@article{
author={Huey-Pin Tsai and Che-Wei,Lin and Ying-Jun,Lin and Chun-Sheng Yeh and Yan-Shen,Shan},
year={2023},
month={2023},
title={Novel Software for High-level Virological Testing: Self-Designed Immersive Virtual Reality Training Approach},
journal={Journal of Medical Internet Research},
volume={25},
number={1},
note={Copyright - © 2023. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-05-28},
abstract={Background:To ensure the timely diagnosis of emerging infectious diseases, high-tech molecular biotechnology is often used to detect pathogens and has gradually become the gold standard for virological testing. However, beginners and students are often unable to practice their skills due to the higher costs associated with high-level virological testing, the increasing complexity of the equipment, and the limited number of specimens from patients. Therefore, a new training program is necessary to increase training and reduce the risk of test failure.Objective:The aim of the study is to (1) develop and implement a virtual reality (VR) software for simulated and interactive high-level virological testing that can be applied in clinical practice and skills building or training settings and (2) evaluate the VR simulation’s effectiveness on reaction, learning, and behavior of the students (trainees).Methods:Viral nucleic acid tests on a BD MAX instrument were selected for our VR project because it is a high-tech automatic detection system. There was cooperation between teachers of medical technology and biomedical engineering. Medical technology teachers were responsible for designing the lesson plan, and the biomedical engineering personnel developed the VR software. We designed a novel VR teaching software to simulate cognitive learning via various procedure scenarios and interactive models. The VR software contains 2D VR “cognitive test and learning” lessons and 3D VR “practical skills training” lessons. We evaluated students’ learning effectiveness pre- and posttraining and then recorded their behavior patterns when answering questions, performing repeated exercises, and engaging in clinical practice.Results:The results showed that the use of the VR software met participants’ needs and enhanced their interest in learning. The average posttraining scores of participants exposed to 2D and 3D VR training were significantly higher than participants who were exposed solely to traditional demonstration teaching (P<.001). Behavioral assessments of students pre- and posttraining showed that students exposed to VR-based training to acquire relevant knowledge of advanced virological testing exhibited significantly improved knowledge of specific items posttraining (P<.01). A higher participant score led to fewer attempts when responding to each item in a matching task. Thus, VR can enhance students’ understanding of difficult topics.Conclusions:The VR program designed for this study can reduce the costs associated with virological testing training, thus, increasing their accessibility for students and beginners. It can also reduce the risk of viral infections particularly during disease outbreaks (eg, the COVID-19 pandemic) and also enhance students’ learning motivation to strengthen their practical skills.},
keywords={Medical Sciences--Computer Applications; design; immersive; virtual reality; VR; high-level clinical virology; skill training; testing; virological; medical education; clinical practice; simulation; biotechnology; molecular; detection; pathogen; development; software; teaching; Risk reduction; Teaching methods; Medical diagnosis; Trainees; Clinical skills; Equipment; Laboratories; Medical technology; Cooperation; Access; Clinical medicine; Motivation; COVID-19; Teachers; Engineering; Skill development; Pandemics; Behavior; Tests; Infectious diseases; Students; Learning; Cytomegalovirus},
language={English},
url={https://www.proquest.com/scholarly-journals/novel-software-high-level-virological-testing/docview/2917628839/se-2},
}

@article{
author={Rosa Maria Baños and Laura-Maria Peltonen and Martin,Blaine and Koledova,Ekaterina},
year={2023},
month={2023},
title={An Augmented Reality Mobile App (Easypod AR) as a Complementary Tool in the Nurse-Led Integrated Support of Patients Receiving Recombinant Human Growth Hormone: Usability and Validation Study},
journal={JMIR Nursing},
volume={6},
note={Name - Merck KGaA; Copyright - © 2023. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-23; SubjectsTermNotLitGenreText - Germany; United Kingdom--UK},
abstract={Background:Children with growth hormone deficiency face the prospect of long-term recombinant human growth hormone (r-hGH) treatment requiring daily injections. Adherence to treatment is important, especially at treatment initiation, to achieve positive health outcomes. Historically, telenursing services embedded in patient support programs (PSPs) have been a valid approach to support r-hGH treatment initiation and patient education and facilitate adherence by identifying and optimizing appropriate injection techniques. The development of mobile phones with augmented reality (AR) capabilities offers nurses new tools to support patient education.Objective:To investigate experiences among nurses of a new mobile phone app developed to support patient training with a phone-based PSP for r-hGH treatment.Methods:In 2020, the Easypod AR mobile app was launched to support nurse-driven telehealth education for patients initiating r-hGH therapy with the Easypod electromechanical auto-injector device. Nurses who were part of PSPs in countries where the Easypod AR app had been launched or where training was provided as part of an anticipated future launch of the app were invited to participate in an online survey based on the Mobile App Rating Scale to capture their feedback after using the app.Results:In total, 23 nurses completed the online questionnaire. They positively rated the quality of the app across multiple dimensions. The highest mean scores were 4.0 for engagement (ie, adaptation to the target group; SD 0.74), 4.1 (SD 0.79) for functionality (navigation) and 4.1 (SD 0.67) for aesthetics (graphics). Responses indicated the potential positive impact of such a tool on enhancing patient education, patient support, and communication between patients and PSP nurses. Some participants also suggested enhancements to the app, including gamification techniques that they felt have the potential to support the formation of positive treatment behaviors and habits.Conclusions:This study highlights the potential for new digital health solutions to reinforce PSP nurse services, including patient education. Future studies could explore possible correlations between any behavioral and clinical benefits that patients may derive from the use of such apps and how they may contribute to support improved patient experiences and treatment outcomes.},
keywords={Medical Sciences--Nurses And Nursing; augmented reality; growth hormone; growth hormone deficiency; mobile app; mobile health; nurse; patient support program; telehealth; telemedicine; treatment; Growth hormones; Medical equipment; Usability; Caregivers; Feedback; Patient education; Nurses; Questionnaires; United Kingdom--UK; Germany},
language={English},
url={https://www.proquest.com/scholarly-journals/augmented-reality-mobile-app-easypod-ar-as/docview/2917605936/se-2},
}

@article{
author={Delgado-Rodríguez,Santiago and Domínguez,Silvia C. and Garcia-Fandino,Rebeca},
year={2023},
month={2023},
title={Design, Development and Validation of an Educational Methodology Using Immersive Augmented Reality for STEAM Education},
journal={Journal of New Approaches in Educational Research},
volume={12},
number={1},
pages={19-39},
note={Copyright - © 2023. This work is published under https://creativecommons.org/licenses/by-nc/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-04-16; SubjectsTermNotLitGenreText - Secondary Education; Educational Practices; Educational Resources; Learning Processes; Teaching Methods; Academic Achievement; Educational Technology; Educational Environment; Educational Needs},
abstract={The main objective of this study is the design and validation of an educational methodological model based on the use of immersive technological resources (Augmented Reality - AR) to improve learning processes in secondary education science subjects (Biology and Geology). The process was developed based on three main quantitative studies: an exploratory study, a study of performance divided into three cases studies, and an attitudinal study. The information obtained was completed with a fourth qualitative study of the training of teachers who participate in educational technology. This research provides empirical evidence that allows validation of the methodological model developed to explain key concepts and to improve the level of motivation and acceptance of AR technology by students. The proposed model can induce improvements in educational processes in the field of STEAM when used with an immersive AR technological resource and an adapted digital evaluation system. It also demonstrates that teachers require specific training in connection with the creation and the adequate use of AR educational resources, and of digital evaluation systems as well. The results of this study have important implications for the field of education, demonstrating the potential of AR technology to improve learning outcomes and the need for teacher training in its use.},
keywords={Education; Teaching; Augmented reality; Secondary education; Students; Academic achievement; Virtual reality; Technology; Learning; Teacher education; Educational Practices; Educational Environment; Educational Resources; Educational Technology; Educational Needs; Learning Processes; Teaching Methods},
language={English},
url={https://www.proquest.com/scholarly-journals/design-development-validation-educational/docview/2909794444/se-2},
}

@article{
author={Noetscher,Gregory M. and Serano Peter,J. and Horner,Marc and Prokop,Alexander and Hanson,Jonathan and Kyoko,Fujimoto and Brown,James and Ara,Nazarian and Ackerman,Jerome and Makaroff,Sergey N.},
year={2023},
month={2023},
title={An in silico testbed for fast and accurate MR labeling of orthopedic implants},
journal={eLife},
volume={12},
note={Name - Food & Drug Administration--FDA; Department of Health & Human Services; Copyright - © 2023, Noetscher, Serano et al. This work is published under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-01; SubjectsTermNotLitGenreText - United States--US},
abstract={One limitation on the ability to monitor health in older adults using magnetic resonance (MR) imaging is the presence of implants, where the prevalence of implantable devices (orthopedic, cardiac, neuromodulation) increases in the population, as does the pervasiveness of conditions requiring MRI studies for diagnosis (musculoskeletal diseases, infections, or cancer). The present study describes a novel multiphysics implant modeling testbed using the following approaches with two examples: (1) an in silico human model based on the widely available Visible Human Project (VHP) cryo-section dataset; (2) a finite element method (FEM) modeling software workbench from Ansys (Electronics Desktop/Mechanical) to model MR radio frequency (RF) coils and the temperature rise modeling in heterogeneous media. The in silico VHP-Female model (250 parts with an additional 40 components specifically characterizing embedded implants and resultant surrounding tissues) corresponds to a 60-year-old female with a body mass index of 36. The testbed includes the FEM-compatible in silico human model, an implant embedding procedure, a generic parameterizable MRI RF birdcage two-port coil model, a workflow for computing heat sources on the implant surface and in adjacent tissues, and a thermal FEM solver directly linked to the MR coil simulator to determine implant heating based on an MR imaging study protocol. The primary target is MR labeling of large orthopedic implants. The testbed has very recently been approved by the US Food and Drug Administration (FDA) as a medical device development tool for 1.5 T orthopedic implant examinations.},
keywords={Biology; orthopedic impants; MR imaging studies; temperature rise; MR safety/labeling; multiphysics modeling; Infections; Patients; Software; Magnetic resonance imaging; Transplants & implants; Orthopedics; Finite element method; Labeling; Medical equipment; Neuromodulation; Females; Musculoskeletal diseases; Body mass index; Embedding; United States--US},
language={English},
url={https://www.proquest.com/scholarly-journals/silico-testbed-fast-accurate-mr-labeling/docview/2908076992/se-2},
}

@article{
author={Forsberg,Karin and Jirlén,Johan and Jacobson,Inger and Röijezon,Ulrik},
year={2023},
month={2023},
title={Concurrent Validity of Cervical Movement Tests Using VR Technology—Taking the Lab to the Clinic},
journal={Sensors},
volume={23},
number={24},
pages={9864},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-23; SubjectsTermNotLitGenreText - Sweden},
abstract={Reduced cervical range of motion (ROM) and movement velocity are often seen in people with neck pain. Objective assessment of movement characteristics is important to identify dysfunction, to inform tailored interventions, and for the evaluation of the treatment effect. The purpose of this study was to investigate the concurrent validity of a newly developed VR technology for the assessment of cervical ROM and movement velocity. VR technology was compared against a gold-standard three-dimensional optical motion capture system. Consequently, 20 people, 13 without and 7 with neck pain, participated in this quantitative cross-sectional study. ROM was assessed according to right/left rotation, flexion, extension, right/left lateral flexion, and four diagonal directions. Velocity was assessed according to fast cervical rotation to the right and left. The correlations between VR and the optical system for cervical ROM and velocity were excellent, with intraclass correlation coefficient (ICC) values > 0.95. The mean biases between VR and the optical system were ≤ 2.1° for the ROM variables, <12°/s for maximum velocity, and ≤3.0°/s for mean velocity. In conclusion, VR is a useful assessment device for ROM and velocity measurements with clinically acceptable biases. It is a feasible tool for the objective measurement of cervical kinematics in the clinic.},
keywords={Chemistry--Analytical Chemistry; neck pain; cervical; virtual reality; VR; 3D motion capture; validity; agreement; correlation; range of motion; velocity; Software; Motion capture; Data collection; Accuracy; Laboratory equipment; Laboratories; Sweden},
language={English},
url={https://www.proquest.com/scholarly-journals/concurrent-validity-cervical-movement-tests-using/docview/2904929845/se-2},
}

@article{
author={Mobile Computing Wireless,Communications a.},
year={2023},
month={2023},
title={Retracted: The Construction of Immersive Learning System Based on Virtual Testing Technology of Virtual Reality},
journal={Wireless Communications & Mobile Computing (Online)},
volume={2023},
note={Copyright - Copyright © 2023 Wireless Communications and Mobile Computing. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-11},
keywords={Computers; Peer review; Virtual reality},
isbn={1530-8669},
language={English},
url={https://www.proquest.com/scholarly-journals/retracted-construction-immersive-learning-system/docview/2900108277/se-2},
}

@article{
author={Gardini,Valentina and Ruini,Chiara and Tossani,Eliana and Grandi,Silvana and Tomba,Elena},
year={2023},
month={2023},
title={Protocol for a Randomized Controlled Trial Testing the Efficacy of a Transdiagnostic Virtual Reality-Based Intervention for the Reduction of Unhealthy Lifestyles and Behaviors in the General Population},
journal={Journal of Clinical Medicine},
volume={12},
number={23},
pages={7470},
note={Name - University of Bologna; Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-02},
abstract={Virtual reality (VR) is a valuable tool for the treatment and prevention of psychiatric disorders and dysfunctional behaviors. Although VR software is mainly developed following a disorder-specific approach, this randomized controlled trial (RCT) will test the efficacy of a new transdiagnostic VR application (H.O.M.E. VR-based psychological intervention) in improving dysfunctional behaviors, three transdiagnostic factors concurrently (emotion regulation, experiential avoidance, and psychological flexibility), and stress. Three groups screened as at-risk for nicotine dependence, alcohol abuse, and eating disorders will be assigned to the H.O.M.E. VR intervention and compared to a waiting-list (WL) condition. Participants will be assessed before and after the H.O.M.E. intervention/WL and at the 3- and 6-month follow-ups in the levels of the displayed dysfunctional behavior, the three transdiagnostic factors, and stress. Changes in dysfunctional behaviors, transdiagnostic factors, and stress in each population VR group and differences in such improvements between each population of the VR and WL groups will be evaluated using mixed-model repeated measure analyses of variance. It is expected that, after the H.O.M.E. intervention and at follow-ups, participants will display improvements in physical and psychological health compared to controls. The H.O.M.E. protocol is expected to result in a cost-effective option to tackle cognitive–behavioral factors shared among several psychopathologies and dysfunctional behaviors.},
keywords={Medical Sciences; virtual reality; transdiagnostic factors; eating disorders; substance use disorder; alcohol use disorder; Software; Emotions; Mental disorders; Clinical medicine},
language={English},
url={https://www.proquest.com/scholarly-journals/protocol-randomized-controlled-trial-testing/docview/2899453852/se-2},
}

@article{
author={Xie,Sujun and Grimstrup,Sø and Leizl,Joy N. and Wang,Zheng and Wan,Xing and Konge,Lars},
year={2023},
month={2023},
title={Using a novel virtual-reality simulator to assess performance in lumbar puncture: a validation study},
journal={BMC Medical Education},
volume={23},
pages={1-8},
note={Name - Guangzhou University; Copyright - © 2023. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-04-16; SubjectsTermNotLitGenreText - China; Standardized Tests; Educational Strategies; Computer Simulation; Physicians; Patients; Competence; Validity; Video Technology; Skill Centers; Educational Methods; Reliability; Mastery Learning; Test Results; Outcome Measures; Medical Students; Evidence; Simulation; Feedback (Response); Novices; Anesthesiology; Trainees; Statistical Analysis; Item Analysis; Internal Medicine},
abstract={BackgroundA lumbar puncture procedure’s success depends on a competent physician minimizing the risk of failing to get a sample and avoiding complications such as post-dural headache. A new virtual-reality simulator might be helpful in deciding when a physician is competent to perform lumbar puncture. We aimed to investigate validity evidence for a simulator-based test in lumbar puncture and establish a pass/fail standard to allow a mastery learning training program.MethodsValidity evidence was investigated using Messick’s framework by including participants who were novices, intermediates, or experienced in lumbar puncture. Each participant performed two lumbar puncture procedures on the simulator, and fifty-nine predefined simulator metrics were automatically recorded. Cronbach’s alpha was used to explore internal consistency reliability. Intergroup comparisons were made using independent sample t-tests with Tukey’s correction for multiple comparisons. The learning effect was explored using paired sample t-test analysis, and a pass/fail standard was established using the contrasting groups’ method.Results73 novices, 18 intermediates, and 19 physicians performed the test resulting in a total of 220 procedures. 25 metrics (42.4%) had good discriminatory ability, and the reliability of these metrics was good, Cronbach’s α = 0.81. The experienced physicians were significantly better than the novices (18.3 vs. 13.3, p < 0.001), and the pass/fail standard was established at 16 points. This standard resulted in 22 (30.1%) novices passing (i.e., false positives) and 5 (26.3%) physicians failing (i.e., false negatives).ConclusionThis study provides validity evidence for a simulator-based test of lumbar puncture competence. The test can help ensure basic competence at the end of a simulation-based training program for trainees, i.e., a mastery learning training program.},
keywords={Medical Sciences; Lumbar puncture; Virtual reality; Assessment; Validity; Mastery learning; Simulation; Medicine; Medical students; Clinical medicine; Curricula; Feedback; Diagnostic tests; Independent sample; Validation studies; Educational Methods; Trainees; Competence; Physicians; Skill Centers; China; Computer Simulation; Evidence; Statistical Analysis; Feedback (Response); Educational Strategies; Test Results; Outcome Measures; Internal Medicine; Patients; Video Technology; Standardized Tests; Item Analysis; Anesthesiology; Reliability; Novices},
language={English},
url={https://www.proquest.com/scholarly-journals/using-novel-virtual-reality-simulator-assess/docview/2890060331/se-2},
}

@article{
author={Gomindes,Austin R. and Adeeko,Elizabeth S. and Chetan,Khatri and Ahmed,Imran and Simran,Sehdev and Carlos,William J. and Ward,Thomas and Leverington,James and Luke,Debenham and Metcalfe,Andrew and Ward,Jayne},
year={2023},
month={2023},
title={Use of Virtual Reality in the Education of Orthopaedic Procedures: A Randomised Control Study in Early Validation of a Novel Virtual Reality Simulator},
journal={Cureus},
volume={15},
number={9},
note={Copyright - Copyright © 2023, Gomindes et al. This work is published under https://creativecommons.org/licenses/by/3.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-06},
abstract={BackgroundVirtual reality (VR) simulation is a potential solution to the barriers surgical trainees are facing. There needs to be validation for its implementation within current training. We aimed to compare VR simulation to traditional methods in acquiring surgical skills for a TFN-ADVANCED™ Proximal Femoral Nailing System (TFNA; DePuy Synthes, Auckland, New Zealand) femoral nailing system.MethodsThirty-one surgical trainees were randomised to two groups: traditional-training group (control group) and a VR-training group (intervention group) for insertion of a short cephalomedullary TFNA nail. Both groups then inserted the same TFNA system into saw-bone femurs. Surveys evaluated validity of the relevant activities, perception of simulation, confidence, stress and anxiety. The primary outcomes were tip-apex distance (TAD) and user anxiety/confidence levels. Secondary outcomes included number of screw- and nail-guidewire insertion attempts, the time taken to complete and user validity of the VR system.ResultsThere was no statistical difference in TAD between the intervention and control groups (9mm vs 15mm, p=0.0734). The only TAD at risk of cut-out was in the control group (25mm). There was no statistical difference in time taken (2547.5ss vs 2395ss, p=0.668), nail guide-wire attempts (two for both groups, p=0.355) and screw guide-wire attempts (one for both groups, p=0.702).The control group versus intervention had higher anxiety levels (50% vs 33%) and had lower confidence (61% vs 84%).InterpretationThere was no objective difference in performance on a saw-bone model between groups. However, this VR simulator resulted in more confidence and lower anxiety levels whilst performing a simulated TFNA. Whilst further studies with larger sample sizes and exploration of transfer validity to the operating theatre are required, this study does indicate potential benefits of VR within surgical training.},
keywords={Medical Sciences; training effect; haptics; orthopaedics & traumatology; virtual reality in medical education; virtual reality simulation; virtual augmented reality; tfn-advanced proximal femoral nailing system (tfna); skills and simulation training; Simulation; Software; Surgeons; Anxiety; Validity; Orthopedics; Training; Virtual reality; Questionnaires},
language={English},
url={https://www.proquest.com/scholarly-journals/use-virtual-reality-education-orthopaedic/docview/2884555859/se-2},
}

@article{
author={Pai,Hyunjoo},
year={2023},
month={2023},
title={Presidential address: improving item validity and adopting computer-based testing, clinical skills assessments, artificial intelligence, and virtual reality in health professions licensing examinations in Korea},
journal={Journal of Educational Evaluation for Health Professions},
volume={20},
pages={1-3},
note={Copyright - Copyright Korea Health Personnel Licensing Examination Institute 2023; Last updated - 2023-12-01},
keywords={Medical Sciences; Artificial intelligence},
language={English},
url={https://www.proquest.com/scholarly-journals/presidential-address-improving-item-validity/docview/2884356400/se-2},
}

@article{
author={Sensors,Journal o.},
year={2023},
month={2023},
title={Retracted: Test of Ultimate Bearing Capacity of Building Concrete Structures in Earthquake Area Based on Virtual Reality},
journal={Journal of Sensors},
volume={2023},
note={Copyright - Copyright © 2023 Journal of Sensors. This is an open access article distributed under the Creative Commons Attribution License (the “License”), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License. https://creativecommons.org/licenses/by/4.0; Last updated - 2023-10-30},
keywords={Computers--Automation; Research; Earthquakes; Virtual reality; Bearing capacity; Concrete structures},
isbn={1687725X},
language={English},
url={https://www.proquest.com/scholarly-journals/retracted-test-ultimate-bearing-capacity-building/docview/2883383052/se-2},
}

@article{
author={Fekih-Romdhane,Feten and Azzi,Vanessa and Hallit,Rabih and Malaeb,Diana and Dabbous,Mariam and Sakr,Fouad and Obeid,Sahar and Hallit,Souheil},
year={2023},
month={2023},
title={Validation of the Arabic version of the brief irritability test (Ar-BITe) in non-clinical adolescents},
journal={BMC Psychiatry},
volume={23},
pages={1-8},
note={Copyright - © 2023. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-26; SubjectsTermNotLitGenreText - Arab countries; Lebanon},
abstract={BackgroundDespite the substantial clinical relevance of irritability in the development and maintenance of several mental disorders and its negative effects on functioning, no valid and reliable measures are available yet to identify the presence and consequences of irritability as a distinct construct among the Arabic-speaking populations. To bridge this gap, and help advance this field in the under-researched Arab region, we aimed to validate an Arabic-language version of the Brief Irritability Test (BITe).MethodsEligible participants were native Arabic-speaking non-clinical adolescents from Lebanon; 527 participants aged 15.73 ± 1.81 years (56% females) completed the survey.ResultsUtilizing the Confirmatory Factor Analysis approach, we found that the five items of the Arabic BITe loaded into a single factor structure. The scale showed excellent reliability, as both Cronbach’s alpha and McDonald’s omega coefficient values were of 0.88. Multi-group analyses showed invariance across sex groups in our sample at the configural, metric, and scalar levels. Female adolescents exhibited higher BITe scores than their male counterparts (14.01 vs. 13.25), but this difference did not reach the statistical significance. Good concurrent validity was supported based on positive correlations between irritability scores and measures of aggression, anger and hostility (r Pearson’s coefficients ranging from 0.35 to 0.42), as well as positive correlations with insomnia symptoms scores.ConclusionThe present findings allow us to conclude that the Arabic version of the BITe is a unidimensional, reliable, valid, brief, and economic self-report measure of the irritability construct for both male and female Arabic-speakers. Providing an Arabic validated version of the BITe will hopefully foster the research efforts of the Arab scientific community in this area, and promote the implementation of timely, evidence-informed and culturally-sensitive mental health interventions that appropriately address irritability-related problems and consequences among Arab young populations.},
keywords={Medical Sciences--Psychiatry And Neurology; Irritability; BITe; Arabic; Psychometric properties; Adolescents; Qualitative research; Self report; Factor analysis; Quantitative research; Surveys & questionnaires; Research; Physiology; Insomnia; Validity; Sleep disorders; Quantitative psychology; Chronic pain; Mental disorders; Questionnaires; Psychopathology; Anger; University students; Hostility; Mental health; Teenagers; Psychiatry; Lebanon; Arab countries},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-arabic-version-brief-irritability-test/docview/2877493299/se-2},
}

@article{
author={Xu,Tianming and Wei,Yuesong},
year={2023},
month={2023},
title={Ratio Test for Mean Changes in Time Series with Heavy-Tailed AR(p) Noise Based on Multiple Sampling Methods},
journal={Mathematics},
volume={11},
number={18},
pages={3988},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-10-12},
abstract={This paper discusses the problem of the mean changes in time series with heavy-tailed AR(p) noise. Firstly, it proposes a modified ratio-type test statistic, and the results show that under the null hypothesis of no mean change, the asymptotic distribution of the modified statistic is a functional of Lévy processes and the consistency under the alternative hypothesis is obtained. However, a heavy-tailed index exists in the asymptotic distribution and is difficult to estimate. This paper uses bootstrap sampling, jackknife sampling, and subsampling to approximate the distribution under the null hypothesis, and obtain more accurate critical values and empirical power. In addition, some results from a small simulation study and a practical example give an idea of the finite sample behavior of the proposed statistic.},
keywords={Mathematics; ratio test; heavy tailed; limit distribution; bootstrap; jackknife; subsampling; Statistics; Null hypothesis; Asymptotic properties; Hypothesis testing; Random variables; Time series; Hypotheses; Sampling methods; Normal distribution; Food science},
language={English},
url={https://www.proquest.com/scholarly-journals/ratio-test-mean-changes-time-series-with-heavy/docview/2869422274/se-2},
}

@article{
author={Hallit,Souheil and Rogoza,Radosław and Carl,Abi S. and Azzi,Vanessa and Sawma,Toni and Obeid,Sahar},
year={2023},
month={2023},
title={Validation of the Arabic version of the cyberchondria severity scale 12 items (CSS-12-Ar) among a sample of Lebanese adults},
journal={BMC Psychiatry},
volume={23},
pages={1-8},
note={Copyright - © 2023. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-26; SubjectsTermNotLitGenreText - Beirut Lebanon; Lebanon},
abstract={BackgroundTo the best of our knowledge, the Cyberchondria Severity Scale-12 (CSS-12) has not been translated into Arabic; therefore, our objective was to assess the psychometric properties of the Arabic version of the CSS (CSS-12-Ar) among a sample of Lebanese adults.MethodsParticipants were enrolled in January 2021. A confirmatory factor analysis (CFA) was carried out using the MPlus software v.7.2, reporting several goodness-of-fit indicators: Relative Chi-square (χ2/df), Root Mean Square Error of Approximation (RMSEA), Comparative Fit Index (CFI) and Tucker Lewis Index (TLI). To evaluate measurement invariance across gender, we conducted higher-order multiple group confirmatory analysis using lavaan software.Results449 participants enrolled in this study (mean age: 24.34 ± 8.22 years, 70.6% females). Since the correlations between the four-factor model were very high (r > 0.8), we ran the higher-order CFA in which all first-order latent variables were loading a general factor. The analyzed model was well-fitted to the data χ2(50) = 173.34; p < 0.001; CFI = 0.926; RMSEA = 0.074 0.062, 0.086]. The Cronbach’s alpha values were good for the total score (0.92), as well as for excessiveness (0.80), distress (0.77), reassurance (0.81) and compulsion (0.76). The results provided evidence of full scalar invariance across gender. The comparison of latent mean scores revealed no significant differences across gender, in either the cyberchondria total score or its facets. The CSS-12 score was positively associated with anxiety (r = 0.10; p = 0.003) (convergent validity), OCD (r = 0.11; p = 0.016) and stress (r = 0.35; p < 0.001) (concurrent validity).ConclusionThe CSS-12-Ar was deemed a suitable scale to measure the severity of cyberchondria among Lebanese university students. We hope that researchers and clinicians can benefit now from this scale.},
keywords={Medical Sciences--Psychiatry And Neurology; Cyberchondria severity; CSS-12; Arabic; Psychometric properties; Validation; Lebanon; Factor analysis; Quantitative research; Anxiety; Validity; Internet; Gender; Stress; Quantitative psychology; Pandemics; Sociodemographics; Questionnaires; Mental depression; False information; Professionals; Mental health; Psychologists; COVID-19; Chi-square test; Psychiatry; Beirut Lebanon},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-arabic-version-cyberchondria-severity/docview/2865397499/se-2},
}

@article{
author={Palombi,Tommaso and Galli,Federica and Giancamilli,Francesco and D’Amico,Monica and Alivernini,Fabio and Gallo,Luigi and Neroni,Pietro and Predazzi,Marco and De Pietro,Giuseppe and Lucidi,Fabio and Giordano,Antonio and Chirico,Andrea},
year={2023},
month={2023},
title={The role of sense of presence in expressing cognitive abilities in a virtual reality task: an initial validation study},
journal={Scientific Reports (Nature Publisher Group)},
volume={13},
number={1},
pages={13396},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-05},
abstract={There is a raised interest in literature to use Virtual Reality (VR) technology as an assessment tool for cognitive domains. One of the essential advantages of transforming tests in an immersive virtual environment is the possibility of automatically calculating the test’s score, a time-consuming process under natural conditions. Although the characteristics of VR can deliver different degrees of immersion in a virtual environment, the sense of presence could jeopardize the evolution of these practices. The sense of presence results from a complex interaction between human, contextual factors, and the VR environment. The present study has two aims: firstly, it contributes to the validation of a virtual version of the naturalistic action test (i.e., virtual reality action test); second, it aims to evaluate the role of sense of presence as a critical booster of the expression of cognitive abilities during virtual reality tasks. The study relies on healthy adults tested in virtual and real conditions in a cross-over research design. The study’s results support the validity of the virtual reality action test. Furthermore, two structural equation models are tested to comprehend the role of sense of presence as a moderator in the relationship between cognitive abilities and virtual task performance.},
keywords={Sciences: Comprehensive Works; Computer applications; Cognitive ability; Virtual reality},
language={English},
url={https://www.proquest.com/scholarly-journals/role-sense-presence-expressing-cognitive/docview/2852217820/se-2},
}

@article{
author={Wei,Shu and Freeman,Daniel and Rovira,Aitor},
year={2023},
month={2023},
title={A randomised controlled test of emotional attributes of a virtual coach within a virtual reality (VR) mental health treatment},
journal={Scientific Reports (Nature Publisher Group)},
volume={13},
number={1},
pages={11517},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-07-18},
abstract={We set out to test whether positive non-verbal behaviours of a virtual coach can enhance people's engagement in automated virtual reality therapy. 120 individuals scoring highly for fear of heights participated. In a two-by-two factor, between-groups, randomised design, participants met a virtual coach that varied in warmth of facial expression (with/without) and affirmative nods (with/without). The virtual coach provided a consultation about treating fear of heights. Participants rated the therapeutic alliance, treatment credibility, and treatment expectancy. Both warm facial expressions (group difference = 7.44 3.25, 11.62], p = 0.001, etap2=0.10) and affirmative nods (group difference = 4.36 0.21, 8.58], p = 0.040, etap2 = 0.04) by the virtual coach independently increased therapeutic alliance. Affirmative nods increased the treatment credibility (group difference = 1.76 0.34, 3.11], p = 0.015, etap2 = 0.05) and expectancy (group difference = 2.28 0.45, 4.12], p = 0.015, etap2 = 0.05) but warm facial expressions did not increase treatment credibility (group difference = 0.64 − 0.75, 2.02], p = 0.363, etap2 = 0.01) or expectancy (group difference = 0.36 − 1.48, 2.20], p = 0.700, etap2 = 0.001). There were no significant interactions between head nods and facial expressions in the occurrence of therapeutic alliance (p = 0.403, etap2 = 0.01), credibility (p = 0.072, etap2 = 0.03), or expectancy (p = 0.275, etap2 = 0.01). Our results demonstrate that in the development of automated VR therapies there is likely to be therapeutic value in detailed consideration of the animations of virtual coaches.},
keywords={Sciences: Comprehensive Works; Fear; Expectancy; Computer applications; Automation; Credibility; Virtual reality},
language={English},
url={https://www.proquest.com/scholarly-journals/randomised-controlled-test-emotional-attributes/docview/2838513554/se-2},
}

@article{
author={Hutter,Daniel E. and Wingsted,Line and Cejvanovic,Sanja and Jacobsen,Mads F. and Ochoa,Luis and González Daher,Karla P. and la Cour,Morten and Konge,Lars and Thomsen,Ann S. S.},
year={2023},
month={2023},
title={A validated test has been developed for assessment of manual small incision cataract surgery skills using virtual reality simulation},
journal={Scientific Reports (Nature Publisher Group)},
volume={13},
number={1},
pages={10655},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-09-15},
abstract={This study investigates the validity evidence of metrics used for the assessment of surgical skills for Manual Small Incision Cataract Surgery (MSICS) in a virtual reality simulator. MSICS surgery is a low-cost, low-technology cataract surgery technique, which is widely used in low- and middle-income countries. However, there is a lack of cataract surgeons globally, and efficient and evidence-based training of new surgeons is needed. In order to investigate the validity of simulator metrics, we included three groups of participants: (1) MSICS novices who were ophthalmologists with no cataract surgery experience, (2) MSICS novices who were experienced phacoemulsification cataract surgeons, but with no MSICS experience, and (3) experienced phacoemulsification and MSICS surgeons. The evaluation included 11 steps of the MSICS procedure, and all simulator metrics for those steps were reviewed. Of the 55 initial metrics, 30 showed high positive discriminative ability. A test passing score of 20 out of 30 was established, and one of 15 novices with no MSICS experience (mean score 15.5) and 7 out of 10 experienced MSICS surgeons (mean score 22.7) passed the test. We have developed and established validity evidence for a test for MSICS skills in a virtual reality simulator for future use in proficiency-based training and evidence-based testing of training interventions.},
keywords={Sciences: Comprehensive Works; Training; Surgeons; Validity; Computer applications; Eye surgery; Virtual reality; Surgery; Cataracts},
language={English},
url={https://www.proquest.com/scholarly-journals/validated-test-has-been-developed-assessment/docview/2831683460/se-2},
}

@misc{
author={Mercier,J. and Chabloz,N. and Dozot,G. and Audrin,C. and Ertz,O. and Bocher,E. and Rappo,D.},
year={2023},
month={2023},
title={IMPACT OF GEOLOCATION DATA ON AUGMENTED REALITY USABILITY: A COMPARATIVE USER TEST},
journal={The International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences},
volume={XLVIII-4/W7-2023},
pages={133-140},
note={Copyright - © 2023. This work is published under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-06-22},
abstract={While the use of location-based augmented reality (AR) for education has demonstrated benefits on participants’ motivation, engagement, and on their physical activity, geolocation data inaccuracy causes augmented objects to jitter or drift, which is a factor in downgrading user experience. We developed a free and open source web AR application and conducted a comparative user test (n = 54) in order to assess the impact of geolocation data on usability, exploration, and focus. A control group explored biodiversity in nature using the system in combination with embedded GNSS data, and an experimental group used an external module for RTK data. During the test, eye tracking data, geolocated traces, and in-app user-triggered events were recorded. Participants answered usability questionnaires (SUS, UEQ, HARUS).We found that the geolocation data the RTK group was exposed to was less accurate in average than that of the control group. The RTK group reported lower usability scores on all scales, of which 5 out of 9 were significant, indicating that inaccurate data negatively predicts usability. The GNSS group walked more than the RTK group, indicating a partial effect on exploration. We found no significant effect on interaction time with the screen, indicating no specific relation between data accuracy and focus. While RTK data did not allow us to better the usability of location-based AR interfaces, results allow us to assess our system’s overall usability as excellent, and to define optimal operating conditions for future use with pupils.},
keywords={Geography; Biodiversity; Interfaces; Tracking; Augmented reality; User experience; Usability; User interfaces; Eye movements},
language={English},
url={https://www.proquest.com/conference-papers-proceedings/impact-geolocation-data-on-augmented-reality/docview/2828394926/se-2},
}

@article{
author={Maloca,Peter M. and Zarranz-Ventura,Javier and Valmaggia,Philippe and Faludi,Balázs and Zelechowski,Marek and Tufail,Adnan and Zentai,Norbert Z. and Scholl,Hendrik P. N. and Cattin,Philippe C.},
year={2023},
month={2023},
title={Validation of collaborative cyberspace virtual reality oculometry enhanced with near real-time spatial audio},
journal={Scientific Reports (Nature Publisher Group)},
volume={13},
number={1},
pages={10076},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-06-22},
abstract={Currently, most medical image data, such as optical coherence tomography (OCT) images, are displayed in two dimensions on a computer screen. Advances in computer information technology have contributed to the growing storage of these data in electronic form. However, the data are usually processed only locally on site. To overcome such hurdles, a cyberspace virtual reality (csVR) application was validated, in which interactive OCT data were presented simultaneously to geographically distant sites (Lucerne, London, and Barcelona) where three graders independently measured the ocular csVR OCT diameters. A total of 109 objects were measured, each three times, resulting in a total of 327 csVR measurements. A minor mean absolute difference of 5.3 µm was found among the 3 measurements of an object (standard deviation 4.2 µm, coefficient of variation 0.3% with respect to the mean object size). Despite the 5 h of online work, csVR was well tolerated and safe. Digital high-resolution OCT data can be remotely and collaboratively processed in csVR. With csVR, measurements and actions enhanced with spatial audio communication can be made consistently in near real time, even if the users are situated geographically far apart. The proposed visuo-auditory framework has the potential to further boost the convenience of digital medicine toward csVR precision and collaborative medicine.},
keywords={Sciences: Comprehensive Works; Computer applications; Collaboration; Virtual reality},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-collaborative-cyberspace-virtual/docview/2828067503/se-2},
}

@article{
author={Delgado-Rodríguez,Santiago and Carrascal Domínguez,Silvia and Garcia-Fandino,Rebeca},
year={2023},
month={2023},
title={Design, Development and Validation of an Educational Methodology Using Immersive Augmented Reality for STEAM Education},
journal={Journal of New Approaches in Educational Research},
volume={12},
number={1},
pages={19-39},
note={Last updated - 2024-04-20; SubjectsTermNotLitGenreText - 9809ER3 3581ER3 9766ER1 3567ER1; 3324ER3 10854ER3 3311ER1 10805ER1; 10280ER3 3205ER3 10236ER1 3192ER1; 633ER3 3205ER3 633ER1 3192ER1; 6006ER3 1734ER3 5981ER1 1733ER1; 9574ER3 9481ER3 2548ER3 9570ER3 9533ER1 9440ER1 2544ER1 9529ER1; 1007ER3 1006ER3 7097ER3 9507ER3 6069ER3 1007ER1 1006ER1 7065ER1 9466ER1 6042ER1; 4417ER3 3150ER3 8000ER3 7097ER3 9507ER3 6069ER3 4397ER1 3138ER1 7965ER1 7065ER1 9466ER1 6042ER1; 9575ER3 10457ER3 8149ER3 4625ER3 9534ER1 10411ER1 8114ER1 4605ER1; 11401ER3 3691ER3 2448ER3 10197ER3 11346ER1 3677ER1 2445ER1 10154ER1; 6000ER3 6945ER3 5975ER1 6915ER1; 10355ER3 740ER3 10309ER1 740ER1; 10860ER3 10811ER1; 10805ER3 3283ER3 6691ER3 10756ER1 3270ER1 6663ER1; 10691ER3 8402ER3 3205ER3 10642ER1 8365ER1 3192ER1; 11128ER3 11076ER1; 2805ER3 2799ER1; 4185ER3 4414ER3 4166ER1 4394ER1; Spain},
abstract={The main objective of this study is the design and validation of an educational methodological model based on the use of immersive technological resources (Augmented Reality -- AR) to improve learning processes in secondary education science subjects (Biology and Geology). The process was developed based on three main quantitative studies: an exploratory study, a study of performance divided into three cases studies, and an attitudinal study. The information obtained was completed with a fourth qualitative study of the training of teachers who participate in educational technology. This research provides empirical evidence that allows validation of the methodological model developed to explain key concepts and to improve the level of motivation and acceptance of AR technology by students. The proposed model can induce improvements in educational processes in the field of STEAM when used with an immersive AR technological resource and an adapted digital evaluation system. It also demonstrates that teachers require specific training in connection with the creation and the adequate use of AR educational resources, and of digital evaluation systems as well. The results of this study have important implications for the field of education, demonstrating the potential of AR technology to improve learning outcomes and the need for teacher training in its use.},
keywords={ERIC, Current Index to Journals in Education (CIJE); Secondary Education; Geology; Art Education; Student Attitudes; Simulated Environment; Biology; Learning Processes; Foreign Countries; STEM Education; Learning Motivation; Secondary School Students; Teacher Education; Spain; Training; Design; Validity; Secondary School Science; Educational Technology; Technology Uses in Education; Teaching Methods},
language={English},
url={https://www.proquest.com/scholarly-journals/design-development-validation-educational/docview/2821967040/se-2},
}

@article{
author={Muhammad Danish,Affan A. and Ismail,Ismahafezi and Nur Saadah,Mohd S. and Wan Mohd Amir Fazamin,Wan Hamzah and Maizan,Mat A. and Karim,Fazida},
year={2023},
month={2023},
title={Validate the Users’ Comfortable Level in the Virtual Reality Walkthrough Environment for Minimizing Motion Sickness},
journal={International Journal of Advanced Computer Science and Applications},
volume={14},
number={4},
note={Copyright - © 2023. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-27},
abstract={Motion sickness is a common scenario for users when they are exposed to a virtual reality (VR) environment. It is due to the conflict that occurs in the brain that tells the user that they are moving in the environment, but the fact is that the user’s body is sitting still causing them to get symptoms of motion sickness like nausea and dizziness. Therefore, motion sickness has become one of the main reasons why users still do not prefer to use VR to enhance their productivity. Motion sickness can be overcome by increasing the user's comfort level of walkthrough in the VR environment. Meanwhile, a popular VR simulation which is widely used in many industries is a walkthrough in a VR environment at a certain speed. This paper is focused on presenting the result of walkthroughs in a VR environment using movement speed and based on frame rates performance and adopting the unified theory of acceptance and use of technology (UTAUT) model construct variables namely performance expectancy (PE) and effort expectancy (EE) to measure the user’s comfort level. A mobile VR, ‘VR Terrain’ application software was developed based on the proposed framework. The application software was tested by 30 users by moving around in a VR environment with 4 different movement speeds that were implemented into four colored gates using a head-mounted display (HMD). A descriptive and coefficient analysis was used to analyze all the data. The blue gate revealed the most comfortable, outperforming all other three gates. Overall, the most suitable speed to use for VR walkthrough is 4.0 km/h. The experiment result may be used to create a parameter for the VR developers to reduce the VR motion sickness effect in the future.},
keywords={Sciences: Comprehensive Works; Virtual reality; motion sickness; head-mounted display; head lean movement; mobile VR; walkthrough technique; UTAUT; frame rate; Software; Helmet mounted displays; Movement},
isbn={2158107X},
language={English},
url={https://www.proquest.com/scholarly-journals/validate-users-comfortable-level-virtual-reality/docview/2819915820/se-2},
}

@article{
author={Maksoud,Aref and Hussien,Aseel and Mushtaha,Emad and Abdul-Rahman Alawneh,Sarah I.},
year={2023},
month={2023},
title={Computational Design and Virtual Reality Tools as an Effective Approach for Designing Optimization, Enhancement, and Validation of Islamic Parametric Elevation},
journal={Buildings},
volume={13},
number={5},
pages={1204},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-08-24},
abstract={Virtual reality was investigated with various computational design approaches to improve users’ ability to communicate, share, and grasp the design’s requirements to better conceptualize ideas during various design and review stages. The study aims to show how computational design and virtual reality are utilized to forecast challenges, address design problems/limitations in a specific study space, and validate results. A case study of the main Architectural Engineering department building at the University of Sharjah (UoS) campus in Sharjah, United Arab Emirates, was considered. The study focused on indoor daylight intake, ventilation, functionality, user comfortability, structural integrity, coherency and consistency, and performance optimization as factors to further evaluate and aid in the selection process of the optimal design. Consequently, innovative computational design tools were used in the study’s methodology to assess offered alternatives, such as altering and fabricating the building’s skin to deal with the challenges described above and improving the selected room’s visual and environmental conditions, such as optimal daylighting and ensuring users’ comfortability. The users’ immersive experience resulted in more accurate visualization and navigation around the to-be-built environment, allowing for more significant analysis and comprehension that further validated the results obtained. The chosen case study thus demonstrated the potential for computational design, mixed reality techniques, and strategies to enable an efficient process that ultimately verifies approaches taken toward a much more optimal solution through better visualization and contextualizing.},
keywords={Building And Construction; computational design; energy performance; visual comfort; virtual reality; lighting design optimization; grasshopper; Construction; Case studies; Collaboration; Optimization; Structural integrity; Sustainability; Environmental conditions; Design; Architecture; Computer applications; Visualization; Urban environments; Mixed reality; Software; Daylight},
language={English},
url={https://www.proquest.com/scholarly-journals/computational-design-virtual-reality-tools-as/docview/2819413204/se-2},
}

@article{
author={Campo-Prieto,Pablo and José Mª Cancela-Carral and Rodríguez-Fuentes,Gustavo},
year={2023},
month={2023},
title={Immersive Virtual Reality Reaction Time Test and Relationship with the Risk of Falling in Parkinson’s Disease},
journal={Sensors},
volume={23},
number={9},
pages={4529},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-04},
abstract={Immersive virtual reality (IVR) uses customized and advanced software and hardware to create a digital 3D reality in which all of the user’s senses are stimulated with computer-generated sensations and feedback. This technology is a promising tool that has already proven useful in Parkinson’s disease (PD). The risk of falls is very high in people with PD, and reaction times and processing speed may be markers of postural instability and functionality, cognitive impairment and disease progression. An exploratory study was conducted to explore the feasibility of reaction time tests performed in IVR as predictors of falls. A total of 26 volunteers (79.2% male; 69.73 ± 6.32 years) diagnosed with PD (1.54 ± 0.90 H&Y stage; 26.92 ± 2.64 MMSE) took part in the study. IVR intervention was feasible, with no adverse effects (no Simulator Sickness Questionnaire symptoms). IVR reaction times were related (Spearman’s rho) to functionality (timed up and go test (TUG) (rho = 0.537, p = 0.005); TUG-Cognitive (rho = 0.576, p = 0.020); cognitive impairment mini mental state exam (MMSE) (rho = −0.576, p = 0.002)) and the years of the patients (rho = 0.399, p = 0.043) but not with the first PD symptom or disease stage. IVR test is a complementary assessment tool that may contribute to preventing falls in the proposed sample. Additionally, based on the relationship between TUG and reaction times, a cut-off time is suggested that would be effective at predicting the risk of suffering a fall in PD patients using a simple and quick IVR test.},
keywords={Chemistry--Analytical Chemistry; virtual reality exposure therapy; Parkinson's disease; Timed Up and Go test; Mental chronometry; Autumn; Immersion; Virtual reality; digital health; Parkinson’s disease; reaction time; falls; videogames; physical activity; measurement of movement; rehabilitation; games for health; Software; Older people; Risk; Signs and symptoms; Immersive virtual reality; Feasibility studies; Impairment; Exercise},
language={English},
url={https://www.proquest.com/scholarly-journals/immersive-virtual-reality-reaction-time-test/docview/2812737457/se-2},
}

@article{
author={Faity,Germain and Sidahmed,Yasmine and Laffont,Isabelle and Froger,Jé},
year={2023},
month={2023},
title={Quantification and Rehabilitation of Unilateral Spatial Neglect in Immersive Virtual Reality: A Validation Study in Healthy Subjects},
journal={Sensors},
volume={23},
number={7},
pages={3481},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-23},
abstract={Unilateral spatial neglect is a common sensorimotor disorder following the occurrence of a stroke, for which prismatic adaptation is a promising rehabilitation method. However, the use of prisms for rehabilitation often requires the use of specific equipment that may not be available in clinics. To address this limitation, we developed a new software package that allows for the quantification and rehabilitation of unilateral spatial neglect using immersive virtual reality. In this study, we compared the effects of virtual and real prisms in healthy subjects and evaluated the performance of our virtual reality tool (HTC Vive) against a validated motion capture tool. Ten healthy subjects were randomly exposed to virtual and real prisms, and measurements were taken before and after exposure. Our findings indicate that virtual prisms are at least as effective as real prisms in inducing aftereffects (4.39° ± 2.91° with the virtual prisms compared to 4.30° ± 3.49° with the real prisms), but that these effects were not sustained beyond 2 h regardless of exposure modality. The virtual measurements obtained with our software showed excellent metrological qualities (ICC = 0.95, error = 0.52° ± 1.18°), demonstrating its validity and reliability for quantifying deviation during pointing movements. Overall, our results suggest that our virtual reality software (Virtualis, Montpellier, France) could provide an easy and reliable means of quantifying and rehabilitating spatial neglect. Further validation of these results is required in individuals with unilateral spatial neglect.},
keywords={Chemistry--Analytical Chemistry; stroke rehabilitation; Stroke; Hemispatial neglect; Rehabilitation; Immersion; Virtual reality; unilateral spatial neglect; prism adaptation; subjective straight ahead; visual open-loop; pointing; serious game; HTC Vive; mocap; Prisms; Software packages; Immersive virtual reality; Exposure; Motion capture; Computer & video games; Educational software},
language={English},
url={https://www.proquest.com/scholarly-journals/quantification-rehabilitation-unilateral-spatial/docview/2799788723/se-2},
}

@article{
author={Tang,Yingying and Chen,Yuling and Luo,Yun and Sen,Dong and Li,Tao},
year={2023},
month={2023},
title={VR-PEKS: A Verifiable and Resistant to Keyword Guess Attack Public Key Encryption with Keyword Search Scheme},
journal={Applied Sciences},
volume={13},
number={7},
pages={4166},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-19},
abstract={Public key encryption with keyword search (PEKS) allows users to perform keyword searches of ciphertext on untrusted cloud storage servers, protecting data privacy while sharing data. However, it faces several security problems in practical applications. First, an attacker can launch a keyword guessing attack to obtain keywords of interest to users, causing the leakage of their sensitive information. Second, untrusted cloud servers may return incorrect or incomplete results. In addition, with the continuous development of quantum computers, existing PEKS schemes face the problem of quantum attacks. Since cloud servers are mostly untrusted, verifiable search has become a hot research topic among scholars. However, most of the current schemes are based on bilinear pairing constructions, which are vulnerable to quantum attacks. To solve these problems, we propose a new ciphertext retrieval scheme based on fully homomorphic encryption (FHE), called VR-PEKS. This scheme implements verifiable search and is able to solve the problems of keyword guessing attacks and quantum attacks. We propose to improve the security of the scheme by using the oblivious pseudorandom function to randomize keywords and then encrypt them using FHE. An encrypted verified index structure is constructed and exposed by the data owner, enabling the data recipient to achieve verification of the correctness and integrity of the retrieved results without relying on a trusted third party. We demonstrate the security of the proposed scheme in a stochastic prediction model, and prove that our scheme satisfies keyword ciphertext indistinguishability and keyword trapdoor indistinguishability under adaptive keyword selection attacks. The comparison shows that our scheme is secure and feasible.},
keywords={Sciences: Comprehensive Works; cloud storage; public key encryption with keyword search; fully homomorphic encryption; keyword guess attack; verifiable; Encryption; Homomorphic encryption; Public-key cryptography; Hospitals; Medical records; Information sharing; Privacy; Keywords; Servers},
language={English},
url={https://www.proquest.com/scholarly-journals/vr-peks-verifiable-resistant-keyword-guess-attack/docview/2799592277/se-2},
}

@article{
author={Guzsvinecz,Tibor and Perge,Erika and Szűcs,Judit},
year={2023},
month={2023},
title={Examining the Results of Virtual Reality-Based Egocentric Distance Estimation Tests Based on Immersion Level},
journal={Sensors},
volume={23},
number={6},
pages={3138},
note={Name - Samsung Electronics Co Ltd; Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-04},
abstract={Depth perception as well as egocentric distance estimation can be trained in virtual spaces, although incorrect estimates can occur in these environments. To understand this phenomenon, a virtual environment with 11 changeable factors was created. Egocentric distance estimation skills of 239 participants were assessed with it in the range 25 cm, 160 cm]. One hundred fifty-seven people used a desktop display and seventy-two the Gear VR. According to the results, these investigated factors can have various effects combined with the two display devices on distance estimation and its time. Overall, desktop display users are more likely to accurately estimate or overestimate distances, and significant overestimations occur at 130 and 160 cm. With the Gear VR, distances in the range 40 cm, 130 cm] are significantly underestimated, while at 25 cm, they are significantly overestimated. Estimation times are significantly decreased with the Gear VR. When developing future virtual environments that require depth perception skills, developers should take these results into account.},
keywords={Chemistry--Analytical Chemistry; desktop display; Virtual environment; Gear; Virtual reality; Depth perception; egocentric distance estimation; Gear VR; head-mounted display; human–computer interaction; immersion; Investigations; Display devices; Space perception; Estimates; Keyboards; Skills; Virtual environments},
language={English},
url={https://www.proquest.com/scholarly-journals/examining-results-virtual-reality-based/docview/2791721803/se-2},
}

@article{
author={Loetscher,Tobias and Nadia,Siena J. and Michalski,Stefan C. and Billinghurst,Mark and Lee,Gun},
year={2023},
month={2023},
title={Online Platforms for Remote Immersive Virtual Reality Testing: An Emerging Tool for Experimental Behavioral Research},
journal={Multimodal Technologies and Interaction},
volume={7},
number={3},
pages={32},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-30},
abstract={Virtual Reality (VR) technology is gaining in popularity as a research tool for studying human behavior. However, the use of VR technology for remote testing is still an emerging field. This study aimed to evaluate the feasibility of conducting remote VR behavioral experiments that require millisecond timing. Participants were recruited via an online crowdsourcing platform and accessed a task on the classic cognitive phenomenon “Inhibition of Return” through a web browser using their own VR headset or desktop computer (68 participants in each group). The results confirm previous research that remote participants using desktop computers can be used effectively for conducting time-critical cognitive experiments. However, inhibition of return was only partially replicated for the VR headset group. Exploratory analyses revealed that technical factors, such as headset type, were likely to significantly impact variability and must be mitigated to obtain accurate results. This study demonstrates the potential for remote VR testing to broaden the research scope and reach a larger participant population. Crowdsourcing services appear to be an efficient and effective way to recruit participants for remote behavioral testing using high-end VR headsets.},
keywords={Computers--Cybernetics; crowdsourcing; Inhibition of return; Reality testing; Immersion; Virtual reality; online testing; reaction time; Prolific; Research; Behavior; Data collection; Headsets; Personal computers; Experiments; Immersive virtual reality; Consent; Inhibition (psychology)},
language={English},
url={https://www.proquest.com/scholarly-journals/online-platforms-remote-immersive-virtual-reality/docview/2791673654/se-2},
}

@article{
author={Gorash,Yevgen and Comlekci,Tugrul and Styger,Gary and Kelly,James and Brownlie,Frazer and Milne,Lewis},
year={2023},
month={2023},
title={Ultrasonic Fatigue Testing of Structural Steel S275JR+AR with Insights into Corrosion, Mean Stress and Frequency Effects},
journal={Materials},
volume={16},
number={5},
pages={1799},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-03-10},
abstract={There are limited experimental data on VHCF for structural steels for >107 cycles. Unalloyed low-carbon steel S275JR+AR is a common structural material for the heavy machinery in minerals, sand and aggregate applications. The purpose of this research is to investigate the fatigue behaviour in the gigacycle domain (>109 cycles) for S275JR+AR grade steel. This is achieved using accelerated ultrasonic fatigue testing in as-manufactured, pre-corroded and non-zero mean stress conditions. As internal heat generation is a massive challenge for ultrasonic fatigue testing of structural steels which exhibit a pronounced frequency effect, effective temperature control is crucial for implementation of testing. The frequency effect is assessed by comparing the test data at 20 kHz and 15–20 Hz. Its contribution is significant, as there is no overlap between the stress ranges of interest. The obtained data are intended to be applied to the fatigue assessments of the equipment operating at the frequency for up to 1010 cycles over years of continuous service.},
keywords={Engineering--Civil Engineering; structural steel; very high cycle fatigue; ultrasonic fatigue; corrosion; frequency effect; mean stress correction; Corrosion effects; Ultrasonic testing; Metal fatigue; Low carbon steels; Heat generation; Yield stress; Structural steels; Temperature control; Crack initiation; Accelerated tests; Design; Fatigue tests; Corrosion fatigue; Steel; Crack propagation},
language={English},
url={https://www.proquest.com/scholarly-journals/ultrasonic-fatigue-testing-structural-steel/docview/2785231150/se-2},
}

@article{
author={Veiga-Canuto,Diana and Cerdà-Alberich,Leonor and Jiménez-Pastor,Ana and José Miguel,Carot S. and Gomis-Maya,Armando and Sangüesa-Nebot,Cinta and Fernández-Patón,Matías and Blanca Martínez de,las H. and Taschner-Mandl,Sabine and Düster,Vanessa and Pötschger,Ulrike and Simon,Thorsten and Neri,Emanuele and Alberich-Bayarri,Ángel and Cañete,Adela and Hero,Barbara and Ladenstein,Ruth and Martí-Bonmatí,Luis},
year={2023},
month={2023},
title={Independent Validation of a Deep Learning nnU-Net Tool for Neuroblastoma Detection and Segmentation in MR Images},
journal={Cancers},
volume={15},
number={5},
pages={1622},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-22; SubjectsTermNotLitGenreText - Spain},
abstract={Simple SummaryTumor segmentation is a key step in oncologic imaging processing. We have recently developed a model to detect and segment neuroblastic tumors on MR images based on deep learning architecture nnU-Net. In this work, we performed an independent validation of the automatic segmentation tool with a large heterogeneous dataset. We reviewed the automatic segmentations and manually edited them when necessary. We were able to show that the automatic network was able to locate and segment the primary tumor on the T2 weighted images in the majority of cases, with an extremely high agreement between the automatic tool and the manually edited masks. The time needed for manual adjustment was very low.AbstractObjectives. To externally validate and assess the accuracy of a previously trained fully automatic nnU-Net CNN algorithm to identify and segment primary neuroblastoma tumors in MR images in a large children cohort. Methods. An international multicenter, multivendor imaging repository of patients with neuroblastic tumors was used to validate the performance of a trained Machine Learning (ML) tool to identify and delineate primary neuroblastoma tumors. The dataset was heterogeneous and completely independent from the one used to train and tune the model, consisting of 300 children with neuroblastic tumors having 535 MR T2-weighted sequences (486 sequences at diagnosis and 49 after finalization of the first phase of chemotherapy). The automatic segmentation algorithm was based on a nnU-Net architecture developed within the PRIMAGE project. For comparison, the segmentation masks were manually edited by an expert radiologist, and the time for the manual editing was recorded. Different overlaps and spatial metrics were calculated to compare both masks. Results. The median Dice Similarity Coefficient (DSC) was high 0.997; 0.944–1.000 (median; Q1–Q3). In 18 MR sequences (6%), the net was not able neither to identify nor segment the tumor. No differences were found regarding the MR magnetic field, type of T2 sequence, or tumor location. No significant differences in the performance of the net were found in patients with an MR performed after chemotherapy. The time for visual inspection of the generated masks was 7.9 ± 7.5 (mean ± Standard Deviation (SD)) seconds. Those cases where manual editing was needed (136 masks) required 124 ± 120 s. Conclusions. The automatic CNN was able to locate and segment the primary tumor on the T2-weighted images in 94% of cases. There was an extremely high agreement between the automatic tool and the manually edited masks. This is the first study to validate an automatic segmentation model for neuroblastic tumor identification and segmentation with body MR images. The semi-automatic approach with minor manual editing of the deep learning segmentation increases the radiologist’s confidence in the solution with a minor workload for the radiologist.},
keywords={Medical Sciences--Oncology; tumor segmentation; Machine learning; Neuroblastoma; Deep learning; Neurodegenerative disease; independent validation; external validation; neuroblastic tumors; automatic segmentation; Cancer; Datasets; Artificial intelligence; Algorithms; Segmentation; Neural networks; Medical research; Biomarkers; Tumors; Image processing; Chemotherapy; Performance evaluation; Feasibility studies; Pediatrics; Reproducibility; Spain},
language={English},
url={https://www.proquest.com/scholarly-journals/independent-validation-deep-learning-nnu-net-tool/docview/2785176591/se-2},
}

@article{
author={Malhotra,Shivali and Halabi,Osama and Sarada,Prasad D. and Padhan,Jhasketan and Santu,Paul and Palliyali,Waseem},
year={2023},
month={2023},
title={Augmented Reality in Surgical Navigation: A Review of Evaluation and Validation Metrics},
journal={Applied Sciences},
volume={13},
number={3},
pages={1629},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-19},
abstract={Pre-operative imaging has been used earlier to guide traditional surgical navigation systems. There has been a lot of effort in the last decade to integrate augmented reality into the operating room to help surgeons intra-operatively. An augmented reality (AR) based navigation system provides a clear three-dimensional picture of the interested areas over the patient to aid surgical navigation and operations, which is a promising approach. The goal of this study is to review the application of AR technology in various fields of surgery and how the technology is used for its performance in each field. Assessment of the available AR assisted navigation systems being used for surgery is reviewed in this paper. Furthermore, a discussion about the required evaluation and validation metric for these systems is also presented. The paper comprehensively reviews the literature since the year 2008 for providing relevant information on applying the AR technology for training, planning and surgical navigation. It also describes the limitations which need to be addressed before one can completely rely on this technology for surgery. Thus, additional research is desirable in this emerging field, particularly to evaluate and validate the use of AR technology for surgical navigation.},
keywords={Sciences: Comprehensive Works; augmented reality; surgery; visualization; evaluation; validation; Navigation; Computer-assisted surgery; Navigation systems; Usability; Trauma; Bone surgery; Technology; Planning; Magnetic resonance imaging; Neurosurgery; Surgical techniques; Three dimensional imaging; Registration; Orthopedics; Medical imaging; Back surgery; Virtual reality; Cognition & reasoning; Clinical outcomes; Interfaces},
language={English},
url={https://www.proquest.com/scholarly-journals/augmented-reality-surgical-navigation-review/docview/2779899590/se-2},
}

@article{
author={Fratini,Elena and Welsh,Ruth and Thomas,Pete},
year={2023},
month={2023},
title={Ranking Crossing Scenario Complexity for eHMIs Testing: A Virtual Reality Study},
journal={Multimodal Technologies and Interaction},
volume={7},
number={2},
pages={16},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-30},
abstract={External human–machine interfaces (eHMIs) have the potential to benefit AV–pedestrian interactions. The majority of studies investigating eHMIs have used relatively simple traffic environments, i.e., a single pedestrian crossing in front of a single eHMI on a one-lane straight road. While this approach has proved to be efficient in providing an initial understanding of how pedestrians respond to eHMIs, it over-simplifies interactions which will be substantially more complex in real-life circumstances. A process is illustrated in a small-scale study (N = 10) to rank different crossing scenarios by level of complexity. Traffic scenarios were first developed for varying traffic density, visual complexity of the road scene, road geometry, weather and visibility conditions, and presence of distractions. These factors have been previously shown to increase difficulty and riskiness of the crossing task. The scenarios were then tested in a motion-based, virtual reality environment. Pedestrians’ perceived workload and objective crossing behaviour were measured as indirect indicators of the level of complexity of the crossing scenario. Sense of presence and simulator sickness were also recorded as a measure of the ecological validity of the virtual environment. The results indicated that some crossing scenarios were more taxing for pedestrians than others, such as those with road geometries where traffic approached from multiple directions. Further, the presence scores showed that the virtual environments experienced were found to be realistic. This paper concludes by proposing a “complex” environment to test eHMIs under more challenging crossing circumstances.},
keywords={Computers--Cybernetics; external human-machine interface; Simulator sickness; Virtual reality; User interface; eHMI; autonomous vehicles; head-mounted display; pedestrian behaviour; road safety; pedestrian–vehicle interaction; traffic interaction; workload (SIM-TLX); Fatalities; Traffic volume; Pedestrian crossings; Complexity; Pedestrians; Ecological effects; Decision making; Virtual environments},
language={English},
url={https://www.proquest.com/scholarly-journals/ranking-crossing-scenario-complexity-ehmis/docview/2779630214/se-2},
}

@article{
author={Eagleson,Roy and Joskowicz,Leo},
year={2023},
month={2023},
title={Verification, Evaluation, and Validation: Which, How & Why, in Medical Augmented Reality System Design},
journal={Journal of Imaging},
volume={9},
number={2},
pages={20},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-27},
abstract={This paper presents a discussion about the fundamental principles of Analysis of Augmented and Virtual Reality (AR/VR) Systems for Medical Imaging and Computer-Assisted Interventions. The three key concepts of Analysis (Verification, Evaluation, and Validation) are introduced, illustrated with examples of systems using AR/VR, and defined. The concepts of system specifications, measurement accuracy, uncertainty, and observer variability are defined and related to the analysis principles. The concepts are illustrated with examples of AR/VR working systems.},
keywords={Photography; system analysis; Verification; Medical imaging; Reality; Computer-assisted interventions; Evaluation; Validation; Virtual reality; Augmented reality; medical augmented reality; uncertainty; observer variability; measurements accuracy; Accuracy; Validity; Systems design; Design engineering; Design; Cognitive ability; Back surgery; Reproducibility; Cognition & reasoning; Principles},
language={English},
url={https://www.proquest.com/scholarly-journals/verification-evaluation-validation-which-how-amp/docview/2779555958/se-2},
}

@article{
author={Fekih-Romdhane,Feten and Merhy,Georges and Moubarak,Verginia and He,Jinbo and Rogoza,Radoslaw and Hallit,Rabih and Obeid,Sahar and Hallit,Souheil},
year={2023},
month={2023},
title={Validation of the Arabic version of the Muscle Dysmorphic Disorder Inventory (Ar-MDDI) among Lebanese male university students},
journal={Journal of Eating Disorders},
volume={11},
pages={1-10},
note={Copyright - © 2023. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-26; SubjectsTermNotLitGenreText - Lebanon},
abstract={BackgroundTo date, the vast majority of research on disordered eating symptomatology and body image disturbances from the Arab world have been performed exclusively among women; and mainly used thinness-oriented measures that are not sensitive to detect muscularity-oriented symptoms, which are more evident in males. Therefore, the objective of our study was to validate the Arabic version of the Muscle Dysmorphic Disorder Inventory (Ar-MDDI), in order to make it accessible for Arabic-speaking populations.MethodsUsing a snowball sampling technique, men university students (n = 396) from multiple universities in Lebanon filled the survey in this cross-sectional designed study (January–May 2022). A soft copy of the questionnaire was created using google forms software, and sent to participants through the different social media platforms such as Facebook, Instagram, and WhatsApp. We used the Muscle Dysmorphic Disorder Inventory to assess Muscle Dysmorphia, along with the Big Three Perfectionism Scale to assess perfectionism and Eating Attitude Test (EAT) to evaluate the inappropriate eating attitudes. To explore the factor structure of Ar-MDDI, we computed a principal-axis Exploratory Factor Analysis (EFA) with the first split-half subsample using the FACTOR software. We used data from the second split-half to conduct a Confirmatory Factor Analysis (CFA) using the SPSS AMOS v.29 software. Pearson correlation test was used to test the convergent and divergent validity of the Ar-MDDI scale with the other scores included in the study.ResultsThe results of the EFA revealed three factors, which explained 57.68% of the common variance: Factor 1 = Appearance intolerance, Factor 2 = Drive for size, and Factor 3 = Functional impairment. The CFA fit indices of the three-factor model of the Ar-MDDI scale showed good results. Moreover, 254 (64.1%) of the participants had inappropriate eating attitudes (EAT scores ≥ 20). Indices suggested that configural, metric, and scalar invariance was supported according to eating attitudes. No significant difference between participants with appropriate versus inappropriate eating attitudes in terms of functional impairment, drive for size and appearance intolerance. Perfectionism scores correlated positively with the Ar-MDDI, which suggests divergent validity.ConclusionOur findings revealed that the validation of the Arabic scale yielded excellent properties, preliminarily supporting its use for the assessment of muscle dysmorphia among Arabic-speaking university men. This would hopefully allow for its timely detection and management in Arab clinical settings and encourage cross-cultural research on this topic.},
keywords={Psychology; Muscle dysmorphia; Skeletal muscle; Dysmorphic; Eating Attitudes Test; Fatigue; Arabic; Disordered eating; Confirmatory factor analysis; Validity; Validation; Factor analysis; Quantitative research; Surveys & questionnaires; Qualitative research; Cross-cultural research; Research; Arabic language; Self image; Data collection; University students; Eating behavior; Eating disorders; Social networks; Body image; Questionnaires; Lebanon},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-arabic-version-muscle-dysmorphic/docview/2777784984/se-2},
}

@article{
author={Charlery-Adèle,Ambre and Guigou,Caroline and Ryard,Julien and Chartier,Mathis and Toupet,Michel and Guillet,Christophe and Mérienne,Férédric and Bozorg Grayeli,Alexis},
year={2023},
month={2023},
title={Effects of saccade delay, side of deficit, and training on detection of catch-up saccades during head-impulse test in virtual-reality-enhanced mannequin},
journal={Scientific Reports (Nature Publisher Group)},
volume={13},
number={1},
pages={2718},
note={Copyright - © The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-04},
abstract={In this study, a training simulator for the examination of dizzy patients based on a virtual-reality-enhanced mannequin (VREM) was developed to evaluate the detection of catch-up saccades during head impulse test (HIT) and the effect of training in VREM. For novices (n = 35), 2 trials were conducted before and after a training session. Experts (n = 7) were submitted to an evaluation session. In each trial, a left or a right horizontal canal deficit with an overt catch-up saccade (delay between 110 and 320 ms) was randomly presented. Participants scored the difficulty in performing the maneuver, in recognizing the saccades, and the self-confidence in the diagnosis using a visual analogue scale (VAS). Saccade delay significantly influenced the performance. Training significantly improved the sensitivity in the residents (69.1% before to 97.9% after the training, p < 0.001, Fisher's exact test, n = 560 tests), surpassing experts’ performances (p < 0.001, versus 87% in experts, Fisher's exact test). The specificity also increased to the expert level (78% before to 95% after the training, and 95% in experts, p < 0.001, Fisher’s exact test). The VAS showed a decrease difficulty to execute the HIT, with an increase in the confidence after training. VREM improved the HIT execution performance and the confidence in novice practitioners.},
keywords={Sciences: Comprehensive Works; Saccade; Virtual reality; Dizziness; Training; Clinical trials; Confidence; Saccadic eye movements},
language={English},
url={https://www.proquest.com/scholarly-journals/effects-saccade-delay-side-deficit-training-on/docview/2776897684/se-2},
}

@article{
author={Afrashtehfar,Kelvin I. and Jing-Wen,Yang and Al-Sammarraie,A. and Chen,Hui and Saeed,Musab H.},
year={2023},
month={2023},
title={Pre-clinical undergraduate students’ perspectives on the adoption of virtual and augmented reality to their dental learning experience: A one-group pre- and post-test design protocol},
journal={F1000Research},
volume={10},
note={Copyright - Copyright: © 2023 Afrashtehfar KI et al. This work is published under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-24},
abstract={Background: We live in a time where traditional education has rapidly incorporated online modalities due to the recent SARS-CoV-2 (COVID-19) safety measures such as social distancing. Regardless of these challenges, health education constantly strives to implement the best technologies available for an effective student deep learning outcome. Virtual (VR) and augmented reality (AR) in the dental pre-clinical stage may help stimulate students to better understand the foundation material prescribed in the curriculum. Most visual material available for students is still mainly based on 2D graphics. Thus, this study will attempt to evaluate the students' perceptions about implementing VR/AR technologies in the learning setting. Methods: A single-group pretest-posttest design will be implemented where students will be exposed to VR/AR and fill out two questionnaires, one before and one after the exposure. Conclusions: This project is intended to start once the institutional ethical approval is obtained. It is expected that the analysis from the current project will provide recommendations to improve the students' academic curriculum pre-clinical experience. The recommendations will be provided in the form of at least three scientific publications, with one publication for each subject area intended to be evaluated (i.e., head and neck anatomy, dental anatomy, and removable prosthodontics).},
keywords={Medical Sciences; Augmented Reality; Dentistry; Undergraduate education; Virtual reality; Curriculum; Dental Students; Health Education; Immersion; Learning; Perception; Prosthodontics; Research; Software; Perceptions; Neck; Anatomy; School environment; Questionnaires; College students; Severe acute respiratory syndrome coronavirus 2; Data collection; Data analysis; COVID-19; Core curriculum; Deep learning; Dental prosthetics; Consent},
language={English},
url={https://www.proquest.com/scholarly-journals/pre-clinical-undergraduate-students-perspectives/docview/2771303786/se-2},
}

@article{
author={Alnahdi,Ghaleb H. and Alwadei,Arwa},
year={2023},
month={2023},
title={Validation of the Arabic Version of the Transition Planning Inventory (TPI-AR)},
journal={International Journal of Environmental Research and Public Health},
volume={20},
number={2},
pages={1135},
note={Copyright - © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-25; SubjectsTermNotLitGenreText - Saudi Arabia},
abstract={The Transition Planning Inventory (TPI) is an important tool for planning the transition to life after school for students with disabilities. While interest in transition services has increased in the last decade in the Arab region, no transition assessment tools validated for the Arab population are currently available. This study is the first to validate an Arabic version (TPI-AR) for all three rating forms (student, home, and school) and examine its psychometric properties. The sample comprised 203 students with disabilities, a member of their family, and one of their teachers. The 11 subscales of TPI-AR for all three forms were found reliable and valid to be used with students with disabilities in Saudi Arabia, particularly in middle and high schools.},
keywords={Sciences: Comprehensive Works; transition planning inventory; Planning; Transition; Validation; arabic TPI; psychometric properties; students with disabilities; transition planning; confirmatory factor analysis; Arabic language; Students; Validity; Quantitative psychology; Families & family life; Special education; Translations; Schools; Bilingualism; Learning; People with disabilities; Saudi Arabia},
isbn={1661-7827},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-arabic-version-transition-planning/docview/2767225381/se-2},
}

@article{
author={Navab,Nassir and Martin-Gomez,Alejandro and Seibold,Matthias and Sommersperger,Michael and Song,Tianyu and Winkler,Alexander and Yu,Kevin and Eck,Ulrich},
year={2023},
month={2023},
title={Medical Augmented Reality: Definition, Principle Components, Domain Modeling, and Design-Development-Validation Process},
journal={Journal of Imaging},
volume={9},
number={1},
pages={4},
note={Copyright - © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-27},
abstract={Three decades after the first set of work on Medical Augmented Reality (MAR) was presented to the international community, and ten years after the deployment of the first MAR solutions into operating rooms, its exact definition, basic components, systematic design, and validation still lack a detailed discussion. This paper defines the basic components of any Augmented Reality (AR) solution and extends them to exemplary Medical Augmented Reality Systems (MARS). We use some of the original MARS applications developed at the Chair for Computer Aided Medical Procedures and deployed into medical schools for teaching anatomy and into operating rooms for telemedicine and surgical guidance throughout the last decades to identify the corresponding basic components. In this regard, the paper is not discussing all past or existing solutions but only aims at defining the principle components and discussing the particular domain modeling for MAR and its design-development-validation process, and providing exemplary cases through the past in-house developments of such solutions.},
keywords={Photography; Augmented Reality; Reality; Augment; Medical education; Medical Augmented Reality; surgical data science; Artificial Intelligence; multi-modal sensing; computer vision; acoustic sensing; perceptual visualization; sonification; validation; Design; Ethics; Modelling; Domains; Ultrasonic imaging; Principles; Data science},
language={English},
url={https://www.proquest.com/scholarly-journals/medical-augmented-reality-definition-principle/docview/2767223766/se-2},
}

@article{
author={Mayer,Gwendolyn and Gronewold,Nadine and Polte,Kirsten and Hummel,Svenja and Barniske,Joshua and Korbel,Jakob J. and Zarnekow,Rü and Schultz,Jobst-Hendrik},
year={2022/12//},
month={Dec 2022},
title={Experiences of Patients and Therapists Testing a Virtual Reality Exposure App for Symptoms of Claustrophobia: Mixed Methods Study},
journal={JMIR Mental Health},
volume={9},
number={12},
note={Copyright - © 2022. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-20},
abstract={Background: The effectiveness of virtual reality exposure (VRE) in the treatment of anxiety disorders is well established. Several psychological mechanisms of VRE have been identified, whereby both emotional processing and the sense of presence play a key role. However, there are only few studies that contribute to our knowledge of examples of implementation in the case of VRE for claustrophobia based on patients' experiences and the perspective of therapists. Objective: This study asks for key elements of a VRE app that are necessary for effective exposure for people with claustrophobic symptoms. Methods: A mixed methods design was applied in which patients (n=15) and therapeutic experts (n=15) tested a VRE intervention of an elevator ride at 5 intensity levels. Intensity was varied by elevator size, duration of the elevator ride, and presence of virtual humans. Quantitative measures examined self-reported presence with the Igroup Presence Questionnaire (IPQ) ranging from 0 to 6 and 15 Likert-scaled evaluation items that had been developed for the purpose of this study, ranging from 1 to 5. In both measures, higher scores indicate higher levels of presence or agreement. Think-aloud protocols of the patients and semistructured interviews posttreatment of all participants were conducted to gain in-depth perspectives on emotional processes. Results: The intervention induced a feeling of presence in patients and experts, posttreatment scores showed a high IPQ presence score (mean 3.84, SD 0.88), with its subscores IPQ spatial presence (mean 4.53, SD 1.06), IPQ involvement (mean 3.83, SD 1.22), and IPQ experienced realism (mean 2.75, SD 1.02). Patients preferred a setting in the presence of a therapist (mean 4.13, SD 0.83) more than the experts did (mean 3.33, SD 1.54). Think-aloud protocols of the patients revealed that presence and anxiety both were achieved. Qualitative interviews of patients and experts uncovered 8 topics: feelings and emotions, personal story, telepresence, potential therapeutic effects, barriers, conditions and requirements, future prospects, and realization. The intensity levels were felt to appropriately increase in challenge, with ambivalent results regarding the final level. Virtual humans contributed to feelings of fear. Conclusions: Key elements of a VRE app for claustrophobic symptoms should include variation of intensity by adding challenging cues in order to evoke presence and anxiety. Virtual humans are a suitable possibility to make the intervention realistic and to provide a sense of closeness; however, some of the fears might then be related to symptoms of social phobia or agoraphobia. Patients may need the physical presence of a therapist, though not all of them share this view. A higher degree of sophistication in the intensity levels is needed to deliver targeted help for specific symptoms of anxiety.},
keywords={Medical Sciences--Psychiatry And Neurology; virtual reality; Claustrophobia; Anxiety; Presence; Anxiety disorder; Multimethodology; Therapy; Intervention; exposure therapy; anxiety disorders; think-aloud; mixed methods; virtual reality exposure therapy; VR; mental health; user experience; perspective; Quantitative research; Surveys & questionnaires; Qualitative research; Self report; Interviews; Mixed-methods; Comorbidity; Fear & phobias; Therapists; Success factors; Mental disorders; Social anxiety; Mixed methods research},
language={English},
url={https://www.proquest.com/scholarly-journals/experiences-patients-therapists-testing-virtual/docview/2759738752/se-2},
}

@article{
author={Kovshov,Evgeny E. and Kuvshinnikov,Vladimir S.},
year={2022/12//},
month={Dec 2022},
title={Non-destructive testing operations simulation in virtual reality environment},
journal={Journal of Physics: Conference Series},
volume={2373},
number={6},
pages={062024},
note={Copyright - Published under licence by IOP Publishing Ltd. This work is published under http://creativecommons.org/licenses/by/3.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-28},
abstract={This article considers the prerequisites for creating virtual educational simulators for non-destructive testing teaching. Currently, virtual reality technologies are most widely used in the training process of engineers and workers directly engaged in production during complex and responsible operations, including the control of products and materials. Approaches to the creation and application of virtual reality in the development and use of a digital radiography simulator for non-destructive testing of materials and products are announced. It is noted that the developed software and algorithmic solutions allow to judge their effective applicability in industry as the results of R&D and various computational experiments. Constructing and processing images technology of digital twins’ samples, which allows to obtain image close to the results of metal samples’ X-ray film is considered. Basic physical principles underlying the developing of a digital model are formalized. The results of obtaining digital X-ray images are presented. Prospects for expanding the applicability range of virtual reality software and hardware solutions in non-destructive testing educational process are touched upon.},
keywords={Physics; Simulation; Nondestructive testing; Digital twin; Virtual; Digital radiography; Virtual reality; Digital imaging; Simulators; Education; Software; Digital twins},
isbn={17426588},
language={English},
url={https://www.proquest.com/scholarly-journals/non-destructive-testing-operations-simulation/docview/2755151671/se-2},
}

@article{
author={Gottlieb,Amihai and Doniger,Glen M. and Kimel-Naor,Shani and Ben-Gal,Oran and Cohen,Maya and Iny,Hila and Beeri,Michal S. and Plotnik,Meir},
year={2022/09/14/},
month={2022 Sep 14},
title={Development and validation of virtual reality-based Rey Auditory Verbal Learning Test},
journal={Frontiers in Aging Neuroscience},
note={Copyright - © 2022. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-24},
abstract={Objective: Translations and adaptations of traditional neuropsychological tests to Virtual Reality (VR) technology bear the potential to increase their ecological validity since the technology enables simulating everyday life conditions in a controlled manner. The current paper describes our attempt in translating a commonly used neuropsychological test to VR, the Rey Auditory Verbal Learning Test (RAVLT). For this aim, we developed a VR adaptation of the RAVLT (VR-RAVLT) Which is based on a conversation with a secretary in a virtual office using a fully immersive VR system. To validate the VR-RAVLT, we tested its construct validity, its age-related discriminant validity, and its test-retest validity in reference to the original gold standard RAVLT (GS-RAVLT). Method: 78 participants from different age groups performed GS-RAVLT and the VR-RAVLT test in a counterbalanced order in addition to other neuropsychological tests. Construct validity was validated using Pearson's correlations coefficients and serial position effects; discriminant validity was validated using receiver operating characteristic area under the curve values and test-retest reliability was validated using intraclass correlation coefficients. Results: Comparing both RAVLTs' format results indicates that the VR-RAVLT has comparable construct, discriminant, and test-retest validities. Conclusions: the novel VR-RAVLT and the GS-RAVLT share similar psychometric properties suggesting that the two tests measure the same cognitive construct. This is an indication of the feasibility of adapting the RAVLT to the VR environment. Future developments will employ this approach for clinical diagnosis and treatment.},
keywords={Medical Sciences--Psychiatry And Neurology; Memory and learning tests; Neuropsychological test; Virtual reality; Validation; Adaptation; Neuropsychological Tests; reliability and validity; Rey Auditory Verbal Learning Test; Validation study; Validity; Memory; Position effects; Dementia; Age; Retention; Computer applications; Neuropsychology; Cognitive ability; Auditory discrimination learning; Verbal learning; Virtual offices; Validation studies},
isbn={16634365},
language={English},
url={https://www.proquest.com/scholarly-journals/development-validation-virtual-reality-based-rey/docview/2714184431/se-2},
}

@article{
author={Sauer,Yannick and Sipatchin,Alexandra and Wahl,Siegfried and García García,Miguel},
year={2022/09//},
month={Sep 2022},
title={Assessment of consumer VR-headsets’ objective and subjective field of view (FoV) and its feasibility for visual field testing},
journal={Virtual Reality},
volume={26},
number={3},
pages={1089-1101},
note={Copyright - © The Author(s) 2022. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-06},
abstract={Virtual reality as a research environment has seen a boost in its popularity during the last decades. Not only the usage fields for this technology have broadened, but also a research niche has appeared as the hardware improved and became more affordable. Experiments in vision research are constructed upon the basis of accurately displaying stimuli with a specific position and size. For classical screen setups, viewing distance and pixel position on the screen define the perceived position for subjects in a relatively precise fashion. However, projection fidelity in HMDs strongly depends on eye and face physiological parameters. This study introduces an inexpensive method to measure the perceived field of view and its dependence upon the eye position and the interpupillary distance, using a super wide angle camera. Measurements of multiple consumer VR headsets show that manufacturers’ claims regarding field of view of their HMDs are mostly unrealistic. Additionally, we performed a “Goldmann” perimetry test in VR to obtain subjective results as a validation of the objective camera measurements. Based on this novel data, the applicability of these devices to test humans’ field of view was evaluated.},
keywords={Computers--Computer Graphics; Virtual reality; Visual field; Virtual reality headset; Visual system; Field of View; HMD; Perimetry; Eye relief; Eye; Position measurement; Visual fields; Headsets; Eye (anatomy); Cameras},
isbn={13594338},
language={English},
url={https://www.proquest.com/scholarly-journals/assessment-consumer-vr-headsets-objective/docview/2708604340/se-2},
}

@article{
author={McLaren,Ruth and Chaudhary,Shikha and Rashid,Usman and Ravindran,Shobika and Taylor,Denise},
year={2022/08/12/},
month={2022 Aug 12},
title={Reliability of the triangle completion test in the real-world and in virtual reality},
journal={Frontiers in Human Neuroscience},
note={Name - Auckland University of Technology; Copyright - © 2022. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-24},
abstract={BACKGROUND: The triangle completion test has been used to assess egocentric wayfinding for decades, yet there is little information on its reliability. We developed a virtual reality (VR) based test and investigated whether either test of spatial navigation was reliable. OBJECTIVE: To examine test-retest reliability of the real-world and VR triangle completion tests. A secondary objective was to examine the usability of the VR based test. METHODS: 30 healthy adults aged 18-45yrs were recruited to this block randomised study. Participants completed two sessions of triangle completion tests in the real-world and VR on the same day with a break between sessions. RESULTS: In both test versions distance from the endpoint and angle of deviation showed poor test-retest reliability (r<0.5). Distance traveled had moderate reliability in both the real-world and VR tests (r=0.55 95% CI 0.23, 0.76]; r=0.66 95% CI 0.4, 0.83 respectively]). The VR triangle test showed poor correlation with the real-world test. CONCLUSIONS: The triangle completion test has poor test-retest reliability and demonstrates poor concurrent validity between the real-world and VR. Nevertheless, it was feasible to translate a real-world test of spatial navigation into VR. VR provides opportunities for development of clinically relevant spatial navigation tests in the future.},
keywords={Medical Sciences--Psychiatry And Neurology; spatial navigation; Reliability; Wayfinding; Test; Virtual reality; triangle completion test; navigation; spatial cognition; vestibular; Motion sickness; Usability; Validity; Computer applications; Animal memory; Navigation behavior; Cognition & reasoning; Questionnaires},
language={English},
url={https://www.proquest.com/scholarly-journals/reliability-triangle-completion-test-real-world/docview/2701315477/se-2},
}

@article{
author={Gammeri,Roberto and Léonard,Jacques and Toupet,Michel and Hautefort,Charlotte and van Nechel,Christian and Besnard,Stéphane and Machado,Marie-Laure and Nakul,Estelle and Montava,Marion and Lavieille,Jean-Pierre and Lopez,Christophe},
year={2022/08//},
month={Aug 2022},
title={Navigation strategies in patients with vestibular loss tested in a virtual reality T-maze},
journal={Journal of neurology},
volume={269},
number={8},
pages={4333-4348},
note={Copyright - © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany 2022; Last updated - 2024-01-22},
abstract={During navigation, humans mainly rely on egocentric and allocentric spatial strategies, two different frames of reference working together to build a coherent representation of the environment. Spatial memory deficits during navigation have been repeatedly reported in patients with vestibular disorders. However, little is known about how vestibular disorders can change the use of spatial navigation strategies. Here, we used a new reverse T-maze paradigm in virtual reality to explore whether vestibular loss specifically modifies the use of egocentric or allocentric spatial strategies in patients with unilateral (n = 23) and bilateral (n = 23) vestibular loss compared to healthy volunteers (n = 23) matched for age, sex and education level. Results showed that the odds of selecting and using a specific strategy in the T-maze were significantly reduced in both unilateral and bilateral vestibular loss. An exploratory analysis suggests that only right vestibular loss decreased the odds of adopting a spatial strategy, indicating an asymmetry of vestibular functions. When considering patients who used strategies to navigate, we observed that a bilateral vestibular loss reduced the odds to use an allocentric strategy, whereas a unilateral vestibular loss decreased the odds to use an egocentric strategy. Age was significantly associated with an overall lower chance to adopt a navigation strategy and, more specifically, with a decrease in the odds of using an allocentric strategy. We did not observe any sex difference in the ability to select and use a specific navigation strategy. Findings are discussed in light of previous studies on visuo-spatial abilities and studies of vestibulo-hippocampal interactions in peripheral vestibular disorders. We discuss the potential impact of the history of the disease (chronic stage in patients with a bilateral vestibulopathy vs. subacute stage in patients with a unilateral vestibular loss), of hearing impairment and non-specific attentional deficits in patients with vestibular disorders.},
keywords={Medical Sciences--Psychiatry And Neurology; Vestibular system; Allocentrism; Egocentrism; Hearing loss; T-maze; Spatial navigation; Balance disorder; Virtual reality; Labyrinth; Spatial strategies; Egocentric; Allocentric; Reference frame; Hippocampus; Sex differences; Computer applications; Animal memory; Navigation behavior; Spatial memory; Neurology},
isbn={03405354},
language={English},
url={https://www.proquest.com/scholarly-journals/navigation-strategies-patients-with-vestibular/docview/2691245149/se-2},
}

@article{
author={Misa,Anamaria and Melenciuc,Mihaela and Pădurariu,Ioana and Văduva,Cecilia},
year={2022},
month={2022},
title={Augmented Reality Body and Face Filters for Digitally Manipulated Visual Narratives: Physical Appearance Ideals, Perceived Social Validation, and Aesthetic and Affective Technologies},
journal={Journal of Research in Gender Studies},
volume={12},
number={2},
pages={160-175},
note={Copyright - Copyright Addleton Academic Publishers 2022; Last updated - 2024-05-09},
abstract={This paper provides a systematic literature review of studies investigating flawless fashionable ideals, digitally-enhanced augmented reality-based perception of beauty, and individual expressions and representations of visual identity. Throughout June 2022, we performed a quantitative literature review of the Web of Science, Scopus, and ProQuest databases, with search terms including "augmented reality body and face filters for digitally manipulated visual narratives" + "physical appearance ideals," "perceived social validation," and "aesthetic and affective technologies." As we inspected research published between 2013 and 2022, only 169 articles satisfied the eligibility criteria. By eliminating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, we decided upon 32, generally empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AMSTAR, Distiller SR, MMAT, and ROBIS.},
keywords={Social Sciences: Comprehensive Works; Augmented reality; Y; GenderWatch; Narratives; Visualization; Databases; Literature reviews; Objectification; Social networks; Aesthetics; Body image; Mapping; Visual perception; Social structure; Augmentation; Quality assessment; Layout; Beauty; Social interaction; Self image; Self expression; Algorithms; Consciousness; Physical appearance; Personal appearance; Bibliometrics},
isbn={21640262},
language={English},
url={https://www.proquest.com/scholarly-journals/augmented-reality-body-face-filters-digitally/docview/2809782660/se-2},
}

@article{
author={Won,JuHye and Kim,Yoon S.},
year={2022/07//},
month={Jul 2022},
title={A New Approach for Reducing Virtual Reality Sickness in Real Time: Design and Validation Study},
journal={JMIR Serious Games},
volume={10},
number={3},
note={Copyright - © 2022. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-02-23},
abstract={Background: Recently, technology that provides virtual reality (VR) content based on streaming services has been rapidly developed. However, there have been few studies to reduce VR sickness that occurs while the user watches VR content while wearing a head-mounted display (HMD) in real time. Objective: Based on this background, we propose a new approach to measure and reduce VR sickness that occurs while the user watches VR content while wearing an HMD in real time. Methods: The proposed approach is to apply VR sickness reduction methods in accordance with the user’s real-time VR sickness level. Three methods that are known to be effective in reducing VR sickness and a single type of VR content were used to examine the effectiveness of the proposed approach, which was confirmed by the experimental results. Results: Our results show that VR sickness significantly decreased when a new approach was applied to VR content (in all cases, P<.05). Conclusions: From our results, it was confirmed that VR sickness could be measured without wearing additional equipment, and its reduction method could be applied in real time in accordance with the user’s condition by the proposed approach in this paper.},
keywords={Medical Sciences; virtual reality; Head-mounted display; Virtual; Reality; VR; VR sickness; VR sickness reduction method; simulator sickness questionnaire; SSQ, visual guide; field of view; serious game; VR sickness reduction; VR content; technology; digital health; Methods; Experiments; Real time; Questionnaires; Computer & video games; Educational software},
language={English},
url={https://www.proquest.com/scholarly-journals/new-approach-reducing-virtual-reality-sickness/docview/2719579909/se-2},
}

@article{
author={Kalron,Alon and Frid,Lior and Fonkatz,Iliya and Menascu,Shay and Dolev,Mark and Magalashvili,David and Achiron,Anat},
year={2022/07//},
month={Jul 2022},
title={The Design, Development, and Testing of a Virtual Reality Device for Upper Limb Training in People With Multiple Sclerosis: Single-Center Feasibility Study},
journal={JMIR Serious Games},
volume={10},
number={3},
note={Copyright - © 2022. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-26; SubjectsTermNotLitGenreText - Israel},
abstract={Background: Multiple sclerosis (MS) is a common nontraumatic, neurological, disabling disease that often presents with upper limb dysfunction. Exercise training has resulted in improvement for patients; however, there can be a lack of compliance due to access because of location and lack of MS experts. Virtual reality (VR) is a promising technology that can offer exercise therapy/rehabilitation at a distance. This type of remote training can be motivational and effective for patients with MS and can improve range of motion and muscle strength for those with upper limb dysfunction. Objective: The aim of this study is to evaluate the safety and feasibility of the XRHealth software and the Oculus Rift Station for patients with MS with upper limb motor dysfunction. Methods: A single-center, prospective, feasibility study was conducted with patients with MS who had upper limb motor dysfunction. Patients participated in a single 45-minute digital environment session with VR and completed a questionnaire about the quality of the training and fatigability. The clinician also completed a questionnaire to evaluate the suitability and safety of the training. Results: Overall, 30 patients were enrolled between the ages of 20 and 81 years. Patients reported that the training sessions within the digital environment were helpful, challenging, fun, and simple to understand, and that they would be willing to repeat the sessions again. The physical therapist that oversaw the patients reported that the training was suitable for 87% (n=26) of the patients. Anticipated adverse events were fatigue, temporary dizziness, and temporary nausea. The operator complications included that the cable of the head-mounted display interrupted the training (n=2, 7%) and fatigue that caused cessation of the VR training session (n=2, 7%). No serious adverse events were reported. Conclusions: These preliminary results demonstrated that the use of the XRHealth software and Oculus Rift Station platform is feasible, safe, and engaging for patients, and has the potential to improve the functionality of the upper limbs in patients with MS. This study provides support for future studies of implementing a series of training sessions with virtual reality in a home-based environment.},
keywords={Medical Sciences; virtual reality; Feasibility study; Multiple sclerosis; Virtual environment; Training; Physical therapy; Upper limb; rehabilitation; feasibility; Patients; Exercise; Software; Physical fitness; Physical therapists; Therapy; Multimedia; FDA approval; Questionnaires; Medical research; Feasibility studies; Fitness training programs; Israel},
language={English},
url={https://www.proquest.com/scholarly-journals/design-development-testing-virtual-reality-device/docview/2719579907/se-2},
}

@article{
author={Sureshkumar,Haarisudhan and Xu,Ruidi and Erukulla,Nikith and Wadhwa,Aditi and Zhao,Linping},
year={2022/06//},
month={Jun 2022},
title={“Snap on” or Not? A Validation on the Measurement Tool in a Virtual Reality Application},
journal={Journal of Digital Imaging},
volume={35},
number={3},
pages={692-703},
note={Copyright - © The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine 2022; Last updated - 2023-11-27},
abstract={This multi-rater comparison study aims to validate the measurement tool with a “snap” feature option (SNAP ON vs. SNAP OFF), in a virtual reality (VR) application, ImmersiveView v. 2.1, against a conventional software Mimics Innovation Suite v.22 (MIS). It is hypothesized that these measurement tools are equivalent between SNAP ON, and SNAP OFF, and when compared to MIS, in terms of basic linear and angular measurements. Six (6) raters conducted a set of 40 linear and 15 angular measurements using CT scan data of three objects (L-block, hand model, and dry skull) with fiducial markers. Inter-rater repeatability and intra-rater reproducibility were assessed via inter-class coefficient (ICC). Equivalency between each pair of modules (SNAP ON, SNAP OFF, and MIS) was analyzed via Bland–Altman plots and two one-sided t-tests (TOST) procedure. The ICC for intra-rater repeatability yielded 0.999 to 1.000, and inter-rater reproducibility yielded 0.998 to 1.000, which suggests high degree of intra- and inter-rater reliability. The Bland–Altman plots demonstrated that measurements acquired from SNAP ON, SNAP OFF, and MIS were equivalent. The TOST procedure yielded that the measurements through all three modules are equivalent within ± 0.2 mm interval for distance, and ± 0.3° interval for angular measurements. The measurement tool with the “snap” feature in a newly developed VR application (ImmersiveView v.2.1) has been validated through a multi-rater comparison study. In terms of linear and angular measurements, this VR application, whether the “snap” feature was on or off, was equivalent to each other and to the control software (MIS) under the condition of this study. A strong reliability, both intra-rater repeatability and inter-rater reproducibility, has been found.},
keywords={Medical Sciences--Radiology And Nuclear Medicine; Validation; Virtual; Measuring instrument; Virtual reality; Measurements; Reliability; Reproducibility; Equivalency; Reliability aspects; Software; Computer applications; Modules; Computed tomography; Equivalence},
isbn={08971889},
language={English},
url={https://www.proquest.com/scholarly-journals/snap-on-not-validation-measurement-tool-virtual/docview/2671808915/se-2},
}

@article{
author={Tibor,Guzsvinecz and Orbán-Mihálykó Éva and Sik-Lányi Cecília and Erika,Perge},
year={2022/06//},
month={Jun 2022},
title={Investigation of spatial ability test completion times in virtual reality using a desktop display and the Gear VR},
journal={Virtual Reality},
volume={26},
number={2},
pages={601-614},
note={Copyright - © The Author(s) 2021. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-05},
abstract={The interaction time of students who did spatial ability tests in a virtual reality environment is analyzed. The spatial ability test completion times of 240 and 61 students were measured. A desktop display as well as the Gear VR were used by the former group and by the latter one, respectively. Logistic regression analysis was used to investigate the relationship between the probability of correct answers and completion times, while linear regression was used to evaluate effects and interactions of following factors on test completion times: the users’ gender and primary hand, test type and device used. The findings were that while the completion times are not significantly affected by the users’ primary hand, other factors have significant effects on them: they are decreased by the male gender in itself, while they are increased by solving Mental Rotation Tests or by using the Gear VR. The largest significant increment in interaction time in virtual reality during spatial ability tests is when Mental Rotation Tests are accomplished by males with the Gear VR, while the largest significant decrease in interaction time is when Mental Cutting Tests are completed with a desktop display.},
keywords={Computers--Computer Graphics; Cognitive skills; Gender; Virtual reality; Display; Desktop display; Gear VR; Human-computer interaction; Interaction time; Mental rotation; Spatial ability; Ability tests; Regression analysis; Statistical analysis; Rotation; Students},
isbn={13594338},
language={English},
url={https://www.proquest.com/scholarly-journals/investigation-spatial-ability-test-completion/docview/2666079302/se-2},
}

@article{
author={Kapp,Karmen and Sivén,Mia and Laurén,Patrick and Virtanen,Sonja and Katajavuori,Nina and Södervik,Ilona},
year={2022},
month={2022},
title={Design and Usability Testing of an Augmented Reality (AR) Environment in Pharmacy Education—Presenting a Pilot Study on Comparison between AR Smart Glasses and a Mobile Device in a Laboratory Course},
journal={Education Sciences},
volume={12},
number={12},
pages={854},
note={Copyright - © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-04-16; SubjectsTermNotLitGenreText - Independent Study; Pharmaceutical Education; Computer Simulation; Authentic Learning; Guidance; Science Education; Environment; Self Efficacy; Pharmacy; Learning Motivation; Teaching Methods; Learning Experience; Laboratory Training; Usability; Computer Assisted Instruction; Chemistry; College Students; Student Evaluation; Beliefs; Thinking Skills; Student Motivation; Science Instruction; Organic Chemistry; Higher Education},
abstract={An essential feature of pharmacy education is the teaching of theoretical knowledge with the support of practical work in the laboratory. When properly utilized, laboratory activities have the potential to enhance students’ achievement, conceptual understanding, and positive attitudes towards learning. In this pilot study, an augmented reality (AR) environment was designed and introduced for teaching laboratory skills in pharmacy education at the university level. The AR environment was used by pharmacy students (n = 36), featuring gate questions, information screens, Quick Response codes, think-aloud questions, and instant feedback. The environment was utilized with smart glasses and mobile devices with the aim of comparing the support to students’ performance. User experience was evaluated through self-efficacy beliefs and anxiety towards the technology. As a result, students found the environment a useful supplement to traditional laboratory teaching. Smart glasses and mobile devices were both accepted with great positivity but neither being clearly preferred over the other. Smart glasses were noted to provide sufficient feedback in the right stages of work. In contrast, mobile devices promoted the learning process more than the smart glasses. The self-efficacy results for mobile device use were higher, especially related to device handling and operating the AR environment. The pilot study gives educators valuable insights on the usability of AR technology in guiding laboratory tasks, although future work should involve larger and more diverse samples, as well as different learning tasks.},
keywords={Education; augmented reality; Usability testing; Pharmacy school; Usability; Self-efficacy; Smartglasses; Mobile device; educational technology; higher education; laboratory education; mixed reality; Teaching; Students; Anxiety; Smartphones; User experience; Technology adoption; Pharmacy; Science education; Medical research; Pharmaceutical industry; Core curriculum; Learning; Laboratories; Self Efficacy; Student Evaluation; Beliefs; Independent Study; Computer Assisted Instruction; Thinking Skills; Computer Simulation; Teaching Methods; Organic Chemistry; Authentic Learning; Science Instruction; Learning Experience; Pharmaceutical Education; Laboratory Training; Learning Motivation; Guidance; Student Motivation; Chemistry; College Students; Environment},
language={English},
url={https://www.proquest.com/scholarly-journals/design-usability-testing-augmented-reality-ar/docview/2756683027/se-2},
}

@article{
author={Frizziero,Leonardo and Donnici,Giampiero and Santi,Gian M. and Leon-Cardenas,Christian and Ferretti,Patrich and Pascucci,Gaia and Liverani,Alfredo},
year={2022/01//},
month={Jan 2022},
title={Disassembly sequence planning validated thru augmented reality for a speed reducer},
journal={Cogent Engineering},
volume={9},
number={1},
note={Copyright - © 2022 The Author(s). This open access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license. This work is licensed under the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-22},
abstract={The lifecycle of a product is getting shorter in today’s market realities. Latest developments in the industry are heading towards achieving products that are easy to recycle, by developing further technological advances in raw materials ought to include input from End of Life (EOL) products so a reduction of natural harm could be achieved, hence reducing the overall production environmental footprint. Therefore, the approach taken as a design for environment, a key request nowadays in order to develop products that would ease the reverse manufacturing process leading to a more efficient element recycling for later use as spare parts or remanufacturing. The methodology proposed compares three probable disassembly sequences following a comparison of literature-found procedures between genetic algorithms and as a “state space search” problem, followed by a hybrid approach developed by the authors. Time and evaluation of these procedures reached to the best performing sequence. A subsequent augmented reality disassembly simulation was performed with the top-scored operation sequence with which the user is better able to familiarize himself with the assembly than a traditional paper manual, therefore enlightening the feasibility of the top performing sequence in the real world.},
keywords={Engineering; Disassembly; Manufacturing; Genetic algorithm; State space search; Spare Parts; Augmented reality; optimization; closed loop; genetic algorithms; metaheuristic method; particle swarm optimizer; Remanufacturing; Disassembly sequences; Dismantling; End of life; Industrial development; Raw materials},
language={English},
url={https://www.proquest.com/scholarly-journals/disassembly-sequence-planning-validated-thru/docview/2755975622/se-2},
}

@article{
author={Hub,Fabian and Oehl,Michael},
year={2022},
month={2022},
title={Design and Field Test of a Mobile Augmented Reality Human–Machine Interface for Virtual Stops in Shared Automated Mobility On-Demand},
journal={Electronics},
volume={11},
number={17},
pages={2687},
note={Copyright - © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-23},
abstract={Shared automated mobility on-demand (SAMOD) is considered as a promising mobility solution in the future. Users book trips on-demand via a smartphone, and service algorithms set up virtual stops (vStop) where users then need to walk to board the automated shuttle. Navigation and identification of the virtual pickup location, which has no references in the real world, can be challenging. Providing users with an intuitive information system in that situation is essential to achieve high user acceptance of new automated mobility services. Our novel vStop human–machine interface (HMI) prototype for mobile augmented reality (AR) supports users with information in reference to the street environment. This work firstly presented the results of an online interview study (N = 21) to conceptualize an HMI. Secondly, the HMI was prototyped by means of AR and evaluated (N = 45) regarding user experience (UX), workload, and acceptance. The results show that the AR prototype provided high rates of UX especially in terms of high pragmatic quality. Furthermore, cognitive workload when using the HMI was low, and acceptance ratings were high. The results show the positive perception of AR for navigation tasks in general and the highly assistive character of the vStop prototype in particular. In the future, SAMOD services can provide customers with vStop HMIs to foster user acceptance and smooth operation of their service.},
keywords={Electronics; virtual stop; User interface; Augmented reality; User experience; shared automated mobility on-demand; HMI; field test; user-centered design; Field tests; Customer services; Navigation; Usability; Smartphones; Infrastructure; Acceptance; Workload; Prototypes; Algorithms; User interfaces; Automation; Vehicles},
language={English},
url={https://www.proquest.com/scholarly-journals/design-field-test-mobile-augmented-reality-human/docview/2711287714/se-2},
}

@article{
author={Chi-Yi,Tsai and Yu-Cheng,Lai},
year={2022},
month={2022},
title={Design and Validation of an Augmented Reality Teaching System for Primary Logic Programming Education},
journal={Sensors},
volume={22},
number={1},
pages={389},
note={Copyright - © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-04; SubjectsTermNotLitGenreText - Taiwan},
abstract={Programming is a skill that requires high levels of logical thinking and problem-solving abilities. According to the Curriculum Guidelines for the 12-Year Basic Education currently implemented in Taiwan, programming has been included in the mandatory courses of middle and high schools. Nevertheless, the guidelines simply recommend that elementary schools conduct fundamental instructions in related fields during alternative learning periods. This may result in the problem of a rough transition in programming learning for middle school freshmen. To alleviate this problem, this study proposes an augmented reality (AR) logic programming teaching system that combines AR technologies and game-based teaching material designs on the basis of the fundamental concepts for seventh-grade structured programming. This system can serve as an articulation curriculum for logic programming in primary education. Thus, students are able to develop basic programming logic concepts through AR technologies by performing simple command programming. This study conducted an experiment using the factor-based quasi-experimental research design and questionnaire survey method, with 42 fifth and sixth graders enrolled as the experimental subjects. The statistical analysis showed the following results: In terms of learning effectiveness, both AR-based and traditional learning groups displayed a significant performance. However, of the two groups, the former achieved more significant effectiveness in the posttest results. Regarding learning motivation, according to the evaluation results of the Attention, Relevance, Confidence, and Satisfaction (ARCS) motivation model, the AR-based learning group manifested significantly higher levels of learning motivation than the traditional learning group, with particularly significant differences observed in the dimension of Attention. Therefore, the experimental results validate that the proposed AR-based logic programming teaching system has significant positive effects on enhancing students’ learning effectiveness and motivation.},
keywords={Chemistry--Analytical Chemistry; augmented reality; Logic programming; Primary education; Reality; logic programming teaching; learning effectiveness; learning motivation; analysis of covariance; Teaching; Students; Structured programming; Guidelines; Smartphones; Education; Curricula; Statistical analysis; Learning; Problem solving; Artificial intelligence; Taiwan},
language={English},
url={https://www.proquest.com/scholarly-journals/design-validation-augmented-reality-teaching/docview/2618267582/se-2},
}

@article{
author={Budiman,E. and Firdaus,M. B. and Hairah,U.},
year={2021/06//},
month={Jun 2021},
title={Augmented Reality Peripheral Performance: Light Intensity, Distance, Occlusion and Marker Testing},
journal={Journal of Physics: Conference Series},
volume={1898},
number={1},
note={Copyright - © 2021. This work is published under http://creativecommons.org/licenses/by/3.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-01-24},
abstract={Augmented Reality peripherals (ARP) that use marker detection objects have developed rapidly and are implemented in various forms to support the activities of everyday human life. The challenge that is currently being faced is the increasingly widespread application of ARP technology to the reliability of software product performance in detecting objects. This research has developed and implemented ARP in the academic space. The application development method uses the Multimedia Development Life Cycle (MDLC) approach, developed based on the Android operating system, using the Unity 3D Engine and Vuforia SDK. 3D object modelling with Sweet Home 3D. Whereas for testing the reliability of ARP performance in object detection using testing of light intensity, distance, occlusion and marker with each scenario. The research produces augmented reality technology products that are able to offer visualization in the form of interactive 2D and 3D objects in academic rooms that provide information to users about the peripheral layout and division of academic spatial layouts and the good reliability performance.},
keywords={Physics; Peripheral; Visualization; Object detection; Augmented reality; Software reliability; Layouts; Markers; Object recognition; Luminous intensity; Mobile operating systems; Occlusion; Three dimensional models; Life cycle analysis; Multimedia},
isbn={17426588},
language={English},
url={https://www.proquest.com/scholarly-journals/augmented-reality-peripheral-performance-light/docview/2546086424/se-2},
}

@article{
author={Kourtesis,Panagiotis and Collina,Simona and Doumas,Leonidas A. and MacPherson,Sarah E.},
year={2021/02//},
month={Feb 2021},
title={Validation of the Virtual Reality Everyday Assessment Lab (VR-EAL): An Immersive Virtual Reality Neuropsychological Battery with Enhanced Ecological Validity},
journal={Journal of the International Neuropsychological Society : JINS},
volume={27},
number={2},
pages={181-196},
note={Name - University of Edinburgh; Copyright - Copyright © INS. Published by Cambridge University Press, 2020; Last updated - 2024-03-22},
abstract={Objective:The assessment of cognitive functions such as prospective memory, episodic memory, attention, and executive functions benefits from an ecologically valid approach to better understand how performance outcomes generalize to everyday life. Immersive virtual reality (VR) is considered capable of simulating real-life situations to enhance ecological validity. The present study attempted to validate the Virtual Reality Everyday Assessment Lab (VR-EAL), an immersive VR neuropsychological battery, against an extensive paper-and-pencil neuropsychological battery.Methods:Forty-one participants (21 females) were recruited: 18 gamers and 23 non-gamers who attended both an immersive VR and a paper-and-pencil testing session. Bayesian Pearson’s correlation analyses were conducted to assess construct and convergent validity of the VR-EAL. Bayesian t-tests were performed to compare VR and paper-and-pencil testing in terms of administration time, similarity to real-life tasks (i.e., ecological validity), and pleasantness.Results:VR-EAL scores were significantly correlated with their equivalent scores on the paper-and-pencil tests. The participants’ reports indicated that the VR-EAL tasks were significantly more ecologically valid and pleasant than the paper-and-pencil neuropsychological battery. The VR-EAL battery also had a shorter administration time.Conclusion:The VR-EAL appears as an effective neuropsychological tool for the assessment of everyday cognitive functions, which has enhanced ecological validity, a highly pleasant testing experience, and does not induce cybersickness.},
keywords={Medical Sciences--Psychiatry And Neurology; Prospective memory; Ecological validity; Cognitive skill; Virtual reality; Neuropsychology; Episodic memory; Attention; Executive function; Everyday functioning; Memory; Brain damage; Validity; Computer applications; Bayesian analysis; Cognitive ability; Multitasking; Laboratories},
isbn={13556177},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-virtual-reality-everyday-assessment/docview/2488081410/se-2},
}

@article{
author={Setyadi,Rudy and Ranggadara,Indra},
year={2020/02//},
month={Feb 2020},
title={Augmented reality using features accelerated segment test for property catalogue},
journal={TELKOMNIKA},
volume={18},
number={1},
pages={140-147},
note={Copyright - © 2020. This work is published under https://creativecommons.org/licenses/by/3.0 (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-05},
abstract={The FAST algorithm will calculate every pixel on the target image in determining the corner when scanning the home catalog then it will produce a 3D object home to see the real shape design of the house. Augmented reality is a technology that combines two-dimensional or three-dimensional virtual objects into a real environment in real time 7] so there is no boundary between the real world and the virtual world 8]. With the application of the augmented reality, the user can more easily get the information about the home in the form of 3D models by aiming the camera to the marker on the catalog. 2.RESEARCH METHOD 2.1.Multimedia development life cycle This study uses the MDLC (Multimedia Development Life Cycle) method. According to Luther in Nurajizah 20] the development of the multimedia method was carried out based on six stages, arranged systematically as follows: - The first step of this method is Concept.},
keywords={Technology: Comprehensive Works; Augment; 3D modeling; Augmented reality; Reality; Software; Marketing; Research methodology; Houses; Multimedia; Three dimensional models; Accelerated tests; Housing; Algorithms; Target recognition},
isbn={16936930},
language={English},
url={https://www.proquest.com/scholarly-journals/augmented-reality-using-features-accelerated/docview/2379528897/se-2},
}

@article{
author={Andriyandi,Adi P. and Darmalaksana,Wahyudin and Maylawati,Dian S. and Irwansyah,Ferli S. and Mantoro,Teddy and Ramdhani,Muhammad A.},
year={2020/02//},
month={Feb 2020},
title={Augmented reality using features accelerated segment test for learning ta},
journal={TELKOMNIKA},
volume={18},
number={1},
pages={208-216},
note={Copyright - © 2020. This work is published under https://creativecommons.org/licenses/by/3.0 (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-12-05},
abstract={Interactive learning media in current digital era is needed, because learning media is a creative media used in providing subject matter to students so that the learning process is more effective, efficient, and enjoyable 2]. ...]the use of multimedia technology is very useful. The features displayed are very simple, while for the main display that is in the form of a camera capture to detect markers 30]. ...]in this study besides implementing the FAST corner detection algorithm, the accuracy and time process of FAST algorithm in detecting the tajweed will be investigated. 2.RESEARCH METHOD Activitiy flow of this research that described in Figure 1 begin from collect and understand the rule of tajweed Qur'an, then collecting the images data of Tajweed Qur'an. ...]conducting the experiment and evaluating the usability of application with quetionnaire. 2.1.Augmented reality Augmented reality (AR) is a revolution in computer graphic technology that which presents visual images as if they were alive and very real 31]. ...]AR technology had been introduced in 1957 until now still be developed 32].},
keywords={Technology: Comprehensive Works; Digital image processing; Augmented reality; Students; Learning; Multimedia; Interactive learning; Muslims; Corner detection; Accelerated tests; Algorithms; Methods; Virtual reality; Education},
isbn={16936930},
language={English},
url={https://www.proquest.com/scholarly-journals/augmented-reality-using-features-accelerated/docview/2379527327/se-2},
}

@article{
author={Kourtesis,Panagiotis and Collina,Simona and Doumas,Leonidas A. A. and MacPherson,Sarah E.},
year={2019/11/26/},
month={2019 Nov 26},
title={Validation of the Virtual Reality Neuroscience Questionnaire: Maximum Duration of Immersive Virtual Reality Sessions Without the Presence of Pertinent Adverse Symptomatology},
journal={Frontiers in Human Neuroscience},
note={Name - University of Edinburgh; Copyright - © 2019. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; People - Parsons, T; Last updated - 2023-11-24; SubjectsTermNotLitGenreText - Italy; Parsons, T; United Kingdom--UK},
abstract={There are major concerns about the suitability of immersive virtual reality (VR) systems (i.e., head-mounted display; HMD) to be implemented in research and clinical settings, because of the presence of nausea, dizziness, disorientation, fatigue, and instability (i.e., VR induced symptoms and effects; VRISE). Research suggests that the duration of a VR session modulates the presence and intensity of VRISE, but there are no suggestions regarding the appropriate maximum duration of VR sessions. The implementation of high-end VR HMDs in conjunction with ergonomic VR software seems to mitigate the presence of VRISE substantially. However, a tool does not currently exist to appraise the quality of software features and VRISE intensity quantitatively. The Virtual Reality Neuroscience Questionnaire (VRNQ) was developed to assess the quality of VR software in terms of user experience, game mechanics, in-game assistance, and VRISE. Forty participants aged between 28 and 43 years were recruited (18 gamers and 22 non-gamers) for the study. They participated in 3 different VR sessions until they felt weary or discomfort and subsequently filled in the VRNQ. Our results demonstrated that VRNQ is a valid tool for assessing VR software as it has good convergent, discriminant, and construct validity. The maximum duration of VR sessions should be between 55-70 minutes to avoid moderate or intense VRISE and, after familiarization with the VR system, while the gaming experience does not affect how long VR sessions should last. Also, while the quality of VR software substantially modulates the maximum duration of VR sessions, age and education do not. Finally, deeper immersion, better quality of graphics and sound, and more helpful in-game instructions and prompts were found to reduce VRISE intensity. The VRNQ facilitates the assessment and reporting of the quality of VR software features and the intensity of VRISE, while its minimum and parsimonious cut-offs may appraise the suitability of VR software for implementation in research and clinical settings. The findings of this study contribute to the establishment of rigorous VR methods that are crucial for the viability of immersive VR as a research and clinical tool in cognitive neuroscience and neuropsychology},
keywords={Medical Sciences--Psychiatry And Neurology; Virtual Reality; Immersion; Head-mounted display; Virtual reality game; Validation; Cybersickness; Neuroscience (Psychology); Neuropsychology; Psychology; VR; VR sickness; VRISE (Virtual Reality Induced Symptoms and Effects); Motion sickness (simulator sickness); Physiology; Research; Software; Computer programs; Nausea; Questionnaires; Neurosciences; Computer applications; Literature reviews; Cognitive ability; Nervous system; United Kingdom--UK; Italy; Parsons, T},
language={English},
url={https://www.proquest.com/scholarly-journals/validation-virtual-reality-neuroscience/docview/2318358052/se-2},
}

@article{
author={R,Dewi A. and Hustinawaty and Jatnika,Ihsan and Medyawati,Henny},
year={2019/03//},
month={Mar 2019},
title={Boundary Value Analysis Testing on Augmented Reality of Indonesian Fruit Recognition at Mekarsari Tourist Park using Cloud Method on Android Mobile Devices},
journal={Journal of Physics: Conference Series},
volume={1196},
number={1},
note={Copyright - © 2019. This work is published under http://creativecommons.org/licenses/by/3.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-28; SubjectsTermNotLitGenreText - Indonesia},
abstract={Software testing is a process of implementing a program with the aim of finding an error. A good test case is if the test has the possibility of finding an uncovered error. A successful test is if the test finds an error that was not initially found. One of the testing types available is black box testing. This paper proposes testing using black box testing technique. The black box testing method consists of several ways including equivalence partitioning, boundary value analysis, comparison testing, sample testing, robustness testing, and others. Among the many methods of testing, Boundary Value Analysis was chosen in this study. Boundary Value Analysis is a method of testing by determining the value of the lower limit and upper limit of the data that will be tested. This test is performed on the functions of Augmented Reality prototype of Indonesia fruit recognition by using the cloud method on Android mobile devices. From testing the distance of marker objects to Android mobile devices on cloud recognition using an Android camera shows that the higher the augmentable rating of the target image and the more the number of markers features detected, the easier the image will be tracked by AR. If the distance between the camera and the real object gets farther away, then the virtual object cannot be displayed. Testing with mobile devices using HSDPA, 3G and WIFI networks connecting a cloud database server to display virtual objects shows the average results of devices that use WIFI networks provide the fastest performance.},
keywords={Physics; Wifi; Augmented reality; Software testing; Markers; Errors; Object recognition; Value analysis; Electronic devices; Cameras; Indonesia},
isbn={17426588},
language={English},
url={https://www.proquest.com/scholarly-journals/boundary-value-analysis-testing-on-augmented/docview/2566088439/se-2},
}

@article{
author={Manuri,Federico and Pizzigalli,Alessandro and Sanna,Andrea},
year={2019},
month={2019},
title={A State Validation System for Augmented Reality Based Maintenance Procedures},
journal={Applied Sciences},
volume={9},
number={10},
note={Copyright - © 2019. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2024-03-25},
abstract={...]since part of the environment that the user sees is real, it is not necessary to compute a virtual model of it; secondly, since the user’s physical point of view is preserved, the physical and mental annoyances that usually occur in a detached full-immersive virtual world are avoided. A set of possible high-impact applications for industrial AR were identified by Navab 8] in 2004. ...]the benefits that AR could provide to maintenance, repair and assembly tasks have been thoroughly analyzed by Henderson and Feiner in 3]. Currently, maintenance, repair and assembly are identified as strategic application fields, since the reduction of associated costs represents a key goal in many domains, thus, any technological advancement is carefully considered in order to take the opportunity to reduce these costs. ...]augmented reality is considered one of the nine pillars of technological advancement comprised by the Industry 4.0 paradigm: to provide an exemplification of the impact of such technologies on Industry, it has been evaluated that Industry 4.0 in the next 5–10 years will boost productivity among all German manufacturing sectors by 90 billion euros to 150 billion euros, possibly driving an additional revenue growth of about 30 billion euros a year 9]. A typical maintenance task can benefit from AR since it is possible to provide assistance to the user through digital assets: 3D models, animations, audio tracks and video clips, which are available to the user to better understand how to perform the given task. ...]AR applications for maintenance and repair are often completed by tele-presence systems:},
keywords={Sciences: Comprehensive Works; augmented reality; maintenance procedures; state validation; computer vision; Maintenance; Fourth Industrial Revolution; Assembly; Repair; Machinery; Manufacturing industry; Industrial applications; Virtual communities; Algorithms; Performance evaluation; Domains; Costs; Repair & maintenance},
language={English},
url={https://www.proquest.com/scholarly-journals/state-validation-system-augmented-reality-based/docview/2331445098/se-2},
}

@article{
author={Nikitenko,M. S. and Zhuravlev,S. S. and Rudometov,S. V. and Neogi,B. and Belyi,A. M.},
year={2018/11//},
month={Nov 2018},
title={Walking support control system algorithms testing with brain-computer interface (BCI) and augmented reality (AR) technology integration},
journal={IOP Conference Series.Earth and Environmental Science},
volume={206},
number={1},
note={Copyright - © 2018. This work is published under http://creativecommons.org/licenses/by/3.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2023-11-25},
abstract={The article presents a perspective platform for the creation of robotic complexes for the effective and safe development of hard-to-extract minerals based on the walking support module. It describes the concept of automation control based on combining BCI and AR technology, and a method for testing control algorithms based on the application of the MTSS (Manufacturing and Transportation Simulation System) as part of the hardware and software complex for debugging and testing the applied software of the automated process control system for coal and ore mines. The reported study was partially funded by RFBR according to the research project No. 18-37-00356.},
keywords={Environmental Studies; Mining; Robotics; Automation; Walking; Augmented reality; Brain; Computer programs; Control algorithms; Process control; Control systems; Human-computer interface; Algorithms; Technology; Minerals; Process controls; Implants; Computer applications; Coal mines; Software; Research projects; Automatic control},
isbn={17551307},
language={English},
url={https://www.proquest.com/scholarly-journals/walking-support-control-system-algorithms-testing/docview/2559448067/se-2},
}

@article{
author={Wójcicki,Tomasz},
year={2015},
month={2015},
title={Use Of Bayesian Networks And Augmented Reality To Reliability Testing Of Complex Technical Objects},
journal={Journal of KONBiN},
volume={35},
number={1},
pages={179-190},
note={Copyright - Copyright De Gruyter Open Sp. z o.o. 2015; Last updated - 2023-11-28},
abstract={This paper presents a methodology developed to support the tests of reliability of complex technical objects. The presented methodology covers the use of modern information technologies in the form of algorithmic models and effective visualization techniques in the form of augmented reality. The possibility of using a probabilistic Bayesian network. The method of determining the probabilities for specific nodes, and the total probability distribution of graph structures are presented. The structure of the model and its basic functions are shown. The results of the verification work for connecting data processing methods and visualization techniques based on augmented reality are presented.},
keywords={Engineering; Bayesian networks; Reliability; Bayesian network; Reliability engineering; Augmented reality; probabilistic networks},
isbn={18958281},
language={English},
url={https://www.proquest.com/scholarly-journals/use-bayesian-networks-augmented-reality/docview/1857873016/se-2},
}

@article{
author={Bifulco,Paolo and Narducci,Fabio and Vertucci,Raffaele and Ambruosi,Pasquale and Cesarelli,Mario and Romano,Maria},
year={2014},
month={2014},
title={Telemedicine supported by Augmented Reality: an interactive guide for untrained people in performing an ECG test},
journal={Biomedical Engineering Online},
volume={13},
note={Copyright - © 2014 Bifulco et al.; licensee BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly credited. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated; Last updated - 2023-12-13},
abstract={Doc number: 153 Abstract Background: In many telemedicine applications, the correct use of medical device at the point of need is essential to provide an appropriate service. Some applications may require untrained people to interact with medical devices and patients: care delivery in transportation, military actions, home care and telemedicine training. Appropriate operation of medical device and correct connection with patient's body are crucial. In these scenarios, tailored applications of Augmented Reality can offer a valid support by guiding untrained people at the point of need. This study aims to explore the feasibility of using Augmented Reality in telemedicine applications, by facilitating an acceptable use of biomedical equipment by any unskilled person. In particular, a prototype system was built in order to estimate how untrained users, with limited or no knowledge, can effectively interact with an ECG device and properly placing ECG electrodes on patient's chest. Methods: An Augmented Reality application was built to support untrained users in performing an ECG test. Simple markers attached to the ECG device and onto patient's thorax allow camera calibration. Once objects and their pose in the space are recognized, the video of the current scene is enriched, in real-time, with additional pointers, text boxes and audio that help the untrained operator to perform the appropriate sequence of operations. All the buttons, switches, ports of the ECG device together with the location of precordial leads were coded and indicated. Some user's voice commands were also included to improve usability. Results: Ten untrained volunteers, supported by the augmented reality, were able to carry out a complete ECG test first on a mannequin and then on a real patient in a reasonable time (about 8 minutes on average). Average positioning errors of precordial electrodes resulted less than 3 mm for the mannequin and less than 7 mm for the real patient. These preliminary findings suggest the effectiveness of the developed application and the validity of clinical ECG recordings. Conclusion: This application can be adapted to support the use of other medical equipment as well as other telemedicine tasks and it could be performed with a Tablet or a Smartphone.},
keywords={Biology--Bioengineering; Human-computer interaction; Telehealth; Electrocardiography; Augmented reality; Telemedicine},
language={English},
url={https://www.proquest.com/scholarly-journals/telemedicine-supported-augmented-reality/docview/1636582634/se-2},
}

@article{
author={Davis,B. C. and Lane,D. M.},
year={2010/09/01/},
month={2010 Sep 01},
title={Guided construction of testing scenarios for autonomous underwater vehicles using the augmented-reality framework and JavaBeans},
journal={Proceedings of the Institution of Mechanical Engineers},
volume={224},
number={3},
pages={173-191},
note={Copyright - © 2010 Institution of Mechanical Engineers; Last updated - 2023-12-03},
abstract={System evaluation and testing of unmanned underwater vehicles in their destined environment can be tedious, error prone, time consuming, and consequently expensive. However, pre-real-world testing facilities, such as hardware-in-the-loop (HIL) testing, are not always available. This is due to the time and expense required to create a specific test environment for the vehicle. Thus the system is not as fault tolerant as it could be since problems can remain undetected until the real-world testing phase. Debugging and fixing errors in the real-world testing phase are much more time consuming and expensive owing to the nature of the harsh underwater environment. This paper introduces a novel framework, the augmented-reality framework (ARF), for the rapid construction of virtual-environment testing scenarios for testing remote platforms with embedded systems such as autonomous underwater vehicles. The ARF provides testing facilities across all stages of the reality continuum, providing capabilities for pure simulation, HIL, hybrid simulation, and real-world testing. The framework architecture is both very generic and flexible and allows mixing of real and simulated components. The ARF is supported by a distributed communications protocol which provides location transparency of systems since this is key to providing mixed-reality testing facilities.},
keywords={Engineering; augmented reality; Hardware-in-the-loop simulation; Underwater environment; Underwater vehicle; hardware-in-the-loop; unmanned underwater vehicle; autonomous underwater vehicle; hybrid simulation; Autonomous underwater vehicles; Embedded systems; Military technology; Underwater vehicles; Underwater equipment; Testing; Errors; Unmanned underwater vehicles; Q2 09302:Underwater Vehicles; O 7020:Ships and Shipbuilding},
isbn={14750902},
language={English},
url={https://www.proquest.com/scholarly-journals/guided-construction-testing-scenarios-autonomous/docview/1885384687/se-2},
}

@article{
author={Davis,B. C. and Lane,D. M.},
year={2010},
month={2010},
title={Guided construction of testing scenarios for autonomous underwater vehicles using the augmented-reality framework and JavaBeans},
journal={Proceedings of the Institution of Mechanical Engineers},
volume={224},
pages={173-191},
note={Copyright - Copyright Professional Engineering Publishing Ltd 2010; Document feature - ; Photographs; Graphs; Diagrams; Last updated - 2023-12-03},
abstract={System evaluation and testing of unmanned underwater vehicles in their destined environment can be tedious, error prone, time consuming, and consequently expensive. However, pre-real-world testing facilities, such as hardware-in-the-loop (HIL) testing, are not always available. This is due to the time and expense required to create a specific test environment for the vehicle. Thus the system is not as fault tolerant as it could be since problems can remain undetected until the real-world testing phase. Debugging and fixing errors in the real-world testing phase are much more time consuming and expensive owing to the nature of the harsh underwater environment. This paper introduces a novel framework, the augmented-reality framework (ARF), for the rapid construction of virtual-environment testing scenarios for testing remote platforms with embedded systems such as autonomous underwater vehicles. The ARF provides testing facilities across all stages of the reality continuum, providing capabilities for pure simulation, HIL, hybrid simulation, and real-world testing. The framework architecture is both very generic and flexible and allows mixing of real and simulated components. The ARF is supported by a distributed communications protocol which provides location transparency of systems since this is key to providing mixed-reality testing facilities. PUBLICATION ABSTRACT]},
keywords={Engineering; Underwater environment; Augmented reality; Underwater vehicle; Autonomous underwater vehicles; Simulation; Testing},
isbn={14750902},
language={English},
url={https://www.proquest.com/scholarly-journals/guided-construction-testing-scenarios-autonomous/docview/863458658/se-2},
}

@article{
author={Grantcharov,Teodor P. and Bardram,Linda and Funch-Jensen,Peter and Rosenberg,Jacob},
year={2003/02//},
month={Feb 2003},
title={Learning curves and impact of previous operative experience on performance on a virtual reality simulator to test laparoscopic surgical skills: [1]},
journal={The American Journal of Surgery},
volume={185},
number={2},
pages={146},
note={Copyright - Copyright Elsevier Limited Feb 2003; Last updated - 2023-09-01},
abstract={Background The study was carried out to analyze the learning rate for laparoscopic skills on a virtual reality training system and to establish whether the simulator was able to differentiate between surgeons with different laparoscopic experience. Methods Forty-one surgeons were divided into three groups according to their experience in laparoscopic surgery: masters (group 1, performed more than 100 cholecystectomies), intermediates (group 2, between 15 and 80 cholecystectomies), and beginners (group 3, fewer than 10 cholecystectomies) were included in the study. The participants were tested on the Minimally Invasive Surgical Trainer-Virtual Reality (MIST-VR) 10 consecutive times within a 1-month period. Assessment of laparoscopic skills included time, errors, and economy of hand movement, measured by the simulator. Results The learning curves regarding time reached plateau after the second repetition for group 1, the fifth repetition for group 2, and the seventh repetition for group 3 (Friedman's testsP0.2) indicating the absence of a learning curve for these parameters. Group 2 error scores reached plateau after the first repetition, and group 3 after the fifth repetition. Group 2 improved their economy of movement score up to the third repetition and group 3 up to the sixth repetition (Friedman's tests,P<0.05). Experienced surgeons (group 1) demonstrated best performance parameters, followed by group 2 and group 3 (Mann-Whitney testP<0.05). Conclusions Different learning curves existed for surgeons with different laparoscopic background. The familiarization rate on the simulator was proportional to the operative experience of the surgeons. Experienced surgeons demonstrated best laparoscopic performance on the simulator, followed by those with intermediate experience and the beginners. These differences indicate that the scoring system of MIST-VR is sensitive and specific to measuring skills relevant for laparoscopic surgery.},
keywords={Medical Sciences--Surgery; Surgery; Validation studies; Teaching hospitals; Validity; Training},
isbn={00029610},
language={English},
url={https://www.proquest.com/scholarly-journals/learning-curves-impact-previous-operative/docview/1444585855/se-2},
}